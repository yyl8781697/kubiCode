
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Federated Search Papers学习笔记 | Kubi Code&#39;Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Kubi Code">
    

    
    <meta name="description" content="Federated Search 介绍1
Federated search is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia

上图就是一个Federated Search的栗子，在搜索了lyon关键">
<meta property="og:type" content="article">
<meta property="og:title" content="Federated Search Papers学习笔记">
<meta property="og:url" content="http://kubicode.me/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/index.html">
<meta property="og:site_name" content="Kubi Code'Blog">
<meta property="og:description" content="Federated Search 介绍1
Federated search is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia

上图就是一个Federated Search的栗子，在搜索了lyon关键">
<meta property="og:image" content="/img/The-Recorder-for-some-Federated-Search-Papers/example.png">
<meta property="og:image" content="/img/The-Recorder-for-some-Federated-Search-Papers/architecture.png">
<meta property="og:image" content="/img/The-Recorder-for-some-Federated-Search-Papers/lambdamerge.png">
<meta property="og:image" content="/img/The-Recorder-for-some-Federated-Search-Papers/linkedin1.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Search Papers学习笔记">
<meta name="twitter:description" content="Federated Search 介绍1
Federated search is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia

上图就是一个Federated Search的栗子，在搜索了lyon关键">

    
    <link rel="alternative" href="/atom.xml" title="Kubi Code&#39;Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/simpson.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?439f8b724bc712e367d66b5e348997bd";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
      </script>

</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/bart-simpson-09.png" alt="Kubi Code&#39;Blog" title="Kubi Code&#39;Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Kubi Code&#39;Blog">Kubi Code&#39;Blog</a></h1>
				<h2 class="blog-motto">The palest ink is better than the best memory.</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/books">Books</a></li>
					
						<li><a href="/favorites">Favorites</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//bing.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:kubicode.me">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/" title="Federated Search Papers学习笔记" itemprop="url">Federated Search Papers学习笔记</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Kubi Code" target="_blank" itemprop="author">Kubi Code</a>
		
  <p class="article-time">
    <time datetime="2017-01-09T01:58:31.000Z" itemprop="datePublished"> 发表于 2017-01-09</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Federated_Search_介绍1"><span class="toc-number">1.</span> <span class="toc-text">Federated Search 介绍1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS&MR]CORI2"><span class="toc-number">2.</span> <span class="toc-text">[RS&MR]CORI2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Semisupervised_Learning(SSL)3"><span class="toc-number">3.</span> <span class="toc-text">[MR]Semisupervised Learning(SSL)3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]REDDE4"><span class="toc-number">4.</span> <span class="toc-text">[RS]REDDE4</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sample-Resample"><span class="toc-number">4.1.</span> <span class="toc-text">Sample-Resample</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Resource_Selection"><span class="toc-number">4.2.</span> <span class="toc-text">Resource Selection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]Adaptation_of_Offline_Vertical_Selection5"><span class="toc-number">5.</span> <span class="toc-text">[RS]Adaptation of Offline Vertical Selection5</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Multiple_Beta_Prior"><span class="toc-number">5.1.</span> <span class="toc-text">Multiple Beta Prior</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Logistic_Normal_Prior"><span class="toc-number">5.2.</span> <span class="toc-text">Logistic Normal Prior</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Similar_Queries"><span class="toc-number">5.3.</span> <span class="toc-text">Similar Queries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Randomizing_Decisions"><span class="toc-number">5.4.</span> <span class="toc-text">Randomizing Decisions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]Vertical_Selection_Evidence6"><span class="toc-number">6.</span> <span class="toc-text">[RS]Vertical Selection Evidence6</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Query_String"><span class="toc-number">6.1.</span> <span class="toc-text">1.Query String</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Rule-based_vertical_triggers(基于规则的触发)"><span class="toc-number">6.1.1.</span> <span class="toc-text">Rule-based vertical triggers(基于规则的触发)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Geographic_features(地理特征)"><span class="toc-number">6.1.2.</span> <span class="toc-text">Geographic features(地理特征)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-_Query-Log_Features"><span class="toc-number">6.2.</span> <span class="toc-text">2. Query-Log Features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Corpus_Features"><span class="toc-number">6.3.</span> <span class="toc-text">3.Corpus Features</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#垂直资源采样"><span class="toc-number">6.3.1.</span> <span class="toc-text">垂直资源采样</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#基于语料的特征"><span class="toc-number">6.3.2.</span> <span class="toc-text">基于语料的特征</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]_Aggregate_Vertical_Results7"><span class="toc-number">7.</span> <span class="toc-text">[MR] Aggregate Vertical Results7</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BLOCK-RANKING_APPROACHES"><span class="toc-number">7.1.</span> <span class="toc-text">BLOCK-RANKING APPROACHES</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Merging_Multiple_Result_Lists8"><span class="toc-number">8.</span> <span class="toc-text">[MR]Merging Multiple Result Lists8</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Federated_Search_at_LinkedIn9"><span class="toc-number">9.</span> <span class="toc-text">[MR]Federated Search at LinkedIn9</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]2013-TREC10"><span class="toc-number">10.</span> <span class="toc-text">[RS]2013-TREC10</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#resource_selection-Krisztian_Balog"><span class="toc-number">10.1.</span> <span class="toc-text">resource selection-Krisztian Balog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#resource_selection-Emanuele_Di_Buccio"><span class="toc-number">10.2.</span> <span class="toc-text">resource selection-Emanuele Di Buccio</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]2014-TREC-Federated_Search11"><span class="toc-number">11.</span> <span class="toc-text">[RS]2014-TREC-Federated Search11</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-resource_selection_-_Qiuyue_Wang"><span class="toc-number">11.1.</span> <span class="toc-text">1.resource selection - Qiuyue Wang</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">12.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考文献"><span class="toc-number">13.</span> <span class="toc-text">参考文献</span></a></li></ol>
		
		</div>
		
		<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px"></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br><a id="more"></a><br>下面就是<code>Federated Search</code>的链路架构<br><center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/architecture.png" width="500px" height="500px"></center>

<p>其<code>Federated Search</code>可以分解为两个任务:</p>
<ol>
<li><code>Resource Selection</code>:也叫<code>Vertical Selection</code>，就是选择不同的<code>Vertical Resource</code>去进行排序</li>
<li><code>Merge Result</code>:也有叫<code>Aggegate Content</code>，在拿到不同<code>Vertical</code>之后进行合并排序</li>
</ol>
<p>其中<code>Resource Selection</code>的难点有:</p>
<ol>
<li>待选择的<code>Vertical</code>可能是黑盒（比如第三方的引擎），没有里面细致的数据（这个点已经就很难了）</li>
<li>待选择的<code>Vertical</code>一般都是异构的</li>
</ol>
<p>另外<code>Merge Result</code>的难点有:</p>
<ol>
<li>各种<code>Vertical</code>出来都是异构的，也就是里面的特征会不一致</li>
<li>就算特征一直，同特征的分布范围还不一致，所以无法用单一的模型去解决这个事情</li>
</ol>
<h2 id="[RS&amp;MR]CORI2">[RS&amp;MR]CORI<sup>2</sup></h2><blockquote>
<p><code>CORI</code>该算法包含了<code>Resource Selection</code>和<code>Merge Result</code></p>
</blockquote>
<p>在给定$Q$、观察到资源类别$C_i$,每个资源根据$P(Q|C_i)$来进行排序</p>
<p>$$T=\frac{df}{df+50+150*cw/avg\_{cw}} \\<br>I=\frac{log(|DB|+0.5)/cf}{log(|DB|+1.0)} \\<br>p(r_k|C_i)=b+(1-b)*T*I<br>$$</p>
<p>其中:</p>
<ul>
<li>$r_k$为$Q$中的第$k$个term</li>
<li>$df$为资源$C_i$中包含$r_k$的文档数量</li>
<li>$cf$为包含$r_k$的资源数量</li>
<li>$|DB|$为需要排序的资源数量</li>
<li>$cw$为在资源$C_i$中出现$r_k$的频次</li>
<li>$avg\_cw$某个$C_i$的平均$cw$</li>
<li>$b$默认值 一般为0.4</li>
</ul>
<p>在合并的时候可以使用类似这种方式进行<code>resultmerge</code>:<br>$$C_i^{*} = \frac{(C_i-C_{min})}{(C_{max}-C_{min})} \\<br>D_i^{*} = \frac{(D_i-D_{min})}{(D_{max}-D_{min})}$$<br>最终归一化的score为(其实这儿就是做了一个映射):<br>$$D^{**} = \frac{D^{*} + 0.4*D^{*}*C_i^{*}}{1.4}$$</p>
<h2 id="[MR]Semisupervised_Learning(SSL)3">[MR]Semisupervised Learning(SSL)<sup>3</sup></h2><blockquote>
<p>这个算法主要用于<code>Merge Result</code>阶段</p>
</blockquote>
<p>用户在输入query时，希望会将该query分发到各个需要排序的引擎(database-specific)上面,此时同时会将query分发到一个中心的涵盖所有的资源的单独引擎上面(database-independent)</p>
<p>这个时候会出两个score:</p>
<ol>
<li><code>database-specific-scorer</code>:不同资源引擎排序的score，不同资源之间的维度不一样</li>
<li><code>database-independent -scroer</code>：中心独立引擎上面，不同资源建所计算的score在同一个维度(估计这里只能用一个common的特征的排序)</li>
</ol>
<p>同时会有讲个假设:</p>
<ol>
<li>同一个query出现在<code>database-specific</code>上面的大部分也会出现在<code>database-independent</code>中</li>
<li><code>database-specific</code>与<code>database-independent</code>两者的overlap的doc拿到的score对使用机器学习方式可计算出一个映射</li>
</ol>
<p>此时假设对于overlap的doc有如下score的pair对$s_{ind},s_{spe}$<br>需要做的就是使用线性回归的方式对两个score简建立一个映射<br>$$s_{ind} = w*s_{spe}+b$$<br>其需要优化的是:</p>
<p>$$argmin_w \sum_i (f(w,s_{spe})-s_{ind})^2$$</p>
<p>这样在各个混排引擎出来的时候就使用归一到同一纬度的score了，并且线性函数的运算很快<br>当然在训练数据不足的时候可以退化为<code>CORI</code></p>
<p>但是他也有其他的缺点：</p>
<ol>
<li>需要额外维护一个中心引擎</li>
<li>中心引擎出的score是同一纬度的算分，也是各个混排引擎的训练目标，但是如果他算分计算不准确，这个训练的结果将会很尴尬</li>
</ol>
<h2 id="[RS]REDDE4">[RS]REDDE<sup>4</sup></h2><blockquote>
<p>主要是做<code>Resource Selection</code>，但是预先先做了<code>Resource Sampling</code></p>
</blockquote>
<h3 id="Sample-Resample">Sample-Resample</h3><p>首先需要使用<code>sample-resample</code>对未知的垂直资源进行一个数据量大小的估计:</p>
<ol>
<li>先从已采样的垂直资源中随机选几个query-term</li>
<li>然后使用<code>query-term</code>再去请求垂直资源拿到返回的请求数以及<code>top rank</code>的部分doc</li>
</ol>
<p>其中</p>
<ul>
<li>$C_j$表示某个垂直资源/数据库</li>
<li>$\tilde{C}_j$表示该垂直资源的采样数据集</li>
<li>$N_{C_j}$表示垂直资源里面的数据大小(条数)[未知]</li>
<li>$N_{\tilde{C}_j}$表示采样垂直资源里面的数据大小条数</li>
<li>$q_i$表示垂直资源中被选择出来的某个<code>query term</code></li>
<li>$df_{q_iC_j}$表示垂直资源$C_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>$df_{q_i\tilde{C}_j}$表示采样垂直资源$\tilde{C}_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>事件$A$表示从垂直资源中采样的某个文档包含$q_i$</li>
<li>事件$B$表示垂直资源中某个文档包含$q_i$</li>
</ul>
<p>则有:<br>$$P(A) = \frac{df_{q_i\tilde{C}_j}}{N_{\tilde{C}_j}} \\<br>P(B) = \frac{df_{q_iC_j}}{N_{C_j}}$$<br>假设采样可以很好的表示整个数据库/垂直资源，因此有$P(A) \approx  P(B)$,则近似的有：<br>$$\hat{N}_{C_j} =  \frac{N_{\tilde{C}_j} *df_{q_iC_j} }{df_{q_i\tilde{C}_j}}$$</p>
<p>最终是使用全部估计的均值来表示的</p>
<h3 id="Resource_Selection">Resource Selection</h3><p>在给定查询词$q$下对于$C_j$的相关性估计为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in C_j}P(rel|d_i) * P(d_i|C_j) * N_{C_j}$$</p>
<p>其中:</p>
<ul>
<li>$N_{C_j}$为资源$C_j$的总文档量，我们使用$\hat{N}_{C_j}$来近似</li>
<li>$P(d_i|C_j)$这个概率将会是$\frac{1}{N_{C_j}}$</li>
</ul>
<p>相应的，相关性的估计将可以被写为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in \tilde{C}_j} P(rel|d_i) \frac{1}{\tilde{N}_{C_j}}  * \hat{N}_{C_j}$$</p>
<p>这样唯一剩下未知就是文档$d_i$与$q$的相关性了$P(rel|d_i)$<br>该paper并没有直接对其相关性做深入的研究，假如目前有一个中心数据库包含了所有的垂直资源，对其中心数据库来检索，则其相关性可以为:<br>$$P(rel|d_i)=\left\{<br>\begin{aligned}<br>C_q &amp; \quad if Rank\_central(d_i) &lt; ratio * \hat{N}_{all} \\<br>0 &amp; \quad \text{otherwise} \\<br>\end{aligned}<br>\right.$$</p>
<p>其中:</p>
<ul>
<li>$Rank\_central(d_i) $为中心数据库中对于$d_i$的排序</li>
<li>$ratio$为一个阈值，指示关注top多少的一个阈值(0.002~0.005表示合适)</li>
<li>$\hat{N}_{all}$为中心数据中所有文档量的一个估计值</li>
<li>$C_q$是一个独立于$q$的常量</li>
</ul>
<p>这种完备的中心数据库其实建立起来不大可行，但是我们可以使用采样的中心数据库.<br>现在向采样的中心进行query检索，可以根据其返回结果来推断出实际中心数据库中各个文档的排序的位置:<br>$$Rank\_central(d_i) = \sum_{d_j | Rank\_S(d_j) &lt; Rank\_S(d_i)} \frac{\hat{N}_{c(d_j)}}{\tilde{N}_{c(d_j)}}$$</p>
<p>这样最终$\hat{Rel}_q(j) $就可以计算出来了，最终在资源选择分布时可以按比例来:<br>$$\hat{Rank\_Rel}_q(j) = \frac{\hat{Rel}_q(j)}{\sum_i \hat{Rel}_q(i)}$$</p>
<h2 id="[RS]Adaptation_of_Offline_Vertical_Selection5">[RS]Adaptation of Offline Vertical Selection<sup>5</sup></h2><p>原本最常用的垂直资源选择是使用<code>one_vs_all</code>的分类分类方法，其中$k$个垂直资源，这样就需要分$k+1$个类别，训练完预测的时候选择类别概率高的来进行展现</p>
<p>而这篇paper主要是在输入类别概率之后还将用户反馈加入了进来再计算:</p>
<h3 id="Multiple_Beta_Prior">Multiple Beta Prior</h3><p>$p_q^v$可以用来表示某个Query下对于某个垂直资源类别v的相关概率，并且它是呈现<code>beta</code>分布的:<br>$$p_q^v \text{~} Beta(a_q^v,b_q^v)$$</p>
<p>其中$\pi_q^v$为离线模型概率，$\mu$为控制因子<br>$$a_q^v=\mu \pi_q^v \quad \quad b_q^v=\mu (1-\pi_q^v)$$</p>
<p>最后我们可以将相关性的后验写为<br>$$\tilde{p}_q^v = \frac{R_q^v + \mu \pi_q^v}{V_q^v + \mu}$$</p>
<blockquote>
<p>$R_q^v$为$q$下展现$v$同时被点击的数量,$\bar{R}_q^v$表示展现了  但是未被点击的数量,$V_q^v$则表示一共展现的数量</p>
</blockquote>
<h3 id="Logistic_Normal_Prior">Logistic Normal Prior</h3><p>其先验为<br>$$p_q^v = \frac{exp(W_{tv})}{exp(W_{tv}) + exp(\bar{W}_{tv})}$$</p>
<blockquote>
<p>$W$和$\bar{W}$是$t \times k$的随机矩阵，并且服从$W,\bar{W} ~ N_{2tk}(\eta,\sum)$,$\sum$为一个协方差矩阵</p>
</blockquote>
<p>则其后验可以转为:<br>$$\tilde{p}_q^v = \frac{\pi_q^v exp(a_q^v)}{\pi_q^v exp(a_q^v) + (1-\pi_q^v) exp(b_q^v)}$$</p>
<p>最终关于$a_q^v,b_q^v$都是可以被计算出来的:<br>$$a_q^v = R_q^v+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} \bar{R}_q^{v’}$$<br>$$b_q^v =  \bar{R}_q^{v’}+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} R_q^v $$<br>其中:</p>
<ol>
<li>$R_q^v$表示$q$与$v$相关的对数</li>
<li>$V_q^v$表示$q$与$v$共现的总次数</li>
</ol>
<h3 id="Similar_Queries">Similar Queries</h3><p>假设某个query1下知道他对于不同垂直资源的偏好，此时有一个query2与query1很相似，那么他关于垂直类目的偏好也会很相似<br>这个也是利用beta分布来估计的，算的是这个Bhattacharyya相似性，感兴趣自己去看paper</p>
<h3 id="Randomizing_Decisions">Randomizing Decisions</h3><p>对于偏好概率很低的垂直资源也会有某个概率$\varepsilon $进行选择它，加了这个概率波动的之后，最后在选择垂直资源是这么计算的，其相关性为：$$P(v)=\frac{1}{Z} exp(\frac{\tilde{p}_q^v}{\tau})$$<br>它是符合<code>Boltzmann</code>分布,其中:</p>
<ol>
<li>$\tilde{p}_q^v$为后验概率</li>
<li>$Z=\sum_vexp(\frac{\tilde{p}_q^v}{\tau})$</li>
<li>$\tau$是一个大于0的值，如果$\tau$趋向于正无穷，那么$P(v)$将会更加随机化，如果$\tau$接近于0，$P(v)$的选择将会更加贪婪（也就是哪个大选哪个）</li>
</ol>
<h2 id="[RS]Vertical_Selection_Evidence6">[RS]Vertical Selection Evidence<sup>6</sup></h2><p>使用分类的方法来进行资源类别选择，里面讲的主要是各种特征</p>
<p>评估指标为:<br>$$P=\frac{1}{|Q|} \left( \sum_{q \in Q | V_q \neq \varnothing } I(\tilde{v}_q \in V_q) + \sum_{q \in Q | V_q = \varnothing } I(\tilde{v}_q = \varnothing)   \right)$$</p>
<p>其中:</p>
<ol>
<li>$V$表示所有垂直资源的集合</li>
<li>$Q$表示所有Query的集合</li>
<li>$V_q$为与某个$q$相关的垂直资源集合</li>
<li>$\tilde{v}_q$表示对于$q$预测的与其相关的一个垂直资源</li>
<li>$I(\cdot)$表示示性函数，应该就是${0,1}$的二值函数吧</li>
</ol>
<p>下面是三大类特征<code>Query String</code>、<code>Query Logs</code>、<code>vertical corpora</code>:</p>
<h3 id="1-Query_String">1.Query String</h3><blockquote>
<p>该特征是为了利用Query中的一些关键短语与垂直资源的内容进行一些匹配</p>
</blockquote>
<h4 id="Rule-based_vertical_triggers(基于规则的触发)">Rule-based vertical triggers(基于规则的触发)</h4><p>文章中一共建立了45类别的属性来刻画query的垂直意图（其实就像类目，比如,local<br>phone, product, person, weather, movies, driving direction,<br>music artist）<br>同时这45类触发将会有三种规则：</p>
<ol>
<li><code>一对一触发</code>:<code>movies → movies, autos→ autos</code></li>
<li><code>一对多触发</code>:<code>{sports players,sports} → sports, {product review, product} → shopping</code></li>
<li><code>不显示对应</code>：但是会提供一些<code>positive或者negative</code>的标志用于分类器,比如, <code>patent, events, weather</code></li>
</ol>
<p>里面的触发类别都是用过正则表达来提出取来，另外一个query可能关联到多个类别，一个触发器至少会匹配到一个query</p>
<h4 id="Geographic_features(地理特征)">Geographic features(地理特征)</h4><p>在输入query下提取地理特征，并且会形成一个指定维护的概率向量:<code>airport,colloquial,continent,town,</code>等，将会与垂直资源中常常提到的这些地理词进行匹配</p>
<h3 id="2-_Query-Log_Features">2. Query-Log Features</h3><p>使用<code>Query-log</code>建立一个一元的语言模型<br>$$QL_q(V_i) = \frac{1}{Z}P(q|\theta_{v_i}^{qlog})$$<br>其中$\theta_{v_i}^{qlog}$为垂直资源$V_i$的语言模型，另外<br>$$Z=\sum_{v_j \in V}P(q|\theta_{v_j}^{qlog})$$</p>
<h3 id="3-Corpus_Features">3.Corpus Features</h3><blockquote>
<p>垂直资源的语料特征</p>
</blockquote>
<h4 id="垂直资源采样">垂直资源采样</h4><blockquote>
<p>应该是这儿的垂直资源可能是分布到各种不同的引擎里面的（第三方），作者并无法取到全部的离线数据，所以在进行语料相关特征计算的时候需要拿到具有代表性的资源文档数据</p>
</blockquote>
<p>在采样的时候使用垂直资源的top-query取访问垂直引擎，拿到文档再去统计，另一次关于垂直资源的语料去Wikipedia获取也是一种相当好的方式，因为里面都做好了结构化</p>
<h4 id="基于语料的特征">基于语料的特征</h4><p>1). <strong>Retrieval Effectiveness Features</strong></p>
<p>$$Clarity_q(C) = \sum_{w \in V} P(w|\theta_q) \text{log} \frac{P(w|\theta_q)}{P(w|\theta_C)}$$</p>
<p>其中:</p>
<ul>
<li>$V$是垂直资源$C$的语料/word</li>
<li>$P(w|\theta_q)$和$P(w|\theta_C)$分别是query和垂直资源的语言模型<br>  $$P(w|\theta_q) = \frac{1}{Z} \sum_{d \in R_{100}} P(w|\theta_d) P(w|\theta_d)$$<br>  $P(q|\theta_d)$为文本$d$的query似然分数，另外$Z=\sum_{d \in R_{100}}P(q|\theta_d)$</li>
</ul>
<blockquote>
<p><code>Clarity</code>分数越小表示检索效果越差</p>
</blockquote>
<p>最终各个资源也是按比例分数来计算的<br>$$Clarity_q^*(V_i) = \frac{1}{Z^*} Clarity_q(S_i^*)$$</p>
<p>2). ReDDE Features.<br>该Feature其实就是Luo.si  2003paper里面的计算方式<br>$$ReDDE_q^*(V_i) = |V_i| \sum_{d \in R_{100}} I(d \in S_i^*) P(q|\theta_d) P(d|S_i^*)$$<br>其中<br>$$P(d|S_i^*) = \frac{1}{S_i^*}$$</p>
<p>3). Soft.ReDDE Features<br>使用Bhattacharyya correlation<br>$$B(d,V_i) = \sum_{w \in top query}\sqrt{P(w|\theta_d) P(w|\theta_{V_i})} $$<br>其中<br>$$\phi(d,V_i) = \frac{B(d,V_i)}{\sum_{V_j \in V}B(d,V_j)}$$<br>最终soft针对文档的$B$进行求和，同时使用$P(q|\theta_d)$来加权:<br>$$Soft.ReDDE_q(V_i) = \sum_{d \in R_{100}} \phi(d,V_i) \times P(q|\theta_d)$$</p>
<p><code>Soft.ReDDE</code>有两大好处：</p>
<ol>
<li>每个文档在他的资源类别排序中多多少少都有贡献</li>
<li>不需要手动做文档到资源类别的映射(这个不懂….)</li>
</ol>
<p>4). Categorical Features<br>最大熵求取多级类目特征</p>
<h2 id="[MR]_Aggregate_Vertical_Results7">[MR] Aggregate Vertical Results<sup>7</sup></h2><p><code>Aggregate Vertical Results</code>(就是最终多源搜索结果的合并)有两大难处：</p>
<ol>
<li>不同来源的特征不一致</li>
<li>就是特征一直，同一个特征的值的分布也是不一致的</li>
</ol>
<p>因此无法直接使用一个ML算法去学习他们的排序,需要一种算法去学习这种不一致的特征排序任务（好像是用了某些特征关系映射）<br>整个<code>Aggregate Result</code>有如下的假设:</p>
<ol>
<li>相同的垂直资源应该是被排到一起的</li>
<li>垂直资源只能被嵌入到指定的坑位</li>
<li>网页结果往往都是主排序</li>
<li>不同的垂直资源是需要有关联的（这个有点难吧）</li>
<li>我们假设用户不会去看那些不相关的垂直资源</li>
</ol>
<p>这儿做的叫做<code>block-rank</code>坑位排序，比如有坑位<code>1~3(w1)</code>、<code>4~6(w2)</code>、<code>7~10(w3)</code>等，其中任务是预测排序顺序$\sigma(q)$与$\sigma^*(q)$尽量相似，其相似度可以使用$\text{Kendall’s} \tau$ 来衡量。<br>另外为了防止某些不相关性的<code>block</code>也被展现，所以有一个叫做<code>end of search result</code>(eos)的模块，如果被预测到这个模块，将会被放置到最下面并且不会展现</p>
<p>先说一下ML所使用到的特征<code>Pre-retrieval Features</code>和<code>Post-retrieval Features</code></p>
<p>1) <strong>Pre-retrieval Features</strong></p>
<blockquote>
<p>在检索到垂直引擎之前的提取的特征</p>
</blockquote>
<ul>
<li><code>Named-Entity Type Features</code></li>
<li><code>Category Features.</code></li>
<li><code>Click-through Features</code></li>
<li><code>Vertical-Intent Features.</code>(这个意图识别还是较难较重)</li>
</ul>
<p>2) <strong>Post-retrieval Features</strong></p>
<blockquote>
<p>这个为在检索到垂直引擎之后提取的特征</p>
</blockquote>
<ul>
<li><code>Hit Count Features</code>:垂直引擎的召回量</li>
<li><code>Temporal Features</code>:时间性相关的特征（时效性）</li>
<li><code>Text-Similarity Features.</code></li>
</ul>
<h3 id="BLOCK-RANKING_APPROACHES">BLOCK-RANKING APPROACHES</h3><blockquote>
<p>下面是实际的排序方法了</p>
</blockquote>
<p>1) <strong>Classification Approach</strong><br>每个垂直资源都有一个自己的分类器(这是使用的LR这个二分类器)<br>这里每个坑位都有一个阈值(除上面<code>w1~3</code>之外，还有一个eos的<code>w4</code>)<br>预测的是这个概率:<br>$$P(\sigma_q(v) &lt; \sigma_q(eos))$$<br>也就是是否要被展现的概率，最终按这种方式进行填坑<br>$$P(\sigma_q(v) &lt; \sigma_q(eos)) &gt; \tau_y \forall x&lt;y $$<br>这样就可以填入<code>x</code>坑位了（$\tau_y$是<code>1~4</code>坑位的阈值）</p>
<p>2) <strong>Voting Approach</strong><br>这里也是使用独立的分类模型,但是他的分类对象是<br>$$P(\sigma_q(i)) &lt; P(\sigma_q(j))$$<br>也就是pair，预测垂直资源$i$是否排在$j$前面，同时由于不同资源特征的限制,不同的$i,j$比较都是需要单独训练一个模型，最终使用投票的方式来确定哪个排在前面</p>
<blockquote>
<p>这种方式将会训练大量模型，虽然paper中将某些<code>block</code>因素归一了，但是训练的模型量还是巨大的</p>
</blockquote>
<p>3) <strong>Learning to Rank Approaches</strong><br>使用<code>RankSvm</code>进行排序,但是会遇到不同类别的特征体系不一致的问题，通过下面三种方式解决</p>
<ol>
<li><code>Equally Correlated Features</code>:针对部分common特征可以合并起来</li>
<li><code>Uniquely Correlated Features.</code>:对类别相关的特征进行copy和平铺出来，比如不同类别下同一个相关性特征可能会写两遍，但是都是时间特征在某些类别下只需要写一遍</li>
<li><code>Equally and Uniquely Correlated Features.</code>:结合上面两种特征</li>
</ol>
<p>但是上面的操作可能会导致过拟合，所以需要比较多的训练样本</p>
<h2 id="[MR]Merging_Multiple_Result_Lists8">[MR]Merging Multiple Result Lists<sup>8</sup></h2><p>用<code>LambdaMerge</code>的方法，其中好多使用了DNN，其框架为:</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/lambdamerge.png" width="500px" height="500px"></center>


<p>其中</p>
<ul>
<li>$f(x_{i,j}^d;\theta)$为文档相关的算法，前面那层的DNN,$x_{i,j}^d$为文档特征</li>
<li>$g(z_i;\eta)$为不同搜索引擎相关的特征（比如google、bing等）,$g(z_i;\eta)$也搜索引擎相关的特征,也是用DNN过了一层</li>
<li>$h(y_j;\phi)$为不同资源相关的特征,$y_j$为特征，也用dnn过了一层</li>
</ul>
<p>最终使用<code>lambdarank</code>来解，感觉这种方法写paper可以，但是实际使用起来代价有点高的</p>
<h2 id="[MR]Federated_Search_at_LinkedIn9">[MR]Federated Search at LinkedIn<sup>9</sup></h2><blockquote>
<p>这篇文章讲了混排在LinkedIn的实践，虽然没有高深的算法，但是讲的实在</p>
</blockquote>
<p>在Linked中的，混排的对象有Job、People、Companies、post等，但是没有一个主要的排序对象（web search中一般网页都是主要排序对象）<br>下面是他们的混排框架</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/linkedin1.png" width="500px" height="500px"></center>


<ol>
<li>用户输入一个query</li>
<li>希望向各个垂直引擎进行请求</li>
<li>请求完了之后各自引擎算完相关性得到top result（用LR进行计算的）</li>
<li>根据top result中各个得分选出主要的资源P,其他的资源都称为C</li>
<li>里面会对P和C的混排分进行一个归一化(没有细讲)</li>
<li>然后以$P_i$为主，将其$C_i$与$P_i$比大小进行插入完成混排</li>
</ol>
<p>其中排序选取的特征有:</p>
<ol>
<li><code>Searcher Intent</code>:用户自身的意图（稳定的，一天跑一把）</li>
<li><code>Keyword Intent</code>:query的意图 实时概率预测</li>
<li><code>Base Ranking Features</code>：基础特征了</li>
</ol>
<p>整个算法简单粗暴，效果还可以，主要实现起来快，而且各个大引擎主要跑一次</p>
<h2 id="[RS]2013-TREC10">[RS]2013-TREC<sup>10</sup></h2><blockquote>
<p>2013年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="resource_selection-Krisztian_Balog">resource selection-Krisztian Balog</h3><p>使用语言模型进行估计:<br>两种方式，将一种资源统一看成一种文档:<br>$$P(q|c) = \prod_{t \in q}\left\{ (1-\lambda)\left(\sum_{d \in c}P(t|d)P(d|c)\right) + \lambda P(t)\right\}^{n(t,q)}$$</p>
<ul>
<li>$t$为$q$中出现的term</li>
<li>$n(t,q)$表示$q$中出现$t$次数</li>
<li>$P(t|d)$和$P(t)$为给定文档下面的最大似然估计</li>
<li>$\lambda$为平滑因子</li>
<li>$P(d|c) = \frac{1}{|c|}$看成均匀分布式</li>
</ul>
<p>另一种方式是看一种资源看成多个文档<br>$$P(q|c) = \sum_{d \in c} P(d|c) \prod_{t \in q} \left( (1-\lambda)P(t|d)+\lambda P(t) \right)^{n(t,q)}$$</p>
<p>最终将两个分数进行一个合并<br>$$P(q|c) = \beta P_{cc}(q|c) + (1-\beta)P_{dc}(q|c)$$</p>
<h3 id="resource_selection-Emanuele_Di_Buccio">resource selection-Emanuele Di Buccio</h3><p>使用两个因子:</p>
<ol>
<li>Inverse Resource Frequency (IRF)   类似逆文档频率<br>$$IRF_t^{(z)} = \text{log} \frac{N^{(z)}}{n_t^{(z)}}$$</li>
</ol>
<ul>
<li>$t$表示term</li>
<li>$N^{(z)}$表示在$z$级别包含$t$的量</li>
<li>$n_t^{(z)}$表示具体某个资源包含$t$的量</li>
</ul>
<blockquote>
<p>关于$z$有是有三个级别:: (1) document, (2) search engines and (3) the set of search engine</p>
</blockquote>
<ol>
<li>Term Weighted Frequency (TWF)<br>$$w_{i,t}^{(z)} = TWF_{i,t}^{(z)} \cdot IRF_t^{(z-1)} $$<br>同时<br>$$TWF_{i,t}^{(z)} = \sum_{r \in R_i^z} TWF_{i,t}^{(z-1)} \cdot IRF_t^{(z-1)}$$</li>
</ol>
<p>这儿是一个递归的方式</p>
<h2 id="[RS]2014-TREC-Federated_Search11">[RS]2014-TREC-Federated Search<sup>11</sup></h2><blockquote>
<p>2014年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="1-resource_selection_-_Qiuyue_Wang">1.resource selection - Qiuyue Wang</h3><p>使用LDA来进行Resource和query的分布<br>由于query很短，作者的处理是用query查询google api取得top 50的文档的摘要，用组成的摘要来训练LDA，最终使用KL距离来衡量相似性</p>
<h2 id="总结">总结</h2><p>看了一些<code>Federated Search</code>相关的<code>Paper</code>（当然还有两个综述也讲的很好[12],[13]），其中</p>
<ul>
<li><code>Resource Selection</code>主要从<code>统计学</code>、<code>相似度计算</code>、<code>概率生成模型</code>以及<code>分类模型来完成</code></li>
<li><code>Merge Result</code>有使用<code>多源归一化</code>，<code>回归模型</code>、<code>LTR模型</code>来完成，同时在算分最后大多使用<code>Slot Filling</code>的方法来做</li>
</ul>
<p><code>Resource Selection</code>目前的方法中好的<code>Resource</code>将会被更多的选择则，该阶段尝试加入<code>Bandit</code>相关策略也许会有比较好的效果,<br>另外<code>Resource Selection</code>和<code>Merge Result</code>目前在优化中其实并没有太大的联系，有没有可能有一种方法能将两个阶段联合起来进行全局优化?</p>
<h2 id="参考文献">参考文献</h2><ol>
<li>Arguello, Jaime, Fernando Diaz, and Milad Shokouhi. “Integrating and ranking aggregated content on the web.” Proc. WWW 2012 (2012).</li>
<li>Callan, James P., Zhihong Lu, and W. Bruce Croft. “Searching distributed collections with inference networks.” Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1995.</li>
<li>Sushmita, Shanu, et al. “Factors affecting click-through behavior in aggregated search interfaces.” Proceedings of the 19th ACM international conference on Information and knowledge management. ACM, 2010.</li>
<li>Si, Luo, and Jamie Callan. “Relevant document distribution estimation method for resource selection.” Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 2003.</li>
<li>Diaz, Fernando, and Jaime Arguello. “Adaptation of offline vertical selection predictions in the presence of user feedback.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, et al. “Sources of evidence for vertical selection.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, Fernando Diaz, and Jamie Callan. “Learning to aggregate vertical results into web search results.” Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 2011.</li>
<li>Lee, Chia-Jung, et al. “An Optimization Framework for Merging Multiple Result Lists.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015</li>
<li>Arya, Dhruv, Viet Ha-Thuc, and Shakti Sinha. “Personalized Federated Search at LinkedIn.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.</li>
<li><a href="http://trec.nist.gov/pubs/trec22/trec2013.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec22/trec2013.html</a></li>
<li><a href="http://trec.nist.gov/pubs/trec23/trec2014.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec23/trec2014.html</a></li>
<li>Shokouhi, Milad, and Luo Si. “Federated search.” Foundations and Trends in Information Retrieval 5.1 (2011): 1-102.</li>
<li>Kopliku, Arlind, Karen Pinel-Sauvagnat, and Mohand Boughanem. “Aggregated search: A new information retrieval paradigm.” ACM Computing Surveys (CSUR) 46.3 (2014): 41.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Search-Engine/">Search Engine</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Search-Engine/">Search Engine</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://kubicode.me/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/" data-title="Federated Search Papers学习笔记 | Kubi Code&#39;Blog" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2017/04/21/Deep Learning/Study-With-Deep-Structured-Semantic-Model/" title="学习记录一下深度语义匹配模型-DSSM">
  <strong>上一篇：</strong><br/>
  <span>
  学习记录一下深度语义匹配模型-DSSM</span>
</a>
</div>


<div class="next">
<a href="/2016/12/12/Machine Learning/Maximum-Entropy-Model/"  title="最大熵模型">
 <strong>下一篇：</strong><br/> 
 <span>最大熵模型
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Federated_Search_介绍1"><span class="toc-number">1.</span> <span class="toc-text">Federated Search 介绍1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS&MR]CORI2"><span class="toc-number">2.</span> <span class="toc-text">[RS&MR]CORI2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Semisupervised_Learning(SSL)3"><span class="toc-number">3.</span> <span class="toc-text">[MR]Semisupervised Learning(SSL)3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]REDDE4"><span class="toc-number">4.</span> <span class="toc-text">[RS]REDDE4</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sample-Resample"><span class="toc-number">4.1.</span> <span class="toc-text">Sample-Resample</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Resource_Selection"><span class="toc-number">4.2.</span> <span class="toc-text">Resource Selection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]Adaptation_of_Offline_Vertical_Selection5"><span class="toc-number">5.</span> <span class="toc-text">[RS]Adaptation of Offline Vertical Selection5</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Multiple_Beta_Prior"><span class="toc-number">5.1.</span> <span class="toc-text">Multiple Beta Prior</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Logistic_Normal_Prior"><span class="toc-number">5.2.</span> <span class="toc-text">Logistic Normal Prior</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Similar_Queries"><span class="toc-number">5.3.</span> <span class="toc-text">Similar Queries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Randomizing_Decisions"><span class="toc-number">5.4.</span> <span class="toc-text">Randomizing Decisions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]Vertical_Selection_Evidence6"><span class="toc-number">6.</span> <span class="toc-text">[RS]Vertical Selection Evidence6</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Query_String"><span class="toc-number">6.1.</span> <span class="toc-text">1.Query String</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Rule-based_vertical_triggers(基于规则的触发)"><span class="toc-number">6.1.1.</span> <span class="toc-text">Rule-based vertical triggers(基于规则的触发)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Geographic_features(地理特征)"><span class="toc-number">6.1.2.</span> <span class="toc-text">Geographic features(地理特征)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-_Query-Log_Features"><span class="toc-number">6.2.</span> <span class="toc-text">2. Query-Log Features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Corpus_Features"><span class="toc-number">6.3.</span> <span class="toc-text">3.Corpus Features</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#垂直资源采样"><span class="toc-number">6.3.1.</span> <span class="toc-text">垂直资源采样</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#基于语料的特征"><span class="toc-number">6.3.2.</span> <span class="toc-text">基于语料的特征</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]_Aggregate_Vertical_Results7"><span class="toc-number">7.</span> <span class="toc-text">[MR] Aggregate Vertical Results7</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BLOCK-RANKING_APPROACHES"><span class="toc-number">7.1.</span> <span class="toc-text">BLOCK-RANKING APPROACHES</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Merging_Multiple_Result_Lists8"><span class="toc-number">8.</span> <span class="toc-text">[MR]Merging Multiple Result Lists8</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[MR]Federated_Search_at_LinkedIn9"><span class="toc-number">9.</span> <span class="toc-text">[MR]Federated Search at LinkedIn9</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]2013-TREC10"><span class="toc-number">10.</span> <span class="toc-text">[RS]2013-TREC10</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#resource_selection-Krisztian_Balog"><span class="toc-number">10.1.</span> <span class="toc-text">resource selection-Krisztian Balog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#resource_selection-Emanuele_Di_Buccio"><span class="toc-number">10.2.</span> <span class="toc-text">resource selection-Emanuele Di Buccio</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#[RS]2014-TREC-Federated_Search11"><span class="toc-number">11.</span> <span class="toc-text">[RS]2014-TREC-Federated Search11</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-resource_selection_-_Qiuyue_Wang"><span class="toc-number">11.1.</span> <span class="toc-text">1.resource selection - Qiuyue Wang</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">12.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考文献"><span class="toc-number">13.</span> <span class="toc-text">参考文献</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/Akka/" title="Akka">Akka<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Algorithm/" title="Algorithm">Algorithm<sup>34</sup></a></li>
		  
		
		  
			<li><a href="/categories/Data-Struct/" title="Data Struct">Data Struct<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Deep-Learning/" title="Deep Learning">Deep Learning<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Dotnet/" title="Dotnet">Dotnet<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/Effective-Java/" title="Effective Java">Effective Java<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/Food/" title="Food">Food<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hadoop/" title="Hadoop">Hadoop<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hexo/" title="Hexo">Hexo<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Java-Base/" title="Java Base">Java Base<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/Java-Source/" title="Java Source">Java Source<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/Javascript/" title="Javascript">Javascript<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/LeetCode/" title="LeetCode">LeetCode<sup>25</sup></a></li>
		  
		
		  
			<li><a href="/categories/Linux/" title="Linux">Linux<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Mac/" title="Mac">Mac<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Machine-Learning/" title="Machine Learning">Machine Learning<sup>27</sup></a></li>
		  
		
		  
			<li><a href="/categories/OSGi/" title="OSGi">OSGi<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/PHP/" title="PHP">PHP<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Python/" title="Python">Python<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Scala/" title="Scala">Scala<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Search-Engine/" title="Search Engine">Search Engine<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Spark/" title="Spark">Spark<sup>5</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Algorithm/" title="Algorithm">Algorithm<sup>37</sup></a></li>
			
		
			
				<li><a href="/tags/Machine-Learning/" title="Machine Learning">Machine Learning<sup>35</sup></a></li>
			
		
			
				<li><a href="/tags/LeetCode/" title="LeetCode">LeetCode<sup>25</sup></a></li>
			
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>21</sup></a></li>
			
		
			
				<li><a href="/tags/Search-Engine/" title="Search Engine">Search Engine<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/CSharp/" title="CSharp">CSharp<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/Food/" title="Food">Food<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Spark/" title="Spark">Spark<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Asp-Net/" title="Asp.Net">Asp.Net<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Scala/" title="Scala">Scala<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Deep-Learning/" title="Deep Learning">Deep Learning<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Vim/" title="Vim">Vim<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Data-Struct/" title="Data Struct">Data Struct<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/OSGi/" title="OSGi">OSGi<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/pager/" title="pager">pager<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Mac/" title="Mac">Mac<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://quanru.github.io/" target="_blank" title="quanru&#39;s Blog">quanru&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://qcl6355.github.io/" target="_blank" title="Sheng Li&#39;s Blog">Sheng Li&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://youngyoungkang.github.io/" target="_blank" title="Young Young Kang&#39;s Blog">Young Young Kang&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://nlpnoob.com/" target="_blank" title="DataKingdom&#39;s Blog">DataKingdom&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Kubi Code">Kubi Code</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'kubiCode';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX","output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['\$','\$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    displayAlign: "center"
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="/js/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>

