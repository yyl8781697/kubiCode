<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Kubi Code'Blog]]></title>
  <subtitle><![CDATA[The palest ink is better than the best memory.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://kubicode.me/"/>
  <updated>2017-01-11T02:05:46.000Z</updated>
  <id>http://kubicode.me/</id>
  
  <author>
    <name><![CDATA[Kubi Code]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Federated Search Papers学习笔记]]></title>
    <link href="http://kubicode.me/2017/01/09/Search%20Engine/The-Recorder-for-some-Federated-Search-Papers/"/>
    <id>http://kubicode.me/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/</id>
    <published>2017-01-09T01:58:31.000Z</published>
    <updated>2017-01-11T02:05:46.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px"></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br><a id="more"></a><br>下面就是<code>Federated Search</code>的链路架构<br><center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/architecture.png" width="500px" height="500px"></center>

<p>其<code>Federated Search</code>可以分解为两个任务:</p>
<ol>
<li><code>Resource Selection</code>:也叫<code>Vertical Selection</code>，就是选择不同的<code>Vertical Resource</code>去进行排序</li>
<li><code>Merge Result</code>:也有叫<code>Aggegate Content</code>，在拿到不同<code>Vertical</code>之后进行合并排序</li>
</ol>
<p>其中<code>Resource Selection</code>的难点有:</p>
<ol>
<li>待选择的<code>Vertical</code>可能是黑盒（比如第三方的引擎），没有里面细致的数据（这个点已经就很难了）</li>
<li>待选择的<code>Vertical</code>一般都是异构的</li>
</ol>
<p>另外<code>Merge Result</code>的难点有:</p>
<ol>
<li>各种<code>Vertical</code>出来都是异构的，也就是里面的特征会不一致</li>
<li>就算特征一直，同特征的分布范围还不一致，所以无法用单一的模型去解决这个事情</li>
</ol>
<h2 id="[RS&amp;MR]CORI2">[RS&amp;MR]CORI<sup>2</sup></h2><blockquote>
<p><code>CORI</code>该算法包含了<code>Resource Selection</code>和<code>Merge Result</code></p>
</blockquote>
<p>在给定$Q$、观察到资源类别$C_i$,每个资源根据$P(Q|C_i)$来进行排序</p>
<p>$$T=\frac{df}{df+50+150*cw/avg\_{cw}} \\<br>I=\frac{log(|DB|+0.5)/cf}{log(|DB|+1.0)} \\<br>p(r_k)=b+(1-b)*T*I<br>$$</p>
<p>其中:</p>
<ul>
<li>$r_k$为$Q$中的第$k$个term</li>
<li>$df$为资源$C_i$中包含$r_k$的文档数量</li>
<li>$cf$为包含$r_k$的资源数量</li>
<li>$|DB|$为需要排序的资源数量</li>
<li>$cw$为在资源$C_i$中出现$r_k$的频次</li>
<li>$avg\_cw$某个$C_i$的平均$cw$</li>
<li>$b$默认值 一般为0.4</li>
</ul>
<p>在合并的时候可以使用类似这种方式进行<code>resultmerge</code>:<br>$$C_i^{*} = \frac{(C_i-C_{min})}{(C_{max}-C_{min})} \\<br>D_i^{*} = \frac{(D_i-C_{min})}{(D_{max}-D_{min})}$$<br>最终归一化的score为(其实这儿就是做了一个映射):<br>$$D^{**} = \frac{D^{*} + 0.4*D^{*}*C_i^{*}}{1.4}$$</p>
<h2 id="[MR]Semisupervised_Learning(SSL)3">[MR]Semisupervised Learning(SSL)<sup>3</sup></h2><blockquote>
<p>这个算法主要用于<code>Merge Result</code>阶段</p>
</blockquote>
<p>用户在输入query时，希望会将该query分发到各个需要排序的引擎(database-specific)上面,此时同时会将query分发到一个中心的涵盖所有的资源的单独引擎上面(database-independent)</p>
<p>这个时候会出两个score:</p>
<ol>
<li><code>database-specific-scorer</code>:不同资源引擎排序的score，不同资源之间的维度不一样</li>
<li><code>database-independent -scroer</code>：中心独立引擎上面，不同资源建所计算的score在同一个维度(估计这里只能用一个common的特征的排序)</li>
</ol>
<p>同时会有讲个假设:</p>
<ol>
<li>同一个query出现在<code>database-specific</code>上面的大部分也会出现在<code>database-independent</code>中</li>
<li><code>database-specific</code>与<code>database-independent</code>两者的overlap的doc拿到的score对使用机器学习方式可计算出一个映射</li>
</ol>
<p>此时假设对于overlap的doc有如下score的pair对$s_{ind},s_{spe}$<br>需要做的就是使用线性回归的方式对两个score简建立一个映射<br>$$s_{spe} = w*s_{ind}+b$$<br>其需要优化的是:</p>
<p>$$argmax_w \sum_i (f(w,s_{spe})-s_{ind})^2$$</p>
<p>这样在各个混排引擎出来的时候就使用归一到同一纬度的score了，并且线性函数的运算很快<br>当然在训练数据不足的时候可以退化为<code>CORI</code></p>
<p>但是他也有其他的缺点：</p>
<ol>
<li>需要额外维护一个中心引擎</li>
<li>中心引擎出的score是同一纬度的算分，也是各个混排引擎的训练目标，但是如果他算分计算不准确，这个训练的结果将会很尴尬</li>
</ol>
<h2 id="[RS]REDDE4">[RS]REDDE<sup>4</sup></h2><blockquote>
<p>主要是做<code>Resource Selection</code>，但是预先先做了<code>Resource Sampling</code></p>
</blockquote>
<h3 id="Sample-Resample">Sample-Resample</h3><p>首先需要使用<code>sample-resample</code>对未知的垂直资源进行一个数据量大小的估计:</p>
<ol>
<li>先从已采样的垂直资源中随机选几个query-term</li>
<li>然后使用<code>query-term</code>再去请求垂直资源拿到返回的请求数以及<code>top rank</code>的部分doc</li>
</ol>
<p>其中</p>
<ul>
<li>$C_j$表示某个垂直资源/数据库</li>
<li>$\tilde{C}_j$表示该垂直资源的采样数据集</li>
<li>$N_{C_j}$表示垂直资源里面的数据大小(条数)[未知]</li>
<li>$N_{\tilde{C}_j}$表示采样垂直资源里面的数据大小条数</li>
<li>$q_i$表示垂直资源中被选择出来的某个<code>query term</code></li>
<li>$df_{q_iC_j}$表示垂直资源$C_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>$df_{q_i\tilde{C}_j}$表示采样垂直资源$\tilde{C}_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>事件$A$表示从垂直资源中采样的某个文档包含$q_i$</li>
<li>事件$B$表示垂直资源中某个文档包含$q_i$</li>
</ul>
<p>则有:<br>$$P(A) = \frac{df_{q_i\tilde{C}_j}}{N_{\tilde{C}_j}} \\<br>P(B) = \frac{df_{q_iC_j}}{N_{C_j}}$$<br>假设采样可以很好的表示整个数据库/垂直资源，因此有$P(A) \approx  P(B)$,则近似的有：<br>$$\hat{N}_{C_j} =  \frac{N_{\tilde{C}_j} *df_{q_iC_j} }{df_{q_i\tilde{C}_j}}$$</p>
<p>最终是使用全部估计的均值来表示的</p>
<h3 id="Resource_Selection">Resource Selection</h3><p>在给定查询词$q$下对于$C_j$的相关性估计为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in C_j}P(rel|d_i) * P(d_i|C_j) * N_{C_j}$$</p>
<p>其中:</p>
<ul>
<li>$N_{C_j}$为资源$C_j$的总文档量，我们使用$\hat{N}_{C_j}$来近似</li>
<li>$P(d_i|C_j)$这个概率将会是$\frac{1}{N_{C_j}}$</li>
</ul>
<p>相应的，相关性的估计将可以被写为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in \tilde{C}_j} P(rel|d_i) \frac{1}{\tilde{N}_{C_j}}  * \hat{N}_{C_j}$$</p>
<p>这样唯一剩下未知就是文档$d_i$与$q$的相关性了$P(rel|d_i)$<br>该paper并没有直接对其相关性做深入的研究，假如目前有一个中心数据库包含了所有的垂直资源，对其中心数据库来检索，则其相关性可以为:<br>$$P(rel|d_i)=\left\{<br>\begin{aligned}<br>C_q &amp; \quad if Rank\_central(d_i) &lt; ratio * \hat{N}_{all} \\<br>0 &amp; \quad \text{otherwise} \\<br>\end{aligned}<br>\right.$$</p>
<p>其中:</p>
<ul>
<li>$Rank\_central(d_i) $为中心数据库中对于$d_i$的排序</li>
<li>$ratio$为一个阈值，指示关注top多少的一个阈值(0.002~0.005表示合适)</li>
<li>$\hat{N}_{all}$为中心数据中所有文档量的一个估计值</li>
<li>$C_q$是一个独立于$q$的常量</li>
</ul>
<p>这种完备的中心数据库其实建立起来不大可行，但是我们可以使用采样的中心数据库.<br>现在向采样的中心进行query检索，可以根据其返回结果来推断出实际中心数据库中各个文档的排序的位置:<br>$$Rank\_central(d_i) = \sum_{d_j | Rank\_S(d_j) &lt; Rank\_S(d_i)} \frac{\hat{N}_{c(d_j)}}{\tilde{N}_{c(d_j)}}$$</p>
<p>这样最终$\hat{Rel}_q(j) $就可以计算出来了，最终在资源选择分布时可以按比例来:<br>$$\hat{Rank\_Rel}_q(j) = \frac{\hat{Rel}_q(j)}{\sum_i \hat{Rel}_q(i)}$$</p>
<h2 id="[RS]Adaptation_of_Offline_Vertical_Selection5">[RS]Adaptation of Offline Vertical Selection<sup>5</sup></h2><p>原本最常用的垂直资源选择是使用<code>one_vs_all</code>的分类分类方法，其中$k$个垂直资源，这样就需要分$k+1$个类别，训练完预测的时候选择类别概率高的来进行展现</p>
<p>而这篇paper主要是在输入类别概率之后还将用户反馈加入了进来再计算:</p>
<h3 id="Multiple_Beta_Prior">Multiple Beta Prior</h3><p>$p_q^v$可以用来表示某个Query下对于某个垂直资源类别v的相关概率，并且它是呈现<code>beta</code>分布的:<br>$$p_q^v \text{~} Beta(a_q^v,b_q^v)$$</p>
<p>其中$\pi_q^v$为离线模型概率，$\mu$为控制因子<br>$$a_q^v=\mu \pi_q^v \quad \quad b_q^v=\mu (1-\pi_q^v)$$</p>
<p>最后我们可以将相关性的后验写为<br>$$\tilde{p}_q^v = \frac{R_q^v + \mu \pi_q^v}{V_q^v + \mu}$$</p>
<blockquote>
<p>$R_q^v$为$q$下展现$v$同时被点击的数量,$\bar{R}_q^v$表示展现了  但是未被点击的数量,$V_q^v$则表示一共展现的数量</p>
</blockquote>
<h3 id="Logistic_Normal_Prior">Logistic Normal Prior</h3><p>其先验为<br>$$p_q^v = \frac{exp(W_{tv})}{exp(W_{tv}) + exp(\bar{W}_{tv})}$$</p>
<blockquote>
<p>$W$和$\bar{W}$是$t \times k$的随机矩阵，并且服从$W,\bar{W} ~ N_{2tk}(\eta,\sum)$,$\sum$为一个协方差矩阵</p>
</blockquote>
<p>则其后验可以转为:<br>$$\tilde{p}_q^v = \frac{\pi_q^v exp(a_q^v)}{\pi_q^v exp(a_q^v) + (1-\pi_q^v) exp(b_q^v)}$$</p>
<p>最终关于$a_q^v,b_q^v$都是可以被计算出来的:<br>$$a_q^v = R_q^v+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} \bar{R}_q^{v’}$$<br>$$b_q^v =  \bar{R}_q^{v’}+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} R_q^v $$<br>其中:</p>
<ol>
<li>$R_q^v$表示$q$与$v$相关的对数</li>
<li>$V_q^v$表示$q$与$v$共现的总次数</li>
</ol>
<h3 id="Similar_Queries">Similar Queries</h3><p>假设某个query1下知道他对于不同垂直资源的偏好，此时有一个query2与query1很相似，那么他关于垂直类目的偏好也会很相似<br>这个也是利用beta分布来估计的，算的是这个Bhattacharyya相似性，感兴趣自己去看paper</p>
<h3 id="Randomizing_Decisions">Randomizing Decisions</h3><p>对于偏好概率很低的垂直资源也会有某个概率$\varepsilon $进行选择它，加了这个概率波动的之后，最后在选择垂直资源是这么计算的，其相关性为：$$P(v)=\frac{1}{Z} exp(\frac{\tilde{p}_q^v}{\tau})$$<br>它是符合<code>Boltzmann</code>分布,其中:</p>
<ol>
<li>$\tilde{p}_q^v$为后验概率</li>
<li>$Z=\sum_vexp(\frac{\tilde{p}_q^v}{\tau})$</li>
<li>$\tau$是一个大于0的值，如果$\tau$趋向于正无穷，那么$P(v)$将会更加随机化，如果$\tau$接近于0，$P(v)$的选择将会更加贪婪（也就是哪个大选哪个）</li>
</ol>
<h2 id="[RS]Vertical_Selection_Evidence6">[RS]Vertical Selection Evidence<sup>6</sup></h2><p>使用分类的方法来进行资源类别选择，里面讲的主要是各种特征</p>
<p>评估指标为:<br>$$P=\frac{1}{|Q|} \left( \sum_{q \in Q | V_q \neq \varnothing } I(\tilde{v}_q \in V_q) + \sum_{q \in Q | V_q = \varnothing } I(\tilde{v}_q = \varnothing)   \right)$$</p>
<p>其中:</p>
<ol>
<li>$V$表示所有垂直资源的集合</li>
<li>$Q$表示所有Query的集合</li>
<li>$V_q$为与某个$q$相关的垂直资源集合</li>
<li>$\tilde{v}_q$表示对于$q$预测的与其相关的一个垂直资源</li>
<li>$I(\cdot)$表示示性函数，应该就是${0,1}$的二值函数吧</li>
</ol>
<p>下面是三大类特征<code>Query String</code>、<code>Query Logs</code>、<code>vertical corpora</code>:</p>
<h3 id="1-Query_String">1.Query String</h3><blockquote>
<p>该特征是为了利用Query中的一些关键短语与垂直资源的内容进行一些匹配</p>
</blockquote>
<h4 id="Rule-based_vertical_triggers(基于规则的触发)">Rule-based vertical triggers(基于规则的触发)</h4><p>文章中一共建立了45类别的属性来刻画query的垂直意图（其实就像类目，比如,local<br>phone, product, person, weather, movies, driving direction,<br>music artist）<br>同时这45类触发将会有三种规则：</p>
<ol>
<li><code>一对一触发</code>:<code>movies → movies, autos→ autos</code></li>
<li><code>一对多触发</code>:<code>{sports players,sports} → sports, {product review, product} → shopping</code></li>
<li><code>不显示对应</code>：但是会提供一些<code>positive或者negative</code>的标志用于分类器,比如, <code>patent, events, weather</code></li>
</ol>
<p>里面的触发类别都是用过正则表达来提出取来，另外一个query可能关联到多个类别，一个触发器至少会匹配到一个query</p>
<h4 id="Geographic_features(地理特征)">Geographic features(地理特征)</h4><p>在输入query下提取地理特征，并且会形成一个指定维护的概率向量:<code>airport,colloquial,continent,town,</code>等，将会与垂直资源中常常提到的这些地理词进行匹配</p>
<h3 id="2-_Query-Log_Features">2. Query-Log Features</h3><p>使用<code>Query-log</code>建立一个一元的语言模型<br>$$QL_q(V_i) = \frac{1}{Z}P(q|\theta_{v_i}^{qlog})$$<br>其中$\theta_{v_i}^{qlog}$为垂直资源$V_i$的语言模型，另外<br>$$Z=\sum_{v_j \in V}P(q|\theta_{v_j}^{qlog})$$</p>
<h3 id="3-Corpus_Features">3.Corpus Features</h3><blockquote>
<p>垂直资源的语料特征</p>
</blockquote>
<h4 id="垂直资源采样">垂直资源采样</h4><blockquote>
<p>应该是这儿的垂直资源可能是分布到各种不同的引擎里面的（第三方），作者并无法取到全部的离线数据，所以在进行语料相关特征计算的时候需要拿到具有代表性的资源文档数据</p>
</blockquote>
<p>在采样的时候使用垂直资源的top-query取访问垂直引擎，拿到文档再去统计，另一次关于垂直资源的语料去Wikipedia获取也是一种相当好的方式，因为里面都做好了结构化</p>
<h4 id="基于语料的特征">基于语料的特征</h4><p>1). <strong>Retrieval Effectiveness Features</strong></p>
<p>$$Clarity_q(C) = \sum_{w \in V} P(w|\theta_q) \text{log} \frac{P(w|\theta_q)}{P(w|\theta_C)}$$</p>
<p>其中:</p>
<ul>
<li>$V$是垂直资源$C$的语料/word</li>
<li>$P(w|\theta_q)$和$P(w|\theta_C)$分别是query和垂直资源的语言模型<br>  $$P(w|\theta_q) = \frac{1}{Z} \sum_{d \in R_{100}} P(w|\theta_d) P(w|\theta_d)$$<br>  $P(q|\theta_d)$为文本$d$的query似然分数，另外$Z=\sum_{d \in R_{100}}P(q|\theta_d)$</li>
</ul>
<blockquote>
<p><code>Clarity</code>分数越小表示检索效果越差</p>
</blockquote>
<p>最终各个资源也是按比例分数来计算的<br>$$Clarity_q^*(V_i) = \frac{1}{Z^*} Clarity_q(S_i^*)$$</p>
<p>2). ReDDE Features.<br>该Feature其实就是Luo.si  2003paper里面的计算方式<br>$$ReDDE_q^*(V_i) = |V_i| \sum_{d \in R_{100}} I(d \in S_i^*) P(q|\theta_d) P(d|S_i^*)$$<br>其中<br>$$P(d|S_i^*) = \frac{1}{S_i^*}$$</p>
<p>3). Soft.ReDDE Features<br>使用Bhattacharyya correlation<br>$$B(d,V_i) = \sum_{w \in top query}\sqrt{P(w|\theta_d) P(w|\theta_{V_i})} $$<br>其中<br>$$\phi(d,V_i) = \frac{B(d,V_i)}{\sum_{V_j \in V}B(d,V_j)}$$<br>最终soft针对文档的$B$进行求和，同时使用$P(q|\theta_d)$来加权:<br>$$Soft.ReDDE_q(V_i) = \sum_{d \in R_{100}} \phi(d,V_i) \times P(q|\theta_d)$$</p>
<p><code>Soft.ReDDE</code>有两大好处：</p>
<ol>
<li>每个文档在他的资源类别排序中多多少少都有贡献</li>
<li>不需要手动做文档到资源类别的映射(这个不懂….)</li>
</ol>
<p>4). Categorical Features<br>最大熵求取多级类目特征</p>
<h2 id="[MR]_Aggregate_Vertical_Results7">[MR] Aggregate Vertical Results<sup>7</sup></h2><p><code>Aggregate Vertical Results</code>(就是最终多源搜索结果的合并)有两大难处：</p>
<ol>
<li>不同来源的特征不一致</li>
<li>就是特征一直，同一个特征的值的分布也是不一致的</li>
</ol>
<p>因此无法直接使用一个ML算法去学习他们的排序,需要一种算法去学习这种不一致的特征排序任务（好像是用了某些特征关系映射）<br>整个<code>Aggregate Result</code>有如下的假设:</p>
<ol>
<li>相同的垂直资源应该是被排到一起的</li>
<li>垂直资源只能被嵌入到指定的坑位</li>
<li>网页结果往往都是主排序</li>
<li>不同的垂直资源是需要有关联的（这个有点难吧）</li>
<li>我们假设用户不会去看那些不相关的垂直资源</li>
</ol>
<p>这儿做的叫做<code>block-rank</code>坑位排序，比如有坑位<code>1~3(w1)</code>、<code>4~6(w2)</code>、<code>7~10(w3)</code>等，其中任务是预测排序顺序$\sigma(q)$与$\sigma^*(q)$尽量相似，其相似度可以使用$\text{Kendall’s} \tau$ 来衡量。<br>另外为了防止某些不相关性的<code>block</code>也被展现，所以有一个叫做<code>end of search result</code>(eos)的模块，如果被预测到这个模块，将会被放置到最下面并且不会展现</p>
<p>先说一下ML所使用到的特征<code>Pre-retrieval Features</code>和<code>Post-retrieval Features</code></p>
<p>1) <strong>Pre-retrieval Features</strong></p>
<blockquote>
<p>在检索到垂直引擎之前的提取的特征</p>
</blockquote>
<ul>
<li><code>Named-Entity Type Features</code></li>
<li><code>Category Features.</code></li>
<li><code>Click-through Features</code></li>
<li><code>Vertical-Intent Features.</code>(这个意图识别还是较难较重)</li>
</ul>
<p>2) <strong>Post-retrieval Features</strong></p>
<blockquote>
<p>这个为在检索到垂直引擎之后提取的特征</p>
</blockquote>
<ul>
<li><code>Hit Count Features</code>:垂直引擎的召回量</li>
<li><code>Temporal Features</code>:时间性相关的特征（时效性）</li>
<li><code>Text-Similarity Features.</code></li>
</ul>
<h3 id="BLOCK-RANKING_APPROACHES">BLOCK-RANKING APPROACHES</h3><blockquote>
<p>下面是实际的排序方法了</p>
</blockquote>
<p>1) <strong>Classification Approach</strong><br>每个垂直资源都有一个自己的分类器(这是使用的LR这个二分类器)<br>这里每个坑位都有一个阈值(除上面<code>w1~3</code>之外，还有一个eos的<code>w4</code>)<br>预测的是这个概率:<br>$$P(\sigma_q(v) &lt; \sigma_q(eos))$$<br>也就是是否要被展现的概率，最终按这种方式进行填坑<br>$$P(\sigma_q(v) &lt; \sigma_q(eos)) &gt; \tau_y \forall x&lt;y $$<br>这样就可以填入<code>x</code>坑位了（$\tau_y$是<code>1~4</code>坑位的阈值）</p>
<p>2) <strong>Voting Approach</strong><br>这里也是使用独立的分类模型,但是他的分类对象是<br>$$P(\sigma_q(i)) &lt; P(\sigma_q(j))$$<br>也就是pair，预测垂直资源$i$是否排在$j$前面，同时由于不同资源特征的限制,不同的$i,j$比较都是需要单独训练一个模型，最终使用投票的方式来确定哪个排在前面</p>
<blockquote>
<p>这种方式将会训练大量模型，虽然paper中将某些<code>block</code>因素归一了，但是训练的模型量还是巨大的</p>
</blockquote>
<p>3) <strong>Learning to Rank Approaches</strong><br>使用<code>RankSvm</code>进行排序,但是会遇到不同类别的特征体系不一致的问题，通过下面三种方式解决</p>
<ol>
<li><code>Equally Correlated Features</code>:针对部分common特征可以合并起来</li>
<li><code>Uniquely Correlated Features.</code>:对类别相关的特征进行copy和平铺出来，比如不同类别下同一个相关性特征可能会写两遍，但是都是时间特征在某些类别下只需要写一遍</li>
<li><code>Equally and Uniquely Correlated Features.</code>:结合上面两种特征</li>
</ol>
<p>但是上面的操作可能会导致过拟合，所以需要比较多的训练样本</p>
<h2 id="[MR]Merging_Multiple_Result_Lists8">[MR]Merging Multiple Result Lists<sup>8</sup></h2><p>用<code>LambdaMerge</code>的方法，其中好多使用了DNN，其框架为:</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/lambdamerge.png" width="500px" height="500px"></center>


<p>其中</p>
<ul>
<li>$f(x_{i,j}^d;\theta)$为文档相关的算法，前面那层的DNN,$x_{i,j}^d$为文档特征</li>
<li>$g(z_i;\eta)$为不同搜索引擎相关的特征（比如google、bing等）,$g(z_i;\eta)$也搜索引擎相关的特征,也是用DNN过了一层</li>
<li>$h(y_j;\phi)$为不同资源相关的特征,$y_j$为特征，也用dnn过了一层</li>
</ul>
<p>最终使用<code>lambdarank</code>来解，感觉这种方法写paper可以，但是实际使用起来代价有点高的</p>
<h2 id="[MR]Federated_Search_at_LinkedIn9">[MR]Federated Search at LinkedIn<sup>9</sup></h2><blockquote>
<p>这篇文章讲了混排在LinkedIn的实践，虽然没有高深的算法，但是讲的实在</p>
</blockquote>
<p>在Linked中的，混排的对象有Job、People、Companies、post等，但是没有一个主要的排序对象（web search中一般网页都是主要排序对象）<br>下面是他们的混排框架</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/linkedin1.png" width="500px" height="500px"></center>


<ol>
<li>用户输入一个query</li>
<li>希望向各个垂直引擎进行请求</li>
<li>请求完了之后各自引擎算完相关性得到top result（用LR进行计算的）</li>
<li>根据top result中各个得分选出主要的资源P,其他的资源都称为C</li>
<li>里面会对P和C的混排分进行一个归一化(没有细讲)</li>
<li>然后以$P_i$为主，将其$C_i$与$P_i$比大小进行插入完成混排</li>
</ol>
<p>其中排序选取的特征有:</p>
<ol>
<li><code>Searcher Intent</code>:用户自身的意图（稳定的，一天跑一把）</li>
<li><code>Keyword Intent</code>:query的意图 实时概率预测</li>
<li><code>Base Ranking Features</code>：基础特征了</li>
</ol>
<p>整个算法简单粗暴，效果还可以，主要实现起来快，而且各个大引擎主要跑一次</p>
<h2 id="[RS]2013-TREC10">[RS]2013-TREC<sup>10</sup></h2><blockquote>
<p>2013年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="resource_selection-Krisztian_Balog">resource selection-Krisztian Balog</h3><p>使用语言模型进行估计:<br>两种方式，将一种资源统一看成一种文档:<br>$$P(q|c) = \prod_{t \in q}\left\{ (1-\lambda)\left(\sum_{d \in c}P(t|d)P(d|c)\right) + \lambda P(t)\right\}^{n(t,q)}$$</p>
<ul>
<li>$t$为$q$中出现的term</li>
<li>$n(t,q)$表示$q$中出现$t$次数</li>
<li>$P(t|d)$和$P(t)$为给定文档下面的最大似然估计</li>
<li>$\lambda$为平滑因子</li>
<li>$P(d|c) = \frac{1}{|c|}$看成均匀分布式</li>
</ul>
<p>另一种方式是看一种资源看成多个文档<br>$$P(q|c) = \sum_{d \in c} P(d|c) \prod_{t \in q} \left( (1-\lambda)P(t|d)+\lambda P(t) \right)^{n(t,q)}$$</p>
<p>最终将两个分数进行一个合并<br>$$P(q|c) = \beta P_{cc}(q|c) + (1-\beta)P_{dc}(q|c)$$</p>
<h3 id="resource_selection-Emanuele_Di_Buccio">resource selection-Emanuele Di Buccio</h3><p>使用两个因子:</p>
<ol>
<li>Inverse Resource Frequency (IRF)   类似逆文档频率<br>$$IRF_t^{(z)} = \text{log} \frac{N^{(z)}}{n_t^{(z)}}$$</li>
</ol>
<ul>
<li>$t$表示term</li>
<li>$N^{(z)}$表示在$z$级别包含$t$的量</li>
<li>$n_t^{(z)}$表示具体某个资源包含$t$的量</li>
</ul>
<blockquote>
<p>关于$z$有是有三个级别:: (1) document, (2) search engines and (3) the set of search engine</p>
</blockquote>
<ol>
<li>Term Weighted Frequency (TWF)<br>$$w_{i,t}^{(z)} = TWF_{i,t}^{(z)} \cdot IRF_t^{(z-1)} $$<br>同时<br>$$TWF_{i,t}^{(z)} = \sum_{r \in R_i^z} TWF_{i,t}^{(z-1)} \cdot IRF_t^{(z-1)}$$</li>
</ol>
<p>这儿是一个递归的方式</p>
<h2 id="[RS]2014-TREC-Federated_Search11">[RS]2014-TREC-Federated Search<sup>11</sup></h2><blockquote>
<p>2014年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="1-resource_selection_-_Qiuyue_Wang">1.resource selection - Qiuyue Wang</h3><p>使用LDA来进行Resource和query的分布<br>由于query很短，作者的处理是用query查询google api取得top 50的文档的摘要，用组成的摘要来训练LDA，最终使用KL距离来衡量相似性</p>
<h2 id="总结">总结</h2><p>看了一些<code>Federated Search</code>相关的<code>Paper</code>（当然还有两个综述也讲的很好[12],[13]），其中</p>
<ul>
<li><code>Resource Selection</code>主要从<code>统计学</code>、<code>相似度计算</code>、<code>概率生成模型</code>以及<code>分类模型来完成</code></li>
<li><code>Merge Result</code>有使用<code>多源归一化</code>，<code>回归模型</code>、<code>LTR模型</code>来完成，同时在算分最后大多使用<code>Slot Filling</code>的方法来做</li>
</ul>
<p><code>Resource Selection</code>目前的方法中好的<code>Resource</code>将会被更多的选择则，该阶段尝试加入<code>Bandit</code>相关策略也许会有比较好的效果,<br>另外<code>Resource Selection</code>和<code>Merge Result</code>目前在优化中其实并没有太大的联系，有没有可能有一种方法能将两个阶段联合起来进行全局优化?</p>
<h2 id="参考文献">参考文献</h2><ol>
<li>Arguello, Jaime, Fernando Diaz, and Milad Shokouhi. “Integrating and ranking aggregated content on the web.” Proc. WWW 2012 (2012).</li>
<li>Callan, James P., Zhihong Lu, and W. Bruce Croft. “Searching distributed collections with inference networks.” Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1995.</li>
<li>Sushmita, Shanu, et al. “Factors affecting click-through behavior in aggregated search interfaces.” Proceedings of the 19th ACM international conference on Information and knowledge management. ACM, 2010.</li>
<li>Si, Luo, and Jamie Callan. “Relevant document distribution estimation method for resource selection.” Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 2003.</li>
<li>Diaz, Fernando, and Jaime Arguello. “Adaptation of offline vertical selection predictions in the presence of user feedback.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, et al. “Sources of evidence for vertical selection.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, Fernando Diaz, and Jamie Callan. “Learning to aggregate vertical results into web search results.” Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 2011.</li>
<li>Lee, Chia-Jung, et al. “An Optimization Framework for Merging Multiple Result Lists.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015</li>
<li>Arya, Dhruv, Viet Ha-Thuc, and Shakti Sinha. “Personalized Federated Search at LinkedIn.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.</li>
<li><a href="http://trec.nist.gov/pubs/trec22/trec2013.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec22/trec2013.html</a></li>
<li><a href="http://trec.nist.gov/pubs/trec23/trec2014.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec23/trec2014.html</a></li>
<li>Shokouhi, Milad, and Luo Si. “Federated search.” Foundations and Trends in Information Retrieval 5.1 (2011): 1-102.</li>
<li>Kopliku, Arlind, Karen Pinel-Sauvagnat, and Mohand Boughanem. “Aggregated search: A new information retrieval paradigm.” ACM Computing Surveys (CSUR) 46.3 (2014): 41.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px" /></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[最大熵模型]]></title>
    <link href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/"/>
    <id>http://kubicode.me/2016/12/12/Machine Learning/Maximum-Entropy-Model/</id>
    <published>2016-12-12T01:39:30.000Z</published>
    <updated>2017-01-03T13:16:38.000Z</updated>
    <content type="html"><![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br><a id="more"></a></p>
<center><img src="/img/Maximum-Entropy-Model/binary_ent.png" width="400px"></center>

<blockquote>
<p>上图是两个类别的示例，可以看到这两个类别的<code>概率一样</code>时其熵值最大</p>
</blockquote>
<p>在机器学习领域，我们通常以最小化风险为目标，其实就是将熵进行最大化.<br>最大熵模型亦是如此，直观的说，<code>最大熵模型就是在满足现有的约束条件之下，将那部分不确定的都设为等可能（熵最大）</code>，<br>下面看一个简单的例子:<br>假设现在有一个随机变量$X$可能取值为$\{A,B,C\}$,现在需要来估计各个值的概率:$P(A)$,$P(B)$,$P(C)$</p>
<p>其实这些概率值肯定会满足如下条件:<br>$$P(A)+P(B)+P(C)=1$$<br>但是满足这个约束条件的概率分布有无限多个，如果没有其他信息的条件下，则取值风险最小的方法是:<br>$$P(A)=P(B)=P(C)=\frac{1}{3}$$<br>现告诉你取$P(A)$的概率为$\frac{1}{2}$,则根据熵最大的原理其他两个概率取值将会为<br>$$P(B) = P(C) = \frac{1}{4}$$<br>也就是$B$和$C$是等概率的，假如接下来还有其他可知的约束条件的话，在满足其他约束条件的情况下继续进行等概率分布.上面的整个划分的过程也就是遵循了<code>最大熵原理</code></p>
<p>现假如用欧式空间的单纯形来表示随机变量$X$的话，定义单纯形中的任意一点到$x$到达相应顶点对应边的距离为取值概率，并且三边距离之和为1，这两种取值情况:<br>$$P(A)=1,P(B)=P(C)=0 \\<br>P(A)=P(B)=P(C)=\frac{1}{3}$$<br>可以依次使用下面两个图来表示</p>
<center><img src="/img/Maximum-Entropy-Model/complex1.png" width="400px"></center>

<p>知道了上面单纯形的表示方法之后，根据下图其最大熵原理可以得到如下的刻画:</p>
<ol>
<li>不加任何约束的时候，可以用图(a)表示，整个取值空间为单纯形上的任何一点，只需要找到熵最大的情况即可</li>
<li>当添加约束<code>C1</code>的时候，将需要在满足<code>C1</code>的情况下再寻找熵最大的取值(也就是图(b))</li>
<li>图(c)表示在图(b)的<code>C1</code>基础上继续增加了<code>C2</code>的约束，此时对两个约束进行了满足之后取值空间将会被固定在<code>C1</code>和$C2$的交点上，只有一个唯一解</li>
<li>假设图(d)里面在<code>C1</code>的基础了增加了<code>C2</code>，但是此时<code>C1</code>和<code>C2</code>并无交点，在这两者约束下将会无解<center><img src="/img/Maximum-Entropy-Model/complex2.png"></center>

</li>
</ol>
<h2 id="最大熵模型介绍">最大熵模型介绍</h2><blockquote>
<p>最大熵模型其实就是在<code>满足已有约束的条件下求得熵最大的过程</code>,最终会转为一个<code>解约束最优化</code>的问题</p>
</blockquote>
<p>现将最大熵原理应用到分类的最大熵模型:<br>假设现有训练数据集<br>$$T=\{(x_1,y_1),(x_2,y_2),….(x_n,y_n)\}$$<br>最大熵模型就是分别根据已有的输入$X$和输出$Y$集合去学习训练数据的条件概率分布$P(y|x)$，应用最大熵原理去学习分类能力最好的模型.<br>根据最大熵原理，是需要在满足约束的情况对已有数据求得熵最大，那在最大熵分类模型里面的<code>约束条件</code>又是啥呢？</p>
<p>对于给定的训练数据集，我们可以确定联合分布$P(X,Y)$的<code>经验分布</code>$\tilde{P}(X,Y)$以及边缘分布$P(X)$的<code>经验分布</code>$\tilde{P}(X)$，即:<br>$$\tilde{P}(X=x,Y=y)=\frac{count(X=x,Y=y)}{N} \\ \tilde{P}(X=x) = \frac{count(X=x)}{N}$$</p>
<blockquote>
<p>其中$count(\cdot)$表示满足条件在样本中的计数，$N$表示总的训练样本容量</p>
</blockquote>
<p>现在引入<code>特征函数</code>$f(x,y)$，它是描述输入$x$与输出$y$之间满足的某一事实，为了方便起见，我们将$f(x,y)$定义为二值函数:<br>$$ f(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{x,y满足某一事实} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>上面的特征函数比较抽象，下面借用别人的栗子来说明一下:<br>假设我们需要来判断<code>打</code>字是量词还是动词，目前有下面的训练数据集:<br>$$<br>(x_1,y_1) = (\text{一打火柴},\text{量词}) \\<br>(x_2,y_2) = (\text{三打啤酒},\text{量词}) \\<br>(x_3,y_3) = (\text{五打袋子},\text{量词}) \\<br>(x_4,y_4) = (\text{打电话},\text{动词}) \\<br>(x_5,y_5) = (\text{打篮球},\text{动词})<br>$$<br>通过观察我们可以发现<code>打</code>前面位<code>数字</code>时，<code>打</code>为<code>量词</code>，如果<code>打</code>后面跟着的是<code>名词</code>,则打为<code>动词</code>，为基于刚刚观察的两个实时我们用特征函数来表示则为:<br>$$ f_1(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的前面为数字} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>$$ f_2(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的后面为名词} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>有了特征函数之后，我们将现有的数据代入这两个特征函数即有:<br>$$f_1(x_1,y_1) = f_1(x_2,y_2) = f_1(x_3,y_3) = 1,f_1(x_4,y_4) = f_1(x_5,y_5) = 0 \\<br>f_2(x_1,y_1) = f_2(x_2,y_2) = f_2(x_3,y_3) = 0,f_2(x_4,y_4) = f_2(x_5,y_5) = 1<br>$$</p>
</blockquote>
<p>对于任意的特征函数$f(x,y)$,<br>现记$E_{\tilde{P}}(f)$表示特征函数$f$在训练数据集$T$上关于$\tilde{P}(x,y)$的数学期望，有:<br>$$E_{\tilde{P}}(f) = \sum_{x,y} \tilde{P}(x,y) f(x,y)$$<br>另记$E_{P}(f)$表示特征函数$f$在训练数据集$T$上关于$P(x,y)$的数学期望，有:<br>$$E_{P}(f) = \sum_{x,y} P(x,y) f(x,y)$$<br>但是$P(x,y)$是未知的，而我们的目标是为了计算$P(y|x)$，根据<code>Bayes</code>我们可以做如下转换<br>$$P(x,y) = P(y|x) \cdot p(x)$$<br>虽说$p(x)$仍为未知，但是我们此时可以使用$\tilde{P}(x)$进行近似,也就是最终有:<br>$$E_{P}(f) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>我们希望上述两个期望值是一值的（应该也是符合既定事实的吧?），这样就会有:<br>$$E_{\tilde{P}}(f) = E_{P}(f)$$<br>或者<br>$$ \sum_{x,y} \tilde{P}(x,y) f(x,y) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>上述式子就可以作为模型的<code>约束条件</code>，假如有$n$个特征函数，则就会有$n$个约束条件(实际中一般特征的维度就是约束条件的个数)<br>用$C$来表示满足约束的模型集合:<br>$$C=\{P|E_{\tilde{P}}(f) = E_{P}(f),I=1,2,3..n\}$$<br>满足约束条件同时使用$P(y|x)$的熵最大的模型即为最大熵模型~</p>
<p>到了这里我们还差一个熵的定义，我们的目标是为了获取条件概率的分布，因为也使用了相应的<code>条件熵</code><br>$$H(P)= - \sum_{x,y}  \tilde{P}(x) P(y|x) log P(y|x)$$</p>
<blockquote>
<p>向上面一样,$P(x)$用$\tilde{P}(x)$进行了近似</p>
</blockquote>
<p>这样我们就可以给出最大熵模型的完成公式描述了:<br>$$<br>\begin{align}<br>\underset{P \in C}{max} &amp;\quad H(P) = - \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad E_{P}(f) = E_{\tilde{P}}(f),I=1,2,3..n \\<br>&amp;\quad \sum_y P(y|x)=1<br>\end{align}<br>$$</p>
<h2 id="最大熵模型学习">最大熵模型学习</h2><p>最大熵模型的学习就是求解最大熵的过程，按照优化的习惯，我们一般会将<code>最大化</code>问题转为<code>最小化</code>再进行优化:<br>$$<br>\begin{align}<br>\underset{P \in C}{min} &amp;\quad -H(P) =  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad  E_{\tilde{P}}(f)- E_{P}(f) = 0,I=1,2,3..n \\<br>&amp;\quad 1-\sum_y P(y|x)=0<br>\end{align}<br>$$</p>
<p>接下来我们求解的思路是:</p>
<ol>
<li>接下来的求解方式是利用拉格朗日乘子将带约束的最优化问题转为等价无约束优化，它是一个<code>极小极大问题</code></li>
<li>然后利用对偶的等价性，将上述<code>极小极大问题</code>转为对偶的<code>极大极小问题</code></li>
</ol>
<h3 id="原始问题与对偶问题">原始问题与对偶问题</h3><p>首先我们引入拉格朗日乘子$w_0,w_1,w_2….w_n$,定义拉格朗日函数为$L(P,W)$<br>$$<br>\begin{align}<br>L(P,W) &amp;= -H(P) + w_0\left(1-\sum_y P(y|x) \right) + \sum_{i=1}^n w_i\left( E_{\tilde{P}}(f)- E_{P}(f) \right) \\<br> &amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right)<br>\end{align}<br>$$</p>
<p>则最优化的原始问题为:<br>$$\underset{P \in C}{\text{min}}  \underset{W}{\text{max}} L(P,W)$$<br>则转为等价的对偶问题为:<br>$$ \underset{W}{\text{max}} \underset{P \in C}{\text{min}} L(P,W)$$</p>
<p>其中$L(P,W)$是关于$P$的凸函数,那我们首先求对偶的极小化部分$ \underset{P \in C}{\text{min}} L(P,W)$,它是关于$W$的函数，将其记为:<br>$$\varphi(w) =  \underset{P \in C}{\text{min}} L(P,W) = L(P_w,W)$$<br>其中<br>$$P_w = \underset{P \in C}{\text{argmin}} L(P,W) = P_w(y|x)$$</p>
<blockquote>
<p>关于这里，我认为我们需要求解的是$P(y|x)$，同时可以将$L(P,W)$看为关于$P(y|x)$的函数,所以为了上面的解，需要下面的偏导~</p>
</blockquote>
<h3 id="指数形式求解">指数形式求解</h3><p>先对$L(P,W)$求$P(y|x)$的偏导,<br>$$<br>\begin{align}<br>\frac{\delta L(P,W)}{\delta P(y|x)} &amp;=  \left( \sum_{x,y}  \tilde{P}(x)  \text{log} P(y|x) + \sum_{x,y}  \tilde{P}(x)  \right) - \sum_yw_0 -\sum_{i=1}^n w_i \tilde{P}(x) f_i(x,y) \\<br> &amp;=  \sum_{x,y} \tilde{P}(x) \left( \text{log} P(y|x) + 1-w_0- \sum_{i=1}^n w_i  f_i(x,y) \right)<br> \end{align}<br>$$</p>
<p>这里对于$\tilde{P}(x)&gt;0$，在求最小值是其偏导数为0，因此会有:<br>$$P(y|x) = e^{\sum_{i=1}^n w_i  f_i(x,y)+w_0-1} = \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{e^{1-w_0}}$$</p>
<p>因为有$\sum_yP(y|x)=1$,则可以有:<br>$$e^{1-w_0} = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>最终我们可以将$P_w(y|x)$表示为:<br>$$P_w(y|x) = \frac{1}{Z_w(x)} e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>其中<br>$$Z_w(x) = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)}$$</p>
<blockquote>
<p>$Z_w(x)$被称为规范化因子，上面样式的算分与逻辑回归非常相似，所以又称为<code>对数线性模型</code>，同时又经过了规范化因子之后可以发现其最后的算分与<code>Softmax</code>极其相似</p>
</blockquote>
<p>这里上面两个式子就是表示$P_w = P_w(y|x)$的最大熵模型，其中向量$W$即为模型的参数<br>现在求解了内部的极小化之后，还需要求解外部的极大化<br>$$\underset{w}{\text{max}} \varphi(W) $$<br>其解标记为$W^{*}$<br>$$W^{*} = \underset{w}{\text{max}} \varphi(W) $$<br>模型参数$W^{*}$就是对对偶的极大化，得到的$W^{*}$可以表示为$W^{*} \in C$，最终$P_{w^{*}} = P_{w^{*}}(y|x)$即为模型的最终解。也就是最大熵模型需要解对偶函数 $\varphi(W)$的极大化~</p>
<h3 id="最大似然估计">最大似然估计</h3><p>在求解上面极大化之前，我们先来看下最大熵模型的极大似然法:<br>已知其经验概率分布$\tilde{P}(X,Y)$和其条件概率分布$P(Y|X)$，可以得到其对数似然函数为:<br>$$<br>\begin{align}<br>LL_{\tilde{P}}(P_w) &amp;=  \text{log} \prod_{x,y} P(y|x)^{\tilde{P}(x,y)} \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} P(y|x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{Z_w(x)}  \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} e^{\sum_{i=1}^n w_i  f_i(x,y)} - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x) \tilde{P}(y|x) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y \tilde{P}(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) \text{log} Z_w(x) \quad    \text{利用} {\color{Blue} {\sum_y \tilde{P}(y|x)=1}}<br> \end{align}<br>$$</p>
<p>回头再将$P(y|x)$的解代入到对偶函数$\varphi(W)$中:<br>$$<br>\begin{align}<br>\varphi(w) &amp;=  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \left(\sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x) \right) \\<br>&amp;\quad +  \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= {\color{Red}{\sum_{x,y}  \tilde{P}(x) P(y|x) \sum_{i=1}^n w_i f_i(x,y)}}  - \sum_{x,y}  \tilde{P}(x) P(y|x)\text{log}Z_w(x) \\<br>&amp;\quad +  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y)- {\color{Red}{\sum_{i=1}^n w_i \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)}}  \\<br>&amp;=  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y P(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y)\sum_{i=1}^n w_i f(x,y) - \sum_x \tilde{P}(x)\text{log} Z_w(x)<br> \end{align}<br>$$</p>
<blockquote>
<p>上面第一步的换算是借助了$\text{log} P(y|x) = \sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x)$，同时还有$\sum_y P(y|x)=1$</p>
</blockquote>
<p>现在再来对比$\varphi(w)$与$LL_{\tilde{P}}(P_w)$最终的表达式，可以惊奇的发现:<br>$$\varphi(w) = LL_{\tilde{P}}(P_w)$$<br>于是就证明了对偶函数的极大化等于模型极大似然估计这一事实，这样模型学习就可以在给定训练数据条件下进行极大化似然估计~</p>
<h2 id="总结">总结</h2><blockquote>
<p>关于具体的解就不再详说了，既然是可以用最大似然法解，则其常用的解法有<code>梯度下降法</code>、<code>牛顿法</code>或者还有专门的<code>GIS</code>法等，参考[2]</p>
</blockquote>
<p>关于最大熵模型:</p>
<ol>
<li>利用最大熵原理<code>熵越大事物越混乱，其分类风险越小</code></li>
<li>为了防止其解空间太大，利用<code>特征函数</code>建立起约束</li>
<li>在求解模型时使用对偶的方式进行求解，先解最小化的负熵，再求极大化的对偶函数</li>
<li>解最小化负熵时可以得到最大熵模型最后的形式是指数形式，类似逻辑回归</li>
<li>又在求极大化对偶函数时，可以发现其对偶函数与模型的极大似然法形式一致</li>
<li>因此最终可以按极大似然法的方式去解决模型</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://www.cnblogs.com/ooon/p/5677098.html" target="_blank" rel="external">最大熵模型 Maximum Entropy Model</a></li>
<li>《统计学习方法》.李航 第6章</li>
<li><a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="external">最大熵学习笔记</a></li>
<li>1996-A Maximum Entropy Approach</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Softmax的二三事]]></title>
    <link href="http://kubicode.me/2016/11/27/Machine%20Learning/Something-for-Softmax/"/>
    <id>http://kubicode.me/2016/11/27/Machine Learning/Something-for-Softmax/</id>
    <published>2016-11-27T08:24:28.000Z</published>
    <updated>2016-11-29T13:28:19.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All" target="_blank" rel="external">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One" target="_blank" rel="external">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯" target="_blank" rel="external">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li>。。。</li>
</ol>
<a id="more"></a>
<p>同时本文要说到的<code>Softmax</code>是一个是<code>Logistic</code>模型上的一个扩展，可以轻松的完成多分类任务，它是一个有监督的学习，不过可以和相当热门的神经网络可以轻松结合起来.</p>
<h2 id="Logistic回顾">Logistic回顾</h2><p><code>Logistic</code>模型是一个非常基础而又高效的<code>二分类</code>模型，并且由于其最终值会归一化到0~1，因此也很多场景下也会作为<code>回归</code>模型使用，比如<code>ctr预估</code>。<br><code>Logistic</code>的输入数据是<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>其中$x^i$为输入的特征向量，$y^i$即为要训练的目标，在<code>二分类</code>中，一般$y^i \in \{0,1\}$，则<code>Logistic</code>的算分函数为<br>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^Tx}}$$</p>
<p>使用最大似然法进行参数估计,其似然函数为<br>$$\prod h_{\theta}(x^i)^{y^i} \times (1-h_{\theta}(x^i))^{(1-y^i)}$$</p>
<p>对其进行负的对数转换之后则最终的损失函数为<br>$$ J(\theta) = -\frac{1}{m} \sum_{i=1}^m \left [ y^i \text{log}h_{\theta}(x^i) + (1-y^i)\text{log}(1-h_{\theta}(x^i)) \right ]    $$</p>
<p>在<code>Logistic</code>模型中我们可以发现我们最终需要求的是$\theta$向量.</p>
<h2 id="Softmax_模型">Softmax 模型</h2><p>在<code>Softmax</code>模型中，其输入也是类似向量的设计<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>只是这个的$y^i \in \{1,2,…k\}$有$k$个类别，而最终要求的应该是这个值<br>$$P(y=k_j | x)$$<br>也就是类别$k_j$可能的概率，也就是会形成一个$k$维的输出<br>$$<br>h_{\theta}(x^i)=\begin{bmatrix} P(y^i=1|\theta_1,x_i)<br>\\ P(y^i=2|\theta_2,x_i)<br>\\ …<br>\\ P(y^i=k|\theta_k,x_i)<br>\end{bmatrix}<br>=<br>\frac{1}{\sum_{s=1}^k e^{-\theta_s^Tx_i}}<br>\begin{bmatrix} e^{-\theta_1^Tx_i}<br>\\ e^{-\theta_2^Tx_i}<br>\\ …<br>\\ e^{-\theta_k^Tx_i}<br>\end{bmatrix}<br>$$</p>
<p>则我们整个模型最终要求的是一个$\theta$<code>矩阵</code>(注意,在<code>Logistic</code>中求是一个向量),矩阵的每一行$\theta_i$其实就是与输入参数$x$相乘的向量~</p>
<blockquote>
<p>注意:分子$\frac{1}{\sum_{s=1}^k e^{-\theta_s^Tx_i}}$是为了让最终所有类别的概率之和为<code>1</code></p>
</blockquote>
<p>每个类别j的概率为:<br>$$p_j=\frac{e^{-\theta_j^Tx}}{\sum_{s=1}^k e^{-\theta_s^Tx}}$$</p>
<h2 id="Softmax的损失函数">Softmax的损失函数</h2><p>同样,<code>Softmax</code>使用最大似然法进行参数的估计,则似然函数为<br>$$\prod_i^m \prod_{j=1}^k p_j^{I\{y^i = k_j\}}$$</p>
<blockquote>
<p>其中$I\{y^i = k_j\}$为二值函数，当且仅当$y^i == k_j$时为1，否则为0</p>
</blockquote>
<p>对其<code>取负的对数</code>可以得到其损失函数:<br>$$J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \text{log} p_j \right]$$</p>
<p>假设我们使用梯度下降法对损失函数进行优化，因此对$\theta$进行求导,在求导之前先算下面这个:<br>$$ \frac{\delta p_j}{\delta \theta_i}=\left\{<br>\begin{aligned}<br>\frac{\frac{e^{-\theta_j^Tx}}{\delta \theta_{\color{Red} j}}\sum_{s=1}^k e^{-\theta_s^Tx}-\frac{\sum_{s=1}^k e^{-\theta_s^Tx}}{\delta \theta_{\color{Red} j}}e^{-\theta_s^Tx}}{(\sum_{s=1}^k e^{-\theta_s^Tx})^2} &amp;= x p_j(1-p_j)  &amp; \quad if i=j \\<br>\frac{\frac{e^{-\theta_j^Tx}}{\delta \theta_{\color{Red} i}}\sum_{s=1}^k e^{-\theta_s^Tx}-\frac{\sum_{s=1}^k e^{-\theta_s^Tx}}{\delta \theta_{\color{Red} i}}e^{-\theta_j^Tx}}{(\sum_{s=1}^k e^{-\theta_s^Tx})^2} &amp;= x p_ip_j &amp; \quad if i \neq j\\<br>\end{aligned}<br>\right.$$</p>
<p>有了上面的基础之后，我们对于$J(\theta)$进行求导，就可以得到如下的梯度:</p>
<p>$$\begin{equation}\begin{split} \triangledown_{\theta_j}J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \frac{1}{p_j} \frac{\delta p_j}{\delta \theta_j  }  \right]\\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \left ( I\{y^i = k_i\} \frac{1}{p_i} x^i p_i(1-p_i) -  \sum_{j=1,j \neq i}^k I\{y^i = k_j\} \frac{1}{p_j} x^i p_i p_j \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_i\} (1-p_i) -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} i}\} - I\{y^i = k_i\}p_i -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} j}\} -  \sum_{j=1}^k I\{y^i = k_j\} p_i \right )  \right ]  \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_j\} - p_i \right )  \right ]<br>\end{split}\end{equation}$$</p>
<p>注意有:</p>
<ul>
<li>$\sum_{j=1}^k I\{y^i = k_j\} = 1 $ ,因为样本必定会落到一个类别上</li>
<li>同时上面式子里面红色的${\color{Red} j}$是因为左侧分离出来,其中分离的条件是$i=j$</li>
</ul>
<p>上面的梯度最终将会是一个向量的形式,$\frac{\delta J(\theta)}{\delta \theta_{j,l}}$表示第$j$的类别的第$l$个特征的梯度方式，有了该梯度了之后，最终可以得到如下的参数更新:<br>$$\theta_j = \theta_j - \alpha \triangledown_{\theta_j}J(\theta) \quad j \in \{1,…k\}$$</p>
<p>到了这一步，整体看到就和二分类的<code>Logistic</code>很像了，上面是使用梯度下降法的求解，当然还可以使用类似<code>L-BFGS</code>算法进行优化~<br>另外关于其<code>L1</code>和<code>L2</code>的正则项也是可以参考<code>Logistic</code></p>
<h2 id="Softmax与Logistic的联系">Softmax与Logistic的联系</h2><p>在<code>Softmax</code>的$k=2$时(其实就是二分类了)，再来观察<code>Softmax</code>的一些式子</p>
<h3 id="算分函数">算分函数</h3><p>$$\begin{equation}\begin{split} h_\theta(x^i) &amp;= \frac{1}{e^{-\theta_1^Tx_i}+e^{-\theta_2^Tx_i}}<br>\begin{bmatrix} e^{-\theta_1^Tx_i}<br>\\ e^{-\theta_2^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \frac{1}{e^{-(\theta_1-\theta_1)^Tx_i}+e^{-(\theta_2-\theta_1)^Tx_i}}<br>\begin{bmatrix} e^{-(\theta_1-\theta_1)^Tx_i}<br>\\ e^{-(\theta_2-\theta_1)^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{-(\theta_2-\theta_1)^Tx_i}}<br>\\ \frac{e^{-(\theta_2-\theta_1)^Tx_i}}{1+e^{-(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{-(\theta_2-\theta_1)^Tx_i}}<br>\\ 1- \frac{1}{1+e^{-(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>在上面第一到第二步减去$\theta_1$任成立的原因是，<code>Softmax</code>的参数过多，是一个大矩阵，里面存在着冗余的参数:<br>$$\begin{equation}\begin{split} h_{\theta_j}(x^i) &amp;= \frac{e^{-\theta_jx^i}}{\sum_{s=1}^k e^{-\theta_sx^i}} \\<br>&amp;= \frac{e^{-(\theta_j-\phi)x^i}}{\sum_{s=1}^k e^{-(\theta_s-\phi)x^i}} \\<br>&amp;= \frac{e^{-\theta_jx^i}e^{-\phi x^i}}{\sum_{s=1}^k e^{-\theta_sx^i}e^{-\phi x^i}} \\<br>&amp;= \frac{e^{-\theta_jx^i}}{\sum_{s=1}^k e^{-\theta_sx^i}}<br>\end{split}\end{equation}$$<br>因此，参数矩阵中减去同一个<code>向量</code>并不会影响最终的优化结果~关于参数过度化问题可以参考<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">这里</a></p>
</blockquote>
<p>所以当$k=2$时<code>Softmax</code>的算分函数其实就是<code>Logistic</code>的变形~</p>
<h3 id="损失函数">损失函数</h3><p><code>Softmax</code>的损失函数为<br>$$\begin{equation}\begin{split} J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^2 I\{y^i = k_j\} \text{log} p_j \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + I\{y^i = k_2\} \text{log} p_2  \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + (1-I\{y^i = k_1\}) \text{log} (1-p_1)  \right]  \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>因为:$I\{y^i = k_1\} + I\{y^i = k_2\}  =1$ 以及 $p_1+p_2=1$</p>
</blockquote>
<p>最终也就变成了<code>Logistic</code>的损失函数形式了</p>
<h2 id="总结">总结</h2><ol>
<li><code>Softmax</code>模型其实是<code>Logistic</code>对于多分类上面的扩展</li>
<li><code>Softmax</code>最终产出的每一类的概率之和为1</li>
<li><code>Softmax</code>其实并不是一个损失函数（因为看到很多文章中都会很自然的写道<code>Softmax损失函数</code>）,它自己求优化时还是使用者交叉熵的这一套</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">Softmax回归 ufldl</a><blockquote>
<p>文本大致组织按这个参考来的，因为它写的实在太好了，自己在造一遍轮子，以便记忆^_^</p>
</blockquote>
</li>
<li><a href="http://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function" target="_blank" rel="external">Derivative of Softmax loss function</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li>。。。</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用点击图来计算Query-Doc的文本相关性]]></title>
    <link href="http://kubicode.me/2016/11/03/Search%20Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/"/>
    <id>http://kubicode.me/2016/11/03/Search Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/</id>
    <published>2016-11-03T12:07:18.000Z</published>
    <updated>2016-11-07T01:59:53.000Z</updated>
    <content type="html"><![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br><a id="more"></a></p>
</blockquote>
<h2 id="已有点击行为的向量计算">已有点击行为的向量计算</h2><p>在搜索场景下用户输入query，对搜索的结果进行点击反馈，将所有用户的搜索行为收集起来之后可以形成一张大的<code>Click-Graph</code>，为了简单，我们使用二部分来表示，其中左侧为$Query$，右侧为$Doc$，如果$q_i$到$d_j$存在点击行为，则左右侧将会有一条边连接，连上的权重及<code>点击的次数</code></p>
<center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/co-click-graph.png" width="400px"></center>

<p>现在假设语料的长度为$V$,则$Query$构成的矩阵为$|Query| \times V$，以及$Doc$构成的矩阵为$|Doc| \times V$，那么现在的任务就是如何计算这两个矩阵!</p>
<blockquote>
<p>其实这个语料就是上面所说道的$Query$和$Doc$同处的向量空间,一般值$Query$里面抠出来的<code>Term</code>或者$Doc$里面的<code>title</code>/<code>content</code>抠出来的<code>term</code>.</p>
</blockquote>
<p>这里使用的是<code>向量传播</code>来对$Query$和$Doc$进行计算，计算之前有这么这个假设:</p>
<ol>
<li><code>点击二部图</code>上的边连接的$q_i$和$d_i$是有相关性的(或者说有较高的相关性)</li>
<li>$q_i$上的<code>term</code>与$d_i$上的<code>title</code>/<code>content</code>的<code>term</code>应该是存在联系的</li>
</ol>
<p>目前暂不考虑缺少行为的$Query$和$Doc$，向量传播模型的步骤为:</p>
<ol>
<li>随意选择一侧进行向量初始化（$Query$和$Doc$端均可），我们使用$Query$向量来进行初始化$Q_i^0$,其中$Q_i^0$使用<code>one-hot</code>来表示，同时用$L2$进行归一化<blockquote>
<p>$i$表示第$Query$中的第$i$个,$0$表示第1次迭代（也就是初始化~）</p>
</blockquote>
</li>
<li>则第$D_j^n$个值($n&gt;=1$)的更新根据被点击$Query$的向量进行加权求和即可:<br> $$D_j^n=\frac{1}{||\sum_{i=1}^{|Query|}C_{i,j} \cdot Q_i^{n-1}||_2} \sum_{i=1}^{Query}C_{i,j} \cdot Q_i^{n-1}$$<blockquote>
<p>其中$Q_i^n$就是上一次迭代的$Query$向量，同样$D_j^n$也会进行一个$L2$正则化。</p>
</blockquote>
</li>
<li>$Doc$的向量表示进行了一次迭代更新之后继续更新$Query$的向量，这里是根据$Query$下公共点击的文档信息进行更新，其方式与$Doc$的更新是一样的:<br> $$Q_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}C_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}C_{i,j} \cdot D_i^{n-1}$$</li>
<li>按<code>2</code>、<code>3</code>的步骤不断进行迭代，直至收敛，其产出的$Query$的$Doc$的向量就都在一个空间内，同时还可以计算相似度/相关性</li>
</ol>
<p>这里以上的图为例再说一下计算过程:</p>
<ol>
<li>初始化$Query$的向量:<ul>
<li>$Q_1:\{yahoo:\frac{1}{\sqrt{2}},finance:\frac{1}{\sqrt{2}},mail:0\}$</li>
<li>$Q_2:\{yahoo:1,finance:0,mail:0\}$</li>
<li>$Q_3:\{yahoo:\frac{1}{\sqrt{2}},finance:0,mail:\frac{1}{\sqrt{2}}\}$<blockquote>
<p>因为图中$Query$的语料三个<code>term</code>，所以这里初始化为3维.</p>
</blockquote>
</li>
</ul>
</li>
<li>根据上一次$Query$的迭代信息以及与$Doc$的点击信息来更新$Doc$的向量:<ul>
<li>$D_1=\frac{(\frac{3}{8}Q_1 + \frac{5}{8}Q_2)}{||\frac{3}{8}Q_1 + \frac{5}{8}Q_2||_2}$</li>
<li>$D_2=\frac{(\frac{1}{5}Q_2 + \frac{4}{5}Q_3)}{||\frac{1}{5}Q_2 + \frac{4}{5}Q_3||_2}$</li>
</ul>
</li>
<li>然后就是不断的迭代就行了，这样已经很清晰了</li>
</ol>
<p>了解过一些信息检索或者链接分析的朋友可能会马上想到，咦~这好像<code>Hits</code>这个算法。的确是的，在计算过程中极为相似，不过<code>Hits</code>权重主要是计算<code>Hubs</code>与<code>Authority</code>两端的权重，而[1]中迭代完得到的是各个向量，有异曲同工之妙~<br>另外在实际的query量级一般都是百万以上，这样$Query$的语料的量就很大了,而搜索引擎中需要计算的性能要求极高，，所以一般进行稀疏存储，并且只取一些重要的<code>term</code>来对$Query$进行表示</p>
<h2 id="缺少点击行为的向量计算">缺少点击行为的向量计算</h2><p>但是实际应用中用户搜索之后带来了点击行为的只是一小部分就，如果仅按照上述点击传播的方式来计算的话无query点击的文档将会将会无法得到正常的向量，同时一些新的$\hat{Query}$（从未有用户搜索过的query）也就无法得到正常的向量数据，所以需要一种对于这种缺失行为的$\hat{Query}$和$\hat{Doc}$进行向量表示估计.</p>
<p>由于在线计算相关性时对于已有行为的$Query-Doc$和缺失行为的是一视同仁的，因此为了在线计算时不应该因为训练数据产生偏差，所以需要与已有行为的$Qeury-Doc$向量在同一个空间内，同时考虑已有行为的$Query$和$Doc$的向量均已计算得到，我们还借助这些数据来预估缺失行为的向量.</p>
<h3 id="提取Unit向量">提取Unit向量</h3><p>既然未行为的$\hat{Query}$与$\hat{Doc}$之间没有任何边向量，那我们可以通过有行为的$Query$进行造边，先将$\hat{Query}$分解为各种<code>Unit</code>，这样就有$u_i \in unit(q_i)$,如果存在$Query$含有$u_i$，则将$u_i$对对应的$Query$之间形成一条虚拟的边,同时称含有$u_i$的所有$Query$的集合为$O_{u_i}$</p>
<blockquote>
<p>这里分解时可以按<code>n-gram</code>进行分解，但是某个$Query$进行分解之后不能有<code>overlap</code></p>
</blockquote>
<p><center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/absent_graph.png" width="700px"></center><br>这种边的构建方式如上图，$q_1$、$q_2$和$q_3$均都包含了<code>yahoo</code>这个词，则在他们之间形成这条虚线的边。<br>接下来我们可以理解$Query-Doc$之间的向量传播方法，我们当然也可以完成$Unit-Doc$的传播.<br>$u_i$会有$q_i$有边相连，而$q_i$与$d_i$又有变相连，因此我们可以间接认为$u_i$与$d_i$也是有边相连。<br>现假设$q_k$包含了$u_i$，同时$q_k$与$d_j$存在点击行为，$P_{i,k,j}$表示为这个二折线的权重，则该权重其实为$q_k$与$d_j$的点击次数，那么我们就会有<br>$$P_{i,j} = \sum_{k=1}^{|O_{u_i}|} P_{i,k,j}$$<br>其演示就是上图的右侧部分，<code>yahoo</code>与$d_1$之间的权重为8，与$d_2$之间的权重为5，既然到了这一步，我们就可以按照上一小节的传播方式来计算,这样就可以巧妙的得到$U_i$的向量:<br>$$U_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}P_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}P_{i,j} \cdot D_i^{n-1}$$</p>
<p>上面得到的是关于$\hat{Query}$上<code>unit</code>的向量，同样的我们也可以从$\hat{Doc}$这一侧出发，来计算$\hat{Doc}$<br>相关的<code>unit</code></p>
<h3 id="计算Unit向量权重">计算Unit向量权重</h3><p>有了<code>unit</code>的向量之后，接下来要解决的问题就是如何得到$\hat{Query}$或者$\hat{Doc}$的向量了，其实最简单的方法就是将他们各自的<code>unit</code>进行平均即可,不过[1]使用线性回来来解决该权重问题，在进行权重训练时使用最小平方差:<br>$$\underset{w}{min} \sum_{i=1}^{|T|} || T_i-\sum_{u_j \in U_{T_i}^{all}} W_j \cdot U_j||_2^2$$</p>
<blockquote>
<p>$T_i$是使用有点击行为的$Query$计算得到的向量，也就是我们所认为的<code>gold-set</code><br>这样求出来的$W$就是各个$unit_i$不同的权重</p>
</blockquote>
<h3 id="预估向量">预估向量</h3><p>根据上面两个步骤得到的<code>unit</code>的向量和权重之后，得到整体的$\hat{Query}$或者$\hat{Doc}$就很方便了，由于<code>unit</code>本身就是$\hat{Query}$或者$\hat{Doc}$分解出来的，这里基础数据也都已经计算完成了，所以直接进行加权求和即可:<br>$$q_v=\sum_{u_i \in u_q} W_iU_i$$<br>和<br>$$d_v=\sum_{u_i \in u_d} W_iU_i$$</p>
<p>这样一来缺失形式的向量数据也都可以计算出来了</p>
<h2 id="总结">总结</h2><p>该方法成功的借助了点击日志对于相关性进行估计（其实我觉得这种方式得到的文本相关性与ctr的预估会有部分重叠了），并且在实现上:</p>
<ol>
<li>已有点击数据的$Query$和$Doc$的向量直接离线就按完成</li>
<li>缺失点击的$\hat{Query}$和$\hat{Doc}$可以利用离线计算的<code>unit</code>向量在线直接进行加权求和即可</li>
<li>对于在线存储均使用稀疏方式并只存<code>top-k</code>，因此存储并不是问题</li>
<li>在线计算相关性可以直接按相似度计算，复杂度为$k log k$所以并不是很高~</li>
</ol>
<p>可实现性还是比较强的，但是对于一些未登录词就无能为力了….</p>
<blockquote>
<p>关于改算法的最终实现结果去看paper吧，效果自然是还可以的</p>
</blockquote>
<p>看了这篇paper，其实还是有点其他启发:</p>
<ol>
<li>如果搜索了query之后对于未点击的文档是不是可以进行降权（因为点击的文档是进行加权的）</li>
<li>再想想，~其实直接使用来计算文本相关性风险还是挺大</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>2016-Learning Query and Document Relevance from a Web-scale Click Graph</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br>]]>
    
    </summary>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[语言模型在信息检索中的平滑方法]]></title>
    <link href="http://kubicode.me/2016/10/24/Machine%20Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/"/>
    <id>http://kubicode.me/2016/10/24/Machine Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/</id>
    <published>2016-10-24T11:58:01.000Z</published>
    <updated>2016-11-05T16:33:15.000Z</updated>
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br><a id="more"></a><br>由于在给定$q$下，不同文档的$p(q)$是一样的，这里关注的是排序，所以可以直接将$p(q)$进行移除，另外式子右侧的$p(d)$为文档$d$对于任何$q$的相关性先验，在$p(q|d)$就是在给定$d$下生成$q$的概率，也就是文档$d$到$q$的匹配程度.<br>为了简单起见，我们假设$p(d)$是均匀分布的，这样的话$p(d)$就不会影响排序，那么信息检索的问题就会转为一个一元语言模型:<br>$$p(q|d) = \prod_i p(q_i|d)$$<br>大多数平滑的方法都会使用两类分布:</p>
<ol>
<li>一类是对于在文档中出现的词的模型$p_s(w|d)$</li>
<li>另一个是没有出现在文档中的词的模型$p_u(w|d)$</li>
</ol>
<p>这样的话在一个$q$中根据词在文档中的出现与否可以写为:<br>$$\begin{equation}\begin{split}log p(q|d)&amp;= \sum_i log p(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) - \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i|d)&gt;0} log \frac{p_s(q_i|d)}{p_u(q_i|d)} + \sum_i log p_u(q_i|d) \\<br>\end{split}\end{equation}$$</p>
<p>其中未在文档中出现的词的概率典型的表示方法就是该词在所有集合中出现的频率:<br>$$p_u(q_i|d) = \alpha_d p(q_i|C)$$</p>
<blockquote>
<p>其中$\alpha_d$为独立于文档的一个常量，$p(q_i|C)$为集合中的语言模型，这样我们就会有</p>
</blockquote>
<p>$$log p(q|d) = \sum_{i:c(q_i:d)&gt;0} log \frac{p_s(q_i|d)}{\alpha_d p(q_i|C)} + n log \alpha_d + \sum_i log p(q_i|C)$$</p>
<blockquote>
<p>其中$n$为$q$的长度，上面式子的右侧与$d$并没有关系，所以直接去掉也不会影响排序</p>
</blockquote>
<p>这样的话检索函数就变成了两部分，第一部分为$q$与$d$相匹配<code>term</code>的权重，第二部分为与$q$无关的一个常量，一般是用于对非匹配<code>term</code>的平滑。</p>
<p>这时候再看下第一部分，其实可以上面$p(q_i|C)$大致可以看为<code>IDF</code>,而$p_s(q_i|d)$又非常向tf,因为上面的Language Model与<code>tf*idf</code>路线还是挺像的。</p>
<h2 id="Smoothing_Methods">Smoothing Methods</h2><p>看了上面的描述，接下来主要讲一下对于$p(w|d)$的估计，最简单的使用数数的方式，最大似然法进行估计为:<br>$$p_{ml}(w|d) = \frac{w;d}{\sum_w c(w;d)}$$</p>
<blockquote>
<p>其实就是词在文档中出现的频率</p>
</blockquote>
<p>这种方式对于没出现在文档中的词将会低估（其实就是没值了），因为对于没有在文档中出现的词会给予一个非0概率的平滑。<br>通常我们会对出现在文档中的词的概率进行一个折损，同时对于未出现在文档中的词的概率给予一个额外的值:<br>$$ p(w|d)=\left\{<br>\begin{aligned}<br>p_s(w|d) &amp; \quad if \quad word \quad w \quad is \quad seen \\<br>\alpha_d p(w|C) &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>同时$\alpha_d$将会依赖$d$，如果$p(w|d)$给定的情况下，我们将会有:<br>$$\alpha_d = \frac{1-\sum_{w:c(w:d)&gt;0} p_s(w|d)}{1-\sum_{w:c(w:d)&gt;0}p(w|C)}$$</p>
<p>因此这里最大的问题是需要计算$p_s(w|d)$,因为在信息检索中对于性能的要求将其高，因此为考虑性能和效果，下面主要简单的介绍三种平滑方式</p>
<h3 id="Jelinek-Mercer">Jelinek-Mercer</h3><p>这种方式是融合了最大似然发以及一个置信因子来控制各个模型<br>$$p_{\lambda} = (1-\lambda)p_{ml}(w|d) + \lambda p(w|C)$$</p>
<blockquote>
<p>这种方式非常的高效</p>
</blockquote>
<h3 id="Dirichlet">Dirichlet</h3><p>他其实是贝叶斯平滑，然后使用了<code>Dirichlet</code>先验，使用这种可以得到<br>$$p_{\mu}(w|d) = \frac{c(w;d) + \mu p(w|C)}{\sum_w c(w;d)+ \mu}$$</p>
<h3 id="Absolute_discount">Absolute discount</h3><p>这种方式主要是通过降低可见词的概率来完成的,类似<code>Jelinek-Mercer</code>方法,与$1-\lambda$不同的是  使用减去一个常量来完成:<br>$$p_{\delta } = \frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \sigma p(w|C)$$</p>
<blockquote>
<p>其中$\delta \in [0,1]$,为一个折损常量，$\sigma = \delta|d|_u/|d|$,所以所有的概率之和为1，$|d|_u$为文档中不同<code>term</code>的数量,$|d|$为文档中<code>term</code>的总数量</p>
</blockquote>
<p>另外注意$max(c(w:d)-\delta,0)$中的$c(w:d)$应该是归一化0~1了，这样才可以和$\delta$相减</p>
<p>对于这三种平滑方式的一个表格表示（非常清晰）:</p>
<table>
<thead>
<tr>
<th style="text-align:center">平滑方法</th>
<th style="text-align:center">$p_s(w &#124; d)$</th>
<th style="text-align:center">$\alpha_d$</th>
<th style="text-align:center">参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Jelinek-Mercer</code></td>
<td style="text-align:center">$(1-\lambda)p_{ml}(w &#124; d) + \lambda p(w &#124; C)$</td>
<td style="text-align:center">$\lambda$</td>
<td style="text-align:center">$\lambda$</td>
</tr>
<tr>
<td style="text-align:center"><code>Dirichlet</code></td>
<td style="text-align:center">$\frac{c(w;d) + \mu p(w &#124; C)}{\sum_w c(w;d)+ \mu}$</td>
<td style="text-align:center">$\frac{\mu}{\sum_w c(w;d)+\mu}$</td>
<td style="text-align:center">$\mu$</td>
</tr>
<tr>
<td style="text-align:center"><code>Absolute discount</code></td>
<td style="text-align:center">$\frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} p(w &#124; C)$</td>
<td style="text-align:center">$\frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} $</td>
<td style="text-align:center">$\delta$</td>
</tr>
</tbody>
</table>
<p>看上面三种平滑的计算方式都是非常的简单，并且$\alpha$都是可以离线计算，其最终的复杂度为$O(k|q|)$,$k为文档的平均长度$</p>
<blockquote>
<p>其实复杂度不用这么多，如果在线查找term时使用二分的话  复杂度仅为$O(log(k)|q|)$</p>
</blockquote>
<h2 id="总结">总结</h2><p>这三种方法比较经典，并且可实现性强，$p_s(w|d)$和$\alpha_d$全部都可以离线计算完成，在线只需要进行简单的求和即可,值得一试~</p>
<h2 id="参考">参考</h2><ol>
<li>Zhai, Chengxiang, and John Lafferty. “A study of smoothing methods for language models applied to ad hoc information retrieval.” Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2001.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Python画ROC曲线以及AUC值]]></title>
    <link href="http://kubicode.me/2016/09/19/Machine%20Learning/AUC-Calculation-by-Python/"/>
    <id>http://kubicode.me/2016/09/19/Machine Learning/AUC-Calculation-by-Python/</id>
    <published>2016-09-18T16:02:43.000Z</published>
    <updated>2016-09-18T16:39:41.000Z</updated>
    <content type="html"><![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/" target="_blank" rel="external">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br><a id="more"></a></p>
<h2 id="AUC计算">AUC计算</h2><p><code>AUC</code>的计算分为下面三个步骤：</p>
<ol>
<li>计算数据的准备，如果模型训练时只有训练集的话一般使用交叉验证的方式来计算，如果有评估集(<code>evaluate</code>)一般就可以直接计算了，数据的格式一般就是需要预测得分以及其目标类别（注意是目标类别，不是预测得到的类别）</li>
<li>根据阈值划分得到横（X:<code>False Positive Rate</code>）以及纵（Y:<code>True Positive Rate</code>）点</li>
<li>将坐标点连成曲线之后计算其曲线下面积,就是<code>AUC</code>的值</li>
</ol>
<p>直接上python代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! -*- coding=utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log,exp,sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluate_result=<span class="string">"you file path"</span></span><br><span class="line">db = []  <span class="comment">#[score,nonclk,clk]</span></span><br><span class="line">pos, neg = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">with</span> open(evaluate_result,<span class="string">'r'</span>) <span class="keyword">as</span> fs:</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">		nonclk,clk,score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		nonclk = int(nonclk)</span><br><span class="line">		clk = int(clk)</span><br><span class="line">		score = float(score)</span><br><span class="line">		db.append([score,nonclk,clk])</span><br><span class="line">		pos += clk</span><br><span class="line">		neg += nonclk</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">db = sorted(db, key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算ROC坐标点</span></span><br><span class="line">xy_arr = []</span><br><span class="line">tp, fp = <span class="number">0.</span>, <span class="number">0.</span>			</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(db)):</span><br><span class="line">	tp += db[i][<span class="number">2</span>]</span><br><span class="line">	fp += db[i][<span class="number">1</span>]</span><br><span class="line">	xy_arr.append([fp/neg,tp/pos])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算曲线下面积</span></span><br><span class="line">auc = <span class="number">0.</span>			</span><br><span class="line">prev_x = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> xy_arr:</span><br><span class="line">	<span class="keyword">if</span> x != prev_x:</span><br><span class="line">		auc += (x - prev_x) * y</span><br><span class="line">		prev_x = x</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"the auc is %s."</span>%auc</span><br><span class="line"></span><br><span class="line">x = [_v[<span class="number">0</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">y = [_v[<span class="number">1</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">pl.title(<span class="string">"ROC curve of %s (AUC = %.4f)"</span> % (<span class="string">'svm'</span>,auc))</span><br><span class="line">pl.xlabel(<span class="string">"False Positive Rate"</span>)</span><br><span class="line">pl.ylabel(<span class="string">"True Positive Rate"</span>)</span><br><span class="line">pl.plot(x, y)<span class="comment"># use pylab to plot x and y</span></span><br><span class="line">pl.show()<span class="comment"># show the plot on the screen</span></span><br></pre></td></tr></table></figure></p>
<p>输入的数据集可以参考<a href="/img/AUC-Calculation-by-Python/evaluate_result.txt">svm预测结果</a><br>其格式为:</p>
<pre><code>nonclk <span class="string">\t</span> clk <span class="string">\t</span> score
</code></pre><p>其中：</p>
<ol>
<li><code>nonclick</code>:未点击的数据，可以看做负样本的数量</li>
<li><code>clk</code>:点击的数量，可以看做正样本的数量</li>
<li><code>score</code>:预测的分数，以该分数为group进行正负样本的预统计可以减少<code>AUC</code>的计算量</li>
</ol>
<p>运行的结果为:</p>
<center><img src="/img/AUC-Calculation-by-Python/auc.png" width="500px"></center>


<blockquote>
<p>如果本机没安装<code>pylab</code>可以直接注释依赖以及画图部分</p>
</blockquote>
<h2 id="注意">注意</h2><p>上面贴的代码:</p>
<ol>
<li>只能计算二分类的结果（至于二分类的标签随便处理）</li>
<li>上面代码中每个<code>score</code>都做了一次阈值，其实这样效率是相当低的，可以对样本进行采样或者在计算横轴坐标时进行等分计算</li>
</ol>
<h2 id="参考">参考</h2><ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm" target="_blank" rel="external">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm</a></li>
</ul>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LambdaRank-支持非平滑损失函数的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/08/28/Machine%20Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/"/>
    <id>http://kubicode.me/2016/08/28/Machine Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/</id>
    <published>2016-08-28T14:44:59.000Z</published>
    <updated>2016-09-06T15:59:12.000Z</updated>
    <content type="html"><![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br><a id="more"></a></p>
<p><center><img src="/img/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/rank.png" alt=""><br>图1</center><br>如图1，每个线条表示一个文档，位置越上面表示排序越靠前，其中蓝色线条表示相关的文档，灰色则是不相关的文档，计算左侧得到的<code>Pairwise Error</code>为13，此时将最上面的蓝色线条下移3个位置，将下面的蓝色线条上移5个位置，则其<code>Pairwise Error</code>下降到了11。然而传统的排序评估指标<code>NDCG</code>或者<code>ERR</code>都是比较关心靠前的位置，类似刚刚右侧的变化并不希望出现。<br>而<code>LambdaRank</code>可以支持对这种非平滑的评估指标(比如<code>NDCG</code>)进行直接的优化.</p>
<h2 id="LambdaRank原理">LambdaRank原理</h2><p>在图1右侧中，我们用$D_i$和$D_j$分别表示上下两个相关的文档，对于训练时下一次的移动中，我们更加愿意看到红色箭头的变化，因为此时$D_i$移动头部比$D_j$移动到头部明显代价更小，并且同样能减少损失函数.<br>对于$i &lt;&lt; j$这种情况($D_i$排在前面)，<code>LambdaRank</code>将会有:<br>$$|\frac{\partial C}{\partial o_i}| &gt;&gt; |\frac{\partial C}{\partial o_j}|$$</p>
<p>同时，<code>LambdaRank</code>并不是显示对的优化函数进行求导在求最优，而是<br>$$\frac{\partial C}{\partial o_i} = -\lambda_i(o_1,l_1…o_n,l_n)$$，</p>
<blockquote>
<p>$o_i$表示给定query下文档的打分值,$l_i$表示该文档对应的标签</p>
</blockquote>
<p>可以看到这个梯度是依赖<code>query</code>下全部文档的分数以及其标签,这也应该是算一个<code>ListWise</code>的学习方法了,其中式子中带了符号表示$\lambda_i$为正数时将会在排序列表中向上移动同时会降低损失函数的值.<br>那么问题来了，这个$\lambda$函数该如何选呢?</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的神经网络加速算法中，其<br>$$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} =  -\frac{1}{1+e^{o_i-o_j}} $$</p>
<blockquote>
<p>这里目标概率$\overline{P}_{i,j}=1$</p>
</blockquote>
<p><code>LambdaRank</code>的机智之处就是在计算$\lambda_{i,j}$的时候引入了优化指标的梯度,变成了<br>$$\lambda_{i,j} =  -\frac{1}{1+e^{o_i-o_j}} |\Delta Z|$$<br>其中$\Delta Z$表示将文档$D_i$和$D_j$的位置相关调换之后重新计算得到的评估指标的差值（此时其他的文档顺序是不变的）<br>即可从新计算得到$\lambda_i$为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$<br>这个$\lambda$可以理解为上面图中的箭头<code>方向和强度</code></p>
<ol>
<li>符号表示方向，正好为向上移动</li>
<li>大小表示强度，绝对值越大，表示移动的距离越大</li>
</ol>
<p>接下来<code>LambdaRank</code>具体的训练和使用方式就即可和<code>RankNet</code>一致了.</p>
<p>这个的$\Delta Z$可以替换成任何评估指标(比如<code>NDCG</code>、<code>ERR</code>)了，这样的话其实$LambdaRank$就可以变相的直接对学习排序的评估指标进行优化了，解决了之前评估指标由于是非凸无法进行优化的问题</p>
<blockquote>
<p>这个具体的证明要看去原始paper了[1],是一个不是很容易理解的东西 -_-||</p>
</blockquote>
<h2 id="总结">总结</h2><p>$LambdaRank$其实是做了两个大贡献:</p>
<ol>
<li>一是对传统的<code>RankNet</code>提出了一个加速算法（我直接将其丢了<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的学习中）</li>
<li>二是在<code>RankNet</code>的优化目标的基础上添加了一个基于评估指标的梯度$\Delta Z$因子，可以变相的直接对学习排序的评估指标进行优化</li>
</ol>
<p>虽然貌似没有见一些其他工业上说明使用了该算法，但是该算法对于鼎鼎大名的<code>LambdaMart</code>的启发无疑是最大的。</p>
<h2 id="参考">参考</h2><ol>
<li>Schölkopf, B, Platt, J, Hofmann, T. Learning to Rank with Nonsmooth Cost Functions[C]// MIT Press, 2007:193 - 200.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankNet:基于梯度下降的学习排序]]></title>
    <link href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/"/>
    <id>http://kubicode.me/2016/05/30/Machine Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/</id>
    <published>2016-05-30T11:51:21.000Z</published>
    <updated>2016-09-22T17:33:19.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>
<a id="more"></a>
<p>我们现在将$P(D_i \triangleright D_j)$前后顺序的预测概率表示为$P_{i,j}$,同时定义$o_i \equiv f(x_i)$ 以及 $o_{i,j}=f(x_i)-f(x_j)$，则我们可以<code>logistic</code>函数来表示$P_{i,j}$:<br>$$P_{i,j} \equiv \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} \equiv \frac{1}{1+e^{-o_{i,j}}}$$</p>
<p>为了衡量预测概率$P_{i,j}$与期望/目标概率$\bar{P}_{i,j}$的接近程度，这里使用<code>Cross Entropy</code>作为损失函数:<br>$$C_{i,j} = -\bar{P}_{i,j} log P_{i,j} - (1-\bar{P}_{i,j}) log (1-P_{i,j})$$</p>
<p>将$P_{i,j}$代入损失函数$C_{i,j}$之后即可得到:<br>$$\begin{equation}\begin{split}C_{i,j}&amp;=-\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (1-\frac{e^{o_{i,j}}}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (\frac{1}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} \left( log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - log (\frac{1}{1+e^{o_{i,j}}}) \right) - log (\frac{1}{1+e^{o_{i,j}}})  \\<br>&amp;= -\bar{P}_{i,j}  o_{i,j} + log(1+e^{o_{i,j}})<br>\end{split}\end{equation}$$</p>
<p>下面的图是当$\bar{P}_{i,j} \in \{0,0.5,1\}$时的损失函数情况:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/lossfunction.png" style="align:center;margin:0 auto" width="400px"></p>
<p>当$\bar{P}_{i,j} = 1$的时候，<code>Cross Entropy</code>的损失函数将会变为:$$C_{i,j}=log(1+e^{-o_{i,j}})$$<br>直接会变为一个<code>log</code>型的损失函数，其中$o_i-o_j$越大，损失函数的值也就会越小，这也是我们所期望训练的结果(表示我们的样本全部成立)</p>
<p>现我们损失函数$C_{i,j}$求$o$的偏导:<br>$$\frac{ \partial{C}}{ \partial{o_i}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) =\left( -\bar{P}_{i,j}+P_{i,j} \right) = -\frac{ \partial{C}}{ \partial{o_j}}$$</p>
<blockquote>
<p>其实可以发现就是在$-\bar{P}_{i,j}+P_{i,j}=0 $时就是我们的目标<br>另外请注意这里的$P_{i,j}$其实就是<code>文献2</code>中的$S_{i,j}$，但是由于他们的取值范围不一致 $P_{i,j} \in \{0,0.5,1\}$,$S_{i,j} \in \{-1,0,1\}$，因此导致了<code>文献2</code>中对于<code>C</code>的偏导与本文的有微小的偏差</p>
</blockquote>
<p>现我们认为$w$为$o=f(x:w)$的一个权重,也就是我们最终希望求解的值，而这个参数我们就可以使用<code>随机梯度下降法来求解</code>:<br>$$w_k \rightarrow  w_k - \eta \frac{\partial{C}}{\partial{w_k}} = w_k - \eta \left( \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}} \right)$$</p>
<p>其中$\eta$表示学习率，一般取一个比较小的数（比如:$1e-3$,$1e-5$）<br>另外我们可以求得$C$的增量变化:<br>$$\Delta C = \sum_k \frac{\partial{C}}{\partial{w_k}} \Delta w_k = \sum_k \frac{\partial{C}}{\partial{w_k}} \left( - \eta \frac{\partial{C}}{\partial{w_k}} \right) = - \eta \sum_k \left( \frac{\partial{C}}{\partial{w_k}} \right)^2  &lt; 0 $$</p>
<ol>
<li>$\Delta C &lt; 0 $表示随着权重参数$w$的沿着负梯度的变化，损失函数$C$会越来越小</li>
<li>另外当梯度$\frac{\partial{C}}{\partial{w_k}} = 0$时，才会让损失函数达到最小值</li>
</ol>
<p>上面的式子告诉我们通过梯度下降法求解<code>RankNet</code>时，就算<code>算分</code>函数没有好的梯度或者不可求导时任可以进行权重的更新（直接对$o$进行梯度下降，但是其梯度方向需要自己指定，并且要求权重$w$与最终的算法$o$是相关的）。</p>
<h2 id="合并概率">合并概率</h2><p>理想的情况下，$\bar{o}$的输出得到的模型应该是这样纸的:$$\bar{P}_{i,j}=\frac{e^{\bar{o}_{i,j}}}{1+e^{\bar{o}_{i,j}}}$$</p>
<blockquote>
<p>其中$\bar{o}_{i,j}=\bar{o}_i-\bar{o}_j$</p>
</blockquote>
<p>上面的模型需要$\bar{P}_{i,j}$保持一致性，也就是如果$D_i$的相关性要高于$D_j$,$D_j$的相关性同时也是要高于$D_k$，则$D_i$的相关性也是一定要高于$D_j$，如果没有保持一致性，其实上面的理论就不好使了。。。<br>现给定$\bar{P}_{i,j}$和$\bar{P}_{j,k}$时会有:</p>
<p>$$\begin{equation}\begin{split} \bar{P}_{i,k}&amp;= \frac{e^{\bar{o}_{i,k}}}{1+e^{\bar{o}_{i,k}}}\\<br>&amp;= \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}} \\<br>&amp;= \frac{ \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})} }{ \frac{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{\frac{(1+e^{\bar{o}_{i,j}}+e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})+(2e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{i,j}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{1+2\bar{P}_{i,j}\bar{P}_{j,k}-\bar{P}_{i,j}-\bar{P}_{j,k}}<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>其中第一步是基于这个来的:$$\begin{equation}\begin{split}e^{\bar{o}_{i,k}}&amp;=e^{\bar{o}_i-\bar{o}_k} \\<br>&amp;= e^{\bar{o}_i-\bar{o}_j+\bar{o}_j-\bar{o}_k}\\<br>&amp;= e^{\bar{o}_{i,j}+\bar{o}_{j,k}}  \\<br>&amp;= e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}}<br>\end{split}\end{equation}$$</p>
</blockquote>
<p>当$\bar{P}_{i,j}=\bar{P}_{i,k}=P$时，其$\bar{P}_{i,k}$的取值情况为:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/pik.png" width="400px"></p>
<ol>
<li>$P=0$时，有$\bar{P}_{i,k}=P=0$ 表示:$D_i$排$D_j$后面,$D_j$排$D_j$的后面，则$D_i$也一定排$D_j$的后面</li>
<li>$0 &lt; P &lt; 0.5$时，$\bar{P}_{i,k} &lt; P$</li>
<li>$P=0.5$时，有$\bar{P}_{i,k}=P=0.5$ 表示:$D_i$有一般概率排$D_j$前面,$D_j$也有一半的概率排$D_j$的前面，则$D_i$同样也是一半的概率排$D_j$的前面</li>
<li>$0.5 &lt; P &lt; 1$时，$\bar{P}_{i,k} &gt; P$</li>
<li>$P=1$时，有$\bar{P}_{i,k}=P=1$ 表示:$D_i$排$D_j$前面,$D_j$排$D_j$的前面，则$D_i$也一定排$D_j$的前面</li>
</ol>
<blockquote>
<p>从上面的图中可以看到，其实目标概率是都可以保持一致性的.</p>
</blockquote>
<h2 id="神经网络训练">神经网络训练</h2><p><code>RankNet</code>使用的是一个2层的神经网络作为算分模型$f(x:w,b)$,他在排序分数的公式是:<br>$$o = f(x:w,b) = f^{(2)}  \left( \sum_l w_l^{(2)} \cdot f^{(1)}  \left( \sum_k w_{lk}^{(1)}x_k +b^{(1)} \right) +b^{(2)} \right)$$</p>
<p>其中:</p>
<ol>
<li>$x_k$表示输入的$k$个特征元素</li>
<li>$w$表示每一层的权重,$b$表示每一层的偏置，上标$(\cdot)$表示当前所属的神经网络的层数</li>
<li>下标$l$表示第一层的单元数量</li>
<li>$f$使用<code>sigmoid</code>作为激活函数</li>
</ol>
<p>在对于上面的二层神经网络求解时:<br>$$\frac{\partial{C}}{\partial{b^{(2)}}} = \lambda_{i,j}({f’}_i^{(2)}-{f’}_i^{(2)}) = \Delta_i^{(2)} - \Delta_j^{(2)} \\<br>\frac{\partial{C}}{\partial{w^{(2)}}} = \Delta_i^{(2)}f_i^{(1)}  - \Delta_j^{(2)}f_j^{(1)} \\<br>\frac{\partial{C}}{\partial{b^{(1)}}} = \Delta_i^{(2)}f_i^{(1)}w^{(2)}   - \Delta_j^{(2)}f_j^{(1)}w^{(2)} \\<br>\frac{\partial{C}}{\partial{w_k^{(1)}}} = \Delta_i^{(2)} x_{i,k} - \Delta_j^{(2)} x_{j,k}<br>$$<br>这样神经网络就可以使用<code>前向预测</code>和<code>后向反馈</code>来进行训练了,只是其后向反馈阶段是需要通过<code>pair</code>进行计算的。</p>
<h2 id="神经网络加速">神经网络加速</h2><p>这里我们输入的样本是<code>pair</code>对$\{(x_i,x_j),\bar{P}_{i,j}\}$,其中$\bar{P}_{i,j}$就是我们的目标概率,根据第一小节(算法原理)中指到的，使用梯度下降法进行求解:<br>$$\begin{equation}\begin{split} \frac{\partial{C}}{\partial{w_k}} &amp;= \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}}  \\<br>&amp;=  \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right)\\<br>&amp;=  \lambda_{i,j} \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right) \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>记$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) $</p>
</blockquote>
<p>上面的是对于每一对<code>pair</code>都会进行一次权重的更新，其实是可以对同一个query下的所有文档<code>pair</code>全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数，其更新的公式为:</p>
<p>$$\Delta w_k = -\eta \sum_{\{i,j\}\in I}  \left(\lambda_{i,j} \frac{\partial{o_i}}{\partial{w_k}} - \lambda_{i,j} \frac{\partial{o_j}}{\partial{w_k}}\right) = -\eta \sum_i \lambda_i \frac{\partial{o_i}}{\partial{w_k}} $$</p>
<blockquote>
<p>$I$表示某个<code>query</code>下所有不同排序的<code>pair</code>出现一次的集合，$\{i,j\}$表示两个文档满足$D_i \triangleright D_j$,也就是$\bar{P}_{i,j}=1$</p>
</blockquote>
<p>这里要着重介绍一下$\lambda_i$:</p>
<p>$\lambda$可以理解为某个给定query（给定排序）下第$i$个文档$D_i$的一个<code>值</code>,为了计算$\lambda_i$，需要找到这个排序下所有排在$D_i$前面的文档$D_j$（此时有$\{i,j\} \in I$），以及所有排在$D_i$后面的文档$D_k$（有$\{k,i\} \in I$）,同时针对$\lambda_{i,j}$的文档进行累加，对于$\lambda_{k,i}$的文档进行累减.</p>
<blockquote>
<p>比如  当前排序下只有一个pair,有$I=\{\{1,2\}\}$，则有$\lambda_1 = \lambda_{1,2} = -\lambda_2$<br>又比如，当前排序下有三个pair，有$I=\{\{1,2\},\{1,3\},\{2,3\}\}$,则有$\lambda_1 = \lambda_{1,2}+\lambda_{1,3}$、$\lambda_2 = \lambda_{2,3}-\lambda_{1,2}$、$\lambda_3 = -\lambda_{1,3}-\lambda_{2,3}$</p>
</blockquote>
<p>对于表示成式子为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$</p>
<p>因此，我们可以认为$\lambda_i$为在某个给定<code>query</code>的$D_i$需要移动的方向以及移动的强度,另外这种方式可以看做是一种mini-batch的梯度下降算法，不要将全部的<code>pair</code>进行反向传播,其复杂度可以降到$O(n_q)$可以大大加快原始的神经网络训练.这也为<code>LambdaRank</code>奠定了基础（其实很多在<code>LambdaRank</code>的paper提出来的）</p>
<h2 id="总结">总结</h2><p><code>RankNet</code>训练希望文档<code>pair</code>对的前后排序概率与目标概率一致，用交叉熵作为损失函数，在实际排序中使用了神经网络作为算分排序函数，同时可以有<code>min-batch</code>的批量训练方法。据说微软的<code>Bing</code>之前使用着他.</p>
<h2 id="参考">参考</h2><ol>
<li>Burges, Chris, et al. “Learning to rank using gradient descent.” Proceedings of the 22nd international conference on Machine learning. ACM, 2005.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GBRank:一种基于回归的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/05/08/Machine%20Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/"/>
    <id>http://kubicode.me/2016/05/08/Machine Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/</id>
    <published>2016-05-08T09:30:39.000Z</published>
    <updated>2016-05-08T15:27:47.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting" target="_blank" rel="external">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/" target="_blank" rel="external">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br><a id="more"></a></p>
<p>从$R(h)$可以知道知道每个<code>pair</code>对$\left \langle x_i,y_i \right \rangle$的cost为:</p>
<p><center><img src="/img/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/cost_function.png" width="400px"></center><br>可以发现当:</p>
<ol>
<li>$h(x_i) \geq h(y_i)$，cost代价为0，也就是并不会对最终的风险函数的值产生影响</li>
<li>$h(x_i) &lt; h(y_i)$，cost代价为其差值的平方</li>
</ol>
<p>上述风险函数直接优化比较困难，这里一个巧妙的解决方案时使用回归的方法，也就是$x_i$或者$y_i$去拟合他们另个预测值目标。<br>为了避免优化函数$h$是一个常量，风险函数一般情况下会加上一个平滑项$\tau$($0 &lt; \tau \leq 1$)：$$R(h,\tau ) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)+\tau \} \right)^2 -\lambda \tau^2 $$</p>
<blockquote>
<p>因为当$h$为常量函数时，先前的$R(h)=0$就没有再优化的空间了<br>其实加了平滑项就变相的转为:如果希望$x_i \succ y_i$，就得有$h(x_i) &gt; h(y_i)+\tau$，也就是更为严格了，多了一个<code>gap</code></p>
</blockquote>
<p>对于$R(h)$计算$h(x_i)$和$h(y_i)$的负梯度为:$$max\{0,h(y_i)-h(x_i)\} \quad,\quad -max\{0,h(y_i)-h(x_i)\}$$<br>可以发现当<code>pair</code>对符合$\left \langle x_i,y_i \right \rangle$的顺序时，上述的梯度均为0，对于这类<code>case</code>就没有必要在去优化了(以为已经满足目标了)，但是对于另一类，如果$h$不满足<code>pair</code>$\left \langle x_i,y_i \right \rangle$，他们对应的梯度为:$$h(y_i)-h(x_i) \quad,\quad h(x_i)-h(y_i)$$</p>
<blockquote>
<p>因为此时$h(y_i)&gt;h(x_i)$<br>还有对于上面两个梯度的后面那个式子存在的意义不是很理解-_-</p>
</blockquote>
<p>到了这儿，我们知道所谓的训练样本就是对于$x_i \succ y_i$但是$h(y_i) &gt; h(x_i)$，并且使用的是回归方法，<code>GBRank</code>为其巧妙的找了训练的目标:$x_i$的目标为$h(y_i)+ \tau$以及$y_i$的目标为$h(x_i)- \tau$，也就是在每次迭代是将会构建以下训练集:$$\{(x_i,h(y_i)+\tau),(y_i,h(x_i)-\tau)\}$$</p>
<h2 id="算法步骤">算法步骤</h2><p><code>GBRank</code>使用<code>GBT</code>为回归函数，所以整个<code>GBRank</code>的算法过程为:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集,真实的排序pair对$S=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>迭代的次数:$K$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$h(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>随机初始化为一个函数$h_o$</li>
<li>循环$k \in \{1….K\}$<ol>
<li>使用$h_{k-1}$作为近似的$h$函数,我们将对样本的计算结果分到两个不相交的集合:$$S^+=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) \geq h_{k-1}(y_i)+\tau \}$$和$$S^-=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) &lt; h_{k-1}(y_i)+\tau \}$$</li>
<li>使用<code>GBT</code>对下面的数据集拟合一个回归函数$g(x)$:$$\{(x_i,h_{k-1}(y_i)+\tau),(y_i,h_{k-1}(x_i)-\tau) | (x_i,y_i) \in S^- \}$$</li>
<li>进行模型的更新:$$h_k(x) = \frac{kh_{k-1}(x)+\eta g_k(x)}{k+1}$$其中$\eta$为收缩因子</li>
</ol>
</li>
<li>输出最终的模型$h_k(x)$</li>
</ol>
<blockquote>
<p>注意了，其实这里的回归函数还可以使用其他的回归函数来代替，比如$Linear Regression$之类的</p>
</blockquote>
<h2 id="总结">总结</h2><p>$h(x)$为最终的排序函数，<code>GBRank</code>在训练时每次迭代中将$h_k(x)$的排序结果与真实结果不一样的样本（就是分错的样本）单独拿出来做训练样本，并且其训练目标为<code>pair</code>的另一个预测值作为回归目标，非常巧妙。<br>此时重新看这个<code>GBRank</code>模型与<code>AdaBoost</code>、<code>GBT</code>其实很大同小异，都是将上一次训练中分错的样本再拿来训练，也是一个提升的模型</p>
<p>在其paper中的实验结果也是要略好于$RankSvm$，但是其比较疼的时其训练还是比较复杂的，或者说比较耗时,其预测也会比较麻烦一点，所以使用时得慎重~</p>
<h2 id="参考">参考</h2><p>[1]. 2007-GBRank-A Regression Framework for Learning Ranking Functions Using Relative Relevance Judgments</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在CentOS上自己安装python]]></title>
    <link href="http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/"/>
    <id>http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/</id>
    <published>2016-04-29T07:50:41.000Z</published>
    <updated>2016-08-29T08:22:44.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id="下载python2-6-5">下载python2.6.5</h3><p>直接在这个地址进行下载即可<a href="https://www.python.org/download/releases/2.6.5/" target="_blank" rel="external">https://www.python.org/download/releases/2.6.5/</a></p>
<h3 id="进行解压">进行解压</h3><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">tar</span> xvf Python-<span class="number">2</span>.<span class="number">6</span>.<span class="number">5</span>.tgz</span><br></pre></td></tr></table></figure>
<h3 id="编译安装">编译安装</h3><p>先配置安装的前缀<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.<span class="regexp">/configure --prefix=/u</span>sr<span class="regexp">/local/</span>python2.<span class="number">6.5</span></span><br></pre></td></tr></table></figure></p>
<p>然后真正的执行编译安装<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make</span></span><br><span class="line"><span class="built_in">make</span> install</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意如果是非管理员用户 请在两个<code>make</code>前面都加上<code>sudo</code></p>
</blockquote>
<h3 id="添加快捷方式">添加快捷方式</h3><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -sf <span class="regexp">/usr/</span>local<span class="regexp">/python2.6.5/</span>bin<span class="regexp">/python /u</span>sr<span class="regexp">/bin/</span>python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果原来快捷方式存在  那么先删除，再添加</p>
</blockquote>
<h3 id="完工">完工</h3><pre><code><span class="keyword">python</span> --<span class="keyword">version</span>
Python <span class="number">2.6</span>.<span class="number">5</span> 
</code></pre><h3 id="参考">参考</h3><p><a href="http://blog.csdn.net/jationxiaozi/article/details/7665691" target="_blank" rel="external">CentOS5.5下安装python2.6</a>   实用，但是排版太难看了-_-</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id=]]>
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从Gradient Boosting 到GBT]]></title>
    <link href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/"/>
    <id>http://kubicode.me/2016/04/24/Machine Learning/From-Gradient-Boosting-to-GBT/</id>
    <published>2016-04-24T15:51:08.000Z</published>
    <updated>2016-05-02T15:48:21.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br><a id="more"></a></p>
<p>现在假如训练完$G_{m+1}$可以得到完美的$f_{m+1}$，那么也就是有:$$f_{m+1} = f_m+G_{m+1}=y$$<br>这个式子可以写成$$G_{m+1}=y-f_m$$ 其中$y-f_m$表示上一次迭代得到分类器预测结果与真实结果的差值，我们一般称之为的<code>残差</code>(residual)，因此也可以理解为<code>Gradient Boosting</code>在每一轮训练新的分类器将会拟合<code>残差</code>进行最优化</p>
<h2 id="Gradient_Boosting算法">Gradient Boosting算法</h2><p>假设现有训练集$\left\{ (x_1,y_1),(x_2,y_2)…(x_n,y_n)  \right\}$，其中$x$是特征向量，$y$是相应的训练目标，在给定相应的损失函数$L(y,f(x))$,我们的目标是找到一个近似的函数$f(x)$使得与真实函数$f^*(x)$的损失最小期望值最接近:$$f^* = \underset{f}{argmin} E_{x,y} \left[ L(y,f(x)) \right]$$</p>
<p><code>Gradient Boosting</code>方法假设$y$是一个实值，而$f(x)$近似目标函数是一个弱分类器$G_m(x)$加权求和的形式$$f(x)=\sum_{m=1}^M \gamma_mG_m(x)+const$$ 根据经验风险最小化的原则，近似函数$f(x)$将会尝试对训练集上的平均损失函数进行最小化，它从一个常量函数进行起步，并且通过贪心的方式进行逐步优化<br>$$<br>f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) \\<br>f_m(x) = f_{m-1}(x) + \underset{G \in H}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+G_m(x_i) \right)<br>$$<br>然而，对于$L$为任意的损失函数时,在选择每一步最佳的$G_m(x_i)$时将会很难优化。<br>这里使用最速下降法(<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">steepest descent</a>)来解决这个问题<br>,在使用这种方法时，对于损失函数$L(y,G)$不要将其看做一个函数，而是将其看做通过函数得到的值的向量$G(x_1),G(x_2)…G(x_n)$,那么这样的话我们就可以将模型的式子写成如下的等式:<br>$$<br>f_m(x) = f_{m-1}(x) - \gamma_m \sum_{i=1}^n \triangledown_G L \left( y_i,f_{m-1}(x_i) \right) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left ( y_i,f_{m-1}(x_i)-\gamma \frac{\partial L(y_i,f_{m-1}(x_i))}{\partial G(x_i)}  \right )<br>$$<br>上面第一个式子表示根据梯度的负方向进行更新,第二个式子表明了$\gamma$使用线性搜索进行计算。</p>
<p>下面就是具体的<code>gradient boosting</code>步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>可导的损失函数:$L(y,f(x))$</li>
<li>迭代的次数:$M$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$f(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>使用一个常量进行模型的初始化$$f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) $$</li>
<li>循环$m \in \{1….M\}$<ol>
<li>计算残差$$r_{im}=-\left[ \frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}  \right]_{f(x_i)=f_{m-1}(x_i)} \quad i=1…n$$</li>
<li>使用训练集$\{ (x_i,r_{im}) \}$对弱分类器$G_m(x)$进行拟合</li>
<li>通过线性搜索进行乘子$\gamma_m$的计算$$\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)$$</li>
<li>进行模型的更新:$$f_m(x) = f_{m-1}(x)+\gamma_m G_m(x)$$</li>
</ol>
</li>
<li>输出最终的模型$f_M(x)$</li>
</ol>
<p>下面是来自[2]中的对于不同损失函数下不同残差的计算<br><img src="/img/From-Gradient-Boosting-to-GBT/loss_functions.png" width="500px"><br>可以发现当损失函数为最小平方差时残差就是真实值与预测值的差值</p>
<h2 id="Gradient_tree_boosting">Gradient tree boosting</h2><p>提升树(Gradient tree boosting)故名思议就是使用决策树(一般使用<code>CART</code>树)来作为弱分类器.<br>提升树在第$m$步迭代时将会使用决策树$G_m(x)$来集合残差，现在假设这棵树有$J$个叶子节点，则决策树将会将空间划分为$J$个不相交的区域$R_{1m},R_{2m}…R_{3m}$，以及每个区域都是预测一个常量值，则树模型$G_m(x)$对于特征$x$的输入将可以写成$$G_m(x)=\sum_{j=1}^J b_{jm}I(x \in R_{jm})$$，其中$b_{jm}$表示每个区域的预测值，上面的介绍可以用下图来表示:</p>
<center><img src="/img/From-Gradient-Boosting-to-GBT/cart.png" width="400px"></center>

<p>在实际使用时，$b_{jm}$也会与一个乘子$\gamma_m$相乘,最终模型的训练与上面一小节的介绍一致:<br>$$<br>f_m(x)=f_{m-1}(x)+\gamma_mG_m(x) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)<br>$$</p>
<blockquote>
<p>可以发现树的模型是关键，一般来时$4 \leq J \leq 8$比较合适，有时候$J=2$就足够了，并且$j &gt; 10$比较少用</p>
</blockquote>
<h2 id="正则化">正则化</h2><blockquote>
<p>其实用过<code>Gradient Boosting</code>的同学应该有同感，<code>Gradient Boosting</code>类型的模型(<code>GBDT</code>)调参很重要-_-，大致可以发现这些参数就是正则化的关键</p>
</blockquote>
<h3 id="调整树的个数">调整树的个数</h3><p>树的个数$M$越多，过拟合的情况可能越为严重，这里树的个数一般使用交叉验证的误差来调整确定</p>
<h3 id="Shrinkage">Shrinkage</h3><p><code>Shrinkage</code>又称学习率，是指在<code>Gradient Boosting</code>训练时不训练全部的残差，而是:$$f_m(x)=f_{m-1}(x)+v \cdot \gamma_mG_m(x) \quad 0 &lt; v \leq 1$$<br>经验表明较小的学习率($v &lt; 0.1$)将会取得较为明显的正则化效果，但是学习率太小会导致训练次数增加..</p>
<blockquote>
<p>感觉这个大致可以这么理解，如果$v=1$，弱分类器犯错一次真的就错了，但是如果$v &lt; 1$时，如果某个分类器犯错了，其他的的弱分类器可能还可以补救^_^</p>
</blockquote>
<h3 id="Stochastic_gradient_boosting">Stochastic gradient boosting</h3><p>随机梯度提升法，表示每一轮迭代时并不是拿所有的数据进行训练，所以按无放回的随机取一定的比率$\eta$进行训练，这里的$ 0.5 &lt; \eta &lt; 0.8$将会取得较为不错的正则化效果，同时随机取样本进行训练还能加快模型的训练速度，并且每次迭代中未被抽中的样本还可以作为(out of bag)[<a href="https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计" target="_blank" rel="external">https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计</a></p>
<h3 id="叶子节点的数量">叶子节点的数量</h3><p>一般这个叶子节点的数量不宜太多（其实可以理解为节点数越多，模型复杂度越高…）</p>
<h3 id="使用惩罚项">使用惩罚项</h3><p>额~貌似<code>L2</code>之类的惩罚项也是可以被加入进去</p>
<h2 id="总结">总结</h2><p><code>Gradient Boosting</code>是非常金典而又重要的提升方法，他与<a href="http://kubicode.me/2016/04/18/Machine%20Learning/AdaBoost-Study-Summary/" target="_blank" rel="external">AdaBoost</a>一样都是讲弱分类器合成强分类，但是其大致区别有:</p>
<ol>
<li><code>Gradient Boosting</code>通过残差来变量的改变错误分类的权重,而<code>AdaBoost</code>就真的直接去修改分类错误的训练权重了</li>
<li><code>Gradient Boosting</code>接入的分类器一般完整的决策树居多，但是<code>AdaBoost</code>一般使用二层决策树</li>
</ol>
<p><code>Gradient Boosting</code>中最有代表性的就是<code>GBDT</code>,该模型虽好，可不要贪杯~使用时理解数据以及正确调参才是王道</p>
<h2 id="参考">参考</h2><p>[1]. <a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="external">wiki Gradient boosting</a><br>[2]. The Elements of Statistical Learning<br>[3]. 《统计学习方法》.李航.第八章</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解决在使用scikit-learn时出现ValueError: numpy.dtype has the wrong size的错误]]></title>
    <link href="http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/"/>
    <id>http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/</id>
    <published>2016-04-22T01:33:55.000Z</published>
    <updated>2016-04-22T01:51:20.000Z</updated>
    <content type="html"><![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br><a id="more"></a><br>网上给的建议大都是直接卸载再全部重装，将<code>numpy</code>、<code>scipy</code>和<code>scikit-learn</code>全部卸载了，然后</p>
<pre><code>pip <span class="keyword">install</span> -U numpy scipy scikit-learn
</code></pre><p>装起来。结果一样有问题-_-</p>
<p>继续查资料时终于发现有用的方法了:<br><a href="http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling" target="_blank" rel="external">http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling</a></p>
<p>就是不用使用<code>pip install scikit-learn</code>安装，卸载之后直接使用git上<code>https://github.com/scikit-learn/scikit-learn</code>的自己安装</p>
<pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/scikit-learn/scikit-learn
<span class="keyword">make</span>
sudo <span class="keyword">python</span> setup.<span class="keyword">py</span> install
</code></pre><p>ps：这个时候直接安装可能会出</p>
<pre><code><span class="attribute">RuntimeError</span>: <span class="string">Running cythonize failed!</span>
</code></pre><p>Error提示,这时候安装一下<code>cpython</code>即可</p>
<pre><code>pip <span class="keyword">install</span> cython
</code></pre><p>最后全部安装完之后就可以正常使用了^_^</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br>]]>
    
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[AdaBoost学习总结]]></title>
    <link href="http://kubicode.me/2016/04/18/Machine%20Learning/AdaBoost-Study-Summary/"/>
    <id>http://kubicode.me/2016/04/18/Machine Learning/AdaBoost-Study-Summary/</id>
    <published>2016-04-18T12:30:55.000Z</published>
    <updated>2016-09-08T03:58:57.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>三个凑皮匠，顶一个诸葛亮</code>，打一算法:<code>AdaBoost</code><br>本文是自己对<code>AdaBoost</code>的理解，健忘-_-!! 故记录在此.</p>
</blockquote>
<h2 id="简介">简介</h2><p>痛点:大部分强分类器(<code>LR</code>，<code>svm</code>)分类效果还不错，但是可能会遇到过拟合问题，并且训练相对复杂，耗时~<br>另外大部分弱分类器(<code>阈值分类器</code>,<code>单桩决策树(decision stump)</code>等)，他们分类的效果差，可能是极差，只会出现欠拟合，但是他们训练预测快，很快~</p>
<blockquote>
<p><code>天下武功，唯快不破</code>，<code>做减法不易，但是做加法就相对简单了</code>^_^ 这就是<code>提升方法</code>.</p>
</blockquote>
<p><code>提升方法</code>需要解决的两个问题:</p>
<ol>
<li>在每一轮训练时如何改变数据的权值或概率分布?</li>
<li>如何将弱分类器组合成一个强分类器?</li>
</ol>
<p><code>AdaBoost</code>对此进行了很好的解决:</p>
<ol>
<li><code>分而治之</code>:将前一轮分错的样本加大权重，迫使在第二轮中对这些样本尽量分对，同时减少分对样本的权重.</li>
<li><code>加权多数表决</code>:加大错误率小的弱分类器的权重，使其在最终表决中占较大作用，同时减少错误率较大的弱分类器的权重.</li>
</ol>
<a id="more"></a>
<h2 id="前向分步算法">前向分步算法</h2><p>讲<code>AdaBoost</code>之前，就不得不提到<code>前向分步算法</code>,先来看一个加法模型:<br>$$f(x)=\sum_{m=1}^M \beta_m b(x;\gamma_m)$$其中:</p>
<ul>
<li>$b(x;\gamma_m)$表示基函数</li>
<li>$\gamma_m$表示基函数的参数</li>
<li>$\beta_m$表示基函数的系数</li>
<li>最终加权求和之后形成最终的函数(强模型)</li>
</ul>
<p>假设损失函数为$L(y,f(x))$,则在训练$f(x)$时就是优化损失函数到最小化的问题:<br>$$\underset{\beta,\gamma}{min} \sum_{i=1}^N L\left( y_i,\sum_{m=1}^M \beta_m b(x;\gamma_m) \right)$$</p>
<p>如果直接优化这个损失函数无疑是一个相当复杂的问题:里面嵌入有太多了函数了…，而<code>前向分步算法</code>的策略是:</p>
<pre><code>如果从前往后每一步都是学习一个基函数以及系数，令其逐步逼近优化目标函数，那么复杂度就可以大大简化了<span class="attr_selector">[分而治之]</span>
</code></pre><p>因此每一步只需要如下的损失函数即可:<br>$$\underset{\beta,\gamma}{min} \sum_{i=1}^N L \left( y_i,\beta b(x;\gamma) \right)$$</p>
<p>下面就是<code>前向分步算法</code>的具体步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$，其中$y_i \in \{+1,-1\}$</li>
<li>损失函数:$L(y,f(x))$</li>
<li>基函数数量:$M$</li>
<li>基函数集合$\{b(x;\gamma_m)\}$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>加法模型$f(x)$</li>
</ul>
<p><strong>procedure</strong>:</p>
<ol>
<li>初始化$f_0(x)=0$</li>
<li>循环$m \in \{1….M\}$<ol>
<li>最小化基函数损失函数:$$\underset{\beta_m,\gamma_m}{argmin} \sum_{i=1}^N L\left( y_i,\beta_m b(x;\gamma_m) \right)$$</li>
<li>更新加法模型:$$f_m(x)=f_{m-1}(x)+\beta_m b(x;\gamma_m)$$</li>
</ol>
</li>
<li>最终得到加法模型:$$f(x)=f_M(x)=\sum_{m=1}^M \beta_m b(x;\gamma_m)$$</li>
</ol>
<p><code>前向分步算法</code>通过分而治之的方式求得了损失函数值最小的<code>加法函数</code></p>
<blockquote>
<p>整个算法的学习过程可以有很大的想象空间^_^</p>
</blockquote>
<h2 id="AdaBoost算法逻辑">AdaBoost算法逻辑</h2><p>上面一小节介绍了<code>前向分步算法</code>，但是留下来三个问题:</p>
<ol>
<li>对其损失函数$L(y,f(x))$有啥要求?</li>
<li>基函数的系数$\beta$又是怎么计算的?</li>
<li>基函数$b(x;\gamma)$如何设计比较合理?</li>
</ol>
<p><code>AdaBoost</code>正是对此进行一一填坑，它使用<code>指数损失函数</code>、<code>根据分类错误类来计算基函数系数</code>和  。。  基函数到没有指定，不过一般使用<code>阈值函数</code>或者<code>单桩决策树</code>来作为基函数</p>
<blockquote>
<p>因此也可认为<code>AdaBoost</code>是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法的二分类学习方法.</p>
</blockquote>
<p>先来看下<code>AdaBoost</code>的算法逻辑图:</p>
<p><center><img src="/img/AdaBoost-Study-Summary/exec.png" width="400px"></center></p>
<blockquote>
<p>说明:此图来自<code>PRML Fig14.1</code>[2]，本文的数学符号主要采用[1]的风格，因此有:$y_m(x)\rightarrow G_m(x)$、$Y_M(x) \rightarrow G(x)$</p>
</blockquote>
<p>从图中大致可以发现<code>AdaBoost</code>依次训练多个弱分类器，每个分类器训练完成之后产出一个权重给予下个分类器，下个分类器在此权重上继续进行训练，全部训练完成之后根据弱分类器的系数组合成强分类器，也就是最终的分类模型~</p>
<p>下面就是<code>AdaBoost</code>的具体步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$，其中$y_i \in \{+1,-1\}$</li>
<li>弱分类器数量:$M$</li>
<li>弱分类器集合$\{G_m(x)\}$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$G(x)$  （注意：<code>产出的最终模型并不直接是加法模型哦</code>~）</li>
</ul>
<p><strong>procedure</strong>:</p>
<ol>
<li>初始化训练权值的分布:$$D_1=(w_{1,1},\cdot \cdot \cdot , w_{1,i},\cdot \cdot \cdot ,w_{1,N}),w_{1,i}=\frac{1}{N}$$<blockquote>
<p>ps.其实初始化还有其他方式的 such as:初始化为$\frac{0.5}{N_+}$和$\frac{0.5}{N_-}$，其中$N_+$和$N_-$分别代表正负样本的数量，有$N=N_++N_-$</p>
</blockquote>
</li>
<li>循环$m \in \{1….M\}$<ol>
<li>使用带权重分布$D_m$的训练集进行训练，得到基本的弱分类器:$G_m(x)$</li>
<li>计算$G_m(x)$在训练数据集上的分类误差率:$$e_m=P(G_x(x) \neq y_i) = \sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$$其中$$ I(G_m(x_i) \neq y_i)=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad G_m(x_i) = y_i \\<br>1 &amp; \quad if \quad G_m(x_i) \neq y_i\\<br>\end{aligned}<br>\right.$$<blockquote>
<p>其实就是<code>错误率</code>:分错样本数量占总样本量的比例.</p>
</blockquote>
</li>
<li>计算$G_m(x)$的系数:$$\alpha_m = \frac{1}{2} ln \frac{1-e_m}{e_m}$$</li>
<li><strong>更新训练数据集的权值分布(这点是核心)</strong>:$D_{m+1}=(w_{m+1,1},\cdot \cdot \cdot , w_{m+1,i},\cdot \cdot \cdot ,w_{m+1,N})$<br>其中:$$w_{m+1,i} = \frac{w_{m,i}}{Z_m} e^{-\alpha_m y_i G_m(x_i)}$$ 这里$Z_m$为规范化因子:$$Z_m = \sum_{i=1}^{N} w_{m,i} e^{-\alpha_m y_i G_m(x_i)}$$</li>
</ol>
</li>
<li>构建加法模型:$$f(x)=\sum_{m=1}^M \alpha_m G_m(x)$$产出最终的分类器:$$G(x)=sign(f(x))=sign\left( \sum_{m=1}^M \alpha_m G_m(x) \right)$$其中:$$sign(f(x))=\left\{<br>\begin{aligned}<br>-1 &amp; \quad if \quad f(x) &lt; 0 \\<br>1 &amp; \quad if \quad f(x) \geq 0\\<br>\end{aligned}<br>\right.$$</li>
</ol>
<p>对算法过程中几个重要的点进行一个简单的解释:</p>
<ul>
<li><p>分类器误差率$e_m$对其权重$\alpha_m$的影响:<br><center><img src="/img/AdaBoost-Study-Summary/alpha.png" width="400px"></center><br>从图中可以发现:</p>
<ol>
<li>$e_m$为0.5时其权重$\alpha_m$为0，表示此分类器在最终模型中不起任何作用</li>
<li>$e_m &lt; 0.5$时其$\alpha_m &gt; 0$，表示对最终模型起正向作用,$e_m$的值越小，起到的作用越大</li>
<li>$e_m &gt; 0.5$时其$\alpha_m &lt; 0$，表示对最终模型起父向作用，$e_m$的值越大,起到的负作用也越大</li>
<li>$e_m$不会出现等于0 的情况，因为到了0的时候弱分类器已经全部分正确，也不需要继续更新权重再次训练了</li>
<li>$e_m$也不会出现等于1的情况，因为1表示弱分类器全错，除了程序出问题，应该任何一个弱分类器不会训练到全错的情况吧^_^</li>
</ol>
</li>
<li><p>数据权重的更新策略:<br>原始的更新策略是这样的:$$w_{m+1,i} = \frac{w_{m,i}}{Z_m} e^{-\alpha_m y_i G_m(x_i)}$$原始标签$y_i$和弱分类器结果的输出$G_m(x)$都是$\{+1,-1\}$二值，因此可以将上述更新方式写成:$$w_{m+1,i}=  \left\{<br>\begin{aligned}<br>\frac{w_{m,i}}{Z_m} \times e^{\alpha_m} &amp; \quad if \quad y_i \neq G_m(x)\\<br>\frac{w_{m,i}}{Z_m} \times \frac{1}{e^{\alpha_m}} &amp; \quad if \quad y_i = G_m(x)\\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>观察$w_{m+1,i}$更新时三个元素均恒大于0（$w_{m,i}$可以从$w_1$开始推），因此$w_{m+1,i}$也是恒大于0 ，并且$\sum_{i=1}^N w_{m,i}=1$<br>我们将分类错误率小于0.5的弱分类器称为好分类器，其系数$\alpha_{good}&gt;0$，同时将分类错误率小于0.5的弱分类器称为坏分类器，则其系数$\alpha_{had}&lt;0$，则再观察变形了的权重更新:</p>
</blockquote>
</li>
</ul>
<ol>
<li>如果当前分类器是好分类器，样本$(x_i,y_i)$被错误分类时,$e^{\alpha_m} &gt; 1$,其$w_{m+1,i}$将会被放大，反之正确分类样本的权值将会被缩小</li>
<li>如果当前分类器为坏分类器，样本$(x_i,y_i)$被错误分类时,$e^{\alpha_m} &lt; 1$,其$w_{m+1,i}$将会被缩小，反之正确分类样本的权值将会被放大<blockquote>
<p>这其实应该与误分类样本的权值被放大$e^{2\alpha_m}=\frac{e_m}{1-e_m}$倍一个道理，因为$\frac{e_m}{1-e_m}$不一定恒大于1啊~^_^</p>
</blockquote>
</li>
</ol>
<ul>
<li>弱分类器的权重系数$\alpha_m$:<br>这个权重系数表示了弱分类器$G_m(x)$的重要性，但是$a_m$之和并不为1，另外$G_m(x)$输出的是-1或者1的分类，所以最终模型可以看做一个加权的投票系统^_^</li>
</ul>
<h2 id="AdaBoost-最小化指数误差">AdaBoost-最小化指数误差</h2><p>假如<code>AdaBoost</code>使用的是指数损失函数，则其损失函数为:$$L(y,f(x))=\sum_{i=1}^N e^{-y_if(x)}$$为了优化其损失函数，<code>AdaBoost</code>采用了前向分步算法进行逐步优化,第<code>m</code>轮的迭代需要得到的$\alpha_m$,$G_m$和$f_m(x)$，其中有$$f_m(x)=f_{m-1}(x)+\alpha_m G_m(x)$$，假设前面的$f_{m-1}(x)$已经为最优，则当前需要优化的是:<br>$$L(y,f_m(x))=\sum_{i=1}^N e^{-y_i(f_{m-1}(x)+\alpha_m G_m(x))}$$因为有$\bar{w}_{m,i}=e^{-y_if(x)}$（关于这个式子的成立并不是很理解-_-）所以上述优化目标可以写为$$L(y,f_m(x))= \sum_{i=1}^N \bar{w}_{m,i} e^{-y_i\alpha_m G_m(x)}$$<br>因为我们求的是关于$\alpha_m$和$G_m(x)$的最优化，所以$\bar{w}_{m,i}$相对来说就是常量了.现在假设第$m$轮迭代中有$T_m$个样本分类正确，有$M_m$个样本分类错误，则其优化目标又可以写为:<br>$$\begin{equation}\begin{split} L(y,f_m(x))&amp;=e^{-\alpha_m} \sum_{n \in T_m} w_{m,n}+e^{\alpha_m} \sum_{n \in M_m} w_{m,n}\\<br>&amp;= \left( e^{-\alpha_m} \sum_{n \in T_m} w_{m,n} + e^{-\alpha_m} \sum_{n \in M_m} w_{m,n} \right)+ \left( e^{\alpha_m} \sum_{n \in M_m} w_{m,n} - e^{-\alpha_m} \sum_{n \in M_m} w_{m,n} \right) \\<br>&amp;= e^{-\alpha_m} \sum_{i=1}^N w_{m,i} + (e^{\alpha_m}-e^{-\alpha_m}) \sum_{n=1}^N w_{m,i}I(y_i \neq G_m(x_i))<br>\end{split}\end{equation}$$</p>
<p>接下来惯例的方法就是对$L(y,f_m(x))$求$\alpha$和$G_m(x)$的偏导数，其实在求$G_m(x)$最优时可以发现可以发现第一项和第二项前面的系数并不影响最优化，所以需要求的就是上面步骤中<code>误差率</code>的最优化:$$e_m=P(G_x(x) \neq y_i) = \sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$$<br>而得到了最优的$G_m(x)$之后代入$L(y,f_m(x))$求偏导又可以得到最小的$\alpha_m$为:$$\alpha_m = \frac{1}{2} ln \frac{1-e_m}{e_m}$$<br>又是一面熟悉的场景^_^<br>所以可以说<code>AdaBoost</code>整个过程是一直在优化最新函数的指数误差，只是在实际训练时按<code>前向分步算法</code>只需优化当前的误差率即可.</p>
<h2 id="AdaBoost训练误差分析">AdaBoost训练误差分析</h2><pre><code>这里的边界是我自己的理解，与<span class="attr_selector">[1]</span>稍有区别
</code></pre><p>上一小节我们知道在每一步求$\sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$的最小化时，其实是在优化最终模型的损失函数$\sum_{i=1}^N e^{-y_if(x)}$,关于模型最终的损失函数有这样一个界限:<br>$$\frac{1}{N} \sum_{i=1}^N I(f(x) \neq y_i) \leq \frac{1}{N} \sum_{i=1}^N e^{-y_if(x)} =  \prod_m Z_m$$<br>因为$e^{-y_if(x)}$一定不会小于0，并且当$f(x) \neq y_i$时，$e^{-y_if(x)}$恒大于1，因此第一、二项的不等式是成立的。接下来看后面的那个等式：</p>
<blockquote>
<p>这里的推导需要用到$Z_m$的变形:$w_{m,i}e^{-\alpha_my_iG_m(x)} = Z_mw_{m+1,i}$</p>
</blockquote>
<p>$$\begin{equation}\begin{split} \frac{1}{N} \sum_{i=1}^N e^{-y_if(x)} &amp;= \frac{1}{N} \sum_{i=1}^N e^{-\sum_{m=1}^M \alpha_my_iG_m(x_i)} \\<br>&amp;= \sum_{i=1}^N w_{1,i} \prod_{m=1}^M e^{-\alpha_m y_i G_m(x_i)} \\<br>&amp;= Z_1 \sum_{i=1}^N w_{2,i} \prod_{m=2}^M e^{-\alpha_my_iG_m(x_i)} \\<br>&amp;= Z_1 Z_2 \sum_{i=1}^N w_{3,i} \prod_{m=2}^M e^{-\alpha_my_iG_m(x_i)} \\<br>&amp;… \\<br>&amp;= Z_1 Z_2 … Z_{m-1}\sum_{i=1}^N w_{M,i}  e^{-\alpha_My_iG_M(x_i)} \\<br>&amp;= \prod_{m=1}^M Z_m<br>\end{split}\end{equation}$$</p>
<p>因此可以发现最优化(最小化)损失函数可以降低最终模型的错误率，同时其错误率与$Z_m$也是有关系的.</p>
<h2 id="AdaBoost黑科技">AdaBoost黑科技</h2><h3 id="Real_AdaBoost">Real AdaBoost</h3><p>上面的<code>AdaBoost</code>的介绍中可以发现$G_m(x)$返回的是-1 或者1 （也就是直接离散值），其实这种方式的返回始终会有一定的<code>gap</code>，那么假如$G_m(x)$输出的是$p(x)=P(y=1|x)$,也就是$x$特征下输出值为1的概率.此时我们最优化的函数为:$$e^{-y \left(f_{m-1}(x)+G_m(p(x) \right)}$$而$G_m(x)=\frac{1}{2} ln \frac{x}{1-x}$<br>这种方式将会修复一定的<code>gap</code>，并且在某些实验中效果也是要好于直接离散的<code>AdaBoost</code></p>
<h3 id="提前终止">提前终止</h3><p>一般情况下是弱分类器训练$M$个才停止，而提前终止只是在训练多个层之后组成的最终分类器的结果已经小于一个置信度的误差，有一种方法可以加快这种判断:</p>
<ol>
<li>一般训练数据里面负样本会远多于正样本</li>
<li>在多个级联的弱分类器在被训练之后，如果正样本被误分为负样本了，则人工将这样正样本进行标记并去去除（质量差的）</li>
<li>那么如果每一轮都是有50%的负样本被监测去重，那么久可以大大减小计算量</li>
<li>最终看假阳性和假阴性来判断是否终止</li>
</ol>
<blockquote>
<p>这种方式靠谱吗？要不就是我理解/翻译错了</p>
</blockquote>
<p>这种提前终止的方法可以降低过拟合的可能性^_^</p>
<h3 id="剪枝">剪枝</h3><p>剪枝指的是去除性能较差的弱分类器，提升效率。最简单的方法是:每个弱分类器都自己的系数和测试误差率极其分布，<code>margineantu</code>则提出的建议为:</p>
<ol>
<li>弱分类器的选择应该分类多样性</li>
<li>如果两个弱分类器很相似，则可以将其中一个给去掉,同时增加相似弱分类器的系数(这里其实就是相当于剪枝了)</li>
</ol>
<h2 id="总结">总结</h2><p><code>AdaBoost</code>秉承<code>三个凑皮匠，顶个诸葛亮</code>的原则，与其说<code>AdaBoost</code>是一个机器学习算法，我更觉得他应该是一个经典的机器学习框架，其优点有:</p>
<ol>
<li>可以较为方便的控制过拟合(不能说避免过拟合，在弱分类器很强的情况下还真会过拟合的吧？看$GBRT$)</li>
<li>有非常强的自适应性</li>
<li>如果弱分类器很简单，则训练预测速度将会很快，毕竟最终复杂度是在弱分类器上乘以$M$</li>
<li>分类效果好，实现简单</li>
<li>可扩展性强~弱分类器可以随意换，甚至损失函数也可以换(比如换最小平方误差)</li>
</ol>
<p>当然也有缺点:</p>
<ol>
<li>相邻两个分类器训练有依赖关系，所以在并行实现下还是需要精心设计。</li>
</ol>
<h2 id="参考:">参考:</h2><p>[1] 《统计学习方法》.李航.第八章<br>[2] 《Pattern Recognition And Machine Learning》.Christopher Bishop.chapter 14<br>[3]  <a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="external">https://en.wikipedia.org/wiki/AdaBoost</a></p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>三个凑皮匠，顶一个诸葛亮</code>，打一算法:<code>AdaBoost</code><br>本文是自己对<code>AdaBoost</code>的理解，健忘-_-!! 故记录在此.</p>
</blockquote>
<h2 id="简介">简介</h2><p>痛点:大部分强分类器(<code>LR</code>，<code>svm</code>)分类效果还不错，但是可能会遇到过拟合问题，并且训练相对复杂，耗时~<br>另外大部分弱分类器(<code>阈值分类器</code>,<code>单桩决策树(decision stump)</code>等)，他们分类的效果差，可能是极差，只会出现欠拟合，但是他们训练预测快，很快~</p>
<blockquote>
<p><code>天下武功，唯快不破</code>，<code>做减法不易，但是做加法就相对简单了</code>^_^ 这就是<code>提升方法</code>.</p>
</blockquote>
<p><code>提升方法</code>需要解决的两个问题:</p>
<ol>
<li>在每一轮训练时如何改变数据的权值或概率分布?</li>
<li>如何将弱分类器组合成一个强分类器?</li>
</ol>
<p><code>AdaBoost</code>对此进行了很好的解决:</p>
<ol>
<li><code>分而治之</code>:将前一轮分错的样本加大权重，迫使在第二轮中对这些样本尽量分对，同时减少分对样本的权重.</li>
<li><code>加权多数表决</code>:加大错误率小的弱分类器的权重，使其在最终表决中占较大作用，同时减少错误率较大的弱分类器的权重.</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聊聊机器学习中的损失函数]]></title>
    <link href="http://kubicode.me/2016/04/11/Machine%20Learning/Say-About-Loss-Function/"/>
    <id>http://kubicode.me/2016/04/11/Machine Learning/Say-About-Loss-Function/</id>
    <published>2016-04-11T13:06:23.000Z</published>
    <updated>2016-04-17T12:25:41.000Z</updated>
    <content type="html"><![CDATA[<p>机器学习算法一般都是对损失函数(<code>Loss Function</code>)求最优，大部分损失函数都是包含两项：<code>损失误差项(loss term)</code>以及<code>正则项(regularization term)</code>:<br>$$J(w)=\sum_iL(m_i(w))+\lambda R(w)$$</p>
<h2 id="损失误差项">损失误差项</h2><p>常用的损失误差项有5种:</p>
<ol>
<li><code>Gold Standard</code></li>
<li><code>Hinge</code>:Svm</li>
<li><code>log</code>:logistic regression(cross entropy error)</li>
<li><code>squared</code>:linear regression</li>
<li><code>Exponential</code>:Boosting</li>
</ol>
<a id="more"></a>
<h3 id="Gold_Standard_Loss">Gold Standard Loss</h3><p><code>Gold Standard</code>又称<code>0-1</code>误差，其结果又称为<code>犯错</code>与<code>不犯错</code>,用途比较广(比如<a href="http://kubicode.me/2015/08/06/Machine%20Learning/Perceptron-Learning-Algorithm/" target="_blank" rel="external">PLA</a>模型)，其损失函数也是相当的简单:<br>$$ y=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad m \geq 0 \\<br>1 &amp; \quad if \quad m \le 0\\<br>\end{aligned}<br>\right.$$</p>
<h3 id="Hinge_Loss">Hinge Loss</h3><p><code>Hinge</code>的叫法来源于其损失函数的图形，为一个折线，通用函数方式为:<br>$$L(m_i) = max(0,1-m_i(w))$$</p>
<p><code>Hinge</code>可以解 间距最大化 问题，带有代表性的就是<code>svm</code>,最初的<code>svm</code>优化函数如下:<br>$$\underset{w,\zeta}{argmin} \frac{1}{2}||w||^2+ C\sum_i \zeta_i \\<br>st.\quad \forall y_iw^Tx_i \geq 1- \zeta_i \\<br>\zeta_i \geq 0 $$</p>
<p>将约束项进行变形则为:<br>$$\zeta_i \geq 1-y_iw^Tx_i$$<br>则可以将损失函数进一步写为:<br>$$\begin{equation}\begin{split}J(w)&amp;=\frac{1}{2}||w||^2 + C\sum_i max(0,1-y_iw^Tx_i) \\<br>&amp;= \frac{1}{2}||w||^2 + C\sum_i max(0,1-m_i(w)) \\<br>&amp;= \frac{1}{2}||w||^2 + C\sum_i L_{Linge}(m_i)<br>\end{split}\end{equation}$$</p>
<p>因此<code>svm</code>的损失函数可以看成<code>L2-Norm</code>和<code>Hinge</code>损失误差之和.</p>
<h3 id="Log_Loss">Log Loss</h3><p><code>log</code>类型损失函数的优势可以将连乘转为求和，由于是单调函数，不会改变原结果，并且还很方面求最优，因此<code>log</code>类型的损失函数函数也非常常用，比较著名的一种就是交叉熵(<code>cross entropy</code>)，也就是<code>logistic regression</code>用的损失函数:<br>$$J(w)=\lambda||w||^2+\sum_i y_i log g_w(x_i)+(1-y_i)(log 1-g_w(x_i),y_i \in\{0,1\}$$<br>其中:<br>$$g_w(x_i)=\frac{1}{1+e^{-f_w(x_i)}} \\<br>f_w(x_i) = w^Tx_i<br>$$</p>
<h3 id="Squared_Loss">Squared Loss</h3><p>平方误差，线性回归中最常用:<br>$$L_2(m)=(f_w(x)-y)^2=(m-1)^2$$</p>
<h3 id="Exponential_Loss">Exponential Loss</h3><p>指数误差，在<code>boosting</code>算法中比较常见:<br>$$J(w)=\lambda R(w)+\sum_i exp(-y_if_w(x_i)) \\<br>L_{exp}(m_i) = exp(-m_i(w))<br>$$</p>
<h3 id="误差项对比">误差项对比</h3><p>上面5种误差项的函数为:</p>
<center><img src="/img/Say-About-Loss-Function/error_function.png" width="400px"></center>

<blockquote>
<p>黑色为<code>Squared Loss</code>,<span style="color:red">红色</span>为<code>Hinge Loss</code>,<span style="color:yellow">黄色</span>为:<code>Log Loss</code>,<span style="color:green">绿色</span>为:<code>Exponential Loss</code>,<span style="color:blue">蓝色</span>为:<code>Gold Standard</code></p>
</blockquote>
<p>观察图中:</p>
<ol>
<li><code>Hinge Loss</code>中当$m_i(w) &gt; 1$ 时，其损失项始终未0，当$m_i(w) &lt; 1$时，其损失项的值呈线性增长（正好符合<code>svm</code>的需求）.</li>
<li><code>Squared、Log、Exponential</code>三种损失函数已经<code>Hinge</code>的左侧都是凸函数，并且<code>Gold Stantard</code>损失为他们的下界:<br> $$\zeta_{01} \leq  \hat{\zeta}_{01}(h)+fudge$$</li>
<li>当需要求最大似然时(也就是概率最大化)，使用<code>Log Loss</code>最合适，但是一般会加上一个负号将其转换为求最小</li>
<li>损失函数和的<code>凸特征</code>以及有<code>界</code>是非常重要的，可以防止在一些可以求得无穷的工作上白白浪费时间。有时候为了让函数有界和凸特征，一般会使用一些代理函数来进行替换。</li>
</ol>
<h2 id="正则项">正则项</h2><blockquote>
<p>加入正在项是为了降低模型复杂度，在一定程度上可以有效防止模型过拟合</p>
</blockquote>
<p>常用的正则项有:<br>$$<br>R_2 = \frac{1}{2}||w||^2 \\<br>R_1 = \sum_i |w_i| \\<br>R_0 = |\{i:w_i \neq 0 \}|<br>$$<br>这些正则项可以通用的写成:<br>$$R_p =(\sum_i |w_i|^p)^{\frac{1}{p}}$$</p>
<p>其中：</p>
<ol>
<li>$R_2$最常用，因为它是凸函数，非常方便可以用<code>梯度下降法</code>最优化</li>
<li>$R_1$含有特征选择功能，因此经过$R_1$计算之后会有大量的0权重出现，这样的话我们在实际计算中只需要计算有值特征即可，可以加快速算法的运行速度</li>
<li>$R_0$，额~这个暂时不知道哪里用-_-</li>
</ol>
<p>当$p \leqslant 1$时其正则项就为非凸函数了</p>
<center><img src="/img/Say-About-Loss-Function/reg.png" width="600px"></center>


<h2 id="参考">参考</h2><ol>
<li><a href="http://www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf" target="_blank" rel="external">http://www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf</a></li>
<li><a href="https://www.wikiwand.com/en/Hinge_loss" target="_blank" rel="external">https://www.wikiwand.com/en/Hinge_loss</a></li>
<li><a href="http://www.cnblogs.com/rocketfan/p/4081585.html" target="_blank" rel="external">http://www.cnblogs.com/rocketfan/p/4081585.html</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>机器学习算法一般都是对损失函数(<code>Loss Function</code>)求最优，大部分损失函数都是包含两项：<code>损失误差项(loss term)</code>以及<code>正则项(regularization term)</code>:<br>$$J(w)=\sum_iL(m_i(w))+\lambda R(w)$$</p>
<h2 id="损失误差项">损失误差项</h2><p>常用的损失误差项有5种:</p>
<ol>
<li><code>Gold Standard</code></li>
<li><code>Hinge</code>:Svm</li>
<li><code>log</code>:logistic regression(cross entropy error)</li>
<li><code>squared</code>:linear regression</li>
<li><code>Exponential</code>:Boosting</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Learning To Rank中Pairwise方法的学习]]></title>
    <link href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/"/>
    <id>http://kubicode.me/2016/04/10/Machine Learning/LTR-Pairwise-Study/</id>
    <published>2016-04-10T09:05:18.000Z</published>
    <updated>2016-07-28T13:12:39.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>由于<code>Pairwise</code>方式的排序学习方法 训练样本构建方便、速度快同时效果也还可以，因此在工业界和学术的应用非常广泛^_^</p>
</blockquote>
<h2 id="2002-RankSvm">2002-RankSvm</h2><p><code>RankSvm</code>是最经典的一种，将其余的相关实现方法学习总结简单的记录到本文中。<br><code>RankSvm</code>的学习记录在<a href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/" target="_blank" rel="external">这里</a></p>
<h2 id="2006-IRSVM">2006-IRSVM</h2><p><code>IRSVM</code>直接是<code>RankSvm</code>的改进，<code>RankSvm</code>的训练目标是让序列pair的<code>不一致pair对</code>对最少，其优化函数为：<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$<br>因此直接暴露了两大问题:</p>
<h3 id="问题1:位置误差">问题1:位置误差</h3><a id="more"></a>
<pre><code><span class="tag">Example1</span>:
档位<span class="pseudo">:3</span>,2,1
排序1<span class="pseudo">:2</span> 3 2 1 1 1 1
排序2<span class="pseudo">:3</span> 2 1 2 1 1 1
</code></pre><p>从样例1中可以看到如果是按$\tau$最大化进行优化的话，<code>排序1</code>中<code>2 3</code>为不一致pair,排序2中<code>1 2</code>为不一致pair，因此他们的$\tau$得分是一致的，但是明显可以看到排序2的应该为更优，因为越<code>top</code>级别的重要性越大<br>因此<code>IRSVM</code>考虑了计算$\tau$时将位置顺序纳入误差</p>
<h3 id="问题2:长度误差">问题2:长度误差</h3><pre><code><span class="tag">Example2</span>:
档位<span class="pseudo">:3</span>,2,1
排序3<span class="pseudo">:3</span> 2 2 1 1 1 1
排序4<span class="pseudo">:3</span> 3 2 2 2 1 1 1 1 1
</code></pre><p>现观察样例2，可以发现<code>排序3</code>和<code>排序4</code>中均未出现<code>不一致pair</code>的文档对，因此他们的$\tau$得分是一样的，并且均为1，但是<code>排序3</code>中存在<code>28</code>个文档对，而<code>排序4</code>中存在<code>45</code>个文档对，所以<code>排序4</code>存在更多的训练数据，因此<code>排序4</code>的数据相当于<code>RankSvm</code>来说更加重要。<br>因此<code>IRSVM</code>将召回的文档个数纳入了排序</p>
<blockquote>
<p>其实这点比较纠结，实际使用中会进行数据过滤，而且最终训练的时候也一般都是取<code>top10</code>进行训练，所以这个问题并不会很明显</p>
</blockquote>
<h3 id="优化学习方法">优化学习方法</h3><p>所以<code>IRSVM</code>考虑了不同排序位置的不同重要性，以及各个<code>query</code>召回的数量，对原始的<code>RankSVM</code>损失函数进行修改得到如下:<br>$$\underset{w}{min} \sum_{i=1}^N \tau_{k(i)} \mu_{q(i))} [1-y_i(w,x_i^{(1)}-x_i^{(2)})]_+ + \lambda||w||^2$$</p>
<p>其实重要是添加了位置得分因子$\tau_{k(i)}$，使用<code>NDCG@1</code>中的方法进行折损，以及添加了<code>query</code>召回的文档长度因子$\mu_{q(i)}$，使用的是最简单粗暴的$\frac{1}{n_q}$进行计算，其中$n_q$表示召回的文档数量。</p>
<p>[2]中提出<code>IRSVM</code>的时候还使用了<code>SGD</code>和<code>线性规划</code>进行了优化</p>
<h2 id="2005-RankNet">2005-RankNet</h2><p><code>RankNet</code>的相关学习记录<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/" target="_blank" rel="external">在这里</a></p>
<h2 id="2007-GBRank">2007-GBRank</h2><p><code>GBRank</code>的相关学习记录<a href="http://kubicode.me/2016/05/08/Machine%20Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/" target="_blank" rel="external">在这里</a></p>
<h2 id="参考">参考</h2><ol>
<li>《Learning to Rank for Information Retrieval and Natural Language Processing》.Hang Li</li>
<li>Cao Y, Xu J, Liu T Y, et al. Adapting ranking SVM to document retrieval[C]// SIGIR 2006: Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval, Seattle, Washington, Usa, August. 2006:186-193.</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>由于<code>Pairwise</code>方式的排序学习方法 训练样本构建方便、速度快同时效果也还可以，因此在工业界和学术的应用非常广泛^_^</p>
</blockquote>
<h2 id="2002-RankSvm">2002-RankSvm</h2><p><code>RankSvm</code>是最经典的一种，将其余的相关实现方法学习总结简单的记录到本文中。<br><code>RankSvm</code>的学习记录在<a href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/">这里</a></p>
<h2 id="2006-IRSVM">2006-IRSVM</h2><p><code>IRSVM</code>直接是<code>RankSvm</code>的改进，<code>RankSvm</code>的训练目标是让序列pair的<code>不一致pair对</code>对最少，其优化函数为：<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$<br>因此直接暴露了两大问题:</p>
<h3 id="问题1:位置误差">问题1:位置误差</h3>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankSvm-基于点击数据的搜索排序算法]]></title>
    <link href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/"/>
    <id>http://kubicode.me/2016/03/30/Machine Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/</id>
    <published>2016-03-30T12:49:53.000Z</published>
    <updated>2016-07-26T17:22:22.000Z</updated>
    <content type="html"><![CDATA[<pre><code>RankSvm是Pairwise的学习排序中最早也是非常著名的一种算法，主要解决了传统PontWise构建训练样本难的问题，
并且基于<span class="built_in">Pair</span>的构建的训练样本也更为接近排序概念
</code></pre><h2 id="基本介绍">基本介绍</h2><p>RankSvm是在2002年提出的，之前工作关于LTR的工作貌似只有Pointwise相关的,比如PRanking,这样的排序学习算法Work需要含有档位标注的训练样本，一般有以下几种获取方式：</p>
<ol>
<li>需要人工/专家标注</li>
<li>诱导用户对展现的搜索结果进行反馈</li>
</ol>
<p>这样就会存在会成本高、可持续性低、受标准者影响大等缺点。<br><a id="more"></a></p>
<p>而RankSvm只需要根据搜索引擎的点击日志构建<code>Pair</code>对即可，相对于先前的工作在算法的实用性上有了非常大的改善。</p>
<h2 id="训练样本设计">训练样本设计</h2><p>一般搜索引擎都会记录用户搜索后展现的结果以及用户的点击情况，这种日志成本较低，并且改造系统也较为方便，而RankSvm的训练样本就是从这种点击日志中进行提取。</p>
<p>由于用户点击的<code>doc</code>概率和排序的位置影响很大，虽然一般都是偏爱相关性较大的<code>doc</code>，但是如果这种<code>doc</code>排在很后面的话其实用户也几乎不会点，所有<code>rankSvm</code>就只考虑top级别的点击日志，一般为<code>top 10</code></p>
<p>另外在构建训练数据时同一<code>query</code>下认为用户被点击<code>doc</code>相关性要高于没有被点击的<code>doc</code>，但是由于用户是从上往下浏览网页的，所以排在前面的<code>doc</code>被点击的概率会大于后面的<code>doc</code>，因此<code>RankSvm</code>使用的最终策略为:</p>
<blockquote>
<p><code>pair</code>构建策略:给定一组排序情况($doc_1,doc_2,doc_3,…$),以及$C$记录了用户点击<code>doc</code>的情况,则有<br>$$doc_i{\overset{r^*}{&lt;}} doc_j$$对于所有<code>pair</code>对$1 \leq i$,同时$i \in C$ ,$j \notin C$</p>
</blockquote>
<p>$r^*$表示应有的优化排序，也就是<code>被点击文档</code>的相关性要大于<code>排在该文档前面</code>并且<code>未被点击的文档</code>，看上去很绕口，看个栗子：</p>
<p>假如某个用户搜索某个<code>query</code>得到首页10个<code>doc</code>，按顺序使用$doc_i$进行表示,如果该用户点击了$1,3,7$三个文档，则认为有:<br>$$doc_3 {\overset{r^*}{&lt;}} doc_2 \\<br>doc_7 {\overset{r^*}{&lt;}} doc_2    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_4    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_5    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_6$$</p>
<p>表示该<code>query</code>下$doc_3$的相关性要高于$doc_2$，理应排在前面，而$doc7$的相关性也应该要高于$doc_{2,4,5,6}$，但是可以发现未见$doc_1$的相关性鉴定，这是由于$doc_1$已经是排在了第一位，本身位置点击概率就就是最高的，所以无法判断与其他文档相关性的高低，同理，$doc_{8,9,10}$也未纳入相关性的排序中。</p>
<p>训练样本可以通过这样方式进行构建，但是遗憾的是并没有一种机器学习算法能直接使用这种数据进行训练学习-_-</p>
<h2 id="基本思想">基本思想</h2><p>在上面的栗子中，我们希望用新算法完成$doc_{1,3,7}$排在<code>top 3</code>，那这样的文档的真实相关性高的将会排到前面，<code>RankSvm</code>采用$Kendall’s \quad \tau$来统计实际排序与算法排序的度量，先看下面两个变量:</p>
<ol>
<li>$P$表示排序序列中保持一致性的<code>Pair</code>对数量，也就是真实相关性高的排在第的前面。</li>
<li>$Q$表示排序序列中保持不一致的<code>Pair</code>对数量（就是为逆序了），也就是由于算法的误差导致真实相关性低的排在了高的前面</li>
<li>同时$P+Q=\binom{m}{2}$，$m$表示序列中文档的数量，因为长度为$m$的序列可能组成的<code>pair</code>对为$m$的2组合</li>
</ol>
<p>则$\tau$的计算方式为:<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$</p>
<blockquote>
<p>$r_a$为真实排序，$r_b$为算法排序</p>
</blockquote>
<p>比如实际文档中的顺序为:<br>$$d_1{\overset{r^*}{&lt;}}d_2{\overset{r^*}{&lt;}}d_3{\overset{r^*}{&lt;}}d_4{\overset{r^*}{&lt;}}d_5$$<br>但是算法的排序顺序为:<br>$$d_3{\overset{\hat{r}}{&lt;}}d_1{\overset{\hat{r}}{&lt;}}d_2{\overset{\hat{r}}{&lt;}}d_4{\overset{\hat{r}}{&lt;}}d_5$$</p>
<p>因此可以发现算法排序中有3对<code>pair</code>不一致了($\{d_2,d_3\}$,$\{d_1,d_2\}$,$\{d_1,d_3\}$)，所以$Q=3$，$P=7$，最终的$\tau(r,\hat{r})=\frac{7-3}{10}=4$<br>$\tau$的值越大，表示排序效果越接近真实，比如上面的$\tau(r,r)=\frac{10-0}{10}=1$</p>
<blockquote>
<p><code>RankSvm</code>还证明了由$Q$的倒数正相关的一个式子为平均准确率指标的下界(具体证明看原文附录):<br>$$AvgPrec(\hat{r}) \geq \frac{1}{R} \left[Q+\binom{R+1}{2}\right]^{-1} \left(\sum_{i=1}^{R} \sqrt{i}\right)^2$$<br>$R$为排序出现的文档中与query相关文档数量(这个是<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#MAP" target="_blank" rel="external">Mean Average Precision</a>中的标注，与<code>Pair</code>对的样本稍微有点差别)<br>从这个角度也可以看到$\tau$来衡量排序效果好坏的合理性.</p>
</blockquote>
<p>假设现在有$n$个$q_i$作为训练样本，他们各自的目标排序为$r_i^*$，也就是:<br>$$(q_1,r_1^*),(q_2,r_2^*),(q_3,r_3^*),…(q_n,r_n^*)$$</p>
<p>其中算法排序为$\hat{r}_i$，则排序算法的优化目标是将下列式子<br>$$\tau_{s}=\frac{1}{n} \sum_{i=1}^{n}\tau(r_i^*，\hat{t}_i)$$<br>进行最大化.</p>
<h2 id="RankSvm排序">RankSvm排序</h2><p>假设能找到一个排序算法能使得上面的$\tau_s$得到最大化，对于一个指定的查询$q$，每个文档$d_i$使用特征向量映射方法$\Phi(q,d_i)$，如果是直接使用线性排序方法:<br>$$(d_i,d_j) \in \hat{r} \Leftrightarrow \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j)$$<br>$\vec{w}$表示权重向量，线性排序下，排序分数为<code>权重 x 特征向量</code></p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/linear_example.png" width="400px"></center><br>上图表示一个二维的<code>权重</code>与<code>特征</code>图，在排序的顺序的就是特征在权重上的映射位置顺序，比如单从$W_1$维度进行观察可以看到的排序顺序为<code>{1,2,3,4}</code>，而如果按$W_2$维度则是<code>{2,3,1,4}</code>。</p>
<p>为了最大化$\tau_s$，可以最小化$    Q$来代替，也就是说对于线性的排序，$Q=0$就是表示下面的等式全成立(也就是最大化)<br>$$<br>\forall (d_i,d_j) \in r_1^* : \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j) \\<br>… \\<br>\forall (d_i,d_j) \in r_n^* : \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j)<br>$$</p>
<p>不幸的是，优化这个是一个<code>NP难题</code>。<br>然而<code>SVM</code>在由于软间距最大时可以看到熟悉的身影：<br>minimize:<br>$$\frac{1}{2} \vec{w} \cdot \vec{w} + C \sum \xi_{i,j,k}$$<br>subject to:<br>$$<br>\forall (d_i,d_j) \in r_1^* : \vec{w} \Phi(q,d_i) \geq \vec{w} \Phi(q,d_j) + 1 - \xi_{i,j,1} \\<br>… \\<br>\forall (d_i,d_j) \in r_n^* : \vec{w} \Phi(q,d_i) \geq \vec{w} \Phi(q,d_j) +1 - \xi_{i,j,n} \\<br>\forall_i \forall_j \forall_k:\xi_{i,j,k} \geq 0<br>$$</p>
<blockquote>
<p>$\xi$为松弛项，$C$表示平衡项</p>
</blockquote>
<p>因此优化该问题时可以将约束转为:<br>$$\vec{w} \Phi(q,d_i)-\vec{w} \Phi(q,d_j) \geq 1 - \xi_{i,j,1}$$<br>并且由于是线性排序，可以进一步精简为:<br>$$\vec{w} \left(\Phi(q,d_i)-\Phi(q,d_j)\right) \geq 1 - \xi_{i,j,1}$$</p>
<p>在<code>Pair</code>对中只可能$d_i$是否排在$d_j$前面是一个二值结果，所以我们可以将$d_i$排在$d_j$前面的<code>Pair</code>为正标签，否则为负标签:</p>
<p>$$ y=\left\{<br>\begin{aligned}<br>+1 &amp; \quad if \quad \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j) \\<br>-1 &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>则最终可以将约束可以写成:<br>$$y_i \cdot \vec{w} \left(\Phi(q,d_i)-\Phi(q,d_j)\right) \geq 1 - \xi_{i,j,1}$$</p>
<blockquote>
<p>其中传统的偏置项在<code>RankSvm</code>是不需要的，以为正好<code>Pair</code>相减时就消掉了</p>
</blockquote>
<p>这样就可以完全将上面构建的样本转为一个分类问题，使用<code>SVM</code>的对偶形式进行求解，并且还可以使用核函数进行非线性的分类^_^</p>
<p>训练完<code>Svm</code>之后，在正真排序时只需要将原始$doc$的特征向量输入<code>Svm</code>模型即可:<br>$$resv(q,d_i)= \vec{w} \Phi(q,d_i) = \sum_l^n a_{l}^*y_i(\Phi(q,d_i) \cdot \Phi(q,d_l)) $$</p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/binary_classifiy.png" width="400px"></center><br>上面是表示两个不同的<code>query</code>所表示的特征空间，不同的形状表示文档与对应<code>query</code>的相关性档位,三角形$x_1$表示相关性档位高，圆圈$x_2$表示相关性档位一般，叉叉$x_3$表示相关性档位差。<br>将这些样本转为<code>Pair</code>对之后可以有：</p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/pair_wise_result.png" width="400px"></center><br>可以发现$x_1-x_3$和$x_1-x_2$为正样本，而$x_2-x_1$和$x_3-x_1$为负样本，因此可以形成对应的训练数据进行训练,其实这样形成的样本是对称的，因此在实际使用中一般只保留一侧即可。</p>
<h2 id="总结">总结</h2><p><code>RankSvm</code>很好的解决原始训练样本构建难的问题，根据点击日志构建样本，既考虑了<code>doc</code>之间的顺序，又保证了可持续性，并且其<code>Pair</code>对的训练正好可以使用<code>Svm</code>进行求最优化，而<code>Svm</code>分类器已经是非常成熟并且广泛使用的一种机器学习算法。<br>因此<code>RankSvm</code>虽然在2002年就提出，但是至今在工业界还是广泛使用，但是现在的主要难点是样本<code>Pair</code>对的构建，针对不同的场景也不同的策略，不一定只是根据点击顺序，实际使用中还要考虑新样本数据。</p>
<h2 id="参考">参考</h2><ol>
<li>Joachims T. Optimizing search engines using clickthrough data[C]// Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2002:133-142.</li>
<li>《Learning to Rank for Information Retrieval and Natural Language Processing》.Hang Li</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code>RankSvm是Pairwise的学习排序中最早也是非常著名的一种算法，主要解决了传统PontWise构建训练样本难的问题，
并且基于<span class="built_in">Pair</span>的构建的训练样本也更为接近排序概念
</code></pre><h2 id="基本介绍">基本介绍</h2><p>RankSvm是在2002年提出的，之前工作关于LTR的工作貌似只有Pointwise相关的,比如PRanking,这样的排序学习算法Work需要含有档位标注的训练样本，一般有以下几种获取方式：</p>
<ol>
<li>需要人工/专家标注</li>
<li>诱导用户对展现的搜索结果进行反馈</li>
</ol>
<p>这样就会存在会成本高、可持续性低、受标准者影响大等缺点。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[McRank:一种基于多分类和梯度提升树的排序学习]]></title>
    <link href="http://kubicode.me/2016/03/28/Machine%20Learning/McRank-Learning-to-Rank-Multiple-Classification-and-Gradient-Boosting/"/>
    <id>http://kubicode.me/2016/03/28/Machine Learning/McRank-Learning-to-Rank-Multiple-Classification-and-Gradient-Boosting/</id>
    <published>2016-03-28T08:37:53.000Z</published>
    <updated>2016-09-21T01:56:03.000Z</updated>
    <content type="html"><![CDATA[<pre><code><span class="name">McRank</span>是学习排序(<span class="name">Learning</span> <span class="atom">to</span> <span class="name">Rank</span>)的单文档排序分支(<span class="name">Pointwise</span>)中较为经典的一种，本文是读原<span class="name">Paper</span>[<span class="number">1</span>]之后自己的一个理解.
</code></pre><h2 id="基本介绍">基本介绍</h2><p><code>McRank</code>的全称是<code>Multiple Classification Rank</code>,可以理解为将<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/" target="_blank" rel="external">学习排序</a>转为机器学习中的一个多分类问题.<br><code>McRank</code>对<code>DCG</code>指标进行优化，并且可以证明<code>DCG</code>的误差可以被分类误差给<code>bounded</code>住.</p>
<h2 id="折损累积增益">折损累积增益</h2><blockquote>
<p><code>DCG</code>(Discounted Cumulative Gain)是在信息检索领域评估一个<code>rank</code>好坏的常用指标。(在实际使用中一般会进行归一化，称为<code>NDCG</code>，可以看<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#NDCG" target="_blank" rel="external">这里</a>).</p>
</blockquote>
<p>假设在指定的<code>query</code>下通过某个排序算法对$n$个文档进行排序，则可以得到<br>$$DCG=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1)$$<br><a id="more"></a></p>
<p>其中:</p>
<ol>
<li>$i$表示原文档的索引顺序</li>
<li>$c_{[\pi_i]}=log(i+1)$</li>
<li>$y_i$表示对应文档与<code>query</code>相关性的程度，一般用档位$\{0,1,2,3,4\}$来表示</li>
</ol>
<p>最终的<code>DCG</code>值越大，表示排序效果越好,假如直接根据档位降序得到的排序结果中<code>DCG</code>是最大的，实际使用中一般根据当前可能的最大<code>DCG</code>进行归一化</p>
<h2 id="排序思想">排序思想</h2><p>现在已经知道了文档与<code>query</code>之间一般用档位衡量，而假如按档位降序的<code>DCG</code>值最高,所以排序问题可以转为指定<code>query</code>对文档相关性类别的预测，即多分类问题。</p>
<h3 id="DNCG误差计算">DNCG误差计算</h3><p>现在可以这么理解，我们希望的是<code>DCG</code>越大越好，也即是<code>DCG</code>误差越小越好，但如果是分类问题将直接优化的是分类误差，那如果<code>DCG</code>误差能够被分类误差给<code>bouded</code>住，就可以通过优化分类误差来间接的优化<code>DCG</code>误差了.</p>
<p>对于一个排序的置换映射函数$\pi$,<code>DCG</code>误差为$DCG_g-DCG_{\pi}$，其中$DCG_g$表示最优排序,就是根据实际的<code>query-doc</code>相关性分档降序的排序，所以肯定有$DCG_g \geq DCG_{\pi}$</p>
<p>现给定$n$个<code>URLS</code>的顺序为$\{1,2,3…n\}$，假设分类器分配的相关结果为$\hat{y}_i \in \{0,1,2,3,4\}$，置换映射函数$\pi$直接根据相关性进行排序，高档位的排在前面，相同档位可以随意排序，则可以有以下证明:</p>
<blockquote>
<p>先看变量^_^<br>$y_i$表示<code>query-doc</code>的实际相关性<br>$\hat{y}_i$表示<code>query-doc</code>的分类器预测相关性<br>$c_{[g_i]}$表示根据实际相关性得到的排序<br>$c_{[\pi_i]}$表示根据预测相关性得到的排序</p>
</blockquote>
<p>$$\begin{equation}\begin{split}DCG_{\pi}&amp;=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1) \\<br>&amp;=\sum_{i=1}^{n}c_{[\pi_i]}(2^{\hat{y}_i}-1)+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;\geq \sum_{i=1}^{n}c_{[g_i]}(2^{\hat{y}_i}-1)+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;=\sum_{i=1}^{n}c_{[g_i]}(2^{y_i}-1)-\sum_{i=1}^{n}c_{[g_i]}(2^{y_i}-2^{\hat{y}_i})+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;=DCG_g+\sum_{i=1}^{n}(c_{[\pi_i]}-c_{[g_i]})(2^{y_i}-2^{\hat{y}_i})<br>\end{split}\end{equation}$$</p>
<p>解释下不等式$\sum_{i=1}^{n}c_{[\pi_i]}(2^{\hat{y}_i}-1) \geq \sum_{i=1}^{n}c_{[g_i]}(2^{\hat{y}_i}-1)$成立的原因:$c_{[\pi_i]}$是根据相关性$\hat{y}_i$排序得到的，也就是上面提到的最优排序，得到的$DCG$值是最大的(当然这个是分类器的预测值，不是真实值，就是假象的意思-_-)，所以换一种顺序$c_{[g_i]}$其$DCG$的值必定会小于等于最大值.</p>
<p>根据上面的推导就可以直接得到$DCG$的误差了:<br>$$\begin{equation}\begin{split}DCG_g-DCG_{\pi} &amp;\leq \sum_{i=1}^{n}(c_{[g_i]}-c_{[\pi_i]})(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp; \leq \left(\sum_{i=1}^{n}(c_{[g_i]}-c_{[\pi_i]})^2\right)^{\frac{1}{2}}\left(\sum_{i=1}^{n}(2^{y_i}-2^{\hat{y}_i})^2\right)^{\frac{1}{2}} \\<br>&amp;\leq \left(2\sum_{i+1}^{n}c_{[i]}^2-2n\prod_{i=1}^nc_{[i]}^{\frac{2}{n}}\right)^{\frac{1}{2}} 15 \left(\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}\right)^{\frac{1}{2}} \\<br>&amp;= 15\sqrt{2} \left(\sum_{i+1}^{n}c_{[i]}^2-n\prod_{i=1}^nc_{[i]}^{\frac{2}{n}}\right)^{\frac{1}{2}}\left(\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}\right)^{\frac{1}{2}}<br>\end{split}\end{equation}$$</p>
<p>上面公式<code>1~2</code>是不等式是根据<code>柯西不等式</code>得到的，第<code>2~3行</code>平方展开的不等式成立是因为:</p>
<ol>
<li>$\sum_{i=1}^{n}c_{[\pi_i]}^2=\sum_{i=1}^{n}c_{[g_i]}^2=\sum_{i=1}^{n}c_{[i]}^2$,$\prod_{i=1}^{n}c_{[\pi_i]}^2=\prod_{i=1}^{n}c_{[g_i]}^2=\prod_{i=1}^{n}c_{[i]}^2$，他们虽然是顺序不一样，但是他们集合的内容是一样的，所以<code>求和</code>和<code>连乘</code>的等式是成立的。</li>
<li>两种相关性$y_i$和$\hat{y}_i$的值在<code>0~4</code>范围内,因此有$(2^{y_i}-2^{\hat{y}_i})^2\leq 15$，因为$2^4-2^0=15$</li>
</ol>
<p>因此当需要最小化<code>DCG</code>误差时只需要最小化分类误差$\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}$即可，但是该误差非凸也非平滑，实际使用中使用代理损失函数进行优化:<br>$$\sum_{i=1}^{N}\sum_{k=0}^{K-1}-log(p_{i,k})1_{y_i=k}$$<br>其中$p_{i,k}$表示<code>doc</code>输入每个档位的概率，$K$是总的档位数。</p>
<blockquote>
<p>我感觉:上面不等式里面的排序顺序时间使用$c_{[i]}$代替了，虽然表面上和分档结果无关，因此只需要优化分档即可，但是。。。实际上$c_{[\pi_i]}$的顺序是和分档预测有关的啊….</p>
</blockquote>
<h3 id="分类排序">分类排序</h3><p>上面提到过有了分档结果之后可以按档位顺序降序排序，得到的<code>DCG</code>就是最优的，但是这里存在一个问题，那就是相同档位之间是可以随便排的，就是导致排序的不稳定性，为了得到一种良好的排序机制，<code>McRank</code>在实际排序中会将分类结果转为一个连续的分数，按这个分数进行排序.</p>
<p>假设训练是$\{y_i,x_i\}_i^N$，$y_i$表示多分类的分档,则最终将会学习到的是每个类别的概率$p_{i,k}=Pr(y_i=k)$，则最后的排序分数为:<br>$$S_i=\sum_{k=0}^{K-1}p_i^kT(k)$$<br>其中$T(k)$表示随档位单调递增的函数，比如$T(k)=k$或者$T(k)=2^k$（<code>McRank</code>用的是前者）</p>
<blockquote>
<p>不同的单调递增函数不会对排序进行影响，同时如果对函数进行线性变换也会改变排序结果</p>
</blockquote>
<p>最终<code>McRank</code>是使用<code>Boosting Tree</code>进行多分类预测..</p>
<h3 id="有序分类">有序分类</h3><blockquote>
<p>好吧，其实上面<code>McRank</code>已经讲完了，但是Paper里面提到有序分类(<code>Ordinal Classfifcation</code>，貌似就是<code>Pointwise</code>里面的第三个分支)可以提升排序结果。</p>
</blockquote>
<p>这里在进行多分类时，可以发现每个类别(档位)并不是平等的，比如4档就是要比0档相关性更好，为了考虑这种的偏移，有序分类就是干这个的，多类别有序分类是学习一段区间内的累积概率$Pr(y_i&lt;k)$</p>
<p>首先将训练数据点分类两种$\{y_i \geq 4 \}$和$\{y_i \leq 3\}$，那这样称为了一个二分类问题，这里一样使用<code>boosting Tree</code>进行分类，同样关于$\{y_i \leq 3\}$也可以分为$\{y_i \geq 3 \}$和$\{y_i \leq 2\}$，如果迭代就可以进行变相多分类.</p>
<p>这种方式就是考虑目标类目的不均等性，带来的问题就是会增加训练开销(因为有重复计算，并且可能会带来较大的样本<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All" target="_blank" rel="external">不均衡性</a>。。。。)</p>
<blockquote>
<p>还有一个坏消息。。。<code>McRank</code>的Paper实验里面这种方式并没有比普通多分类提升多少效果-_-</p>
</blockquote>
<h2 id="总结">总结</h2><p><code>McRank</code>是非常经典的一种<code>Pointwise</code>学习排序，将排序转为机器学习的多分类预测，并且对其排序指标<code>DCG</code>误差可以被分类误差给<code>bounded</code>住，最终将分类结果的概率转为一个连续分数进行最终的排序，在实验里面显示该方法比基于回归的<code>subRank</code>以及<code>pairwise</code>的<code>LambdaRank</code>效果更好。</p>
<blockquote>
<p><code>McRank</code>速度快，效果也还行，最大的问题就是<code>训练样本的构建</code>比较麻烦..</p>
</blockquote>
<h2 id="参考">参考</h2><ol>
<li>Li P, Burges C J C, Wu Q. McRank: Learning to Rank Using Multiple Classification and Gradient Boosting[J]. Advances in Neural Information Processing Systems, 2007:897-904.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code><span class="name">McRank</span>是学习排序(<span class="name">Learning</span> <span class="atom">to</span> <span class="name">Rank</span>)的单文档排序分支(<span class="name">Pointwise</span>)中较为经典的一种，本文是读原<span class="name">Paper</span>[<span class="number">1</span>]之后自己的一个理解.
</code></pre><h2 id="基本介绍">基本介绍</h2><p><code>McRank</code>的全称是<code>Multiple Classification Rank</code>,可以理解为将<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/">学习排序</a>转为机器学习中的一个多分类问题.<br><code>McRank</code>对<code>DCG</code>指标进行优化，并且可以证明<code>DCG</code>的误差可以被分类误差给<code>bounded</code>住.</p>
<h2 id="折损累积增益">折损累积增益</h2><blockquote>
<p><code>DCG</code>(Discounted Cumulative Gain)是在信息检索领域评估一个<code>rank</code>好坏的常用指标。(在实际使用中一般会进行归一化，称为<code>NDCG</code>，可以看<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#NDCG">这里</a>).</p>
</blockquote>
<p>假设在指定的<code>query</code>下通过某个排序算法对$n$个文档进行排序，则可以得到<br>$$DCG=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从Bayesion的角度来看Logistic Regression]]></title>
    <link href="http://kubicode.me/2016/03/26/Machine%20Learning/Bayesian-Logistic-Regression/"/>
    <id>http://kubicode.me/2016/03/26/Machine Learning/Bayesian-Logistic-Regression/</id>
    <published>2016-03-26T03:30:54.000Z</published>
    <updated>2017-01-10T06:34:19.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Logistic_Regression公式">Logistic Regression公式</h2><blockquote>
<p><code>Logistic Regression</code>（下面简称<code>LR</code>）是一个二分类的机器学习方法，给定一个输入向量$x_i$，输出$P(y_i|x_i)$,其中$y_i \in {0,1}$。</p>
</blockquote>
<p>作为一个二分类问题，$Y$的后验概率一般会写成这样:<br>$$P(Y=1|X)=\frac{1}{1+exp(- \omega - \sum_{i=1}^n {\omega_ix_i})}=\sigma(W^TX_i)$$<br>那么<br><a id="more"></a><br>$$P(Y=0|X)=1-\sigma(W^TX_i)$$</p>
<p>其中$\sigma(\cdot)$表示激活函数,为$S$形状，<code>x</code>轴可以取值无限大，<code>y</code>轴只能取到$(-1,1)$<br>$$\sigma(a)=\frac{1}{1+exp(-a)}$$</p>
<pre><code>由于LR表示简单，训练预测速度快，效果并不是很差<span class="comment">(加上正则化)</span>，所以深得学术和工业界的囍爱~^_^
</code></pre><h2 id="使用GNB推导">使用GNB推导</h2><blockquote>
<p>谈到LR的时候第一印象就是上面的公式，但是为啥是这个公式呢？这一小节就是从<code>GNB(Gaussion Navie Bayes)</code>的角度来看待这个问题~</p>
</blockquote>
<p>我们先对<code>GNB</code>模型做4个假设:</p>
<ol>
<li>$Y$是布尔值，服从伯努利分布，其中$\pi = P(Y=1)$</li>
<li>其中$X_i$是连续随机变量</li>
<li>对于每个$X_i$，$P(X_i|Y=y_k)$服从高斯分布$N(\mu_{ik},\sigma_i)$(大多数情况下，简单用的$N(\mu_k,\sigma)$)</li>
<li>在给定$Y$下，$X_i$与$X_j$条件独立</li>
</ol>
<p>现在让$P(Y|X)$服从<code>GNB</code>假设，通常根据贝叶斯公式可以得到以下:<br>$$P(Y=1|X)=\frac{P(X|Y=1)P(Y=1)}{P(Y=1)P(X|Y=1)+P(Y=0)P(X|Y=0)}$$</p>
<p>再对这个式子进行进一步处理:</p>
<p>$$<br>\begin{equation}\begin{split} P(Y=1|X)&amp;=\frac{1}{1+\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)}}\quad\quad &amp;(1)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)}\right)}&amp;(2)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{P(Y=0)}{P(Y=1)}+\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}\right)}\quad\quad&amp;(3)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{1-\pi}{\pi}+\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}\right)} &amp;(4)<br>\end{split}\end{equation}<br>$$</p>
<p>其中:</p>
<ol>
<li>式子<code>(1)-&gt;(2)</code>是加了<code>exp</code>函数与<code>ln</code>函数正好相互抵消</li>
<li>式子<code>(2)-&gt;(3)</code>首先将<code>ln</code>函数的相乘转为相加，同时由于$X$中的各个$x_i$相互独立，所以原本写成连乘的式子又可以写成相加求和</li>
<li>式子<code>(3)-&gt;(4)</code>中$P(Y=1)$的概率是$\pi$，则$P(Y=0)$的概率是$1-\pi$</li>
</ol>
<p>在给定假设<code>3</code>情况下，对$\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}$进行进一步展开:<br>$$\begin{equation}\begin{split} \sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)} &amp;=\sum_iln\frac{\frac{1}{\sqrt{2\pi\sigma}}exp(\frac{-(x_i-\mu_{i0})^2}{2\sigma_i^2})}{\frac{1}{\sqrt{2\pi\sigma}}exp(\frac{-(x_i-\mu_{i1})^2}{2\sigma_i^2})}  &amp;(5)\\<br>&amp;= \sum_iln  exp\left(\frac{(x_i-\mu_{i1})^2-(x_i-\mu_{i0})^2}{2\sigma_i^2}\right) &amp;(6)\\<br>&amp;= \sum_i \left(\frac{(x_i^2-2x_i\mu_{i1}+\mu_{i1}^2)-(x_i^2-2x_i\mu_{i0}+\mu_{i0}^2)}{2\sigma_i^2}\right) \quad\quad &amp;(7)\\<br>&amp;= \sum_i \left(\frac{2x_i(\mu_{i0}-\mu_{i1})+\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}\right) &amp;(8)\\<br>&amp;= \sum_i \left(\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}x_i+\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}\right) &amp;(9)<br>\end{split}\end{equation}$$</p>
<ol>
<li>式子<code>(5)</code>根据假设<code>3</code>而得到，它是服从高斯分布</li>
<li>式子<code>(5)-&gt;(6)</code>是消除了公共因此，并且将指数上的相除转为了相减</li>
<li>式子<code>(6)-&gt;(7)</code>是对<code>ln</code>和<code>exp</code>进行了相互抵消，并且对其平方公式进行了展开</li>
<li>式子<code>(7)-&gt;(8)</code>是展开式中除去了公有的变量</li>
<li>式子<code>(8)-&gt;(9)</code>将$x_i$显眼得提了出来</li>
</ol>
<p>现从新将上面的展开式丢到$P(Y=1|X)$中则可以得到<br>$$P(Y=1|X)=\frac{1}{1+exp \left(ln\frac{1-\pi}{\pi}+\sum_i(\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}x_i+\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2})\right)}$$</p>
<p>相应地，则可以将其写为:<br>$$P(Y=1|X)=\frac{1}{1+exp (\omega_0+\sum_i\omega_ix_i)}$$</p>
<blockquote>
<p>可以发现这个式子就是<code>LR</code>的式子了</p>
</blockquote>
<p>其权重$\{\omega_1…\omega_n\}$为<br>$$\omega_i=\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}$$<br>其偏置$\omega_0$为:<br>$$\omega_0=ln\frac{1-\pi}{\pi}+\sum_i\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}$$</p>
<h2 id="总结">总结</h2><p>文本是学习了从贝叶斯角度来看<code>LR</code>式子的来源，根据大家熟知的朴素贝叶斯公式，将定其特定类别下的特征符合高斯分布，根据贝叶斯公式一步步推导出了<code>LR</code>式子的样纸，还是很神奇的。^_^</p>
<h2 id="参考">参考</h2><p>1 <a href="http://web.cse.ohio-state.edu/~kulis/teaching/788_sp12/scribe_notes/lecture6.pdf" target="_blank" rel="external">http://web.cse.ohio-state.edu/~kulis/teaching/788_sp12/scribe_notes/lecture6.pdf</a>(基本就是看了这个，不过里面公式有不少笔误的。。)</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Logistic_Regression公式">Logistic Regression公式</h2><blockquote>
<p><code>Logistic Regression</code>（下面简称<code>LR</code>）是一个二分类的机器学习方法，给定一个输入向量$x_i$，输出$P(y_i|x_i)$,其中$y_i \in {0,1}$。</p>
</blockquote>
<p>作为一个二分类问题，$Y$的后验概率一般会写成这样:<br>$$P(Y=1|X)=\frac{1}{1+exp(- \omega - \sum_{i=1}^n {\omega_ix_i})}=\sigma(W^TX_i)$$<br>那么<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hadoop Streaming导入自定义module]]></title>
    <link href="http://kubicode.me/2016/03/25/Hadoop/Hadoop-Streaming-Import-custom-module/"/>
    <id>http://kubicode.me/2016/03/25/Hadoop/Hadoop-Streaming-Import-custom-module/</id>
    <published>2016-03-24T16:17:54.000Z</published>
    <updated>2016-03-25T01:51:05.000Z</updated>
    <content type="html"><![CDATA[<h2 id="问题">问题</h2><p>今天发现用<code>Python</code>编写<code>Hadoop Streaming</code>脚本时，如果自己导入自定义的模块会报错-_-<br>列如<code>word count</code>中的<a href="http://kubicode.me/2015/11/08/Hadoop/Hadoop-Streaming-Primary-Learning-And-Debug/" target="_blank" rel="external">reducer</a>程序:<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding=utf8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> utils_helper</span><br><span class="line"></span><br><span class="line">lastk = <span class="keyword">None</span> <span class="comment">#这里标志最后一个k  用于控制同一个key 到一个组中</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        w,c = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        c = int(c) <span class="comment">#不转成int会比较麻烦  这是是计数</span></span><br><span class="line">        <span class="keyword">if</span> lastk == <span class="keyword">None</span>: <span class="comment">#这里是判断是否过来的是第一个key</span></span><br><span class="line">                lastk=w</span><br><span class="line">                count = utils_helper.add(count,c)</span><br><span class="line">        <span class="keyword">elif</span> lastk == w:</span><br><span class="line">                count += c</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"%s\t%s"</span>%(lastk,count)</span><br><span class="line">                lastk=w</span><br><span class="line">                count = c <span class="comment">#这里重置计数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> lastk <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"%s\t%s"</span>%(lastk,count)</span><br></pre></td></tr></table></figure></p>
<p>故意使用一个自定义模块来测试<code>utils_helper.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(x,y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x+y</span><br></pre></td></tr></table></figure></p>
<p>如果本地跑起来是(就是本地DEBUG)就可以正常跑的，但是放到<code>Hadoop</code>集群上跑的时候,使用的启动命令为:</p>
<pre><code>hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.7.0.jar \
-<span class="ruby">input /yyl/data/line.txt \
</span>-<span class="ruby">output /yyl/test/ouput/streaming2 \
</span>-<span class="ruby">mapper <span class="string">"python word_count_mapper.py"</span> \
</span>-<span class="ruby">reducer <span class="string">"python word_count_reducer.py"</span> \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/word_count_mapper.py \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/word_count_reducer.py \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/utils_helper.py \</span>
</code></pre><p>可以发现跑到<code>reducer</code>阶段时会报错:</p>
<pre><code><span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">40</span> INFO mapreduce<span class="class">.Job</span>: Running job: job_1458827745768_0018
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">53</span> INFO mapreduce<span class="class">.Job</span>: Job job_1458827745768_0018 running <span class="keyword">in</span> uber mode : false
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">53</span> INFO mapreduce<span class="class">.Job</span>:  map <span class="number">0%</span> reduce <span class="number">0%</span>
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">12</span>:<span class="number">12</span> INFO mapreduce<span class="class">.Job</span>:  map <span class="number">100%</span> reduce <span class="number">0%</span>
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">12</span>:<span class="number">22</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1458827745768_0018_r_000000_0, Status : FAILED
Error: java<span class="class">.lang</span><span class="class">.RuntimeException</span>: PipeMapRed.<span class="function"><span class="title">waitOutputThreads</span><span class="params">()</span></span>: subprocess failed with <span class="tag">code</span> <span class="number">2</span>
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeMapRed</span><span class="class">.waitOutputThreads</span>(PipeMapRed<span class="class">.java</span>:<span class="number">322</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeMapRed</span><span class="class">.mapRedFinished</span>(PipeMapRed<span class="class">.java</span>:<span class="number">535</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeReducer</span><span class="class">.close</span>(PipeReducer<span class="class">.java</span>:<span class="number">134</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.io</span><span class="class">.IOUtils</span><span class="class">.cleanup</span>(IOUtils<span class="class">.java</span>:<span class="number">244</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.ReduceTask</span><span class="class">.runOldReducer</span>(ReduceTask<span class="class">.java</span>:<span class="number">459</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.ReduceTask</span><span class="class">.run</span>(ReduceTask<span class="class">.java</span>:<span class="number">392</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">163</span>)</span></span>
    at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)
    at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1657</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">158</span>)
</code></pre><p>这就疼了，代码应该没问题呀，尝试了好几遍之后还是这个错误。。。-_-!!</p>
<h2 id="解决方案">解决方案</h2><p>后来在<code>stackoverflow</code>发现有人问了同样的问题，并且我使用其中一个方案解决了:</p>
<pre><code>When Hadoop-Streaming starts <span class="keyword">the</span> python scripts, your python <span class="keyword">script</span>'s path <span class="keyword">is</span> <span class="keyword">where</span> <span class="keyword">the</span> <span class="keyword">script</span> <span class="type">file</span> really <span class="keyword">is</span>. However, hadoop starts them <span class="keyword">at</span> './', <span class="keyword">and</span> your lib.py(<span class="keyword">it</span>'s a symlink) <span class="keyword">is</span> <span class="keyword">at</span> './', too. So, <span class="keyword">try</span> <span class="keyword">to</span> add 'sys.path.append(<span class="string">"./"</span>)' <span class="keyword">before</span> you import lib.py like this: 
import sys
sys.path.append('./')
import lib
</code></pre><blockquote>
<p><code>lib.py</code>表示自定义包</p>
</blockquote>
<p>应该就是<code>-file</code>上传到计算机器之后文件路径的问题产生的，不过感觉他的理由有点疑惑，按他说的如果我上传之后会通过软连接组织到同一目录下再使用，所以如果直接导入包可能会出问题，那我如果上传之前就是在同一目录下应该就不会出问题吧？？这里并不是很理解，但是至少是导入包的问题是解决了^_^</p>
<h2 id="参考">参考</h2><ol>
<li><a href="http://stackoverflow.com/questions/18150208/how-to-import-a-custom-module-in-a-mapreduce-job" target="_blank" rel="external">http://stackoverflow.com/questions/18150208/how-to-import-a-custom-module-in-a-mapreduce-job</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="问题">问题</h2><p>今天发现用<code>Python</code>编写<code>Hadoop Streaming</code>脚本时，如果自己导入自定义的模块会报错-_-<br>列如<code>word count</code>中的<a href="http://kubicode.me/2015/11/08/Hadoop/Hadoop-Streaming-Primary-Learning-And-Debug/">reducer</a>程序:<br>]]>
    
    </summary>
    
      <category term="Hadoop" scheme="http://kubicode.me/tags/Hadoop/"/>
    
      <category term="Hadoop" scheme="http://kubicode.me/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[小技巧]让Hexo在使用Mathjax时支持多行公式]]></title>
    <link href="http://kubicode.me/2016/03/18/Hexo/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/"/>
    <id>http://kubicode.me/2016/03/18/Hexo/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/</id>
    <published>2016-03-18T01:46:24.000Z</published>
    <updated>2016-03-28T15:42:26.000Z</updated>
    <content type="html"><![CDATA[<p>还是在<code>Hexo</code>中使用<code>Mathjax</code>写<code>Latex</code>公式的问题，在需要些多行的公式的时候，<br>例如:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>其中:</p>
<ol>
<li><code>begin</code>和<code>end</code>表示公式的起始</li>
<li><code>\\</code>符号表示换行</li>
<li><code>&amp;</code>表示对齐</li>
</ol>
<a id="more"></a>
<p>结果渲染到html页面之后结果是这样的:<br><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/error.png" with="500px"></p>
<p>完全没换行啊，而且又有莫名其妙的空格，按照之前的经验，估计是<code>markdown</code>渲染的<code>html</code>的时候出了问题<br><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/error_code.png"></p>
<p>发现两个问题:</p>
<ol>
<li><code>&amp;</code>符号被转义成了<code>&amp;amp;</code></li>
<li>双反斜杠<code>\\</code>被转义成功了<code>\</code></li>
</ol>
<p>这就是公式没换行的原因，肯定是<code>marked.js</code>里面做了处理，不过仔细看<code>Mathjax</code>脚本的配置项中有一项为<code>processEscapes: true</code>，说明<code>MathJax</code>是支持转义符号的，所以类似<code>&amp;amp;</code>是不需要额外处理的。</p>
<p>那么压力就到了解反斜杠问题，最粗暴的是讲反斜杠的转义从<code>marked.js</code>里面去掉，但是可能会影响其他功能，既然两根反斜杠是转为一根，而<code>Latex</code>是两个换行，最简单的方法就是写4个反斜杠:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>就可以得到期待的结果了:</p>
<center><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/right.png"></center>

<p>这种处理就不影响<code>Hexo</code>自身的功能，又可以满足多行公式的书写^_^</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>还是在<code>Hexo</code>中使用<code>Mathjax</code>写<code>Latex</code>公式的问题，在需要些多行的公式的时候，<br>例如:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>其中:</p>
<ol>
<li><code>begin</code>和<code>end</code>表示公式的起始</li>
<li><code>\\</code>符号表示换行</li>
<li><code>&amp;</code>表示对齐</li>
</ol>]]>
    
    </summary>
    
      <category term="Hexo" scheme="http://kubicode.me/tags/Hexo/"/>
    
      <category term="Hexo" scheme="http://kubicode.me/categories/Hexo/"/>
    
  </entry>
  
</feed>