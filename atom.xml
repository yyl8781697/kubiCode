<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Kubi Code'Blog]]></title>
  <subtitle><![CDATA[The palest ink is better than the best memory.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://kubicode.me/"/>
  <updated>2016-11-05T16:38:27.000Z</updated>
  <id>http://kubicode.me/</id>
  
  <author>
    <name><![CDATA[Kubi Code]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[使用点击图来计算Query-Doc的文本相关性]]></title>
    <link href="http://kubicode.me/2016/11/03/Search%20Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/"/>
    <id>http://kubicode.me/2016/11/03/Search Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/</id>
    <published>2016-11-03T12:07:18.000Z</published>
    <updated>2016-11-05T16:38:27.000Z</updated>
    <content type="html"><![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br><a id="more"></a></p>
</blockquote>
<h2 id="已有点击行为的向量计算">已有点击行为的向量计算</h2><p>在搜索场景下用户输入query，对搜索的结果进行点击反馈，将所有用户的搜索行为收集起来之后可以形成一张大的<code>Click-Graph</code>，为了简单，我们使用二部分来表示，其中左侧为$Query$，右侧为$Doc$，如果$q_i$到$d_j$存在点击行为，则左右侧将会有一条边连接，连上的权重及<code>点击的次数</code></p>
<center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/co-click-graph.png" width="400px"></center>

<p>现在假设语料的长度为$V$,则$Query$构成的矩阵为$|Query| \times V$，以及$Doc$构成的矩阵为$|Doc| \times V$，那么现在的任务就是如何计算这两个矩阵!</p>
<blockquote>
<p>其实这个语料就是上面所说道的$Query$和$Doc$同处的向量空间,一般值$Query$里面抠出来的<code>Term</code>或者$Doc$里面的<code>title</code>/<code>content</code>抠出来的<code>term</code>.</p>
</blockquote>
<p>这里使用的是<code>向量传播</code>来对$Query$和$Doc$进行计算，计算之前有这么这个假设:</p>
<ol>
<li><code>点击二部图</code>上的边连接的$q_i$和$d_i$是有相关性的(或者说有较高的相关性)</li>
<li>$q_i$上的<code>term</code>与$d_i$上的<code>title</code>/<code>content</code>的<code>term</code>应该是存在联系的</li>
</ol>
<p>目前暂不考虑缺少行为的$Query$和$Doc$，向量传播模型的步骤为:</p>
<ol>
<li>随意选择一侧进行向量初始化（$Query$和$Doc$端均可），我们使用$Query$向量来进行初始化$Q_i^0$,其中$Q_i^0$使用<code>one-hot</code>来表示，同时用$L2$进行归一化<blockquote>
<p>$i$表示第$Query$中的第$i$个,$0$表示第1次迭代（也就是初始化~）</p>
</blockquote>
</li>
<li>则第$D_j^n$个值($n&gt;=1$)的更新根据被点击$Query$的向量进行加权求和即可:<br> $$D_j^n=\frac{1}{||\sum_{i=1}^{|Query|}C_{i,j} \cdot Q_i^{n-1}||_2} \sum_{i=1}^{Query}C_{i,j} \cdot Q_i^{n-1}$$<blockquote>
<p>其中$Q_i^n$就是上一次迭代的$Query$向量，同样$D_j^n$也会进行一个$L2$正则化。</p>
</blockquote>
</li>
<li>$Doc$的向量表示进行了一次迭代更新之后继续更新$Query$的向量，这里是根据$Query$下公共点击的文档信息进行更新，其方式与$Doc$的更新是一样的:<br> $$Q_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}C_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}C_{i,j} \cdot D_i^{n-1}$$</li>
<li>按<code>2</code>、<code>3</code>的步骤不断进行迭代，直至收敛，其产出的$Query$的$Doc$的向量就都在一个空间内，同时还可以计算相似度/相关性</li>
</ol>
<p>这里以上的图为例再说一下计算过程:</p>
<ol>
<li>初始化$Query$的向量:<ul>
<li>$Q_1:\{yahoo:\frac{1}{\sqrt{2}},finance:\frac{1}{\sqrt{2}},mail:0\}$</li>
<li>$Q_2:\{yahoo:1,finance:0,mail:0\}$</li>
<li>$Q_3:\{yahoo:\frac{1}{\sqrt{2}},finance:0,mail:\frac{1}{\sqrt{2}}\}$<blockquote>
<p>因为图中$Query$的语料三个<code>term</code>，所以这里初始化为3维.</p>
</blockquote>
</li>
</ul>
</li>
<li>根据上一次$Query$的迭代信息以及与$Doc$的点击信息来更新$Doc$的向量:<ul>
<li>$D_1=\frac{(\frac{3}{8}Q_1 + \frac{5}{8}Q_2)}{||\frac{3}{8}Q_1 + \frac{5}{8}Q_2||_2}$</li>
<li>$D_2=\frac{(\frac{1}{5}Q_2 + \frac{4}{5}Q_3)}{||\frac{1}{5}Q_2 + \frac{4}{5}Q_3||_2}$</li>
</ul>
</li>
<li>然后就是不断的迭代就行了，这样已经很清晰了</li>
</ol>
<p>了解过一些信息检索或者链接分析的朋友可能会马上想到，咦~这好像<code>Hits</code>这个算法。的确是的，在计算过程中极为相似，不过<code>Hits</code>权重主要是计算<code>Hubs</code>与<code>Authority</code>两端的权重，而[1]中迭代完得到的是各个向量，有异曲同工之妙~<br>另外在实际的query量级一般都是百万以上，这样$Query$的语料的量就很大了,而搜索引擎中需要计算的性能要求极高，，所以一般进行稀疏存储，并且只取一些重要的<code>term</code>来对$Query$进行表示</p>
<h2 id="缺少点击行为的向量计算">缺少点击行为的向量计算</h2><p>但是实际应用中用户搜索之后带来了点击行为的只是一小部分就，如果仅按照上述点击传播的方式来计算的话无query点击的文档将会将会无法得到正常的向量，同时一些新的$\hat{Query}$（从未有用户搜索过的query）也就无法得到正常的向量数据，所以需要一种对于这种缺失行为的$\hat{Query}$和$\hat{Doc}$进行向量表示估计.</p>
<p>由于在线计算相关性时对于已有行为的$Query-Doc$和缺失行为的是一视同仁的，因此为了在线计算时不应该因为训练数据产生偏差，所以需要与已有行为的$Qeury-Doc$向量在同一个空间内，同时考虑已有行为的$Query$和$Doc$的向量均已计算得到，我们还借助这些数据来预估缺失行为的向量.</p>
<h3 id="提取Unit向量">提取Unit向量</h3><p>既然未行为的$\hat{Query}$与$\hat{Doc}$之间没有任何边向量，那我们可以通过有行为的$Query$进行造边，先将$\hat{Query}$分解为各种<code>Unit</code>，这样就有$u_i \in unit(q_i)$,如果存在$Query$含有$u_i$，则将$u_i$对对应的$Query$之间形成一条虚拟的边,同时称含有$u_i$的所有$Query$的集合为$O_{u_i}$</p>
<blockquote>
<p>这里分解时可以按<code>n-gram</code>进行分解，但是某个$Query$进行分解之后不能有<code>overlap</code></p>
</blockquote>
<p><center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/absent_graph.png" width="700px"></center><br>这种边的构建方式如上图，$q_1$、$q_2$和$q_3$均都包含了<code>yahoo</code>这个词，则在他们之间形成这条虚线的边。<br>接下来我们可以理解$Query-Doc$之间的向量传播方法，我们当然也可以完成$Unit-Doc$的传播.<br>$u_i$会有$q_i$有边相连，而$q_i$与$d_i$又有变相连，因此我们可以间接认为$u_i$与$d_i$也是有边相连。<br>现假设$q_k$包含了$u_i$，同时$q_k$与$d_j$存在点击行为，$P_{i,k,j}$表示为这个二折线的权重，则该权重其实为$q_k$与$d_j$的点击次数，那么我们就会有<br>$$P_{i,j} = \sum_{k=1}^{|O_{u_i}|} P_{i,k,j}$$<br>其演示就是上图的右侧部分，<code>yahoo</code>与$d_1$之间的权重为8，与$d_2$之间的权重为5，既然到了这一步，我们就可以按照上一小节的传播方式来计算,这样就可以巧妙的得到$U_i$的向量:<br>$$U_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}P_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}P_{i,j} \cdot D_i^{n-1}$$</p>
<p>上面得到的是关于$\hat{Query}$上<code>unit</code>的向量，同样的我们也可以从$\hat{Doc}$这一侧出发，来计算$\hat{Doc}$<br>相关的<code>unit</code></p>
<h3 id="计算Unit向量权重">计算Unit向量权重</h3><p>有了<code>unit</code>的向量之后，接下来要解决的问题就是如何得到$\hat{Query}$或者$\hat{Doc}$的向量了，其实最简单的方法就是将他们各自的<code>unit</code>进行平均即可,不过[1]使用线性回来来解决该权重问题，在进行权重训练时使用最小平方差:<br>$$\underset{w}{min} \sum_{i=1}^{|T|} || T_i-\sum_{u_j \in U_{T_i}^{all}} W_j \cdot U_j||_2^2$$</p>
<blockquote>
<p>$T_i$是使用有点击行为的$Query$计算得到的向量，也就是我们所认为的<code>gold-set</code><br>这样求出来的$W$就是各个$unit_i$不同的权重</p>
</blockquote>
<h3 id="预估向量">预估向量</h3><p>根据上面两个步骤得到的<code>unit</code>的向量和权重之后，得到整体的$\hat{Query}$或者$\hat{Doc}$就很方便了，由于<code>unit</code>本身就是$\hat{Query}$或者$\hat{Doc}$分解出来的，这里基础数据也都已经计算完成了，所以直接进行加权求和即可:<br>$$q_v=\sum_{u_i \in u_q} W_iU_i$$<br>和<br>$$d_v=\sum_{u_i \in u_d} W_iU_i$$</p>
<p>这样一来缺失形式的向量数据也都可以计算出来了</p>
<h2 id="总结">总结</h2><p>该方法成功的借助了点击日志对于相关性进行估计（其实我觉得这种方式得到的文本相关性与ctr的预估会有部分重叠了），并且在实现上:</p>
<ol>
<li>已有点击数据的$Query$和$Doc$的向量直接离线就按完成</li>
<li>缺失点击的$\hat{Query}$和$\hat{Doc}$可以利用离线计算的<code>unit</code>向量在线直接进行加权求和即可</li>
<li>对于在线存储均使用稀疏方式并只存<code>top-k</code>，因此存储并不是问题</li>
<li>在线计算相关性可以直接按相似度计算，复杂度为$k log k$所以并不是很高~</li>
</ol>
<p>可实现性还是比较强的，但是对于一些未登录词就无能为力了….</p>
<blockquote>
<p>关于改算法的最终实现结果去看paper吧，效果自然是还可以的</p>
</blockquote>
<p>看了这篇paper，其实还是有点其他启发:</p>
<ol>
<li>如果搜索了query之后对于未点击的文档是不是可以进行降权（因为点击的文档是进行加权的）</li>
<li>再想想，~其实直接使用来计算文本相关性风险还是挺大</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>2016-Learning Query and Document Relevance from a Web-scale Click Graph</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br>]]>
    
    </summary>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[语言模型在信息检索中的平滑方法]]></title>
    <link href="http://kubicode.me/2016/10/24/Machine%20Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/"/>
    <id>http://kubicode.me/2016/10/24/Machine Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/</id>
    <published>2016-10-24T11:58:01.000Z</published>
    <updated>2016-11-05T16:33:15.000Z</updated>
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br><a id="more"></a><br>由于在给定$q$下，不同文档的$p(q)$是一样的，这里关注的是排序，所以可以直接将$p(q)$进行移除，另外式子右侧的$p(d)$为文档$d$对于任何$q$的相关性先验，在$p(q|d)$就是在给定$d$下生成$q$的概率，也就是文档$d$到$q$的匹配程度.<br>为了简单起见，我们假设$p(d)$是均匀分布的，这样的话$p(d)$就不会影响排序，那么信息检索的问题就会转为一个一元语言模型:<br>$$p(q|d) = \prod_i p(q_i|d)$$<br>大多数平滑的方法都会使用两类分布:</p>
<ol>
<li>一类是对于在文档中出现的词的模型$p_s(w|d)$</li>
<li>另一个是没有出现在文档中的词的模型$p_u(w|d)$</li>
</ol>
<p>这样的话在一个$q$中根据词在文档中的出现与否可以写为:<br>$$\begin{equation}\begin{split}log p(q|d)&amp;= \sum_i log p(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) - \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i|d)&gt;0} log \frac{p_s(q_i|d)}{p_u(q_i|d)} + \sum_i log p_u(q_i|d) \\<br>\end{split}\end{equation}$$</p>
<p>其中未在文档中出现的词的概率典型的表示方法就是该词在所有集合中出现的频率:<br>$$p_u(q_i|d) = \alpha_d p(q_i|C)$$</p>
<blockquote>
<p>其中$\alpha_d$为独立于文档的一个常量，$p(q_i|C)$为集合中的语言模型，这样我们就会有</p>
</blockquote>
<p>$$log p(q|d) = \sum_{i:c(q_i:d)&gt;0} log \frac{p_s(q_i|d)}{\alpha_d p(q_i|C)} + n log \alpha_d + \sum_i log p(q_i|C)$$</p>
<blockquote>
<p>其中$n$为$q$的长度，上面式子的右侧与$d$并没有关系，所以直接去掉也不会影响排序</p>
</blockquote>
<p>这样的话检索函数就变成了两部分，第一部分为$q$与$d$相匹配<code>term</code>的权重，第二部分为与$q$无关的一个常量，一般是用于对非匹配<code>term</code>的平滑。</p>
<p>这时候再看下第一部分，其实可以上面$p(q_i|C)$大致可以看为<code>IDF</code>,而$p_s(q_i|d)$又非常向tf,因为上面的Language Model与<code>tf*idf</code>路线还是挺像的。</p>
<h2 id="Smoothing_Methods">Smoothing Methods</h2><p>看了上面的描述，接下来主要讲一下对于$p(w|d)$的估计，最简单的使用数数的方式，最大似然法进行估计为:<br>$$p_{ml}(w|d) = \frac{w;d}{\sum_w c(w;d)}$$</p>
<blockquote>
<p>其实就是词在文档中出现的频率</p>
</blockquote>
<p>这种方式对于没出现在文档中的词将会低估（其实就是没值了），因为对于没有在文档中出现的词会给予一个非0概率的平滑。<br>通常我们会对出现在文档中的词的概率进行一个折损，同时对于未出现在文档中的词的概率给予一个额外的值:<br>$$ p(w|d)=\left\{<br>\begin{aligned}<br>p_s(w|d) &amp; \quad if \quad word \quad w \quad is \quad seen \\<br>\alpha_d p(w|C) &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>同时$\alpha_d$将会依赖$d$，如果$p(w|d)$给定的情况下，我们将会有:<br>$$\alpha_d = \frac{1-\sum_{w:c(w:d)&gt;0} p_s(w|d)}{1-\sum_{w:c(w:d)&gt;0}p(w|C)}$$</p>
<p>因此这里最大的问题是需要计算$p_s(w|d)$,因为在信息检索中对于性能的要求将其高，因此为考虑性能和效果，下面主要简单的介绍三种平滑方式</p>
<h3 id="Jelinek-Mercer">Jelinek-Mercer</h3><p>这种方式是融合了最大似然发以及一个置信因子来控制各个模型<br>$$p_{\lambda} = (1-\lambda)p_{ml}(w|d) + \lambda p(w|C)$$</p>
<blockquote>
<p>这种方式非常的高效</p>
</blockquote>
<h3 id="Dirichlet">Dirichlet</h3><p>他其实是贝叶斯平滑，然后使用了<code>Dirichlet</code>先验，使用这种可以得到<br>$$p_{\mu}(w|d) = \frac{c(w;d) + \mu p(w|C)}{\sum_w c(w;d)+ \mu}$$</p>
<h3 id="Absolute_discount">Absolute discount</h3><p>这种方式主要是通过降低可见词的概率来完成的,类似<code>Jelinek-Mercer</code>方法,与$1-\lambda$不同的是  使用减去一个常量来完成:<br>$$p_{\delta } = \frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \sigma p(w|C)$$</p>
<blockquote>
<p>其中$\delta \in [0,1]$,为一个折损常量，$\sigma = \delta|d|_u/|d|$,所以所有的概率之和为1，$|d|_u$为文档中不同<code>term</code>的数量,$|d|$为文档中<code>term</code>的总数量</p>
</blockquote>
<p>另外注意$max(c(w:d)-\delta,0)$中的$c(w:d)$应该是归一化0~1了，这样才可以和$\delta$相减</p>
<p>对于这三种平滑方式的一个表格表示（非常清晰）:</p>
<table>
<thead>
<tr>
<th style="text-align:center">平滑方法</th>
<th style="text-align:center">$p_s(w &#124; d)$</th>
<th style="text-align:center">$\alpha_d$</th>
<th style="text-align:center">参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Jelinek-Mercer</code></td>
<td style="text-align:center">$(1-\lambda)p_{ml}(w &#124; d) + \lambda p(w &#124; C)$</td>
<td style="text-align:center">$\lambda$</td>
<td style="text-align:center">$\lambda$</td>
</tr>
<tr>
<td style="text-align:center"><code>Dirichlet</code></td>
<td style="text-align:center">$\frac{c(w;d) + \mu p(w &#124; C)}{\sum_w c(w;d)+ \mu}$</td>
<td style="text-align:center">$\frac{\mu}{\sum_w c(w;d)+\mu}$</td>
<td style="text-align:center">$\mu$</td>
</tr>
<tr>
<td style="text-align:center"><code>Absolute discount</code></td>
<td style="text-align:center">$\frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} p(w &#124; C)$</td>
<td style="text-align:center">$\frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} $</td>
<td style="text-align:center">$\delta$</td>
</tr>
</tbody>
</table>
<p>看上面三种平滑的计算方式都是非常的简单，并且$\alpha$都是可以离线计算，其最终的复杂度为$O(k|q|)$,$k为文档的平均长度$</p>
<blockquote>
<p>其实复杂度不用这么多，如果在线查找term时使用二分的话  复杂度仅为$O(log(k)|q|)$</p>
</blockquote>
<h2 id="总结">总结</h2><p>这三种方法比较经典，并且可实现性强，$p_s(w|d)$和$\alpha_d$全部都可以离线计算完成，在线只需要进行简单的求和即可,值得一试~</p>
<h2 id="参考">参考</h2><ol>
<li>Zhai, Chengxiang, and John Lafferty. “A study of smoothing methods for language models applied to ad hoc information retrieval.” Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2001.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Python画ROC曲线以及AUC值]]></title>
    <link href="http://kubicode.me/2016/09/19/Machine%20Learning/AUC-Calculation-by-Python/"/>
    <id>http://kubicode.me/2016/09/19/Machine Learning/AUC-Calculation-by-Python/</id>
    <published>2016-09-18T16:02:43.000Z</published>
    <updated>2016-09-18T16:39:41.000Z</updated>
    <content type="html"><![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/" target="_blank" rel="external">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br><a id="more"></a></p>
<h2 id="AUC计算">AUC计算</h2><p><code>AUC</code>的计算分为下面三个步骤：</p>
<ol>
<li>计算数据的准备，如果模型训练时只有训练集的话一般使用交叉验证的方式来计算，如果有评估集(<code>evaluate</code>)一般就可以直接计算了，数据的格式一般就是需要预测得分以及其目标类别（注意是目标类别，不是预测得到的类别）</li>
<li>根据阈值划分得到横（X:<code>False Positive Rate</code>）以及纵（Y:<code>True Positive Rate</code>）点</li>
<li>将坐标点连成曲线之后计算其曲线下面积,就是<code>AUC</code>的值</li>
</ol>
<p>直接上python代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! -*- coding=utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log,exp,sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluate_result=<span class="string">"you file path"</span></span><br><span class="line">db = []  <span class="comment">#[score,nonclk,clk]</span></span><br><span class="line">pos, neg = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">with</span> open(evaluate_result,<span class="string">'r'</span>) <span class="keyword">as</span> fs:</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">		nonclk,clk,score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		nonclk = int(nonclk)</span><br><span class="line">		clk = int(clk)</span><br><span class="line">		score = float(score)</span><br><span class="line">		db.append([score,nonclk,clk])</span><br><span class="line">		pos += clk</span><br><span class="line">		neg += nonclk</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">db = sorted(db, key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算ROC坐标点</span></span><br><span class="line">xy_arr = []</span><br><span class="line">tp, fp = <span class="number">0.</span>, <span class="number">0.</span>			</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(db)):</span><br><span class="line">	tp += db[i][<span class="number">2</span>]</span><br><span class="line">	fp += db[i][<span class="number">1</span>]</span><br><span class="line">	xy_arr.append([fp/neg,tp/pos])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算曲线下面积</span></span><br><span class="line">auc = <span class="number">0.</span>			</span><br><span class="line">prev_x = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> xy_arr:</span><br><span class="line">	<span class="keyword">if</span> x != prev_x:</span><br><span class="line">		auc += (x - prev_x) * y</span><br><span class="line">		prev_x = x</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"the auc is %s."</span>%auc</span><br><span class="line"></span><br><span class="line">x = [_v[<span class="number">0</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">y = [_v[<span class="number">1</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">pl.title(<span class="string">"ROC curve of %s (AUC = %.4f)"</span> % (<span class="string">'svm'</span>,auc))</span><br><span class="line">pl.xlabel(<span class="string">"False Positive Rate"</span>)</span><br><span class="line">pl.ylabel(<span class="string">"True Positive Rate"</span>)</span><br><span class="line">pl.plot(x, y)<span class="comment"># use pylab to plot x and y</span></span><br><span class="line">pl.show()<span class="comment"># show the plot on the screen</span></span><br></pre></td></tr></table></figure></p>
<p>输入的数据集可以参考<a href="/img/AUC-Calculation-by-Python/evaluate_result.txt">svm预测结果</a><br>其格式为:</p>
<pre><code>nonclk <span class="string">\t</span> clk <span class="string">\t</span> score
</code></pre><p>其中：</p>
<ol>
<li><code>nonclick</code>:未点击的数据，可以看做负样本的数量</li>
<li><code>clk</code>:点击的数量，可以看做正样本的数量</li>
<li><code>score</code>:预测的分数，以该分数为group进行正负样本的预统计可以减少<code>AUC</code>的计算量</li>
</ol>
<p>运行的结果为:</p>
<center><img src="/img/AUC-Calculation-by-Python/auc.png" width="500px"></center>


<blockquote>
<p>如果本机没安装<code>pylab</code>可以直接注释依赖以及画图部分</p>
</blockquote>
<h2 id="注意">注意</h2><p>上面贴的代码:</p>
<ol>
<li>只能计算二分类的结果（至于二分类的标签随便处理）</li>
<li>上面代码中每个<code>score</code>都做了一次阈值，其实这样效率是相当低的，可以对样本进行采样或者在计算横轴坐标时进行等分计算</li>
</ol>
<h2 id="参考">参考</h2><ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm" target="_blank" rel="external">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm</a></li>
</ul>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LambdaRank-支持非平滑损失函数的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/08/28/Machine%20Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/"/>
    <id>http://kubicode.me/2016/08/28/Machine Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/</id>
    <published>2016-08-28T14:44:59.000Z</published>
    <updated>2016-09-06T15:59:12.000Z</updated>
    <content type="html"><![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br><a id="more"></a></p>
<p><center><img src="/img/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/rank.png" alt=""><br>图1</center><br>如图1，每个线条表示一个文档，位置越上面表示排序越靠前，其中蓝色线条表示相关的文档，灰色则是不相关的文档，计算左侧得到的<code>Pairwise Error</code>为13，此时将最上面的蓝色线条下移3个位置，将下面的蓝色线条上移5个位置，则其<code>Pairwise Error</code>下降到了11。然而传统的排序评估指标<code>NDCG</code>或者<code>ERR</code>都是比较关心靠前的位置，类似刚刚右侧的变化并不希望出现。<br>而<code>LambdaRank</code>可以支持对这种非平滑的评估指标(比如<code>NDCG</code>)进行直接的优化.</p>
<h2 id="LambdaRank原理">LambdaRank原理</h2><p>在图1右侧中，我们用$D_i$和$D_j$分别表示上下两个相关的文档，对于训练时下一次的移动中，我们更加愿意看到红色箭头的变化，因为此时$D_i$移动头部比$D_j$移动到头部明显代价更小，并且同样能减少损失函数.<br>对于$i &lt;&lt; j$这种情况($D_i$排在前面)，<code>LambdaRank</code>将会有:<br>$$|\frac{\partial C}{\partial o_i}| &gt;&gt; |\frac{\partial C}{\partial o_j}|$$</p>
<p>同时，<code>LambdaRank</code>并不是显示对的优化函数进行求导在求最优，而是<br>$$\frac{\partial C}{\partial o_i} = -\lambda_i(o_1,l_1…o_n,l_n)$$，</p>
<blockquote>
<p>$o_i$表示给定query下文档的打分值,$l_i$表示该文档对应的标签</p>
</blockquote>
<p>可以看到这个梯度是依赖<code>query</code>下全部文档的分数以及其标签,这也应该是算一个<code>ListWise</code>的学习方法了,其中式子中带了符号表示$\lambda_i$为正数时将会在排序列表中向上移动同时会降低损失函数的值.<br>那么问题来了，这个$\lambda$函数该如何选呢?</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的神经网络加速算法中，其<br>$$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} =  -\frac{1}{1+e^{o_i-o_j}} $$</p>
<blockquote>
<p>这里目标概率$\overline{P}_{i,j}=1$</p>
</blockquote>
<p><code>LambdaRank</code>的机智之处就是在计算$\lambda_{i,j}$的时候引入了优化指标的梯度,变成了<br>$$\lambda_{i,j} =  -\frac{1}{1+e^{o_i-o_j}} |\Delta Z|$$<br>其中$\Delta Z$表示将文档$D_i$和$D_j$的位置相关调换之后重新计算得到的评估指标的差值（此时其他的文档顺序是不变的）<br>即可从新计算得到$\lambda_i$为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$<br>这个$\lambda$可以理解为上面图中的箭头<code>方向和强度</code></p>
<ol>
<li>符号表示方向，正好为向上移动</li>
<li>大小表示强度，绝对值越大，表示移动的距离越大</li>
</ol>
<p>接下来<code>LambdaRank</code>具体的训练和使用方式就即可和<code>RankNet</code>一致了.</p>
<p>这个的$\Delta Z$可以替换成任何评估指标(比如<code>NDCG</code>、<code>ERR</code>)了，这样的话其实$LambdaRank$就可以变相的直接对学习排序的评估指标进行优化了，解决了之前评估指标由于是非凸无法进行优化的问题</p>
<blockquote>
<p>这个具体的证明要看去原始paper了[1],是一个不是很容易理解的东西 -_-||</p>
</blockquote>
<h2 id="总结">总结</h2><p>$LambdaRank$其实是做了两个大贡献:</p>
<ol>
<li>一是对传统的<code>RankNet</code>提出了一个加速算法（我直接将其丢了<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的学习中）</li>
<li>二是在<code>RankNet</code>的优化目标的基础上添加了一个基于评估指标的梯度$\Delta Z$因子，可以变相的直接对学习排序的评估指标进行优化</li>
</ol>
<p>虽然貌似没有见一些其他工业上说明使用了该算法，但是该算法对于鼎鼎大名的<code>LambdaMart</code>的启发无疑是最大的。</p>
<h2 id="参考">参考</h2><ol>
<li>Schölkopf, B, Platt, J, Hofmann, T. Learning to Rank with Nonsmooth Cost Functions[C]// MIT Press, 2007:193 - 200.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankNet:基于梯度下降的学习排序]]></title>
    <link href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/"/>
    <id>http://kubicode.me/2016/05/30/Machine Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/</id>
    <published>2016-05-30T11:51:21.000Z</published>
    <updated>2016-09-22T17:33:19.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>
<a id="more"></a>
<p>我们现在将$P(D_i \triangleright D_j)$前后顺序的预测概率表示为$P_{i,j}$,同时定义$o_i \equiv f(x_i)$ 以及 $o_{i,j}=f(x_i)-f(x_j)$，则我们可以<code>logistic</code>函数来表示$P_{i,j}$:<br>$$P_{i,j} \equiv \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} \equiv \frac{1}{1+e^{-o_{i,j}}}$$</p>
<p>为了衡量预测概率$P_{i,j}$与期望/目标概率$\bar{P}_{i,j}$的接近程度，这里使用<code>Cross Entropy</code>作为损失函数:<br>$$C_{i,j} = -\bar{P}_{i,j} log P_{i,j} - (1-\bar{P}_{i,j}) log (1-P_{i,j})$$</p>
<p>将$P_{i,j}$代入损失函数$C_{i,j}$之后即可得到:<br>$$\begin{equation}\begin{split}C_{i,j}&amp;=-\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (1-\frac{e^{o_{i,j}}}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (\frac{1}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} \left( log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - log (\frac{1}{1+e^{o_{i,j}}}) \right) - log (\frac{1}{1+e^{o_{i,j}}})  \\<br>&amp;= -\bar{P}_{i,j}  o_{i,j} + log(1+e^{o_{i,j}})<br>\end{split}\end{equation}$$</p>
<p>下面的图是当$\bar{P}_{i,j} \in \{0,0.5,1\}$时的损失函数情况:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/lossfunction.png" style="align:center;margin:0 auto" width="400px"></p>
<p>当$\bar{P}_{i,j} = 1$的时候，<code>Cross Entropy</code>的损失函数将会变为:$$C_{i,j}=log(1+e^{-o_{i,j}})$$<br>直接会变为一个<code>log</code>型的损失函数，其中$o_i-o_j$越大，损失函数的值也就会越小，这也是我们所期望训练的结果(表示我们的样本全部成立)</p>
<p>现我们损失函数$C_{i,j}$求$o$的偏导:<br>$$\frac{ \partial{C}}{ \partial{o_i}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) =\left( -\bar{P}_{i,j}+P_{i,j} \right) = -\frac{ \partial{C}}{ \partial{o_j}}$$</p>
<blockquote>
<p>其实可以发现就是在$-\bar{P}_{i,j}+P_{i,j}=0 $时就是我们的目标<br>另外请注意这里的$P_{i,j}$其实就是<code>文献2</code>中的$S_{i,j}$，但是由于他们的取值范围不一致 $P_{i,j} \in \{0,0.5,1\}$,$S_{i,j} \in \{-1,0,1\}$，因此导致了<code>文献2</code>中对于<code>C</code>的偏导与本文的有微小的偏差</p>
</blockquote>
<p>现我们认为$w$为$o=f(x:w)$的一个权重,也就是我们最终希望求解的值，而这个参数我们就可以使用<code>随机梯度下降法来求解</code>:<br>$$w_k \rightarrow  w_k - \eta \frac{\partial{C}}{\partial{w_k}} = w_k - \eta \left( \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}} \right)$$</p>
<p>其中$\eta$表示学习率，一般取一个比较小的数（比如:$1e-3$,$1e-5$）<br>另外我们可以求得$C$的增量变化:<br>$$\Delta C = \sum_k \frac{\partial{C}}{\partial{w_k}} \Delta w_k = \sum_k \frac{\partial{C}}{\partial{w_k}} \left( - \eta \frac{\partial{C}}{\partial{w_k}} \right) = - \eta \sum_k \left( \frac{\partial{C}}{\partial{w_k}} \right)^2  &lt; 0 $$</p>
<ol>
<li>$\Delta C &lt; 0 $表示随着权重参数$w$的沿着负梯度的变化，损失函数$C$会越来越小</li>
<li>另外当梯度$\frac{\partial{C}}{\partial{w_k}} = 0$时，才会让损失函数达到最小值</li>
</ol>
<p>上面的式子告诉我们通过梯度下降法求解<code>RankNet</code>时，就算<code>算分</code>函数没有好的梯度或者不可求导时任可以进行权重的更新（直接对$o$进行梯度下降，但是其梯度方向需要自己指定，并且要求权重$w$与最终的算法$o$是相关的）。</p>
<h2 id="合并概率">合并概率</h2><p>理想的情况下，$\bar{o}$的输出得到的模型应该是这样纸的:$$\bar{P}_{i,j}=\frac{e^{\bar{o}_{i,j}}}{1+e^{\bar{o}_{i,j}}}$$</p>
<blockquote>
<p>其中$\bar{o}_{i,j}=\bar{o}_i-\bar{o}_j$</p>
</blockquote>
<p>上面的模型需要$\bar{P}_{i,j}$保持一致性，也就是如果$D_i$的相关性要高于$D_j$,$D_j$的相关性同时也是要高于$D_k$，则$D_i$的相关性也是一定要高于$D_j$，如果没有保持一致性，其实上面的理论就不好使了。。。<br>现给定$\bar{P}_{i,j}$和$\bar{P}_{j,k}$时会有:</p>
<p>$$\begin{equation}\begin{split} \bar{P}_{i,k}&amp;= \frac{e^{\bar{o}_{i,k}}}{1+e^{\bar{o}_{i,k}}}\\<br>&amp;= \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}} \\<br>&amp;= \frac{ \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})} }{ \frac{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{\frac{(1+e^{\bar{o}_{i,j}}+e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})+(2e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{i,j}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{1+2\bar{P}_{i,j}\bar{P}_{j,k}-\bar{P}_{i,j}-\bar{P}_{j,k}}<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>其中第一步是基于这个来的:$$\begin{equation}\begin{split}e^{\bar{o}_{i,k}}&amp;=e^{\bar{o}_i-\bar{o}_k} \\<br>&amp;= e^{\bar{o}_i-\bar{o}_j+\bar{o}_j-\bar{o}_k}\\<br>&amp;= e^{\bar{o}_{i,j}+\bar{o}_{j,k}}  \\<br>&amp;= e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}}<br>\end{split}\end{equation}$$</p>
</blockquote>
<p>当$\bar{P}_{i,j}=\bar{P}_{i,k}=P$时，其$\bar{P}_{i,k}$的取值情况为:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/pik.png" width="400px"></p>
<ol>
<li>$P=0$时，有$\bar{P}_{i,k}=P=0$ 表示:$D_i$排$D_j$后面,$D_j$排$D_j$的后面，则$D_i$也一定排$D_j$的后面</li>
<li>$0 &lt; P &lt; 0.5$时，$\bar{P}_{i,k} &lt; P$</li>
<li>$P=0.5$时，有$\bar{P}_{i,k}=P=0.5$ 表示:$D_i$有一般概率排$D_j$前面,$D_j$也有一半的概率排$D_j$的前面，则$D_i$同样也是一半的概率排$D_j$的前面</li>
<li>$0.5 &lt; P &lt; 1$时，$\bar{P}_{i,k} &gt; P$</li>
<li>$P=1$时，有$\bar{P}_{i,k}=P=1$ 表示:$D_i$排$D_j$前面,$D_j$排$D_j$的前面，则$D_i$也一定排$D_j$的前面</li>
</ol>
<blockquote>
<p>从上面的图中可以看到，其实目标概率是都可以保持一致性的.</p>
</blockquote>
<h2 id="神经网络训练">神经网络训练</h2><p><code>RankNet</code>使用的是一个2层的神经网络作为算分模型$f(x:w,b)$,他在排序分数的公式是:<br>$$o = f(x:w,b) = f^{(2)}  \left( \sum_l w_l^{(2)} \cdot f^{(1)}  \left( \sum_k w_{lk}^{(1)}x_k +b^{(1)} \right) +b^{(2)} \right)$$</p>
<p>其中:</p>
<ol>
<li>$x_k$表示输入的$k$个特征元素</li>
<li>$w$表示每一层的权重,$b$表示每一层的偏置，上标$(\cdot)$表示当前所属的神经网络的层数</li>
<li>下标$l$表示第一层的单元数量</li>
<li>$f$使用<code>sigmoid</code>作为激活函数</li>
</ol>
<p>在对于上面的二层神经网络求解时:<br>$$\frac{\partial{C}}{\partial{b^{(2)}}} = \lambda_{i,j}({f’}_i^{(2)}-{f’}_i^{(2)}) = \Delta_i^{(2)} - \Delta_j^{(2)} \\<br>\frac{\partial{C}}{\partial{w^{(2)}}} = \Delta_i^{(2)}f_i^{(1)}  - \Delta_j^{(2)}f_j^{(1)} \\<br>\frac{\partial{C}}{\partial{b^{(1)}}} = \Delta_i^{(2)}f_i^{(1)}w^{(2)}   - \Delta_j^{(2)}f_j^{(1)}w^{(2)} \\<br>\frac{\partial{C}}{\partial{w_k^{(1)}}} = \Delta_i^{(2)} x_{i,k} - \Delta_j^{(2)} x_{j,k}<br>$$<br>这样神经网络就可以使用<code>前向预测</code>和<code>后向反馈</code>来进行训练了,只是其后向反馈阶段是需要通过<code>pair</code>进行计算的。</p>
<h2 id="神经网络加速">神经网络加速</h2><p>这里我们输入的样本是<code>pair</code>对$\{(x_i,x_j),\bar{P}_{i,j}\}$,其中$\bar{P}_{i,j}$就是我们的目标概率,根据第一小节(算法原理)中指到的，使用梯度下降法进行求解:<br>$$\begin{equation}\begin{split} \frac{\partial{C}}{\partial{w_k}} &amp;= \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}}  \\<br>&amp;=  \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right)\\<br>&amp;=  \lambda_{i,j} \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right) \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>记$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) $</p>
</blockquote>
<p>上面的是对于每一对<code>pair</code>都会进行一次权重的更新，其实是可以对同一个query下的所有文档<code>pair</code>全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数，其更新的公式为:</p>
<p>$$\Delta w_k = -\eta \sum_{\{i,j\}\in I}  \left(\lambda_{i,j} \frac{\partial{o_i}}{\partial{w_k}} - \lambda_{i,j} \frac{\partial{o_j}}{\partial{w_k}}\right) = -\eta \sum_i \lambda_i \frac{\partial{o_i}}{\partial{w_k}} $$</p>
<blockquote>
<p>$I$表示某个<code>query</code>下所有不同排序的<code>pair</code>出现一次的集合，$\{i,j\}$表示两个文档满足$D_i \triangleright D_j$,也就是$\bar{P}_{i,j}=1$</p>
</blockquote>
<p>这里要着重介绍一下$\lambda_i$:</p>
<p>$\lambda$可以理解为某个给定query（给定排序）下第$i$个文档$D_i$的一个<code>值</code>,为了计算$\lambda_i$，需要找到这个排序下所有排在$D_i$前面的文档$D_j$（此时有$\{i,j\} \in I$），以及所有排在$D_i$后面的文档$D_k$（有$\{k,i\} \in I$）,同时针对$\lambda_{i,j}$的文档进行累加，对于$\lambda_{k,i}$的文档进行累减.</p>
<blockquote>
<p>比如  当前排序下只有一个pair,有$I=\{\{1,2\}\}$，则有$\lambda_1 = \lambda_{1,2} = -\lambda_2$<br>又比如，当前排序下有三个pair，有$I=\{\{1,2\},\{1,3\},\{2,3\}\}$,则有$\lambda_1 = \lambda_{1,2}+\lambda_{1,3}$、$\lambda_2 = \lambda_{2,3}-\lambda_{1,2}$、$\lambda_3 = -\lambda_{1,3}-\lambda_{2,3}$</p>
</blockquote>
<p>对于表示成式子为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$</p>
<p>因此，我们可以认为$\lambda_i$为在某个给定<code>query</code>的$D_i$需要移动的方向以及移动的强度,另外这种方式可以看做是一种mini-batch的梯度下降算法，不要将全部的<code>pair</code>进行反向传播,其复杂度可以降到$O(n_q)$可以大大加快原始的神经网络训练.这也为<code>LambdaRank</code>奠定了基础（其实很多在<code>LambdaRank</code>的paper提出来的）</p>
<h2 id="总结">总结</h2><p><code>RankNet</code>训练希望文档<code>pair</code>对的前后排序概率与目标概率一致，用交叉熵作为损失函数，在实际排序中使用了神经网络作为算分排序函数，同时可以有<code>min-batch</code>的批量训练方法。据说微软的<code>Bing</code>之前使用着他.</p>
<h2 id="参考">参考</h2><ol>
<li>Burges, Chris, et al. “Learning to rank using gradient descent.” Proceedings of the 22nd international conference on Machine learning. ACM, 2005.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GBRank:一种基于回归的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/05/08/Machine%20Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/"/>
    <id>http://kubicode.me/2016/05/08/Machine Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/</id>
    <published>2016-05-08T09:30:39.000Z</published>
    <updated>2016-05-08T15:27:47.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting" target="_blank" rel="external">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/" target="_blank" rel="external">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br><a id="more"></a></p>
<p>从$R(h)$可以知道知道每个<code>pair</code>对$\left \langle x_i,y_i \right \rangle$的cost为:</p>
<p><center><img src="/img/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/cost_function.png" width="400px"></center><br>可以发现当:</p>
<ol>
<li>$h(x_i) \geq h(y_i)$，cost代价为0，也就是并不会对最终的风险函数的值产生影响</li>
<li>$h(x_i) &lt; h(y_i)$，cost代价为其差值的平方</li>
</ol>
<p>上述风险函数直接优化比较困难，这里一个巧妙的解决方案时使用回归的方法，也就是$x_i$或者$y_i$去拟合他们另个预测值目标。<br>为了避免优化函数$h$是一个常量，风险函数一般情况下会加上一个平滑项$\tau$($0 &lt; \tau \leq 1$)：$$R(h,\tau ) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)+\tau \} \right)^2 -\lambda \tau^2 $$</p>
<blockquote>
<p>因为当$h$为常量函数时，先前的$R(h)=0$就没有再优化的空间了<br>其实加了平滑项就变相的转为:如果希望$x_i \succ y_i$，就得有$h(x_i) &gt; h(y_i)+\tau$，也就是更为严格了，多了一个<code>gap</code></p>
</blockquote>
<p>对于$R(h)$计算$h(x_i)$和$h(y_i)$的负梯度为:$$max\{0,h(y_i)-h(x_i)\} \quad,\quad -max\{0,h(y_i)-h(x_i)\}$$<br>可以发现当<code>pair</code>对符合$\left \langle x_i,y_i \right \rangle$的顺序时，上述的梯度均为0，对于这类<code>case</code>就没有必要在去优化了(以为已经满足目标了)，但是对于另一类，如果$h$不满足<code>pair</code>$\left \langle x_i,y_i \right \rangle$，他们对应的梯度为:$$h(y_i)-h(x_i) \quad,\quad h(x_i)-h(y_i)$$</p>
<blockquote>
<p>因为此时$h(y_i)&gt;h(x_i)$<br>还有对于上面两个梯度的后面那个式子存在的意义不是很理解-_-</p>
</blockquote>
<p>到了这儿，我们知道所谓的训练样本就是对于$x_i \succ y_i$但是$h(y_i) &gt; h(x_i)$，并且使用的是回归方法，<code>GBRank</code>为其巧妙的找了训练的目标:$x_i$的目标为$h(y_i)+ \tau$以及$y_i$的目标为$h(x_i)- \tau$，也就是在每次迭代是将会构建以下训练集:$$\{(x_i,h(y_i)+\tau),(y_i,h(x_i)-\tau)\}$$</p>
<h2 id="算法步骤">算法步骤</h2><p><code>GBRank</code>使用<code>GBT</code>为回归函数，所以整个<code>GBRank</code>的算法过程为:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集,真实的排序pair对$S=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>迭代的次数:$K$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$h(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>随机初始化为一个函数$h_o$</li>
<li>循环$k \in \{1….K\}$<ol>
<li>使用$h_{k-1}$作为近似的$h$函数,我们将对样本的计算结果分到两个不相交的集合:$$S^+=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) \geq h_{k-1}(y_i)+\tau \}$$和$$S^-=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) &lt; h_{k-1}(y_i)+\tau \}$$</li>
<li>使用<code>GBT</code>对下面的数据集拟合一个回归函数$g(x)$:$$\{(x_i,h_{k-1}(y_i)+\tau),(y_i,h_{k-1}(x_i)-\tau) | (x_i,y_i) \in S^- \}$$</li>
<li>进行模型的更新:$$h_k(x) = \frac{kh_{k-1}(x)+\eta g_k(x)}{k+1}$$其中$\eta$为收缩因子</li>
</ol>
</li>
<li>输出最终的模型$h_k(x)$</li>
</ol>
<blockquote>
<p>注意了，其实这里的回归函数还可以使用其他的回归函数来代替，比如$Linear Regression$之类的</p>
</blockquote>
<h2 id="总结">总结</h2><p>$h(x)$为最终的排序函数，<code>GBRank</code>在训练时每次迭代中将$h_k(x)$的排序结果与真实结果不一样的样本（就是分错的样本）单独拿出来做训练样本，并且其训练目标为<code>pair</code>的另一个预测值作为回归目标，非常巧妙。<br>此时重新看这个<code>GBRank</code>模型与<code>AdaBoost</code>、<code>GBT</code>其实很大同小异，都是将上一次训练中分错的样本再拿来训练，也是一个提升的模型</p>
<p>在其paper中的实验结果也是要略好于$RankSvm$，但是其比较疼的时其训练还是比较复杂的，或者说比较耗时,其预测也会比较麻烦一点，所以使用时得慎重~</p>
<h2 id="参考">参考</h2><p>[1]. 2007-GBRank-A Regression Framework for Learning Ranking Functions Using Relative Relevance Judgments</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在CentOS上自己安装python]]></title>
    <link href="http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/"/>
    <id>http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/</id>
    <published>2016-04-29T07:50:41.000Z</published>
    <updated>2016-08-29T08:22:44.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id="下载python2-6-5">下载python2.6.5</h3><p>直接在这个地址进行下载即可<a href="https://www.python.org/download/releases/2.6.5/" target="_blank" rel="external">https://www.python.org/download/releases/2.6.5/</a></p>
<h3 id="进行解压">进行解压</h3><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">tar</span> xvf Python-<span class="number">2</span>.<span class="number">6</span>.<span class="number">5</span>.tgz</span><br></pre></td></tr></table></figure>
<h3 id="编译安装">编译安装</h3><p>先配置安装的前缀<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.<span class="regexp">/configure --prefix=/u</span>sr<span class="regexp">/local/</span>python2.<span class="number">6.5</span></span><br></pre></td></tr></table></figure></p>
<p>然后真正的执行编译安装<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make</span></span><br><span class="line"><span class="built_in">make</span> install</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意如果是非管理员用户 请在两个<code>make</code>前面都加上<code>sudo</code></p>
</blockquote>
<h3 id="添加快捷方式">添加快捷方式</h3><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -sf <span class="regexp">/usr/</span>local<span class="regexp">/python2.6.5/</span>bin<span class="regexp">/python /u</span>sr<span class="regexp">/bin/</span>python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果原来快捷方式存在  那么先删除，再添加</p>
</blockquote>
<h3 id="完工">完工</h3><pre><code><span class="keyword">python</span> --<span class="keyword">version</span>
Python <span class="number">2.6</span>.<span class="number">5</span> 
</code></pre><h3 id="参考">参考</h3><p><a href="http://blog.csdn.net/jationxiaozi/article/details/7665691" target="_blank" rel="external">CentOS5.5下安装python2.6</a>   实用，但是排版太难看了-_-</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id=]]>
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从Gradient Boosting 到GBT]]></title>
    <link href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/"/>
    <id>http://kubicode.me/2016/04/24/Machine Learning/From-Gradient-Boosting-to-GBT/</id>
    <published>2016-04-24T15:51:08.000Z</published>
    <updated>2016-05-02T15:48:21.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br><a id="more"></a></p>
<p>现在假如训练完$G_{m+1}$可以得到完美的$f_{m+1}$，那么也就是有:$$f_{m+1} = f_m+G_{m+1}=y$$<br>这个式子可以写成$$G_{m+1}=y-f_m$$ 其中$y-f_m$表示上一次迭代得到分类器预测结果与真实结果的差值，我们一般称之为的<code>残差</code>(residual)，因此也可以理解为<code>Gradient Boosting</code>在每一轮训练新的分类器将会拟合<code>残差</code>进行最优化</p>
<h2 id="Gradient_Boosting算法">Gradient Boosting算法</h2><p>假设现有训练集$\left\{ (x_1,y_1),(x_2,y_2)…(x_n,y_n)  \right\}$，其中$x$是特征向量，$y$是相应的训练目标，在给定相应的损失函数$L(y,f(x))$,我们的目标是找到一个近似的函数$f(x)$使得与真实函数$f^*(x)$的损失最小期望值最接近:$$f^* = \underset{f}{argmin} E_{x,y} \left[ L(y,f(x)) \right]$$</p>
<p><code>Gradient Boosting</code>方法假设$y$是一个实值，而$f(x)$近似目标函数是一个弱分类器$G_m(x)$加权求和的形式$$f(x)=\sum_{m=1}^M \gamma_mG_m(x)+const$$ 根据经验风险最小化的原则，近似函数$f(x)$将会尝试对训练集上的平均损失函数进行最小化，它从一个常量函数进行起步，并且通过贪心的方式进行逐步优化<br>$$<br>f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) \\<br>f_m(x) = f_{m-1}(x) + \underset{G \in H}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+G_m(x_i) \right)<br>$$<br>然而，对于$L$为任意的损失函数时,在选择每一步最佳的$G_m(x_i)$时将会很难优化。<br>这里使用最速下降法(<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">steepest descent</a>)来解决这个问题<br>,在使用这种方法时，对于损失函数$L(y,G)$不要将其看做一个函数，而是将其看做通过函数得到的值的向量$G(x_1),G(x_2)…G(x_n)$,那么这样的话我们就可以将模型的式子写成如下的等式:<br>$$<br>f_m(x) = f_{m-1}(x) - \gamma_m \sum_{i=1}^n \triangledown_G L \left( y_i,f_{m-1}(x_i) \right) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left ( y_i,f_{m-1}(x_i)-\gamma \frac{\partial L(y_i,f_{m-1}(x_i))}{\partial G(x_i)}  \right )<br>$$<br>上面第一个式子表示根据梯度的负方向进行更新,第二个式子表明了$\gamma$使用线性搜索进行计算。</p>
<p>下面就是具体的<code>gradient boosting</code>步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>可导的损失函数:$L(y,f(x))$</li>
<li>迭代的次数:$M$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$f(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>使用一个常量进行模型的初始化$$f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) $$</li>
<li>循环$m \in \{1….M\}$<ol>
<li>计算残差$$r_{im}=-\left[ \frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}  \right]_{f(x_i)=f_{m-1}(x_i)} \quad i=1…n$$</li>
<li>使用训练集$\{ (x_i,r_{im}) \}$对弱分类器$G_m(x)$进行拟合</li>
<li>通过线性搜索进行乘子$\gamma_m$的计算$$\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)$$</li>
<li>进行模型的更新:$$f_m(x) = f_{m-1}(x)+\gamma_m G_m(x)$$</li>
</ol>
</li>
<li>输出最终的模型$f_M(x)$</li>
</ol>
<p>下面是来自[2]中的对于不同损失函数下不同残差的计算<br><img src="/img/From-Gradient-Boosting-to-GBT/loss_functions.png" width="500px"><br>可以发现当损失函数为最小平方差时残差就是真实值与预测值的差值</p>
<h2 id="Gradient_tree_boosting">Gradient tree boosting</h2><p>提升树(Gradient tree boosting)故名思议就是使用决策树(一般使用<code>CART</code>树)来作为弱分类器.<br>提升树在第$m$步迭代时将会使用决策树$G_m(x)$来集合残差，现在假设这棵树有$J$个叶子节点，则决策树将会将空间划分为$J$个不相交的区域$R_{1m},R_{2m}…R_{3m}$，以及每个区域都是预测一个常量值，则树模型$G_m(x)$对于特征$x$的输入将可以写成$$G_m(x)=\sum_{j=1}^J b_{jm}I(x \in R_{jm})$$，其中$b_{jm}$表示每个区域的预测值，上面的介绍可以用下图来表示:</p>
<center><img src="/img/From-Gradient-Boosting-to-GBT/cart.png" width="400px"></center>

<p>在实际使用时，$b_{jm}$也会与一个乘子$\gamma_m$相乘,最终模型的训练与上面一小节的介绍一致:<br>$$<br>f_m(x)=f_{m-1}(x)+\gamma_mG_m(x) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)<br>$$</p>
<blockquote>
<p>可以发现树的模型是关键，一般来时$4 \leq J \leq 8$比较合适，有时候$J=2$就足够了，并且$j &gt; 10$比较少用</p>
</blockquote>
<h2 id="正则化">正则化</h2><blockquote>
<p>其实用过<code>Gradient Boosting</code>的同学应该有同感，<code>Gradient Boosting</code>类型的模型(<code>GBDT</code>)调参很重要-_-，大致可以发现这些参数就是正则化的关键</p>
</blockquote>
<h3 id="调整树的个数">调整树的个数</h3><p>树的个数$M$越多，过拟合的情况可能越为严重，这里树的个数一般使用交叉验证的误差来调整确定</p>
<h3 id="Shrinkage">Shrinkage</h3><p><code>Shrinkage</code>又称学习率，是指在<code>Gradient Boosting</code>训练时不训练全部的残差，而是:$$f_m(x)=f_{m-1}(x)+v \cdot \gamma_mG_m(x) \quad 0 &lt; v \leq 1$$<br>经验表明较小的学习率($v &lt; 0.1$)将会取得较为明显的正则化效果，但是学习率太小会导致训练次数增加..</p>
<blockquote>
<p>感觉这个大致可以这么理解，如果$v=1$，弱分类器犯错一次真的就错了，但是如果$v &lt; 1$时，如果某个分类器犯错了，其他的的弱分类器可能还可以补救^_^</p>
</blockquote>
<h3 id="Stochastic_gradient_boosting">Stochastic gradient boosting</h3><p>随机梯度提升法，表示每一轮迭代时并不是拿所有的数据进行训练，所以按无放回的随机取一定的比率$\eta$进行训练，这里的$ 0.5 &lt; \eta &lt; 0.8$将会取得较为不错的正则化效果，同时随机取样本进行训练还能加快模型的训练速度，并且每次迭代中未被抽中的样本还可以作为(out of bag)[<a href="https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计" target="_blank" rel="external">https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计</a></p>
<h3 id="叶子节点的数量">叶子节点的数量</h3><p>一般这个叶子节点的数量不宜太多（其实可以理解为节点数越多，模型复杂度越高…）</p>
<h3 id="使用惩罚项">使用惩罚项</h3><p>额~貌似<code>L2</code>之类的惩罚项也是可以被加入进去</p>
<h2 id="总结">总结</h2><p><code>Gradient Boosting</code>是非常金典而又重要的提升方法，他与<a href="http://kubicode.me/2016/04/18/Machine%20Learning/AdaBoost-Study-Summary/" target="_blank" rel="external">AdaBoost</a>一样都是讲弱分类器合成强分类，但是其大致区别有:</p>
<ol>
<li><code>Gradient Boosting</code>通过残差来变量的改变错误分类的权重,而<code>AdaBoost</code>就真的直接去修改分类错误的训练权重了</li>
<li><code>Gradient Boosting</code>接入的分类器一般完整的决策树居多，但是<code>AdaBoost</code>一般使用二层决策树</li>
</ol>
<p><code>Gradient Boosting</code>中最有代表性的就是<code>GBDT</code>,该模型虽好，可不要贪杯~使用时理解数据以及正确调参才是王道</p>
<h2 id="参考">参考</h2><p>[1]. <a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="external">wiki Gradient boosting</a><br>[2]. The Elements of Statistical Learning<br>[3]. 《统计学习方法》.李航.第八章</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解决在使用scikit-learn时出现ValueError: numpy.dtype has the wrong size的错误]]></title>
    <link href="http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/"/>
    <id>http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/</id>
    <published>2016-04-22T01:33:55.000Z</published>
    <updated>2016-04-22T01:51:20.000Z</updated>
    <content type="html"><![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br><a id="more"></a><br>网上给的建议大都是直接卸载再全部重装，将<code>numpy</code>、<code>scipy</code>和<code>scikit-learn</code>全部卸载了，然后</p>
<pre><code>pip <span class="keyword">install</span> -U numpy scipy scikit-learn
</code></pre><p>装起来。结果一样有问题-_-</p>
<p>继续查资料时终于发现有用的方法了:<br><a href="http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling" target="_blank" rel="external">http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling</a></p>
<p>就是不用使用<code>pip install scikit-learn</code>安装，卸载之后直接使用git上<code>https://github.com/scikit-learn/scikit-learn</code>的自己安装</p>
<pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/scikit-learn/scikit-learn
<span class="keyword">make</span>
sudo <span class="keyword">python</span> setup.<span class="keyword">py</span> install
</code></pre><p>ps：这个时候直接安装可能会出</p>
<pre><code><span class="attribute">RuntimeError</span>: <span class="string">Running cythonize failed!</span>
</code></pre><p>Error提示,这时候安装一下<code>cpython</code>即可</p>
<pre><code>pip <span class="keyword">install</span> cython
</code></pre><p>最后全部安装完之后就可以正常使用了^_^</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br>]]>
    
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[AdaBoost学习总结]]></title>
    <link href="http://kubicode.me/2016/04/18/Machine%20Learning/AdaBoost-Study-Summary/"/>
    <id>http://kubicode.me/2016/04/18/Machine Learning/AdaBoost-Study-Summary/</id>
    <published>2016-04-18T12:30:55.000Z</published>
    <updated>2016-09-08T03:58:57.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>三个凑皮匠，顶一个诸葛亮</code>，打一算法:<code>AdaBoost</code><br>本文是自己对<code>AdaBoost</code>的理解，健忘-_-!! 故记录在此.</p>
</blockquote>
<h2 id="简介">简介</h2><p>痛点:大部分强分类器(<code>LR</code>，<code>svm</code>)分类效果还不错，但是可能会遇到过拟合问题，并且训练相对复杂，耗时~<br>另外大部分弱分类器(<code>阈值分类器</code>,<code>单桩决策树(decision stump)</code>等)，他们分类的效果差，可能是极差，只会出现欠拟合，但是他们训练预测快，很快~</p>
<blockquote>
<p><code>天下武功，唯快不破</code>，<code>做减法不易，但是做加法就相对简单了</code>^_^ 这就是<code>提升方法</code>.</p>
</blockquote>
<p><code>提升方法</code>需要解决的两个问题:</p>
<ol>
<li>在每一轮训练时如何改变数据的权值或概率分布?</li>
<li>如何将弱分类器组合成一个强分类器?</li>
</ol>
<p><code>AdaBoost</code>对此进行了很好的解决:</p>
<ol>
<li><code>分而治之</code>:将前一轮分错的样本加大权重，迫使在第二轮中对这些样本尽量分对，同时减少分对样本的权重.</li>
<li><code>加权多数表决</code>:加大错误率小的弱分类器的权重，使其在最终表决中占较大作用，同时减少错误率较大的弱分类器的权重.</li>
</ol>
<a id="more"></a>
<h2 id="前向分步算法">前向分步算法</h2><p>讲<code>AdaBoost</code>之前，就不得不提到<code>前向分步算法</code>,先来看一个加法模型:<br>$$f(x)=\sum_{m=1}^M \beta_m b(x;\gamma_m)$$其中:</p>
<ul>
<li>$b(x;\gamma_m)$表示基函数</li>
<li>$\gamma_m$表示基函数的参数</li>
<li>$\beta_m$表示基函数的系数</li>
<li>最终加权求和之后形成最终的函数(强模型)</li>
</ul>
<p>假设损失函数为$L(y,f(x))$,则在训练$f(x)$时就是优化损失函数到最小化的问题:<br>$$\underset{\beta,\gamma}{min} \sum_{i=1}^N L\left( y_i,\sum_{m=1}^M \beta_m b(x;\gamma_m) \right)$$</p>
<p>如果直接优化这个损失函数无疑是一个相当复杂的问题:里面嵌入有太多了函数了…，而<code>前向分步算法</code>的策略是:</p>
<pre><code>如果从前往后每一步都是学习一个基函数以及系数，令其逐步逼近优化目标函数，那么复杂度就可以大大简化了<span class="attr_selector">[分而治之]</span>
</code></pre><p>因此每一步只需要如下的损失函数即可:<br>$$\underset{\beta,\gamma}{min} \sum_{i=1}^N L \left( y_i,\beta b(x;\gamma) \right)$$</p>
<p>下面就是<code>前向分步算法</code>的具体步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$，其中$y_i \in \{+1,-1\}$</li>
<li>损失函数:$L(y,f(x))$</li>
<li>基函数数量:$M$</li>
<li>基函数集合$\{b(x;\gamma_m)\}$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>加法模型$f(x)$</li>
</ul>
<p><strong>procedure</strong>:</p>
<ol>
<li>初始化$f_0(x)=0$</li>
<li>循环$m \in \{1….M\}$<ol>
<li>最小化基函数损失函数:$$\underset{\beta_m,\gamma_m}{argmin} \sum_{i=1}^N L\left( y_i,\beta_m b(x;\gamma_m) \right)$$</li>
<li>更新加法模型:$$f_m(x)=f_{m-1}(x)+\beta_m b(x;\gamma_m)$$</li>
</ol>
</li>
<li>最终得到加法模型:$$f(x)=f_M(x)=\sum_{m=1}^M \beta_m b(x;\gamma_m)$$</li>
</ol>
<p><code>前向分步算法</code>通过分而治之的方式求得了损失函数值最小的<code>加法函数</code></p>
<blockquote>
<p>整个算法的学习过程可以有很大的想象空间^_^</p>
</blockquote>
<h2 id="AdaBoost算法逻辑">AdaBoost算法逻辑</h2><p>上面一小节介绍了<code>前向分步算法</code>，但是留下来三个问题:</p>
<ol>
<li>对其损失函数$L(y,f(x))$有啥要求?</li>
<li>基函数的系数$\beta$又是怎么计算的?</li>
<li>基函数$b(x;\gamma)$如何设计比较合理?</li>
</ol>
<p><code>AdaBoost</code>正是对此进行一一填坑，它使用<code>指数损失函数</code>、<code>根据分类错误类来计算基函数系数</code>和  。。  基函数到没有指定，不过一般使用<code>阈值函数</code>或者<code>单桩决策树</code>来作为基函数</p>
<blockquote>
<p>因此也可认为<code>AdaBoost</code>是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法的二分类学习方法.</p>
</blockquote>
<p>先来看下<code>AdaBoost</code>的算法逻辑图:</p>
<p><center><img src="/img/AdaBoost-Study-Summary/exec.png" width="400px"></center></p>
<blockquote>
<p>说明:此图来自<code>PRML Fig14.1</code>[2]，本文的数学符号主要采用[1]的风格，因此有:$y_m(x)\rightarrow G_m(x)$、$Y_M(x) \rightarrow G(x)$</p>
</blockquote>
<p>从图中大致可以发现<code>AdaBoost</code>依次训练多个弱分类器，每个分类器训练完成之后产出一个权重给予下个分类器，下个分类器在此权重上继续进行训练，全部训练完成之后根据弱分类器的系数组合成强分类器，也就是最终的分类模型~</p>
<p>下面就是<code>AdaBoost</code>的具体步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$，其中$y_i \in \{+1,-1\}$</li>
<li>弱分类器数量:$M$</li>
<li>弱分类器集合$\{G_m(x)\}$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$G(x)$  （注意：<code>产出的最终模型并不直接是加法模型哦</code>~）</li>
</ul>
<p><strong>procedure</strong>:</p>
<ol>
<li>初始化训练权值的分布:$$D_1=(w_{1,1},\cdot \cdot \cdot , w_{1,i},\cdot \cdot \cdot ,w_{1,N}),w_{1,i}=\frac{1}{N}$$<blockquote>
<p>ps.其实初始化还有其他方式的 such as:初始化为$\frac{0.5}{N_+}$和$\frac{0.5}{N_-}$，其中$N_+$和$N_-$分别代表正负样本的数量，有$N=N_++N_-$</p>
</blockquote>
</li>
<li>循环$m \in \{1….M\}$<ol>
<li>使用带权重分布$D_m$的训练集进行训练，得到基本的弱分类器:$G_m(x)$</li>
<li>计算$G_m(x)$在训练数据集上的分类误差率:$$e_m=P(G_x(x) \neq y_i) = \sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$$其中$$ I(G_m(x_i) \neq y_i)=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad G_m(x_i) = y_i \\<br>1 &amp; \quad if \quad G_m(x_i) \neq y_i\\<br>\end{aligned}<br>\right.$$<blockquote>
<p>其实就是<code>错误率</code>:分错样本数量占总样本量的比例.</p>
</blockquote>
</li>
<li>计算$G_m(x)$的系数:$$\alpha_m = \frac{1}{2} ln \frac{1-e_m}{e_m}$$</li>
<li><strong>更新训练数据集的权值分布(这点是核心)</strong>:$D_{m+1}=(w_{m+1,1},\cdot \cdot \cdot , w_{m+1,i},\cdot \cdot \cdot ,w_{m+1,N})$<br>其中:$$w_{m+1,i} = \frac{w_{m,i}}{Z_m} e^{-\alpha_m y_i G_m(x_i)}$$ 这里$Z_m$为规范化因子:$$Z_m = \sum_{i=1}^{N} w_{m,i} e^{-\alpha_m y_i G_m(x_i)}$$</li>
</ol>
</li>
<li>构建加法模型:$$f(x)=\sum_{m=1}^M \alpha_m G_m(x)$$产出最终的分类器:$$G(x)=sign(f(x))=sign\left( \sum_{m=1}^M \alpha_m G_m(x) \right)$$其中:$$sign(f(x))=\left\{<br>\begin{aligned}<br>-1 &amp; \quad if \quad f(x) &lt; 0 \\<br>1 &amp; \quad if \quad f(x) \geq 0\\<br>\end{aligned}<br>\right.$$</li>
</ol>
<p>对算法过程中几个重要的点进行一个简单的解释:</p>
<ul>
<li><p>分类器误差率$e_m$对其权重$\alpha_m$的影响:<br><center><img src="/img/AdaBoost-Study-Summary/alpha.png" width="400px"></center><br>从图中可以发现:</p>
<ol>
<li>$e_m$为0.5时其权重$\alpha_m$为0，表示此分类器在最终模型中不起任何作用</li>
<li>$e_m &lt; 0.5$时其$\alpha_m &gt; 0$，表示对最终模型起正向作用,$e_m$的值越小，起到的作用越大</li>
<li>$e_m &gt; 0.5$时其$\alpha_m &lt; 0$，表示对最终模型起父向作用，$e_m$的值越大,起到的负作用也越大</li>
<li>$e_m$不会出现等于0 的情况，因为到了0的时候弱分类器已经全部分正确，也不需要继续更新权重再次训练了</li>
<li>$e_m$也不会出现等于1的情况，因为1表示弱分类器全错，除了程序出问题，应该任何一个弱分类器不会训练到全错的情况吧^_^</li>
</ol>
</li>
<li><p>数据权重的更新策略:<br>原始的更新策略是这样的:$$w_{m+1,i} = \frac{w_{m,i}}{Z_m} e^{-\alpha_m y_i G_m(x_i)}$$原始标签$y_i$和弱分类器结果的输出$G_m(x)$都是$\{+1,-1\}$二值，因此可以将上述更新方式写成:$$w_{m+1,i}=  \left\{<br>\begin{aligned}<br>\frac{w_{m,i}}{Z_m} \times e^{\alpha_m} &amp; \quad if \quad y_i \neq G_m(x)\\<br>\frac{w_{m,i}}{Z_m} \times \frac{1}{e^{\alpha_m}} &amp; \quad if \quad y_i = G_m(x)\\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>观察$w_{m+1,i}$更新时三个元素均恒大于0（$w_{m,i}$可以从$w_1$开始推），因此$w_{m+1,i}$也是恒大于0 ，并且$\sum_{i=1}^N w_{m,i}=1$<br>我们将分类错误率小于0.5的弱分类器称为好分类器，其系数$\alpha_{good}&gt;0$，同时将分类错误率小于0.5的弱分类器称为坏分类器，则其系数$\alpha_{had}&lt;0$，则再观察变形了的权重更新:</p>
</blockquote>
</li>
</ul>
<ol>
<li>如果当前分类器是好分类器，样本$(x_i,y_i)$被错误分类时,$e^{\alpha_m} &gt; 1$,其$w_{m+1,i}$将会被放大，反之正确分类样本的权值将会被缩小</li>
<li>如果当前分类器为坏分类器，样本$(x_i,y_i)$被错误分类时,$e^{\alpha_m} &lt; 1$,其$w_{m+1,i}$将会被缩小，反之正确分类样本的权值将会被放大<blockquote>
<p>这其实应该与误分类样本的权值被放大$e^{2\alpha_m}=\frac{e_m}{1-e_m}$倍一个道理，因为$\frac{e_m}{1-e_m}$不一定恒大于1啊~^_^</p>
</blockquote>
</li>
</ol>
<ul>
<li>弱分类器的权重系数$\alpha_m$:<br>这个权重系数表示了弱分类器$G_m(x)$的重要性，但是$a_m$之和并不为1，另外$G_m(x)$输出的是-1或者1的分类，所以最终模型可以看做一个加权的投票系统^_^</li>
</ul>
<h2 id="AdaBoost-最小化指数误差">AdaBoost-最小化指数误差</h2><p>假如<code>AdaBoost</code>使用的是指数损失函数，则其损失函数为:$$L(y,f(x))=\sum_{i=1}^N e^{-y_if(x)}$$为了优化其损失函数，<code>AdaBoost</code>采用了前向分步算法进行逐步优化,第<code>m</code>轮的迭代需要得到的$\alpha_m$,$G_m$和$f_m(x)$，其中有$$f_m(x)=f_{m-1}(x)+\alpha_m G_m(x)$$，假设前面的$f_{m-1}(x)$已经为最优，则当前需要优化的是:<br>$$L(y,f_m(x))=\sum_{i=1}^N e^{-y_i(f_{m-1}(x)+\alpha_m G_m(x))}$$因为有$\bar{w}_{m,i}=e^{-y_if(x)}$（关于这个式子的成立并不是很理解-_-）所以上述优化目标可以写为$$L(y,f_m(x))= \sum_{i=1}^N \bar{w}_{m,i} e^{-y_i\alpha_m G_m(x)}$$<br>因为我们求的是关于$\alpha_m$和$G_m(x)$的最优化，所以$\bar{w}_{m,i}$相对来说就是常量了.现在假设第$m$轮迭代中有$T_m$个样本分类正确，有$M_m$个样本分类错误，则其优化目标又可以写为:<br>$$\begin{equation}\begin{split} L(y,f_m(x))&amp;=e^{-\alpha_m} \sum_{n \in T_m} w_{m,n}+e^{\alpha_m} \sum_{n \in M_m} w_{m,n}\\<br>&amp;= \left( e^{-\alpha_m} \sum_{n \in T_m} w_{m,n} + e^{-\alpha_m} \sum_{n \in M_m} w_{m,n} \right)+ \left( e^{\alpha_m} \sum_{n \in M_m} w_{m,n} - e^{-\alpha_m} \sum_{n \in M_m} w_{m,n} \right) \\<br>&amp;= e^{-\alpha_m} \sum_{i=1}^N w_{m,i} + (e^{\alpha_m}-e^{-\alpha_m}) \sum_{n=1}^N w_{m,i}I(y_i \neq G_m(x_i))<br>\end{split}\end{equation}$$</p>
<p>接下来惯例的方法就是对$L(y,f_m(x))$求$\alpha$和$G_m(x)$的偏导数，其实在求$G_m(x)$最优时可以发现可以发现第一项和第二项前面的系数并不影响最优化，所以需要求的就是上面步骤中<code>误差率</code>的最优化:$$e_m=P(G_x(x) \neq y_i) = \sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$$<br>而得到了最优的$G_m(x)$之后代入$L(y,f_m(x))$求偏导又可以得到最小的$\alpha_m$为:$$\alpha_m = \frac{1}{2} ln \frac{1-e_m}{e_m}$$<br>又是一面熟悉的场景^_^<br>所以可以说<code>AdaBoost</code>整个过程是一直在优化最新函数的指数误差，只是在实际训练时按<code>前向分步算法</code>只需优化当前的误差率即可.</p>
<h2 id="AdaBoost训练误差分析">AdaBoost训练误差分析</h2><pre><code>这里的边界是我自己的理解，与<span class="attr_selector">[1]</span>稍有区别
</code></pre><p>上一小节我们知道在每一步求$\sum_{i=1}^N w_{m,i} I(G_m(x_i) \neq y_i)$的最小化时，其实是在优化最终模型的损失函数$\sum_{i=1}^N e^{-y_if(x)}$,关于模型最终的损失函数有这样一个界限:<br>$$\frac{1}{N} \sum_{i=1}^N I(f(x) \neq y_i) \leq \frac{1}{N} \sum_{i=1}^N e^{-y_if(x)} =  \prod_m Z_m$$<br>因为$e^{-y_if(x)}$一定不会小于0，并且当$f(x) \neq y_i$时，$e^{-y_if(x)}$恒大于1，因此第一、二项的不等式是成立的。接下来看后面的那个等式：</p>
<blockquote>
<p>这里的推导需要用到$Z_m$的变形:$w_{m,i}e^{-\alpha_my_iG_m(x)} = Z_mw_{m+1,i}$</p>
</blockquote>
<p>$$\begin{equation}\begin{split} \frac{1}{N} \sum_{i=1}^N e^{-y_if(x)} &amp;= \frac{1}{N} \sum_{i=1}^N e^{-\sum_{m=1}^M \alpha_my_iG_m(x_i)} \\<br>&amp;= \sum_{i=1}^N w_{1,i} \prod_{m=1}^M e^{-\alpha_m y_i G_m(x_i)} \\<br>&amp;= Z_1 \sum_{i=1}^N w_{2,i} \prod_{m=2}^M e^{-\alpha_my_iG_m(x_i)} \\<br>&amp;= Z_1 Z_2 \sum_{i=1}^N w_{3,i} \prod_{m=2}^M e^{-\alpha_my_iG_m(x_i)} \\<br>&amp;… \\<br>&amp;= Z_1 Z_2 … Z_{m-1}\sum_{i=1}^N w_{M,i}  e^{-\alpha_My_iG_M(x_i)} \\<br>&amp;= \prod_{m=1}^M Z_m<br>\end{split}\end{equation}$$</p>
<p>因此可以发现最优化(最小化)损失函数可以降低最终模型的错误率，同时其错误率与$Z_m$也是有关系的.</p>
<h2 id="AdaBoost黑科技">AdaBoost黑科技</h2><h3 id="Real_AdaBoost">Real AdaBoost</h3><p>上面的<code>AdaBoost</code>的介绍中可以发现$G_m(x)$返回的是-1 或者1 （也就是直接离散值），其实这种方式的返回始终会有一定的<code>gap</code>，那么假如$G_m(x)$输出的是$p(x)=P(y=1|x)$,也就是$x$特征下输出值为1的概率.此时我们最优化的函数为:$$e^{-y \left(f_{m-1}(x)+G_m(p(x) \right)}$$而$G_m(x)=\frac{1}{2} ln \frac{x}{1-x}$<br>这种方式将会修复一定的<code>gap</code>，并且在某些实验中效果也是要好于直接离散的<code>AdaBoost</code></p>
<h3 id="提前终止">提前终止</h3><p>一般情况下是弱分类器训练$M$个才停止，而提前终止只是在训练多个层之后组成的最终分类器的结果已经小于一个置信度的误差，有一种方法可以加快这种判断:</p>
<ol>
<li>一般训练数据里面负样本会远多于正样本</li>
<li>在多个级联的弱分类器在被训练之后，如果正样本被误分为负样本了，则人工将这样正样本进行标记并去去除（质量差的）</li>
<li>那么如果每一轮都是有50%的负样本被监测去重，那么久可以大大减小计算量</li>
<li>最终看假阳性和假阴性来判断是否终止</li>
</ol>
<blockquote>
<p>这种方式靠谱吗？要不就是我理解/翻译错了</p>
</blockquote>
<p>这种提前终止的方法可以降低过拟合的可能性^_^</p>
<h3 id="剪枝">剪枝</h3><p>剪枝指的是去除性能较差的弱分类器，提升效率。最简单的方法是:每个弱分类器都自己的系数和测试误差率极其分布，<code>margineantu</code>则提出的建议为:</p>
<ol>
<li>弱分类器的选择应该分类多样性</li>
<li>如果两个弱分类器很相似，则可以将其中一个给去掉,同时增加相似弱分类器的系数(这里其实就是相当于剪枝了)</li>
</ol>
<h2 id="总结">总结</h2><p><code>AdaBoost</code>秉承<code>三个凑皮匠，顶个诸葛亮</code>的原则，与其说<code>AdaBoost</code>是一个机器学习算法，我更觉得他应该是一个经典的机器学习框架，其优点有:</p>
<ol>
<li>可以较为方便的控制过拟合(不能说避免过拟合，在弱分类器很强的情况下还真会过拟合的吧？看$GBRT$)</li>
<li>有非常强的自适应性</li>
<li>如果弱分类器很简单，则训练预测速度将会很快，毕竟最终复杂度是在弱分类器上乘以$M$</li>
<li>分类效果好，实现简单</li>
<li>可扩展性强~弱分类器可以随意换，甚至损失函数也可以换(比如换最小平方误差)</li>
</ol>
<p>当然也有缺点:</p>
<ol>
<li>相邻两个分类器训练有依赖关系，所以在并行实现下还是需要精心设计。</li>
</ol>
<h2 id="参考:">参考:</h2><p>[1] 《统计学习方法》.李航.第八章<br>[2] 《Pattern Recognition And Machine Learning》.Christopher Bishop.chapter 14<br>[3]  <a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="external">https://en.wikipedia.org/wiki/AdaBoost</a></p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>三个凑皮匠，顶一个诸葛亮</code>，打一算法:<code>AdaBoost</code><br>本文是自己对<code>AdaBoost</code>的理解，健忘-_-!! 故记录在此.</p>
</blockquote>
<h2 id="简介">简介</h2><p>痛点:大部分强分类器(<code>LR</code>，<code>svm</code>)分类效果还不错，但是可能会遇到过拟合问题，并且训练相对复杂，耗时~<br>另外大部分弱分类器(<code>阈值分类器</code>,<code>单桩决策树(decision stump)</code>等)，他们分类的效果差，可能是极差，只会出现欠拟合，但是他们训练预测快，很快~</p>
<blockquote>
<p><code>天下武功，唯快不破</code>，<code>做减法不易，但是做加法就相对简单了</code>^_^ 这就是<code>提升方法</code>.</p>
</blockquote>
<p><code>提升方法</code>需要解决的两个问题:</p>
<ol>
<li>在每一轮训练时如何改变数据的权值或概率分布?</li>
<li>如何将弱分类器组合成一个强分类器?</li>
</ol>
<p><code>AdaBoost</code>对此进行了很好的解决:</p>
<ol>
<li><code>分而治之</code>:将前一轮分错的样本加大权重，迫使在第二轮中对这些样本尽量分对，同时减少分对样本的权重.</li>
<li><code>加权多数表决</code>:加大错误率小的弱分类器的权重，使其在最终表决中占较大作用，同时减少错误率较大的弱分类器的权重.</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聊聊机器学习中的损失函数]]></title>
    <link href="http://kubicode.me/2016/04/11/Machine%20Learning/Say-About-Loss-Function/"/>
    <id>http://kubicode.me/2016/04/11/Machine Learning/Say-About-Loss-Function/</id>
    <published>2016-04-11T13:06:23.000Z</published>
    <updated>2016-04-17T12:25:41.000Z</updated>
    <content type="html"><![CDATA[<p>机器学习算法一般都是对损失函数(<code>Loss Function</code>)求最优，大部分损失函数都是包含两项：<code>损失误差项(loss term)</code>以及<code>正则项(regularization term)</code>:<br>$$J(w)=\sum_iL(m_i(w))+\lambda R(w)$$</p>
<h2 id="损失误差项">损失误差项</h2><p>常用的损失误差项有5种:</p>
<ol>
<li><code>Gold Standard</code></li>
<li><code>Hinge</code>:Svm</li>
<li><code>log</code>:logistic regression(cross entropy error)</li>
<li><code>squared</code>:linear regression</li>
<li><code>Exponential</code>:Boosting</li>
</ol>
<a id="more"></a>
<h3 id="Gold_Standard_Loss">Gold Standard Loss</h3><p><code>Gold Standard</code>又称<code>0-1</code>误差，其结果又称为<code>犯错</code>与<code>不犯错</code>,用途比较广(比如<a href="http://kubicode.me/2015/08/06/Machine%20Learning/Perceptron-Learning-Algorithm/" target="_blank" rel="external">PLA</a>模型)，其损失函数也是相当的简单:<br>$$ y=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad m \geq 0 \\<br>1 &amp; \quad if \quad m \le 0\\<br>\end{aligned}<br>\right.$$</p>
<h3 id="Hinge_Loss">Hinge Loss</h3><p><code>Hinge</code>的叫法来源于其损失函数的图形，为一个折线，通用函数方式为:<br>$$L(m_i) = max(0,1-m_i(w))$$</p>
<p><code>Hinge</code>可以解 间距最大化 问题，带有代表性的就是<code>svm</code>,最初的<code>svm</code>优化函数如下:<br>$$\underset{w,\zeta}{argmin} \frac{1}{2}||w||^2+ C\sum_i \zeta_i \\<br>st.\quad \forall y_iw^Tx_i \geq 1- \zeta_i \\<br>\zeta_i \geq 0 $$</p>
<p>将约束项进行变形则为:<br>$$\zeta_i \geq 1-y_iw^Tx_i$$<br>则可以将损失函数进一步写为:<br>$$\begin{equation}\begin{split}J(w)&amp;=\frac{1}{2}||w||^2 + C\sum_i max(0,1-y_iw^Tx_i) \\<br>&amp;= \frac{1}{2}||w||^2 + C\sum_i max(0,1-m_i(w)) \\<br>&amp;= \frac{1}{2}||w||^2 + C\sum_i L_{Linge}(m_i)<br>\end{split}\end{equation}$$</p>
<p>因此<code>svm</code>的损失函数可以看成<code>L2-Norm</code>和<code>Hinge</code>损失误差之和.</p>
<h3 id="Log_Loss">Log Loss</h3><p><code>log</code>类型损失函数的优势可以将连乘转为求和，由于是单调函数，不会改变原结果，并且还很方面求最优，因此<code>log</code>类型的损失函数函数也非常常用，比较著名的一种就是交叉熵(<code>cross entropy</code>)，也就是<code>logistic regression</code>用的损失函数:<br>$$J(w)=\lambda||w||^2+\sum_i y_i log g_w(x_i)+(1-y_i)(log 1-g_w(x_i),y_i \in\{0,1\}$$<br>其中:<br>$$g_w(x_i)=\frac{1}{1+e^{-f_w(x_i)}} \\<br>f_w(x_i) = w^Tx_i<br>$$</p>
<h3 id="Squared_Loss">Squared Loss</h3><p>平方误差，线性回归中最常用:<br>$$L_2(m)=(f_w(x)-y)^2=(m-1)^2$$</p>
<h3 id="Exponential_Loss">Exponential Loss</h3><p>指数误差，在<code>boosting</code>算法中比较常见:<br>$$J(w)=\lambda R(w)+\sum_i exp(-y_if_w(x_i)) \\<br>L_{exp}(m_i) = exp(-m_i(w))<br>$$</p>
<h3 id="误差项对比">误差项对比</h3><p>上面5种误差项的函数为:</p>
<center><img src="/img/Say-About-Loss-Function/error_function.png" width="400px"></center>

<blockquote>
<p>黑色为<code>Squared Loss</code>,<span style="color:red">红色</span>为<code>Hinge Loss</code>,<span style="color:yellow">黄色</span>为:<code>Log Loss</code>,<span style="color:green">绿色</span>为:<code>Exponential Loss</code>,<span style="color:blue">蓝色</span>为:<code>Gold Standard</code></p>
</blockquote>
<p>观察图中:</p>
<ol>
<li><code>Hinge Loss</code>中当$m_i(w) &gt; 1$ 时，其损失项始终未0，当$m_i(w) &lt; 1$时，其损失项的值呈线性增长（正好符合<code>svm</code>的需求）.</li>
<li><code>Squared、Log、Exponential</code>三种损失函数已经<code>Hinge</code>的左侧都是凸函数，并且<code>Gold Stantard</code>损失为他们的下界:<br> $$\zeta_{01} \leq  \hat{\zeta}_{01}(h)+fudge$$</li>
<li>当需要求最大似然时(也就是概率最大化)，使用<code>Log Loss</code>最合适，但是一般会加上一个负号将其转换为求最小</li>
<li>损失函数和的<code>凸特征</code>以及有<code>界</code>是非常重要的，可以防止在一些可以求得无穷的工作上白白浪费时间。有时候为了让函数有界和凸特征，一般会使用一些代理函数来进行替换。</li>
</ol>
<h2 id="正则项">正则项</h2><blockquote>
<p>加入正在项是为了降低模型复杂度，在一定程度上可以有效防止模型过拟合</p>
</blockquote>
<p>常用的正则项有:<br>$$<br>R_2 = \frac{1}{2}||w||^2 \\<br>R_1 = \sum_i |w_i| \\<br>R_0 = |\{i:w_i \neq 0 \}|<br>$$<br>这些正则项可以通用的写成:<br>$$R_p =(\sum_i |w_i|^p)^{\frac{1}{p}}$$</p>
<p>其中：</p>
<ol>
<li>$R_2$最常用，因为它是凸函数，非常方便可以用<code>梯度下降法</code>最优化</li>
<li>$R_1$含有特征选择功能，因此经过$R_1$计算之后会有大量的0权重出现，这样的话我们在实际计算中只需要计算有值特征即可，可以加快速算法的运行速度</li>
<li>$R_0$，额~这个暂时不知道哪里用-_-</li>
</ol>
<p>当$p \leqslant 1$时其正则项就为非凸函数了</p>
<center><img src="/img/Say-About-Loss-Function/reg.png" width="600px"></center>


<h2 id="参考">参考</h2><ol>
<li><a href="http://www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf" target="_blank" rel="external">http://www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf</a></li>
<li><a href="https://www.wikiwand.com/en/Hinge_loss" target="_blank" rel="external">https://www.wikiwand.com/en/Hinge_loss</a></li>
<li><a href="http://www.cnblogs.com/rocketfan/p/4081585.html" target="_blank" rel="external">http://www.cnblogs.com/rocketfan/p/4081585.html</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>机器学习算法一般都是对损失函数(<code>Loss Function</code>)求最优，大部分损失函数都是包含两项：<code>损失误差项(loss term)</code>以及<code>正则项(regularization term)</code>:<br>$$J(w)=\sum_iL(m_i(w))+\lambda R(w)$$</p>
<h2 id="损失误差项">损失误差项</h2><p>常用的损失误差项有5种:</p>
<ol>
<li><code>Gold Standard</code></li>
<li><code>Hinge</code>:Svm</li>
<li><code>log</code>:logistic regression(cross entropy error)</li>
<li><code>squared</code>:linear regression</li>
<li><code>Exponential</code>:Boosting</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Learning To Rank中Pairwise方法的学习]]></title>
    <link href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/"/>
    <id>http://kubicode.me/2016/04/10/Machine Learning/LTR-Pairwise-Study/</id>
    <published>2016-04-10T09:05:18.000Z</published>
    <updated>2016-07-28T13:12:39.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>由于<code>Pairwise</code>方式的排序学习方法 训练样本构建方便、速度快同时效果也还可以，因此在工业界和学术的应用非常广泛^_^</p>
</blockquote>
<h2 id="2002-RankSvm">2002-RankSvm</h2><p><code>RankSvm</code>是最经典的一种，将其余的相关实现方法学习总结简单的记录到本文中。<br><code>RankSvm</code>的学习记录在<a href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/" target="_blank" rel="external">这里</a></p>
<h2 id="2006-IRSVM">2006-IRSVM</h2><p><code>IRSVM</code>直接是<code>RankSvm</code>的改进，<code>RankSvm</code>的训练目标是让序列pair的<code>不一致pair对</code>对最少，其优化函数为：<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$<br>因此直接暴露了两大问题:</p>
<h3 id="问题1:位置误差">问题1:位置误差</h3><a id="more"></a>
<pre><code><span class="tag">Example1</span>:
档位<span class="pseudo">:3</span>,2,1
排序1<span class="pseudo">:2</span> 3 2 1 1 1 1
排序2<span class="pseudo">:3</span> 2 1 2 1 1 1
</code></pre><p>从样例1中可以看到如果是按$\tau$最大化进行优化的话，<code>排序1</code>中<code>2 3</code>为不一致pair,排序2中<code>1 2</code>为不一致pair，因此他们的$\tau$得分是一致的，但是明显可以看到排序2的应该为更优，因为越<code>top</code>级别的重要性越大<br>因此<code>IRSVM</code>考虑了计算$\tau$时将位置顺序纳入误差</p>
<h3 id="问题2:长度误差">问题2:长度误差</h3><pre><code><span class="tag">Example2</span>:
档位<span class="pseudo">:3</span>,2,1
排序3<span class="pseudo">:3</span> 2 2 1 1 1 1
排序4<span class="pseudo">:3</span> 3 2 2 2 1 1 1 1 1
</code></pre><p>现观察样例2，可以发现<code>排序3</code>和<code>排序4</code>中均未出现<code>不一致pair</code>的文档对，因此他们的$\tau$得分是一样的，并且均为1，但是<code>排序3</code>中存在<code>28</code>个文档对，而<code>排序4</code>中存在<code>45</code>个文档对，所以<code>排序4</code>存在更多的训练数据，因此<code>排序4</code>的数据相当于<code>RankSvm</code>来说更加重要。<br>因此<code>IRSVM</code>将召回的文档个数纳入了排序</p>
<blockquote>
<p>其实这点比较纠结，实际使用中会进行数据过滤，而且最终训练的时候也一般都是取<code>top10</code>进行训练，所以这个问题并不会很明显</p>
</blockquote>
<h3 id="优化学习方法">优化学习方法</h3><p>所以<code>IRSVM</code>考虑了不同排序位置的不同重要性，以及各个<code>query</code>召回的数量，对原始的<code>RankSVM</code>损失函数进行修改得到如下:<br>$$\underset{w}{min} \sum_{i=1}^N \tau_{k(i)} \mu_{q(i))} [1-y_i(w,x_i^{(1)}-x_i^{(2)})]_+ + \lambda||w||^2$$</p>
<p>其实重要是添加了位置得分因子$\tau_{k(i)}$，使用<code>NDCG@1</code>中的方法进行折损，以及添加了<code>query</code>召回的文档长度因子$\mu_{q(i)}$，使用的是最简单粗暴的$\frac{1}{n_q}$进行计算，其中$n_q$表示召回的文档数量。</p>
<p>[2]中提出<code>IRSVM</code>的时候还使用了<code>SGD</code>和<code>线性规划</code>进行了优化</p>
<h2 id="2005-RankNet">2005-RankNet</h2><p><code>RankNet</code>的相关学习记录<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/" target="_blank" rel="external">在这里</a></p>
<h2 id="2007-GBRank">2007-GBRank</h2><p><code>GBRank</code>的相关学习记录<a href="http://kubicode.me/2016/05/08/Machine%20Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/" target="_blank" rel="external">在这里</a></p>
<h2 id="参考">参考</h2><ol>
<li>《Learning to Rank for Information Retrieval and Natural Language Processing》.Hang Li</li>
<li>Cao Y, Xu J, Liu T Y, et al. Adapting ranking SVM to document retrieval[C]// SIGIR 2006: Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval, Seattle, Washington, Usa, August. 2006:186-193.</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>由于<code>Pairwise</code>方式的排序学习方法 训练样本构建方便、速度快同时效果也还可以，因此在工业界和学术的应用非常广泛^_^</p>
</blockquote>
<h2 id="2002-RankSvm">2002-RankSvm</h2><p><code>RankSvm</code>是最经典的一种，将其余的相关实现方法学习总结简单的记录到本文中。<br><code>RankSvm</code>的学习记录在<a href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/">这里</a></p>
<h2 id="2006-IRSVM">2006-IRSVM</h2><p><code>IRSVM</code>直接是<code>RankSvm</code>的改进，<code>RankSvm</code>的训练目标是让序列pair的<code>不一致pair对</code>对最少，其优化函数为：<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$<br>因此直接暴露了两大问题:</p>
<h3 id="问题1:位置误差">问题1:位置误差</h3>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankSvm-基于点击数据的搜索排序算法]]></title>
    <link href="http://kubicode.me/2016/03/30/Machine%20Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/"/>
    <id>http://kubicode.me/2016/03/30/Machine Learning/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/</id>
    <published>2016-03-30T12:49:53.000Z</published>
    <updated>2016-07-26T17:22:22.000Z</updated>
    <content type="html"><![CDATA[<pre><code>RankSvm是Pairwise的学习排序中最早也是非常著名的一种算法，主要解决了传统PontWise构建训练样本难的问题，
并且基于<span class="built_in">Pair</span>的构建的训练样本也更为接近排序概念
</code></pre><h2 id="基本介绍">基本介绍</h2><p>RankSvm是在2002年提出的，之前工作关于LTR的工作貌似只有Pointwise相关的,比如PRanking,这样的排序学习算法Work需要含有档位标注的训练样本，一般有以下几种获取方式：</p>
<ol>
<li>需要人工/专家标注</li>
<li>诱导用户对展现的搜索结果进行反馈</li>
</ol>
<p>这样就会存在会成本高、可持续性低、受标准者影响大等缺点。<br><a id="more"></a></p>
<p>而RankSvm只需要根据搜索引擎的点击日志构建<code>Pair</code>对即可，相对于先前的工作在算法的实用性上有了非常大的改善。</p>
<h2 id="训练样本设计">训练样本设计</h2><p>一般搜索引擎都会记录用户搜索后展现的结果以及用户的点击情况，这种日志成本较低，并且改造系统也较为方便，而RankSvm的训练样本就是从这种点击日志中进行提取。</p>
<p>由于用户点击的<code>doc</code>概率和排序的位置影响很大，虽然一般都是偏爱相关性较大的<code>doc</code>，但是如果这种<code>doc</code>排在很后面的话其实用户也几乎不会点，所有<code>rankSvm</code>就只考虑top级别的点击日志，一般为<code>top 10</code></p>
<p>另外在构建训练数据时同一<code>query</code>下认为用户被点击<code>doc</code>相关性要高于没有被点击的<code>doc</code>，但是由于用户是从上往下浏览网页的，所以排在前面的<code>doc</code>被点击的概率会大于后面的<code>doc</code>，因此<code>RankSvm</code>使用的最终策略为:</p>
<blockquote>
<p><code>pair</code>构建策略:给定一组排序情况($doc_1,doc_2,doc_3,…$),以及$C$记录了用户点击<code>doc</code>的情况,则有<br>$$doc_i{\overset{r^*}{&lt;}} doc_j$$对于所有<code>pair</code>对$1 \leq i$,同时$i \in C$ ,$j \notin C$</p>
</blockquote>
<p>$r^*$表示应有的优化排序，也就是<code>被点击文档</code>的相关性要大于<code>排在该文档前面</code>并且<code>未被点击的文档</code>，看上去很绕口，看个栗子：</p>
<p>假如某个用户搜索某个<code>query</code>得到首页10个<code>doc</code>，按顺序使用$doc_i$进行表示,如果该用户点击了$1,3,7$三个文档，则认为有:<br>$$doc_3 {\overset{r^*}{&lt;}} doc_2 \\<br>doc_7 {\overset{r^*}{&lt;}} doc_2    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_4    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_5    \\<br>doc_7 {\overset{r^*}{&lt;}} doc_6$$</p>
<p>表示该<code>query</code>下$doc_3$的相关性要高于$doc_2$，理应排在前面，而$doc7$的相关性也应该要高于$doc_{2,4,5,6}$，但是可以发现未见$doc_1$的相关性鉴定，这是由于$doc_1$已经是排在了第一位，本身位置点击概率就就是最高的，所以无法判断与其他文档相关性的高低，同理，$doc_{8,9,10}$也未纳入相关性的排序中。</p>
<p>训练样本可以通过这样方式进行构建，但是遗憾的是并没有一种机器学习算法能直接使用这种数据进行训练学习-_-</p>
<h2 id="基本思想">基本思想</h2><p>在上面的栗子中，我们希望用新算法完成$doc_{1,3,7}$排在<code>top 3</code>，那这样的文档的真实相关性高的将会排到前面，<code>RankSvm</code>采用$Kendall’s \quad \tau$来统计实际排序与算法排序的度量，先看下面两个变量:</p>
<ol>
<li>$P$表示排序序列中保持一致性的<code>Pair</code>对数量，也就是真实相关性高的排在第的前面。</li>
<li>$Q$表示排序序列中保持不一致的<code>Pair</code>对数量（就是为逆序了），也就是由于算法的误差导致真实相关性低的排在了高的前面</li>
<li>同时$P+Q=\binom{m}{2}$，$m$表示序列中文档的数量，因为长度为$m$的序列可能组成的<code>pair</code>对为$m$的2组合</li>
</ol>
<p>则$\tau$的计算方式为:<br>$$\tau(r_a,r_b)=\frac{P-Q}{P+Q}=1-\frac{2Q}{\binom{m}{2}}$$</p>
<blockquote>
<p>$r_a$为真实排序，$r_b$为算法排序</p>
</blockquote>
<p>比如实际文档中的顺序为:<br>$$d_1{\overset{r^*}{&lt;}}d_2{\overset{r^*}{&lt;}}d_3{\overset{r^*}{&lt;}}d_4{\overset{r^*}{&lt;}}d_5$$<br>但是算法的排序顺序为:<br>$$d_3{\overset{\hat{r}}{&lt;}}d_1{\overset{\hat{r}}{&lt;}}d_2{\overset{\hat{r}}{&lt;}}d_4{\overset{\hat{r}}{&lt;}}d_5$$</p>
<p>因此可以发现算法排序中有3对<code>pair</code>不一致了($\{d_2,d_3\}$,$\{d_1,d_2\}$,$\{d_1,d_3\}$)，所以$Q=3$，$P=7$，最终的$\tau(r,\hat{r})=\frac{7-3}{10}=4$<br>$\tau$的值越大，表示排序效果越接近真实，比如上面的$\tau(r,r)=\frac{10-0}{10}=1$</p>
<blockquote>
<p><code>RankSvm</code>还证明了由$Q$的倒数正相关的一个式子为平均准确率指标的下界(具体证明看原文附录):<br>$$AvgPrec(\hat{r}) \geq \frac{1}{R} \left[Q+\binom{R+1}{2}\right]^{-1} \left(\sum_{i=1}^{R} \sqrt{i}\right)^2$$<br>$R$为排序出现的文档中与query相关文档数量(这个是<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#MAP" target="_blank" rel="external">Mean Average Precision</a>中的标注，与<code>Pair</code>对的样本稍微有点差别)<br>从这个角度也可以看到$\tau$来衡量排序效果好坏的合理性.</p>
</blockquote>
<p>假设现在有$n$个$q_i$作为训练样本，他们各自的目标排序为$r_i^*$，也就是:<br>$$(q_1,r_1^*),(q_2,r_2^*),(q_3,r_3^*),…(q_n,r_n^*)$$</p>
<p>其中算法排序为$\hat{r}_i$，则排序算法的优化目标是将下列式子<br>$$\tau_{s}=\frac{1}{n} \sum_{i=1}^{n}\tau(r_i^*，\hat{t}_i)$$<br>进行最大化.</p>
<h2 id="RankSvm排序">RankSvm排序</h2><p>假设能找到一个排序算法能使得上面的$\tau_s$得到最大化，对于一个指定的查询$q$，每个文档$d_i$使用特征向量映射方法$\Phi(q,d_i)$，如果是直接使用线性排序方法:<br>$$(d_i,d_j) \in \hat{r} \Leftrightarrow \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j)$$<br>$\vec{w}$表示权重向量，线性排序下，排序分数为<code>权重 x 特征向量</code></p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/linear_example.png" width="400px"></center><br>上图表示一个二维的<code>权重</code>与<code>特征</code>图，在排序的顺序的就是特征在权重上的映射位置顺序，比如单从$W_1$维度进行观察可以看到的排序顺序为<code>{1,2,3,4}</code>，而如果按$W_2$维度则是<code>{2,3,1,4}</code>。</p>
<p>为了最大化$\tau_s$，可以最小化$    Q$来代替，也就是说对于线性的排序，$Q=0$就是表示下面的等式全成立(也就是最大化)<br>$$<br>\forall (d_i,d_j) \in r_1^* : \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j) \\<br>… \\<br>\forall (d_i,d_j) \in r_n^* : \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j)<br>$$</p>
<p>不幸的是，优化这个是一个<code>NP难题</code>。<br>然而<code>SVM</code>在由于软间距最大时可以看到熟悉的身影：<br>minimize:<br>$$\frac{1}{2} \vec{w} \cdot \vec{w} + C \sum \xi_{i,j,k}$$<br>subject to:<br>$$<br>\forall (d_i,d_j) \in r_1^* : \vec{w} \Phi(q,d_i) \geq \vec{w} \Phi(q,d_j) + 1 - \xi_{i,j,1} \\<br>… \\<br>\forall (d_i,d_j) \in r_n^* : \vec{w} \Phi(q,d_i) \geq \vec{w} \Phi(q,d_j) +1 - \xi_{i,j,n} \\<br>\forall_i \forall_j \forall_k:\xi_{i,j,k} \geq 0<br>$$</p>
<blockquote>
<p>$\xi$为松弛项，$C$表示平衡项</p>
</blockquote>
<p>因此优化该问题时可以将约束转为:<br>$$\vec{w} \Phi(q,d_i)-\vec{w} \Phi(q,d_j) \geq 1 - \xi_{i,j,1}$$<br>并且由于是线性排序，可以进一步精简为:<br>$$\vec{w} \left(\Phi(q,d_i)-\Phi(q,d_j)\right) \geq 1 - \xi_{i,j,1}$$</p>
<p>在<code>Pair</code>对中只可能$d_i$是否排在$d_j$前面是一个二值结果，所以我们可以将$d_i$排在$d_j$前面的<code>Pair</code>为正标签，否则为负标签:</p>
<p>$$ y=\left\{<br>\begin{aligned}<br>+1 &amp; \quad if \quad \vec{w} \Phi(q,d_i)&gt;\vec{w} \Phi(q,d_j) \\<br>-1 &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>则最终可以将约束可以写成:<br>$$y_i \cdot \vec{w} \left(\Phi(q,d_i)-\Phi(q,d_j)\right) \geq 1 - \xi_{i,j,1}$$</p>
<blockquote>
<p>其中传统的偏置项在<code>RankSvm</code>是不需要的，以为正好<code>Pair</code>相减时就消掉了</p>
</blockquote>
<p>这样就可以完全将上面构建的样本转为一个分类问题，使用<code>SVM</code>的对偶形式进行求解，并且还可以使用核函数进行非线性的分类^_^</p>
<p>训练完<code>Svm</code>之后，在正真排序时只需要将原始$doc$的特征向量输入<code>Svm</code>模型即可:<br>$$resv(q,d_i)= \vec{w} \Phi(q,d_i) = \sum_l^n a_{l}^*y_i(\Phi(q,d_i) \cdot \Phi(q,d_l)) $$</p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/binary_classifiy.png" width="400px"></center><br>上面是表示两个不同的<code>query</code>所表示的特征空间，不同的形状表示文档与对应<code>query</code>的相关性档位,三角形$x_1$表示相关性档位高，圆圈$x_2$表示相关性档位一般，叉叉$x_3$表示相关性档位差。<br>将这些样本转为<code>Pair</code>对之后可以有：</p>
<p><center><img src="/img/RankSvm-Optimizing-Search-Engines-using-Clickthrough-Data/pair_wise_result.png" width="400px"></center><br>可以发现$x_1-x_3$和$x_1-x_2$为正样本，而$x_2-x_1$和$x_3-x_1$为负样本，因此可以形成对应的训练数据进行训练,其实这样形成的样本是对称的，因此在实际使用中一般只保留一侧即可。</p>
<h2 id="总结">总结</h2><p><code>RankSvm</code>很好的解决原始训练样本构建难的问题，根据点击日志构建样本，既考虑了<code>doc</code>之间的顺序，又保证了可持续性，并且其<code>Pair</code>对的训练正好可以使用<code>Svm</code>进行求最优化，而<code>Svm</code>分类器已经是非常成熟并且广泛使用的一种机器学习算法。<br>因此<code>RankSvm</code>虽然在2002年就提出，但是至今在工业界还是广泛使用，但是现在的主要难点是样本<code>Pair</code>对的构建，针对不同的场景也不同的策略，不一定只是根据点击顺序，实际使用中还要考虑新样本数据。</p>
<h2 id="参考">参考</h2><ol>
<li>Joachims T. Optimizing search engines using clickthrough data[C]// Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2002:133-142.</li>
<li>《Learning to Rank for Information Retrieval and Natural Language Processing》.Hang Li</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code>RankSvm是Pairwise的学习排序中最早也是非常著名的一种算法，主要解决了传统PontWise构建训练样本难的问题，
并且基于<span class="built_in">Pair</span>的构建的训练样本也更为接近排序概念
</code></pre><h2 id="基本介绍">基本介绍</h2><p>RankSvm是在2002年提出的，之前工作关于LTR的工作貌似只有Pointwise相关的,比如PRanking,这样的排序学习算法Work需要含有档位标注的训练样本，一般有以下几种获取方式：</p>
<ol>
<li>需要人工/专家标注</li>
<li>诱导用户对展现的搜索结果进行反馈</li>
</ol>
<p>这样就会存在会成本高、可持续性低、受标准者影响大等缺点。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[McRank:一种基于多分类和梯度提升树的排序学习]]></title>
    <link href="http://kubicode.me/2016/03/28/Machine%20Learning/McRank-Learning-to-Rank-Multiple-Classification-and-Gradient-Boosting/"/>
    <id>http://kubicode.me/2016/03/28/Machine Learning/McRank-Learning-to-Rank-Multiple-Classification-and-Gradient-Boosting/</id>
    <published>2016-03-28T08:37:53.000Z</published>
    <updated>2016-09-21T01:56:03.000Z</updated>
    <content type="html"><![CDATA[<pre><code><span class="name">McRank</span>是学习排序(<span class="name">Learning</span> <span class="atom">to</span> <span class="name">Rank</span>)的单文档排序分支(<span class="name">Pointwise</span>)中较为经典的一种，本文是读原<span class="name">Paper</span>[<span class="number">1</span>]之后自己的一个理解.
</code></pre><h2 id="基本介绍">基本介绍</h2><p><code>McRank</code>的全称是<code>Multiple Classification Rank</code>,可以理解为将<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/" target="_blank" rel="external">学习排序</a>转为机器学习中的一个多分类问题.<br><code>McRank</code>对<code>DCG</code>指标进行优化，并且可以证明<code>DCG</code>的误差可以被分类误差给<code>bounded</code>住.</p>
<h2 id="折损累积增益">折损累积增益</h2><blockquote>
<p><code>DCG</code>(Discounted Cumulative Gain)是在信息检索领域评估一个<code>rank</code>好坏的常用指标。(在实际使用中一般会进行归一化，称为<code>NDCG</code>，可以看<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#NDCG" target="_blank" rel="external">这里</a>).</p>
</blockquote>
<p>假设在指定的<code>query</code>下通过某个排序算法对$n$个文档进行排序，则可以得到<br>$$DCG=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1)$$<br><a id="more"></a></p>
<p>其中:</p>
<ol>
<li>$i$表示原文档的索引顺序</li>
<li>$c_{[\pi_i]}=log(i+1)$</li>
<li>$y_i$表示对应文档与<code>query</code>相关性的程度，一般用档位$\{0,1,2,3,4\}$来表示</li>
</ol>
<p>最终的<code>DCG</code>值越大，表示排序效果越好,假如直接根据档位降序得到的排序结果中<code>DCG</code>是最大的，实际使用中一般根据当前可能的最大<code>DCG</code>进行归一化</p>
<h2 id="排序思想">排序思想</h2><p>现在已经知道了文档与<code>query</code>之间一般用档位衡量，而假如按档位降序的<code>DCG</code>值最高,所以排序问题可以转为指定<code>query</code>对文档相关性类别的预测，即多分类问题。</p>
<h3 id="DNCG误差计算">DNCG误差计算</h3><p>现在可以这么理解，我们希望的是<code>DCG</code>越大越好，也即是<code>DCG</code>误差越小越好，但如果是分类问题将直接优化的是分类误差，那如果<code>DCG</code>误差能够被分类误差给<code>bouded</code>住，就可以通过优化分类误差来间接的优化<code>DCG</code>误差了.</p>
<p>对于一个排序的置换映射函数$\pi$,<code>DCG</code>误差为$DCG_g-DCG_{\pi}$，其中$DCG_g$表示最优排序,就是根据实际的<code>query-doc</code>相关性分档降序的排序，所以肯定有$DCG_g \geq DCG_{\pi}$</p>
<p>现给定$n$个<code>URLS</code>的顺序为$\{1,2,3…n\}$，假设分类器分配的相关结果为$\hat{y}_i \in \{0,1,2,3,4\}$，置换映射函数$\pi$直接根据相关性进行排序，高档位的排在前面，相同档位可以随意排序，则可以有以下证明:</p>
<blockquote>
<p>先看变量^_^<br>$y_i$表示<code>query-doc</code>的实际相关性<br>$\hat{y}_i$表示<code>query-doc</code>的分类器预测相关性<br>$c_{[g_i]}$表示根据实际相关性得到的排序<br>$c_{[\pi_i]}$表示根据预测相关性得到的排序</p>
</blockquote>
<p>$$\begin{equation}\begin{split}DCG_{\pi}&amp;=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1) \\<br>&amp;=\sum_{i=1}^{n}c_{[\pi_i]}(2^{\hat{y}_i}-1)+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;\geq \sum_{i=1}^{n}c_{[g_i]}(2^{\hat{y}_i}-1)+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;=\sum_{i=1}^{n}c_{[g_i]}(2^{y_i}-1)-\sum_{i=1}^{n}c_{[g_i]}(2^{y_i}-2^{\hat{y}_i})+\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp;=DCG_g+\sum_{i=1}^{n}(c_{[\pi_i]}-c_{[g_i]})(2^{y_i}-2^{\hat{y}_i})<br>\end{split}\end{equation}$$</p>
<p>解释下不等式$\sum_{i=1}^{n}c_{[\pi_i]}(2^{\hat{y}_i}-1) \geq \sum_{i=1}^{n}c_{[g_i]}(2^{\hat{y}_i}-1)$成立的原因:$c_{[\pi_i]}$是根据相关性$\hat{y}_i$排序得到的，也就是上面提到的最优排序，得到的$DCG$值是最大的(当然这个是分类器的预测值，不是真实值，就是假象的意思-_-)，所以换一种顺序$c_{[g_i]}$其$DCG$的值必定会小于等于最大值.</p>
<p>根据上面的推导就可以直接得到$DCG$的误差了:<br>$$\begin{equation}\begin{split}DCG_g-DCG_{\pi} &amp;\leq \sum_{i=1}^{n}(c_{[g_i]}-c_{[\pi_i]})(2^{y_i}-2^{\hat{y}_i}) \\<br>&amp; \leq \left(\sum_{i=1}^{n}(c_{[g_i]}-c_{[\pi_i]})^2\right)^{\frac{1}{2}}\left(\sum_{i=1}^{n}(2^{y_i}-2^{\hat{y}_i})^2\right)^{\frac{1}{2}} \\<br>&amp;\leq \left(2\sum_{i+1}^{n}c_{[i]}^2-2n\prod_{i=1}^nc_{[i]}^{\frac{2}{n}}\right)^{\frac{1}{2}} 15 \left(\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}\right)^{\frac{1}{2}} \\<br>&amp;= 15\sqrt{2} \left(\sum_{i+1}^{n}c_{[i]}^2-n\prod_{i=1}^nc_{[i]}^{\frac{2}{n}}\right)^{\frac{1}{2}}\left(\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}\right)^{\frac{1}{2}}<br>\end{split}\end{equation}$$</p>
<p>上面公式<code>1~2</code>是不等式是根据<code>柯西不等式</code>得到的，第<code>2~3行</code>平方展开的不等式成立是因为:</p>
<ol>
<li>$\sum_{i=1}^{n}c_{[\pi_i]}^2=\sum_{i=1}^{n}c_{[g_i]}^2=\sum_{i=1}^{n}c_{[i]}^2$,$\prod_{i=1}^{n}c_{[\pi_i]}^2=\prod_{i=1}^{n}c_{[g_i]}^2=\prod_{i=1}^{n}c_{[i]}^2$，他们虽然是顺序不一样，但是他们集合的内容是一样的，所以<code>求和</code>和<code>连乘</code>的等式是成立的。</li>
<li>两种相关性$y_i$和$\hat{y}_i$的值在<code>0~4</code>范围内,因此有$(2^{y_i}-2^{\hat{y}_i})^2\leq 15$，因为$2^4-2^0=15$</li>
</ol>
<p>因此当需要最小化<code>DCG</code>误差时只需要最小化分类误差$\sum_{i=1}^{n}1_{y_i \neq \hat{y}_i}$即可，但是该误差非凸也非平滑，实际使用中使用代理损失函数进行优化:<br>$$\sum_{i=1}^{N}\sum_{k=0}^{K-1}-log(p_{i,k})1_{y_i=k}$$<br>其中$p_{i,k}$表示<code>doc</code>输入每个档位的概率，$K$是总的档位数。</p>
<blockquote>
<p>我感觉:上面不等式里面的排序顺序时间使用$c_{[i]}$代替了，虽然表面上和分档结果无关，因此只需要优化分档即可，但是。。。实际上$c_{[\pi_i]}$的顺序是和分档预测有关的啊….</p>
</blockquote>
<h3 id="分类排序">分类排序</h3><p>上面提到过有了分档结果之后可以按档位顺序降序排序，得到的<code>DCG</code>就是最优的，但是这里存在一个问题，那就是相同档位之间是可以随便排的，就是导致排序的不稳定性，为了得到一种良好的排序机制，<code>McRank</code>在实际排序中会将分类结果转为一个连续的分数，按这个分数进行排序.</p>
<p>假设训练是$\{y_i,x_i\}_i^N$，$y_i$表示多分类的分档,则最终将会学习到的是每个类别的概率$p_{i,k}=Pr(y_i=k)$，则最后的排序分数为:<br>$$S_i=\sum_{k=0}^{K-1}p_i^kT(k)$$<br>其中$T(k)$表示随档位单调递增的函数，比如$T(k)=k$或者$T(k)=2^k$（<code>McRank</code>用的是前者）</p>
<blockquote>
<p>不同的单调递增函数不会对排序进行影响，同时如果对函数进行线性变换也会改变排序结果</p>
</blockquote>
<p>最终<code>McRank</code>是使用<code>Boosting Tree</code>进行多分类预测..</p>
<h3 id="有序分类">有序分类</h3><blockquote>
<p>好吧，其实上面<code>McRank</code>已经讲完了，但是Paper里面提到有序分类(<code>Ordinal Classfifcation</code>，貌似就是<code>Pointwise</code>里面的第三个分支)可以提升排序结果。</p>
</blockquote>
<p>这里在进行多分类时，可以发现每个类别(档位)并不是平等的，比如4档就是要比0档相关性更好，为了考虑这种的偏移，有序分类就是干这个的，多类别有序分类是学习一段区间内的累积概率$Pr(y_i&lt;k)$</p>
<p>首先将训练数据点分类两种$\{y_i \geq 4 \}$和$\{y_i \leq 3\}$，那这样称为了一个二分类问题，这里一样使用<code>boosting Tree</code>进行分类，同样关于$\{y_i \leq 3\}$也可以分为$\{y_i \geq 3 \}$和$\{y_i \leq 2\}$，如果迭代就可以进行变相多分类.</p>
<p>这种方式就是考虑目标类目的不均等性，带来的问题就是会增加训练开销(因为有重复计算，并且可能会带来较大的样本<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All" target="_blank" rel="external">不均衡性</a>。。。。)</p>
<blockquote>
<p>还有一个坏消息。。。<code>McRank</code>的Paper实验里面这种方式并没有比普通多分类提升多少效果-_-</p>
</blockquote>
<h2 id="总结">总结</h2><p><code>McRank</code>是非常经典的一种<code>Pointwise</code>学习排序，将排序转为机器学习的多分类预测，并且对其排序指标<code>DCG</code>误差可以被分类误差给<code>bounded</code>住，最终将分类结果的概率转为一个连续分数进行最终的排序，在实验里面显示该方法比基于回归的<code>subRank</code>以及<code>pairwise</code>的<code>LambdaRank</code>效果更好。</p>
<blockquote>
<p><code>McRank</code>速度快，效果也还行，最大的问题就是<code>训练样本的构建</code>比较麻烦..</p>
</blockquote>
<h2 id="参考">参考</h2><ol>
<li>Li P, Burges C J C, Wu Q. McRank: Learning to Rank Using Multiple Classification and Gradient Boosting[J]. Advances in Neural Information Processing Systems, 2007:897-904.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code><span class="name">McRank</span>是学习排序(<span class="name">Learning</span> <span class="atom">to</span> <span class="name">Rank</span>)的单文档排序分支(<span class="name">Pointwise</span>)中较为经典的一种，本文是读原<span class="name">Paper</span>[<span class="number">1</span>]之后自己的一个理解.
</code></pre><h2 id="基本介绍">基本介绍</h2><p><code>McRank</code>的全称是<code>Multiple Classification Rank</code>,可以理解为将<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/">学习排序</a>转为机器学习中的一个多分类问题.<br><code>McRank</code>对<code>DCG</code>指标进行优化，并且可以证明<code>DCG</code>的误差可以被分类误差给<code>bounded</code>住.</p>
<h2 id="折损累积增益">折损累积增益</h2><blockquote>
<p><code>DCG</code>(Discounted Cumulative Gain)是在信息检索领域评估一个<code>rank</code>好坏的常用指标。(在实际使用中一般会进行归一化，称为<code>NDCG</code>，可以看<a href="http://kubicode.me/2016/02/15/Machine%20Learning/Learning-To-Rank-Base-Knowledge/#NDCG">这里</a>).</p>
</blockquote>
<p>假设在指定的<code>query</code>下通过某个排序算法对$n$个文档进行排序，则可以得到<br>$$DCG=\sum_{i=1}^{n}c_{[\pi_i]}(2^{y_i}-1)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从Bayesion的角度来看Logistic Regression]]></title>
    <link href="http://kubicode.me/2016/03/26/Machine%20Learning/Bayesian-Logistic-Regression/"/>
    <id>http://kubicode.me/2016/03/26/Machine Learning/Bayesian-Logistic-Regression/</id>
    <published>2016-03-26T03:30:54.000Z</published>
    <updated>2016-03-29T16:55:42.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Logistic_Regression公式">Logistic Regression公式</h2><blockquote>
<p><code>Logistic Regression</code>（下面简称<code>LR</code>）是一个二分类的机器学习方法，给定一个输入向量$x_i$，输出$P(y_i|x_i)$,其中$y_i \in {0,1}$。</p>
</blockquote>
<p>作为一个二分类问题，$Y$的后验概率一般会写成这样:<br>$$P(Y=1|X)=\frac{1}{1+exp(- \omega - \sum_{i=1}^n {\omega_ix_i})}=\sigma(W^TX_i)$$<br>那么<br><a id="more"></a><br>$$P(Y=0|X)=1-\sigma(W^TX_i)$$</p>
<p>其中$\sigma(\cdot)$表示激活函数,为$S$形状，<code>x</code>轴可以取值无限大，<code>y</code>轴只能取到$(-1,1)$<br>$$\sigma(a)=\frac{1}{1+exp(-a)}$$</p>
<pre><code>由于LR表示简单，训练预测速度快，效果并不是很差<span class="comment">(加上正则化)</span>，所以深得学术和工业界的囍爱~^_^
</code></pre><h2 id="使用GNB推导">使用GNB推导</h2><blockquote>
<p>谈到LR的时候第一印象就是上面的公式，但是为啥是这个公式呢？这一小节就是从<code>GNB(Gaussion Navie Bayes)</code>的角度来看待这个问题~</p>
</blockquote>
<p>我们先对<code>GNB</code>模型做4个假设:</p>
<ol>
<li>$Y$是布尔值，服从伯努利分布，其中$\pi = P(Y=1)$</li>
<li>其中$X_i$是连续随机变量</li>
<li>对于每个$X_i$，$P(X_i|Y=y_k)$服从高斯分布$N(\mu_{ik},\sigma_i)$(大多数情况下，简单用的$N(\mu_k,\sigma)$)</li>
<li>在给定$Y$下，$X_i$与$X_j$条件独立</li>
</ol>
<p>现在让$P(Y|X)$服从<code>GBN</code>假设，通常根据贝叶斯公式可以得到以下:<br>$$P(Y=1|X)=\frac{P(X|Y=1)P(Y=1)}{P(Y=1)P(X|Y=1)+P(Y=0)P(X|Y=0)}$$</p>
<p>再对这个式子进行进一步处理:</p>
<p>$$<br>\begin{equation}\begin{split} P(Y=1|X)&amp;=\frac{1}{1+\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)}}\quad\quad &amp;(1)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)}\right)}&amp;(2)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{P(Y=0)}{P(Y=1)}+\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}\right)}\quad\quad&amp;(3)\\<br>&amp;=\frac{1}{1+exp \left(ln\frac{1-\pi}{\pi}+\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}\right)} &amp;(4)<br>\end{split}\end{equation}<br>$$</p>
<p>其中:</p>
<ol>
<li>式子<code>(1)-&gt;(2)</code>是加了<code>exp</code>函数与<code>ln</code>函数正好相互抵消</li>
<li>式子<code>(2)-&gt;(3)</code>首先将<code>ln</code>函数的相乘转为相加，同时由于$X$中的各个$x_i$相互独立，所以原本写成连乘的式子又可以写成相加求和</li>
<li>式子<code>(3)-&gt;(4)</code>中$P(Y=1)$的概率是$\pi$，则$P(Y=0)$的概率是$1-\pi$</li>
</ol>
<p>在给定假设<code>3</code>情况下，对$\sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)}$进行进一步展开:<br>$$\begin{equation}\begin{split} \sum_iln\frac{P(x_i|Y=0)}{P(x_i|Y=1)} &amp;=\sum_iln\frac{\frac{1}{\sqrt{2\pi\sigma}}exp(\frac{-(x_i-\mu_{i0})^2}{2\sigma_i^2})}{\frac{1}{\sqrt{2\pi\sigma}}exp(\frac{-(x_i-\mu_{i1})^2}{2\sigma_i^2})}  &amp;(5)\\<br>&amp;= \sum_iln  exp\left(\frac{(x_i-\mu_{i1})^2-(x_i-\mu_{i0})^2}{2\sigma_i^2}\right) &amp;(6)\\<br>&amp;= \sum_i \left(\frac{(x_i^2-2x_i\mu_{i1}+\mu_{i1}^2)-(x_i^2-2x_i\mu_{i0}+\mu_{i0}^2)}{2\sigma_i^2}\right) \quad\quad &amp;(7)\\<br>&amp;= \sum_i \left(\frac{2x_i(\mu_{i0}-\mu{i1})+\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}\right) &amp;(8)\\<br>&amp;= \sum_i \left(\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}x_i+\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}\right) &amp;(9)<br>\end{split}\end{equation}$$</p>
<ol>
<li>式子<code>(5)</code>根据假设<code>3</code>而得到，它是服从高斯分布</li>
<li>式子<code>(5)-&gt;(6)</code>是消除了公共因此，并且将指数上的相除转为了相减</li>
<li>式子<code>(6)-&gt;(7)</code>是对<code>ln</code>和<code>exp</code>进行了相互抵消，并且对其平方公式进行了展开</li>
<li>式子<code>(7)-&gt;(8)</code>是展开式中除去了公有的变量</li>
<li>式子<code>(8)-&gt;(9)</code>将$x_i$显眼得提了出来</li>
</ol>
<p>现从新将上面的展开式丢到$P(Y=1|X)$中则可以得到<br>$$P(Y=1|X)=\frac{1}{1+exp \left(ln\frac{1-\pi}{\pi}+\sum_i(\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}x_i+\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2})\right)}$$</p>
<p>相应地，则可以将其写为:<br>$$P(Y=1|X)=\frac{1}{1+exp (\omega_0+\sum_i\omega_ix_i)}$$</p>
<blockquote>
<p>可以发现这个式子就是<code>LR</code>的式子了</p>
</blockquote>
<p>其权重$\{\omega_1…\omega_n\}$为<br>$$\omega_i=\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}$$<br>其偏置$\omega_0$为:<br>$$\omega_0=ln\frac{1-\pi}{\pi}+\sum_i\frac{\mu_{i1}^2-\mu_{i0}^2}{2\sigma_i^2}$$</p>
<h2 id="总结">总结</h2><p>文本是学习了从贝叶斯角度来看<code>LR</code>式子的来源，根据大家熟知的朴素贝叶斯公式，将定其特定类别下的特征符合高斯分布，根据贝叶斯公式一步步推导出了<code>LR</code>式子的样纸，还是很神奇的。^_^</p>
<h2 id="参考">参考</h2><p>1 <a href="http://web.cse.ohio-state.edu/~kulis/teaching/788_sp12/scribe_notes/lecture6.pdf" target="_blank" rel="external">http://web.cse.ohio-state.edu/~kulis/teaching/788_sp12/scribe_notes/lecture6.pdf</a>(基本就是看了这个，不过里面公式有不少笔误的。。)</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Logistic_Regression公式">Logistic Regression公式</h2><blockquote>
<p><code>Logistic Regression</code>（下面简称<code>LR</code>）是一个二分类的机器学习方法，给定一个输入向量$x_i$，输出$P(y_i|x_i)$,其中$y_i \in {0,1}$。</p>
</blockquote>
<p>作为一个二分类问题，$Y$的后验概率一般会写成这样:<br>$$P(Y=1|X)=\frac{1}{1+exp(- \omega - \sum_{i=1}^n {\omega_ix_i})}=\sigma(W^TX_i)$$<br>那么<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hadoop Streaming导入自定义module]]></title>
    <link href="http://kubicode.me/2016/03/25/Hadoop/Hadoop-Streaming-Import-custom-module/"/>
    <id>http://kubicode.me/2016/03/25/Hadoop/Hadoop-Streaming-Import-custom-module/</id>
    <published>2016-03-24T16:17:54.000Z</published>
    <updated>2016-03-25T01:51:05.000Z</updated>
    <content type="html"><![CDATA[<h2 id="问题">问题</h2><p>今天发现用<code>Python</code>编写<code>Hadoop Streaming</code>脚本时，如果自己导入自定义的模块会报错-_-<br>列如<code>word count</code>中的<a href="http://kubicode.me/2015/11/08/Hadoop/Hadoop-Streaming-Primary-Learning-And-Debug/" target="_blank" rel="external">reducer</a>程序:<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding=utf8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> utils_helper</span><br><span class="line"></span><br><span class="line">lastk = <span class="keyword">None</span> <span class="comment">#这里标志最后一个k  用于控制同一个key 到一个组中</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        w,c = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        c = int(c) <span class="comment">#不转成int会比较麻烦  这是是计数</span></span><br><span class="line">        <span class="keyword">if</span> lastk == <span class="keyword">None</span>: <span class="comment">#这里是判断是否过来的是第一个key</span></span><br><span class="line">                lastk=w</span><br><span class="line">                count = utils_helper.add(count,c)</span><br><span class="line">        <span class="keyword">elif</span> lastk == w:</span><br><span class="line">                count += c</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"%s\t%s"</span>%(lastk,count)</span><br><span class="line">                lastk=w</span><br><span class="line">                count = c <span class="comment">#这里重置计数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> lastk <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"%s\t%s"</span>%(lastk,count)</span><br></pre></td></tr></table></figure></p>
<p>故意使用一个自定义模块来测试<code>utils_helper.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(x,y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x+y</span><br></pre></td></tr></table></figure></p>
<p>如果本地跑起来是(就是本地DEBUG)就可以正常跑的，但是放到<code>Hadoop</code>集群上跑的时候,使用的启动命令为:</p>
<pre><code>hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.7.0.jar \
-<span class="ruby">input /yyl/data/line.txt \
</span>-<span class="ruby">output /yyl/test/ouput/streaming2 \
</span>-<span class="ruby">mapper <span class="string">"python word_count_mapper.py"</span> \
</span>-<span class="ruby">reducer <span class="string">"python word_count_reducer.py"</span> \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/word_count_mapper.py \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/word_count_reducer.py \
</span>-<span class="ruby">file <span class="variable">$HADOOP_HOME</span>/runjar/pyscript/utils_helper.py \</span>
</code></pre><p>可以发现跑到<code>reducer</code>阶段时会报错:</p>
<pre><code><span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">40</span> INFO mapreduce<span class="class">.Job</span>: Running job: job_1458827745768_0018
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">53</span> INFO mapreduce<span class="class">.Job</span>: Job job_1458827745768_0018 running <span class="keyword">in</span> uber mode : false
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">11</span>:<span class="number">53</span> INFO mapreduce<span class="class">.Job</span>:  map <span class="number">0%</span> reduce <span class="number">0%</span>
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">12</span>:<span class="number">12</span> INFO mapreduce<span class="class">.Job</span>:  map <span class="number">100%</span> reduce <span class="number">0%</span>
<span class="number">16</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">12</span>:<span class="number">12</span>:<span class="number">22</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1458827745768_0018_r_000000_0, Status : FAILED
Error: java<span class="class">.lang</span><span class="class">.RuntimeException</span>: PipeMapRed.<span class="function"><span class="title">waitOutputThreads</span><span class="params">()</span></span>: subprocess failed with <span class="tag">code</span> <span class="number">2</span>
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeMapRed</span><span class="class">.waitOutputThreads</span>(PipeMapRed<span class="class">.java</span>:<span class="number">322</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeMapRed</span><span class="class">.mapRedFinished</span>(PipeMapRed<span class="class">.java</span>:<span class="number">535</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.streaming</span><span class="class">.PipeReducer</span><span class="class">.close</span>(PipeReducer<span class="class">.java</span>:<span class="number">134</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.io</span><span class="class">.IOUtils</span><span class="class">.cleanup</span>(IOUtils<span class="class">.java</span>:<span class="number">244</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.ReduceTask</span><span class="class">.runOldReducer</span>(ReduceTask<span class="class">.java</span>:<span class="number">459</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.ReduceTask</span><span class="class">.run</span>(ReduceTask<span class="class">.java</span>:<span class="number">392</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">163</span>)</span></span>
    at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)
    at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1657</span>)
    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">158</span>)
</code></pre><p>这就疼了，代码应该没问题呀，尝试了好几遍之后还是这个错误。。。-_-!!</p>
<h2 id="解决方案">解决方案</h2><p>后来在<code>stackoverflow</code>发现有人问了同样的问题，并且我使用其中一个方案解决了:</p>
<pre><code>When Hadoop-Streaming starts <span class="keyword">the</span> python scripts, your python <span class="keyword">script</span>'s path <span class="keyword">is</span> <span class="keyword">where</span> <span class="keyword">the</span> <span class="keyword">script</span> <span class="type">file</span> really <span class="keyword">is</span>. However, hadoop starts them <span class="keyword">at</span> './', <span class="keyword">and</span> your lib.py(<span class="keyword">it</span>'s a symlink) <span class="keyword">is</span> <span class="keyword">at</span> './', too. So, <span class="keyword">try</span> <span class="keyword">to</span> add 'sys.path.append(<span class="string">"./"</span>)' <span class="keyword">before</span> you import lib.py like this: 
import sys
sys.path.append('./')
import lib
</code></pre><blockquote>
<p><code>lib.py</code>表示自定义包</p>
</blockquote>
<p>应该就是<code>-file</code>上传到计算机器之后文件路径的问题产生的，不过感觉他的理由有点疑惑，按他说的如果我上传之后会通过软连接组织到同一目录下再使用，所以如果直接导入包可能会出问题，那我如果上传之前就是在同一目录下应该就不会出问题吧？？这里并不是很理解，但是至少是导入包的问题是解决了^_^</p>
<h2 id="参考">参考</h2><ol>
<li><a href="http://stackoverflow.com/questions/18150208/how-to-import-a-custom-module-in-a-mapreduce-job" target="_blank" rel="external">http://stackoverflow.com/questions/18150208/how-to-import-a-custom-module-in-a-mapreduce-job</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="问题">问题</h2><p>今天发现用<code>Python</code>编写<code>Hadoop Streaming</code>脚本时，如果自己导入自定义的模块会报错-_-<br>列如<code>word count</code>中的<a href="http://kubicode.me/2015/11/08/Hadoop/Hadoop-Streaming-Primary-Learning-And-Debug/">reducer</a>程序:<br>]]>
    
    </summary>
    
      <category term="Hadoop" scheme="http://kubicode.me/tags/Hadoop/"/>
    
      <category term="Hadoop" scheme="http://kubicode.me/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[小技巧]让Hexo在使用Mathjax时支持多行公式]]></title>
    <link href="http://kubicode.me/2016/03/18/Hexo/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/"/>
    <id>http://kubicode.me/2016/03/18/Hexo/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/</id>
    <published>2016-03-18T01:46:24.000Z</published>
    <updated>2016-03-28T15:42:26.000Z</updated>
    <content type="html"><![CDATA[<p>还是在<code>Hexo</code>中使用<code>Mathjax</code>写<code>Latex</code>公式的问题，在需要些多行的公式的时候，<br>例如:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>其中:</p>
<ol>
<li><code>begin</code>和<code>end</code>表示公式的起始</li>
<li><code>\\</code>符号表示换行</li>
<li><code>&amp;</code>表示对齐</li>
</ol>
<a id="more"></a>
<p>结果渲染到html页面之后结果是这样的:<br><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/error.png" with="500px"></p>
<p>完全没换行啊，而且又有莫名其妙的空格，按照之前的经验，估计是<code>markdown</code>渲染的<code>html</code>的时候出了问题<br><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/error_code.png"></p>
<p>发现两个问题:</p>
<ol>
<li><code>&amp;</code>符号被转义成了<code>&amp;amp;</code></li>
<li>双反斜杠<code>\\</code>被转义成功了<code>\</code></li>
</ol>
<p>这就是公式没换行的原因，肯定是<code>marked.js</code>里面做了处理，不过仔细看<code>Mathjax</code>脚本的配置项中有一项为<code>processEscapes: true</code>，说明<code>MathJax</code>是支持转义符号的，所以类似<code>&amp;amp;</code>是不需要额外处理的。</p>
<p>那么压力就到了解反斜杠问题，最粗暴的是讲反斜杠的转义从<code>marked.js</code>里面去掉，但是可能会影响其他功能，既然两根反斜杠是转为一根，而<code>Latex</code>是两个换行，最简单的方法就是写4个反斜杠:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span><span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>就可以得到期待的结果了:</p>
<center><img src="/img/The-Trick-about-Hexo-Support-MutliLine-Equation-using-Mathjax/right.png"></center>

<p>这种处理就不影响<code>Hexo</code>自身的功能，又可以满足多行公式的书写^_^</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>还是在<code>Hexo</code>中使用<code>Mathjax</code>写<code>Latex</code>公式的问题，在需要些多行的公式的时候，<br>例如:</p>
<pre><code><span class="command">\begin</span><span class="special">{</span>equation<span class="special">}</span><span class="command">\begin</span><span class="special">{</span>split<span class="special">}</span> a<span class="special">&amp;</span>=b+c-d<span class="command">\\</span>
<span class="special">&amp;</span><span class="command">\quad</span> +e-f<span class="command">\\</span>
<span class="special">&amp;</span>=g+h<span class="command">\\</span>
<span class="special">&amp;</span> =i 
<span class="command">\end</span><span class="special">{</span>split<span class="special">}</span><span class="command">\end</span><span class="special">{</span>equation<span class="special">}</span>
</code></pre><p>其中:</p>
<ol>
<li><code>begin</code>和<code>end</code>表示公式的起始</li>
<li><code>\\</code>符号表示换行</li>
<li><code>&amp;</code>表示对齐</li>
</ol>]]>
    
    </summary>
    
      <category term="Hexo" scheme="http://kubicode.me/tags/Hexo/"/>
    
      <category term="Hexo" scheme="http://kubicode.me/categories/Hexo/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[修复Hexo写Mathjax公式多个下标失效的问题]]></title>
    <link href="http://kubicode.me/2016/03/16/Hexo/Fix-Hexo-Bug-In-Mathjax/"/>
    <id>http://kubicode.me/2016/03/16/Hexo/Fix-Hexo-Bug-In-Mathjax/</id>
    <published>2016-03-16T15:25:29.000Z</published>
    <updated>2016-03-28T01:47:42.000Z</updated>
    <content type="html"><![CDATA[<pre><code>这应该严格意义上不算Hexo的bug，但是在写Mathjax的时候就会踩中-_-
</code></pre><blockquote>
<p>说起<code>Markdown</code>写文章时，加粗的第一反应是<code>**</code>，斜体的第一反应是<code>*</code>，因为各种<code>Markdown</code>格式规范的文章里面都是这么教的，但是你不知道的是<code>__</code>可以支持粗体，<code>_</code>可以支持斜体，一般而言这是没什么问题，但是当在写<code>Latex</code>（<code>Hexo</code>里使用<code>Mathjax</code>实现）数据公式时，<code>_</code>表示下标，并且使用频率很高，当一行里面有多个<code>_</code>出现时，<code>Hexo</code>进行解析导致所期待的公式失效。</p>
</blockquote>
<p>自从用<code>Hexo</code>写数学公式的时候，就发现一点小问题，公式复杂了，在<code>Hexo</code>里面就不<code>work</code>，起初以为是<code>Mathjax</code>的支持不完善的缘故，后来发现用了<code>Mathjax</code>的其他博客里面都可以写复杂的公式，而今天又遇到了这个问题：<br>我的公式文本是:<br><code>对于每个$X_i$，$P(X_i|Y=y_k)$服从高斯分布$N(\mu_{ik},\sigma_i)$</code><br>结果生成页面查看之后却发现:<br><a id="more"></a></p>
<p><img src="/img/Fix-Hexo-Bug-In-Mathjax/error_display.png" width="500px"><br>这完全不是我期待的。。。数据公式完全没呈现，并且还变斜体了..<br>最初怀疑是不是公式写错了，结果每个公式去<a href="http://latex.codecogs.com/eqneditor/editor.php" target="_blank" rel="external">在线Latex编辑器</a>里面测试之后都是通过的。。。 这难道<code>Mathjax</code>又不支持了吗？？</p>
<p>趁着周末，得把这个问题解决一把~搞个单页再引用<code>Mathjax</code>之后上面的公式是<code>work</code>的，看<code>Hexo</code>里面渲染的html惊奇的发现:<br><img src="/img/Fix-Hexo-Bug-In-Mathjax/error_code.png" width="500px"><br>下划线<code>_</code>被渲染成<code>&lt;em&gt;</code>标签了，难怪<code>Mathjax</code>公式无法呈现了，<br>接下来<code>Hexo</code>的<code>Markdown</code>渲染引擎:</p>
<pre><code>yans-MacBook-Pro:node_modules yanyl$ grep -r \<span class="variable">&lt;em\&gt;</span> .
./hexo/node_modules/bunyan/docs/bunyan.<span class="number">1</span>.html:<span class="variable">&lt;em&gt;</span>names<span class="variable">&lt;/em&gt;</span> or numeric values. (See 'Log Levels' below.)<span class="variable">&lt;/p&gt;</span><span class="variable">&lt;/dd&gt;</span>
./hexo/node_modules/bunyan/docs/bunyan.<span class="number">1</span>.html:<span class="variable">&lt;dt&gt;</span><span class="variable">&lt;code&gt;</span>-L<span class="variable">&lt;/code&gt;</span>, <span class="variable">&lt;code&gt;</span>--time local<span class="variable">&lt;/code&gt;</span><span class="variable">&lt;/dt&gt;</span><span class="variable">&lt;dd&gt;</span><span class="variable">&lt;p&gt;</span>Display the time field <span class="keyword">in</span> <span class="variable">&lt;em&gt;</span>local<span class="variable">&lt;/em&gt;</span> time, rather than the <span class="keyword">default</span> UTC
./hexo-renderer-marked/node_modules/marked/lib/marked.js:  return '<span class="variable">&lt;em&gt;</span>' + text + '<span class="variable">&lt;/em&gt;</span>';
./hexo-renderer-marked/node_modules/marked/marked.<span class="keyword">min</span>.js:(function(){var <span class="built_in">block</span>={newline:/^\n+
</code></pre><blockquote>
<p>最后一个<code>marked.min.js</code>因为是单行的，所以后面的不贴了</p>
</blockquote>
<p><code>&lt;em&gt;</code>标签的渲染应该就在<code>marked.js</code>或者<code>marked.min.js</code>中，</p>
<pre><code>yans-MacBook-<span class="string">Pro:</span>node_modules yanyl$ grep -r <span class="string">"marked.js"</span> .
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span>bower.<span class="string">json:</span>  <span class="string">"main"</span>: <span class="string">"lib/marked.js"</span>,
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span>component.<span class="string">json:</span>  <span class="string">"scripts"</span>: [<span class="string">"lib/marked.js"</span>],
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span>component.<span class="string">json:</span>  <span class="string">"main"</span>: <span class="string">"lib/marked.js"</span>,
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="string">Makefile:</span>    <span class="annotation">@cp</span> lib/marked.js marked.js
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="string">Makefile:</span>    <span class="annotation">@uglifyjs</span> --comments <span class="string">'/\*[^\0]+?Copyright[^\0]+?\*/'</span> -o marked.min.js lib/marked.js
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="string">Makefile:</span>    <span class="annotation">@rm</span> marked.js
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span>man/marked.1:.TH marked <span class="number">1</span> <span class="string">"2014-01-31"</span> <span class="string">"v0.3.1"</span> <span class="string">"marked.js"</span>
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="keyword">package</span>.<span class="string">json:</span>  <span class="string">"main"</span>: <span class="string">"./lib/marked.js"</span>,
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span>README.<span class="string">md:</span>  &lt;script src=<span class="string">"lib/marked.js"</span>&gt;&lt;/script&gt;
yans-MacBook-<span class="string">Pro:</span>node_modules yanyl$ grep -r <span class="string">"marked.min.js"</span> .
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="string">Makefile:</span>    <span class="annotation">@uglifyjs</span> --comments <span class="string">'/\*[^\0]+?Copyright[^\0]+?\*/'</span> -o marked.min.js lib/marked.js
.<span class="regexp">/hexo-renderer-marked/</span>node_modules<span class="regexp">/marked/</span><span class="string">Makefile:</span>    <span class="annotation">@rm</span> marked.min.js
</code></pre><p>进一步查找可以发现<code>marked.min.js</code>是<code>marked.js</code>的一个压缩版本，并无其他的模块使用，那么进入<code>marked.js</code>中，可以找到<code>&lt;em&gt;</code>的渲染规则:<br><img src="/img/Fix-Hexo-Bug-In-Mathjax/fix1.png" width="500px"><br>和<br><img src="/img/Fix-Hexo-Bug-In-Mathjax/fix2.png" width="500px"></p>
<p>可以发现<code>&lt;em&gt;</code>标签除了<code>*</code>可以渲染，<code>_</code>同样也可以渲染，那么这样就通了<br>解决问题最方便的方法就是关于<code>_</code>渲染，直接将<code>|</code>左侧的<code>_</code>正则匹配删除即可</p>
<p>然后再重新生成页面，刷新可以发现：<br><img src="/img/Fix-Hexo-Bug-In-Mathjax/correct_display.png" width="500px"><br>终于得到期望的结果了</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code>这应该严格意义上不算Hexo的bug，但是在写Mathjax的时候就会踩中-_-
</code></pre><blockquote>
<p>说起<code>Markdown</code>写文章时，加粗的第一反应是<code>**</code>，斜体的第一反应是<code>*</code>，因为各种<code>Markdown</code>格式规范的文章里面都是这么教的，但是你不知道的是<code>__</code>可以支持粗体，<code>_</code>可以支持斜体，一般而言这是没什么问题，但是当在写<code>Latex</code>（<code>Hexo</code>里使用<code>Mathjax</code>实现）数据公式时，<code>_</code>表示下标，并且使用频率很高，当一行里面有多个<code>_</code>出现时，<code>Hexo</code>进行解析导致所期待的公式失效。</p>
</blockquote>
<p>自从用<code>Hexo</code>写数学公式的时候，就发现一点小问题，公式复杂了，在<code>Hexo</code>里面就不<code>work</code>，起初以为是<code>Mathjax</code>的支持不完善的缘故，后来发现用了<code>Mathjax</code>的其他博客里面都可以写复杂的公式，而今天又遇到了这个问题：<br>我的公式文本是:<br><code>对于每个$X_i$，$P(X_i|Y=y_k)$服从高斯分布$N(\mu_{ik},\sigma_i)$</code><br>结果生成页面查看之后却发现:<br>]]>
    
    </summary>
    
      <category term="Hexo" scheme="http://kubicode.me/tags/Hexo/"/>
    
      <category term="Hexo" scheme="http://kubicode.me/categories/Hexo/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在信息检索中Term之间的Proximity计算研究]]></title>
    <link href="http://kubicode.me/2016/02/23/Search%20Engine/Proximity-Measures-In-Information-Retrieval/"/>
    <id>http://kubicode.me/2016/02/23/Search Engine/Proximity-Measures-In-Information-Retrieval/</id>
    <published>2016-02-23T12:58:43.000Z</published>
    <updated>2016-03-23T07:28:54.000Z</updated>
    <content type="html"><![CDATA[<h2 id="为啥要做Proximity计算">为啥要做Proximity计算</h2><p>先来看下信息检索/搜索引擎 的一般架构流程:</p>
<ol>
<li>对<code>Doc</code>进行分词,这些分词也叫做<code>Term</code>，然后离线做各种计算</li>
<li>将这些<code>Term</code>灌入倒排索引中</li>
<li>用户查询</li>
<li>根据倒排召回命中<code>Term</code>的文档</li>
<li>将文档根据各个<code>Term</code>算分排序</li>
</ol>
<p>其实可以发现这里查的<code>Term</code> 都是<code>bag-of-words</code>的形式，并且第五步的算法也一般是在线的，所以基本不会做全文扫描之类的事情，那么这样的话问题就来了：<br><a id="more"></a></p>
<pre><code>如果搜索“红色连衣裙”,则可能会出现下面的文档:
<span class="number">1.</span>xxxx红色连衣裙xxxx
<span class="number">2.</span>红色高跟鞋配连衣裙
很明显文档<span class="number">1</span>的相关性比<span class="number">2</span>要高，但是此时如果仅仅是bag-<span class="keyword">of</span>-<span class="property">words</span>模型就很难保证<span class="number">1</span>的相关性分要比<span class="number">2</span>高
</code></pre><p>所以一般的搜索引擎还有一个叫做<code>Proximity Measures</code>的特征计算，可以理解为计算文档里面出现的<code>query Term</code>的相近程度，为了保证可行性，降低计算的复杂度，一般也只会计算两个<code>Term</code>之间的<code>Proximity</code>分</p>
<h2 id="使用距离度量">使用距离度量</h2><p>这种方式主要是计算<code>Term</code>之间距离作为<code>Proximity</code>得分，主要分两大类:</p>
<ol>
<li><code>Span-based</code>:使用时将全部的<code>query term</code>丢进去一起算距离</li>
<li><code>Distance aggregation</code>:先算两两之间的距离，再聚集起来</li>
</ol>
<p>假设现在有文档<code>D = t1, t2, t1, t3, t5, t4, t2, t3, t4</code>，基于<code>D</code>集合来讲讲各个距离的计算方式<br><strong>Span-based</strong></p>
<ul>
<li><code>Span</code>:在文档中可以覆盖所有term的最小距离称为<code>Span</code>，<strong>需要包含所有重复的term</strong><br>  比如$Q=t1,t2$这个查询的$Span=7$</li>
<li><code>MinCover</code>:在文档中可以覆盖所有term的最小距离称为<code>MinCover</code>,<strong>每个term至少被包含一次</strong><br>  比如这里的$Q=t1,t2$查询的$MinCover=1$</li>
</ul>
<p><strong>Distance aggregation</strong></p>
<blockquote>
<p>这种方式计算的最近单元是计算一个term pair的最小距离，使用$Dis(t_i,t_j;D)$来表示</p>
</blockquote>
<ul>
<li><code>MinDist(Minimum pair distance)</code>:计算所有pair的最小距离的最小值,<br>  <center>$MinDist=min_{q_1,q_2 \in Q \cap D,q_1 \neq q_2} Dis(q_1,q_2;D)$</center><br>比如$Q={t1,t2,t3}$，则$MinDist=min(1,2,3)=1$</li>
<li><code>AveDist(Average pair distance)</code>:计算所有pair的最小距离的平均值，<br>  <center>$AveDist=\frac{2}{n \cdot (n+1)}min_{q_1,q_2 \in Q \cap D,q_1 \neq q_2} Dis(q_1,q_2;D)$</center><br>比如$Q={t1,t2,t3}$，则$AveDist=(1+2+3)/3=2$</li>
<li><code>MaxDist(Maximum pair distance)</code>:与<code>MinDist</code>正好相反，它是求最大值<br>  <center>$MinDist=max_{q_1,q_2 \in Q \cap D,q_1 \neq q_2} Dis(q_1,q_2;D)$</center><br>  比如$Q={t1,t2,t3}$，则$MaxDist=max(1,2,3)=3$</li>
</ul>
<p>文献中实验表明:</p>
<ol>
<li><code>Span-based</code>为考虑到各个文档长度，以各自文档的长度最为归一化因子进行归一化之后效果要好一些</li>
<li><code>Distance aggregation</code>系列一般比<code>Span-based</code>的效果要好</li>
<li><code>Distance aggregation</code>中<code>MinDist</code>的效果最好</li>
</ol>
<p>但是在一般使用过程中不会直接将距离作为<code>Proximity</code>的值，现将$\delta(Q,D)$作为查询词在各个文档的中的距离度量，$\delta(Q,D)$最小表明查询词与文档越相关，而在使用过程中一般以这个相关性越大最好，这将这个相关性记为:$\pi(Q,D)$，则使用下面的公式来转换:<br>$$\pi(Q,D)=log(\alpha + exp(- \delta(Q,D)))$$</p>
<blockquote>
<p>$\alpha$可以作为调节因子</p>
</blockquote>
<p>使用这种方式的度量最大的优点就是方便，但是单独用起来效果可能不怎么理解，并且波动性较大.~</p>
<h2 id="引入BM25模型">引入BM25模型</h2><p>主要对<code>bi-term</code>进行<code>BM25</code>得分的计算，这里<code>BM25</code>的计算方式可以按传统的进行，<a href="http://kubicode.me/2016/01/26/Search%20Engine/Study-BM25-For-Query-Document-Relevance/" target="_blank" rel="external">参考这个</a> </p>
<p>关于<code>bi-term</code>的构建主要有两种方式:</p>
<ol>
<li>直接使用<code>B-Gram</code>:认为相邻两个<code>term</code>是有依赖的，所以可以直接使用<code>B-Gram</code>的方式来构建</li>
<li>使用滑窗的方式:认为一个窗口里面的两两<code>term</code>有依赖，因此可以对他们进行两两组合，这个窗口大小一般会小于8</li>
</ol>
<blockquote>
<p>其实更好的应该是<code>依存</code>关系来构建这个<code>bi-term</code>，不过上述的几种方式构建出来的<code>pair</code>都会很大，所以还需要其他一些方式来剪枝</p>
</blockquote>
<h1 id="持续研究中~~~">持续研究中~~~</h1><h2 id="参考">参考</h2><ol>
<li>2007-An Exploration of Proximity Measures in Information Retrieval</li>
<li>2005-A Markov random field model for term dependencies</li>
<li>2010-How good is a span of terms?: exploiting proximity to improve web retrieval</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="为啥要做Proximity计算">为啥要做Proximity计算</h2><p>先来看下信息检索/搜索引擎 的一般架构流程:</p>
<ol>
<li>对<code>Doc</code>进行分词,这些分词也叫做<code>Term</code>，然后离线做各种计算</li>
<li>将这些<code>Term</code>灌入倒排索引中</li>
<li>用户查询</li>
<li>根据倒排召回命中<code>Term</code>的文档</li>
<li>将文档根据各个<code>Term</code>算分排序</li>
</ol>
<p>其实可以发现这里查的<code>Term</code> 都是<code>bag-of-words</code>的形式，并且第五步的算法也一般是在线的，所以基本不会做全文扫描之类的事情，那么这样的话问题就来了：<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[针对BM25遇到长文档时失效情况的一种高效解决方案]]></title>
    <link href="http://kubicode.me/2016/02/16/Search%20Engine/BM25-Fails-When-The-Docments-Are-Very-Long/"/>
    <id>http://kubicode.me/2016/02/16/Search Engine/BM25-Fails-When-The-Docments-Are-Very-Long/</id>
    <published>2016-02-16T09:17:19.000Z</published>
    <updated>2016-02-27T06:58:10.000Z</updated>
    <content type="html"><![CDATA[<pre><code>B<span class="title">M25</span>在长文档下会失效，文本是记录SIGIR上的一个Paper的解决方案~
</code></pre><h2 id="当BM25遇到长文档">当BM25遇到长文档</h2><p>文档相关性模型-<code>BM25</code>的拟合公式如下:</p>
<center>$\sum_{i\in Q} log \frac {(r_i+0.5)((N-R)-(n_i-r_i)+0.5)}{(n_i-r_i+0.5)(R-r_i+0.5)} \cdot \frac{(k_1+1)f_i}{K+f_i} \cdot \frac{(k_2+1)qf_i}{k_2+qf_i}$</center>

<p>其中第一部分表示<code>BIM</code>的值，第二部分表示在文档中的权重，第三部分表示在查询词中的权重，(具体符号解释参考之前的<a href="http://kubicode.me/2016/01/26/Search%20Engine/Study-BM25-For-Query-Document-Relevance/" target="_blank" rel="external">BM25介绍</a>)现将第二部分单独拿出来:</p>
<p><center>$f(q,D)=\frac{(k_1+1) \times TF}{k_1 \times ((1-b)+b \cdot \frac{dl}{avdl} )+TF}=\frac{(k_1+1) \times c’(q,D)}{k_1+c’(q,D)}$</center><br>其中:<br><a id="more"></a></p>
<p><center>$c’(q,D)=\frac{TF}{1-b+b \cdot \frac{dl}{avdl}}$</center><br>现在先来做一个假设，假设当前有个文档<code>很长很长</code>，也就是$dl$这个值很大，则可以发现$c’(q,D)$就会很小，小到接近于0，因此会导致文档部分的因子$f(q,D)$也会接近于0，几乎和这个词没有出现在这个文档一样..-_-</p>
<p>在这种情况下，针对长文档，<code>BM25</code>的效果会比较差<br>下面的图就是<code>BM25</code>在不同文档长度下的实验</p>
<p><img src="/img/BM25-Fails-When-The-Docments-Are-Very-Long/doc-len-comp.png" width="600px"></p>
<p>可以发现在<code>BM25</code>中，随着文档的变长，相关性在变高，但是其被检索的概率并没有随着相关性的趋势而变高，也就是长文档使用<code>BM25</code>的效果变得比较差。</p>
<h2 id="高效解决方案">高效解决方案</h2><p>为了避免长文档在<code>BM25</code>的相关性中被惩罚，我们需要对文档权重$f(q,D)$做一个规范化约束，但是由于<code>BM25</code>早已被公认为是一种比较有效的文档相关性，所以这个约束不能破坏掉<code>BM25</code>自身的特征.</p>
<p>我们希望规范化约束之后保持以下三点特性:</p>
<ol>
<li>当$c’(q,D)=0$的时候，$f(q,D)$也为0</li>
<li>随着$c’(q,D)$的变大，$f(q,D)$也需要呈现单调递增，但是会趋向于一个最大值</li>
<li>随着$c’(q,D)$的减少，$f(q,D)$会单调递减趋向于一个最小值，但是这个最小值需要足够大</li>
</ol>
<blockquote>
<p>就是因为原生的<code>BM25</code>不满足第3点，所以会出现在长文档下<code>BM25</code>出现失效的情况</p>
</blockquote>
<!-- 
f'(q,D)=\left\{
\begin{aligned}
\frac{(k_1+1) \cdot [c'(q,D)+\delta ]}{k_1 + [c'(q,D)+\delta ]}  & \quad if \quad c'(q,D)>0\\
0 & \quad otherwise\\
\end{aligned}
\right.
-->
<p>而下面的改进$f’(q,D)$正好可以满足上述三个特性:</p>
<p><img src="/img/BM25-Fails-When-The-Docments-Are-Very-Long/gj.gif" alt=""></p>
<p>使用时针对原来的$c’(q,D)$值增加了一个平滑项$\delta$，增加了平滑项之后依然满足<code>第1、2点</code>特性，并且当$c’(q,D)&gt;0$的时候$f’(q,D)$有一个下界:</p>
<p><center>$\frac{(k_1+1) \cdot \delta}{k_1+ \delta}$</center><br>这样也正好可以满足<code>第3点</code>特性</p>
<p>进行该项小改进之后的模型称为<code>BM25L</code>,遇到长文档时并不会失效，并且还保持原有的<code>BM25</code>特性.</p>
<h2 id="实验效果验证">实验效果验证</h2><p>针对多个数据集  ，使用不同的调节参数$b$,$k_1$,$\delta$进行试验:<br><img src="/img/BM25-Fails-When-The-Docments-Are-Very-Long/exp.png"></p>
<p>在第三章图明显可以发现<code>BM25L</code>的效果对<code>BM25</code>有较大的绝对提升，其中较优的参数范围为:</p>
<ol>
<li>$b \in [0,3,0.6] $</li>
<li>$k_1 \in [1.0,2.0]$</li>
<li>$\delta = 0.5$时最优</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.600.16&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">When Documents Are Very Long, BM25 Fails!</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code>B<span class="title">M25</span>在长文档下会失效，文本是记录SIGIR上的一个Paper的解决方案~
</code></pre><h2 id="当BM25遇到长文档">当BM25遇到长文档</h2><p>文档相关性模型-<code>BM25</code>的拟合公式如下:</p>
<center>$\sum_{i\in Q} log \frac {(r_i+0.5)((N-R)-(n_i-r_i)+0.5)}{(n_i-r_i+0.5)(R-r_i+0.5)} \cdot \frac{(k_1+1)f_i}{K+f_i} \cdot \frac{(k_2+1)qf_i}{k_2+qf_i}$</center>

<p>其中第一部分表示<code>BIM</code>的值，第二部分表示在文档中的权重，第三部分表示在查询词中的权重，(具体符号解释参考之前的<a href="http://kubicode.me/2016/01/26/Search%20Engine/Study-BM25-For-Query-Document-Relevance/">BM25介绍</a>)现将第二部分单独拿出来:</p>
<p><center>$f(q,D)=\frac{(k_1+1) \times TF}{k_1 \times ((1-b)+b \cdot \frac{dl}{avdl} )+TF}=\frac{(k_1+1) \times c’(q,D)}{k_1+c’(q,D)}$</center><br>其中:<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
</feed>