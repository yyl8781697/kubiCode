<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Kubi Code'Blog]]></title>
  <subtitle><![CDATA[The palest ink is better than the best memory.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://kubicode.me/"/>
  <updated>2018-09-29T06:06:49.583Z</updated>
  <id>http://kubicode.me/</id>
  
  <author>
    <name><![CDATA[Kubi Code]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[深度学习在序列化推荐中的应用(1)-GRU4REC以及扩展]]></title>
    <link href="http://kubicode.me/2018/09/19/Deep%20Learning/GRU4REC-Session-Based-Recommendation/"/>
    <id>http://kubicode.me/2018/09/19/Deep Learning/GRU4REC-Session-Based-Recommendation/</id>
    <published>2018-09-19T09:39:51.000Z</published>
    <updated>2018-09-29T06:06:49.583Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>用户在互联网应用上的绝大部分的行为都是可以用一个序列来表示，比如购物、听音乐、看feed流等，用式子来表示就是$${x_1,x_2,x_3,..,x_N} -&gt; x_{N+1}$$<br>因此对于这个序列如何建模来获取整个用户的意图行为至关重要，而之前传统的ML只能基于统计或者经验的方式来尽量抽取这些序列信息，并无法hold整个序列，16年提出的<code>GRU4REC</code>利用<code>RNN-Based</code>对用户序列进行建模并且取得了不错的效果，同时也会有一些研究对于<code>GRU4REC</code>做了不少改进和扩展，本文主要对<code>GRU4REC</code>以及扩展做一些简答的自我了解和记录。</p>
<a id="more"></a>
<h2 id="GRU4REC">GRU4REC</h2><p><code>GRU4REC</code>是Session信息和GRU结合起来完成了推荐，他给定的场景是：</p>
<blockquote>
<p>用户在我们的应用上有一段行为<code>Session</code>（比如说点击item的需求），然后在于该Session信息来预测接下来可能会发生点击的item，而这笔的Session信息主要使用<code>GRU</code>模型来进行刻画：</p>
</blockquote>
<p><img src="/img/Session-Based-Recommendation/gru4rec_arch.png" width="400px"></p>
<ol>
<li>这边第一步的输入是用户的行为序列: $[x_1,x_2,x_3,..,x_N]$</li>
<li>这些行为序列可以接下来使用两种Embedidng表示，一种是<code>One-Hot</code>方式,另一种是在<code>One-Hot</code>接下来过一个Embedding层</li>
<li>将所有的输入进行向量化表示之后，会过若干层的GRU(就是比较核心的序列化建模了)</li>
<li>完成序列化建模之后再进行一个<code>Feedforward</code>的网络转换</li>
<li><p>最终对下一个目标进行预测,这边的目标其实就是$x_{N+1}$</p>
<blockquote>
<p>(作者说这种方式性能好，但是我到觉得这种场景下<code>One-Hot</code>不是很合适，<code>One-Hot</code>在这边他的DIM会巨大，并且会特别的稀疏,可能还是查表的来的好)</p>
</blockquote>
</li>
</ol>
<p>其实<code>GRU4REC</code>的整个思路还是很清晰，模型也很简单，但是该算法中比较重要的应该是他的加速优化和LOSS的选择可能会有比较大的参考价值意义:</p>
<p>为了能提高训练的效率，采用两种策略来进行训练的优化:</p>
<ol>
<li><p>使用<code>Mini-Batch</code>来进行训练:<br> <img src="/img/Session-Based-Recommendation/gru4rec_minibatch.png" width="400px"><br> 因为用户行为的Session有长有短，并且他的差异性很大，传统的滑窗方式来构建训练数据并不适用，他这里用的策略是将不同的<code>Session</code>给拼接了起来，在同一个序列中如果遇到下一次Session时，会将GRU中的向量参数给重新初始化掉，因为这边GRU是对Step进行预测，所以在序列中间直接初始化掉问题也不大，这样还可以提升数据的利用率，会比简单<code>PADDING</code>的方式更加的合适。</p>
</li>
<li><p>取巧的训练数据采样:<br> 原始的模型中是需要过softmax对于每个item都计算才能对目标的item进行训练，因为item的维度非常高，所以这里的计算量是超级大的。作者在这里比较机智的在目标的样本中根据<code>热门</code>程度进行了采样，采样完成之后将同一个<code>mini-batch</code>中但是是其他<code>Session</code>的next-item作为负样本。用这些正负样本来训练整个神经网络。下面这个图对于采样非常形象了：</p>
</li>
</ol>
<p><img src="/img/Session-Based-Recommendation/gru4rec_sampling.png" width="600px"></p>
<p>因此这个模型现在已经转为对正负样本的一个<code>0-1</code>分类的问题,而且推荐里面，并不存在绝对的正负样本，用户也可能会对多个item存在偏好，所以这边比较合适<code>Loss Function</code>就是用<code>Pair-Wise</code>的模式了(只需要   正样本的score大于负样本即可):</p>
<ol>
<li><code>BPR(Bayesian Personalized Ranking)</code>:这是一种基于矩阵分解的损失函数，他的式子是:$$L_s = - \frac{1}{N_s} \cdot \sum_{j=1}^{N_s} \text{log}(\sigma(\hat{r}_{s,i} - \hat{r}_{s,j}))$$ $N_s$是样本量的大小，$\hat{r}_{s,i}$表示正样本的分数，$\hat{r}_{s,j}$表示负样本的分数</li>
<li><code>TOP1</code>:这是种基于正则化方式的损失函数$$L_s = \frac{1}{N_s} \cdot \sum_{j=1}^{N_s} (\sigma(\hat{r}_{s,j} - \hat{r}_{s,i})) +\sigma(\hat{r^2_j})$$ 这种方式可以将$\hat{r}_{s,i}$的分数计算的更高，但是他同是也会是负样本，所以这边加了二范数来压制$\hat{r}$作为负样本时的分数</li>
</ol>
<p><code>GRU4REC</code>的实验结果也是蛮简单的,Baseline的实验不在这个表中，数据后面跟着的涨幅就是和Baseline的对比:<br><img src="/img/Session-Based-Recommendation/gru4rec_exp.png"><br>这边显示的也是<code>BPR</code>和<code>TOP1</code>这两种LOSS的效果会明显好于传统的交叉熵.</p>
<p><code>GRU4REC</code>是较早的将序列行为和GRU进行结合，其中<code>LOSS</code>这块的构建还是非常值得借鉴的。</p>
<blockquote>
<p>该作者还开放了源码<a href="https://github.com/hidasib/GRU4Rec" target="_blank" rel="external">https://github.com/hidasib/GRU4Rec</a></p>
</blockquote>
<h2 id="GRU4REC-Sampling">GRU4REC-Sampling</h2><blockquote>
<p>其中<code>GRU4REC-Sampling</code>和<code>GRU4REC</code>是同一个作者 ^_^</p>
</blockquote>
<p><code>GRU4REC-Sampling</code>也是在基于<code>GRU4REC</code>上的缺陷提出了额外的<code>Sampling</code>和新的<code>Loss Function</code><br>作者认为<code>GRU4REC</code>存在下面三种局限:</p>
<ol>
<li><code>BatchSize</code>一般都是比较小的，在总样本较多时，如果采样少的话，分数比较高的负样本被采样进来的概率就偏少了（这里高分数要用于下面的Loss） </li>
<li><code>BatchSize</code>会影响运行速度，但是由于设计的是<code>Mini-Batch</code>并行的方式，所以增加<code>BatchSize</code>也不会对速度有多大的影响</li>
<li>虽然<code>GRU4REC</code>用的是根据热度采样，但是实际中全根据热度也不一定适应所有数据集</li>
</ol>
<p>所以在<code>GRU4REC-Sampling</code>中又进行了额外的采样:同样是在<code>Mini-Batch</code>中进行采样，采样时根据这个公式$supp_i^\alpha$,而这边的$\alpha$是一个<code>0~1</code>的值，如果$\alpha=0$表示均匀采样，如果$\alpha=1$为完全的热门采样。</p>
<p>另外<code>GRU4REC</code>中的<code>BPR</code>和<code>TOP1</code>会存在梯度的消失问题，因此作者设计了一种新的损失函数希望来最大化正样本的分数:$$L_{pairwise-max}(r_i,{r_j}_{j=1}^{N_s}) = L_{pairwise}(r_i,max_jr^j)$$<br>从这儿可以看出，新的损失函数是对<code>Max-Score</code>的负样本做pair，但是这种是不可求导了，所以作者用了一种近似的方式来实现,刚刚对<code>Max-Score</code>做负样本的方式可以转为<code>Score</code>越大，则<code>Loss</code>中的权重也越大，而这个权重可以用归一化的<code>softmax</code>来表示:$$s_i = \frac{e^{r_i}}{\sum_{j=1}^N e^{r_j}}$$<br>有了每个样本的权重表示之后，原先的<code>Loss Function</code>可以更改为:</p>
<ol>
<li><code>TOP1-MAX</code>:$$L_{top1-max} = \sum_{j=1}^{N_S}s_j(\sigma(r_j-r_i) + sigma(r_j^2))$$</li>
<li><code>BPR-max</code>:$$L_{bpr-max} = -\text{log} \sum_{j=1}^{N_s} s_j \sigma(r_i,r_j)$$</li>
</ol>
<blockquote>
<p>对比一下<code>GRU4REC</code>中的<code>Loss Function</code>，其实就是额外增加了一个$s_j$的权重值。</p>
</blockquote>
<p><img src="/img/Session-Based-Recommendation/gru4rec_sampling_exp.png"><br>看下实验对比，额外的<code>Sampling</code>和新的<code>Loss Function</code>都还是有极大的提升的,惊呆。</p>
<blockquote>
<p>我个人感觉<code>Sampling</code>起这么大的作用应该是采样之后样本不足了，这是一个训练时间和模型性能上的权衡，那么我如果不采样是不是效果就更好了-_-!!</p>
</blockquote>
<h2 id="GRU4REC-DWell">GRU4REC-DWell</h2><p><code>GRU4REC-DWell</code>也是基于<code>GRU4REC</code>的一个简单的改进，其中<code>GRU4REC</code>已经证明在时序的推荐中序列化的建模非常有用。<br>另外作者认为在用户行为序列中，每个item的停留时间是非常重要的一个特征，而之前的<code>GRU4REC</code>算法只是用于简单的交互行为来构建样本，所以<code>GRU4REC-DWell</code>主要是很巧妙将用户在序列item上的停留时间和GRU4REC<code>结合了起来:</code></p>
<p><img src="/img/Session-Based-Recommendation/gru4rec_dwell.png" width="400px"><br>这里主要的Idea就是在原始的用户行为中，作者根据item上面的停留时间根据阈值进行切片，如果停留时间长的可能会有很多个切片，每个切片都作为一个新的行为项:<br>给定一个行为序列的集合$X=\{x_1,x_2,…,x_n\}$,每一个$x_i$对应的停留时间为$dt_i$,其中$t$为切片的阈值，则$x_i$可以分割的切片为$d_t/t + 1$。 也就是如上图所示，$i_{2,1}$就由于停留时间较久，所以分割成了三个切片。<br>然后其他的就如原始的<code>GRU4REC</code>一样了，但是作者在做对比实验室加入了<code>GRU4REC-SAMPLING</code>进行了一起对比：<br><img src="/img/Session-Based-Recommendation/gru4rec_dwell_exp.png" width="400px"><br>实验中显示，停留时间信息的加入对于模型的作用是非常巨大的。</p>
<h2 id="HRNN">HRNN</h2><p>用户往往会存在多段不连续的Session（比如逛淘宝时，早上公交逛一次，中午午睡时逛一次，晚上睡前逛一次，这样就有三段Session序列，每一段内部是连续的），而之前的模型都是将这些Session行为都是独立训练的，文本中作者认为同一用户的不同Session间是有关联的，建模每一段Session可以发现用户的衍化。<br>所以作者提出了一种层次化的RNN序列建模，在每一段的<code>Session-Level</code>内部使用RNN建模的同时，会有一个<code>User-Level</code>的RNN来建模当前用户跨Session的行为，而<code>User-Level</code>的RNN的输入就是每一段<code>Session-Level</code>的final state。</p>
<p>用户的所用行为表示为$$C^u = \{ S_1^u,S_2^u,…S_{M_u}^u \}$$ $S_m^u$代表一次完整的Session，其中$s_m^u$代表对应<code>Session</code>的<code>Representations</code>(也就是最终一个final state),则<code>User</code>级别的<code>Representations</code>为$$c_m = GRU_{usr}(s_m,c_{m-1}),m = 1,…,M_u$$</p>
<p>所以这边<code>HRNN</code>的整个层次结构如图所示:<br><img src="/img/Session-Based-Recommendation/hrnn_arch.png"></p>
<ul>
<li>上面一层代表<code>Session-Level</code>的RNN，输入的是item，会对<code>next basket</code>进行预测，同时输出<code>final state</code></li>
<li>下面一层代表<code>User-Level</code>的RNN，输入的是<code>Session-Level</code>的<code>final state</code>，用户维护当前用户在整个应用的行为建模，并且会将当前Session的state输出作为下一次Session的<code>init state</code></li>
</ul>
<p><img src="/img/Session-Based-Recommendation/hrnn_exp.png" width="600px"><br>主要对比的是原生的<code>GRU4REC</code>，性能大约有10%左右的提升，但是用的数据和<code>GRU4REC-Sampling</code>以及<code>GRU4REC-DWell</code>的不一样，感觉没有他们的提升多，并且在现实过程中，对于<code>Session</code>的划分也是需要很多的<code>trick</code>啊。</p>
<h2 id="总结">总结</h2><p>其实<code>GRU4REC</code>在DL中是一个非常<code>straight-forward</code>的框架，但是他的厉害之处就是设计了<code>Mini-Batch</code>和<code>Sampling</code>将整个模型跑了起来并且起到了一定的效果,另外后面的几个改进中停留时间的改进以及层次的<code>Session</code>还是比较不错，并且可实用性高一些。</p>
<h2 id="参考">参考</h2><ol>
<li>Hidasi, Balázs, et al. “Session-based recommendations with recurrent neural networks.” arXiv preprint arXiv:1511.06939 (2015).</li>
<li>Hidasi, Balázs, and Alexandros Karatzoglou. “Recurrent neural networks with top-k gains for session-based recommendations.” arXiv preprint arXiv:1706.03847 (2017).</li>
<li>Bogina, Veronika, and Tsvi Kuflik. “Incorporating dwell time in session-based recommendations with recurrent Neural networks.” CEUR Workshop Proceedings. Vol. 1922. 2017.</li>
<li>Quadrana, Massimo, et al. “Personalizing session-based recommendations with hierarchical recurrent neural networks.” Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 2017.</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2><p>用户在互联网应用上的绝大部分的行为都是可以用一个序列来表示，比如购物、听音乐、看feed流等，用式子来表示就是$${x_1,x_2,x_3,..,x_N} -&gt; x_{N+1}$$<br>因此对于这个序列如何建模来获取整个用户的意图行为至关重要，而之前传统的ML只能基于统计或者经验的方式来尽量抽取这些序列信息，并无法hold整个序列，16年提出的<code>GRU4REC</code>利用<code>RNN-Based</code>对用户序列进行建模并且取得了不错的效果，同时也会有一些研究对于<code>GRU4REC</code>做了不少改进和扩展，本文主要对<code>GRU4REC</code>以及扩展做一些简答的自我了解和记录。</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[据说有RNN和CNN结合的xDeepFM]]></title>
    <link href="http://kubicode.me/2018/09/17/Deep%20Learning/eXtreme-Deep-Factorization-Machine/"/>
    <id>http://kubicode.me/2018/09/17/Deep Learning/eXtreme-Deep-Factorization-Machine/</id>
    <published>2018-09-17T12:29:14.000Z</published>
    <updated>2018-09-18T02:41:25.767Z</updated>
    <content type="html"><![CDATA[<h2 id="介绍">介绍</h2><p>也是一篇在CTR预估中堆Deep层数的轮子文，先来了解一下：</p>
<ol>
<li><a href="Deep-in-out-Factorization-Machines-Series">DeepFM</a>：使用<code>FM</code>的特征组合能力灌给DNN进行joint-train</li>
<li><a href="Talk-About-CTR-With-Deep-Learning">Deep&amp;Cross</a>：根据首层和次层的依赖可以解决多阶特征组合的问题</li>
</ol>
<p>不过xDeepFM所提出的点是结合RNN和CNN的特性完成多阶特征的抽取，并且最终和和DNN以及Linear整合到一起完成显性特征的使用。<br><a id="more"></a></p>
<h2 id="CIN">CIN</h2><p>据说有RNN和CNN结合的xDeepFM中最重要的核心元素是<code>CIN</code>（Compressed Interaction Network）<br>一个图来解释<code>CIN</code>:<br><img src="/img/eXtreme-Deep-Factorization-Machine/CIN-Network.png" alt=""><br>这里：</p>
<ol>
<li>我们输入的是一个m个特征的D维Embedding数据，简称$X^0 \in R^{m \times D}$,这个作为第一层</li>
<li>然后CIN有设计一种计算下一层的式子：$$X_{h,*}^k = \sum_{i=1}^{H_{k-1}} \sum_{j=1}^m W_{i,j}^{k,h}(X_{i,*}^{k-1} \circ X_{j,*}^0)$$<ol>
<li>这里的$\circ$符号表示点击，$(a_1,a_2,a_3) \circ (b_1,b_2,b_3) = (a_1b_1,a_2b_2,a_3b_3)$</li>
<li>整个式子可以分解为两份，类RNN和CNN</li>
<li>在计算$X^k$时是依赖$X^{k-1}$的，所以类似RNN那种是依赖上一个状态，同时里面还引入了$X^0$，其实是参考了<code>Deep&amp;Cross</code>的做法，这一步形象的画出来就是上图(a)</li>
<li>他们一步完成之后会产生一个中间状态$z^{k+1}$，是一个三维的张量，其实基于$W$矩阵的投射可以重新转为一个二维的$X^{k+1}$，其实是类似一个CNN的卷积过程，就是图中$b$</li>
<li>这些深层级的$X$计算完毕之后，使用一个<code>sum pooling</code>将各个feature map进行聚合$$p_i^k = \sum_{j=1}^D X_{i,j}^k$$</li>
<li>将所有的聚合层concat之后得到$p^+ = [p^1,p^2…p^T]$</li>
<li>再通过激活函数得到最终的结果$$y=\frac{1}{1+exp(p^+W)}$$</li>
</ol>
</li>
</ol>
<p>这儿<code>CIN</code>各种复杂度：</p>
<ol>
<li>他的参数复杂度是:$\sum_{k=1}^T H_k \times (1+H_{k-1} \times m)$<ul>
<li>$T$表示<code>CIN</code>的总层数</li>
<li>每一层的W参数是$H_k \times H_{k−1} \times m$</li>
<li>顶部线性成的参数量是$H_k$</li>
</ul>
</li>
<li>他的计算复杂度是:$O(mH^2DT)$<ul>
<li>他单层的$Z^{k+1}$的计算复杂度是$O(mHD)$</li>
<li>并且额外的我们还需要将feature maps汇聚到$H$个隐藏节点</li>
</ul>
</li>
</ol>
<h2 id="xDeepFM">xDeepFM</h2><p>最终的<code>xDeepFM</code>的大结构是参考了<code>Wide&amp;Deep</code>的方式:<br><img src="/img/eXtreme-Deep-Factorization-Machine/eDeepFM-arch.png" align="center" width="600px"></p>
<ol>
<li>最左侧是一个线性模型（其实这儿是一个稀疏层）</li>
<li>中间是上面刚刚描述的<code>CIN</code>模型</li>
<li>最右侧其实就是一个传统的<code>DNN</code>模型了</li>
<li>最终将所有的隐藏层的值合并进行了计算：$$y=\sigma(W_{\text{linear}}^T a + W_{\text{dnn}}^T  x_{\text{dnn}} + W_{\text{cin}}^Tp^+ + b)$$</li>
</ol>
<p>他和<code>DeepFM</code>的关系：如果将<code>CIN</code>这一层里面的层数改为1，他其实就是一个FM</p>
<h2 id="实验结果">实验结果</h2><p>里面描述的实验结果中，<br><img src="/img/eXtreme-Deep-Factorization-Machine/exp.png" width="600px"><br>看起来<code>xDeepFM</code>还是有一些提升的，不过主要提升是在<code>DianPing</code>数据集上，另外两个数据集提升的还是很微弱，在这种复杂度下，计算性能和带来的效果回报的受益就比较低了。</p>
<h2 id="总结">总结</h2><ol>
<li>感觉<code>xDeepFM</code>主要引入了<code>Deep&amp;Cross</code>里面的<code>Cross</code>机制，就是在做堆叠</li>
<li>另外其实看到堆叠和交叉还是能带来一定效果的，但是受益越来越不明显了，如果运行性能和算法性能的性价比，<code>FM</code>无疑是最高，但是Deep模型可以说故事（chui）啊</li>
<li>作者开放了<a href="https://github.com/Leavingseason/xDeepFM" target="_blank" rel="external">源码</a>，赞一个</li>
</ol>
<h2 id="文献">文献</h2><ol>
<li>Lian, Jianxun, et al. “xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems.” arXiv preprint arXiv:1803.05170 (2018).</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="介绍">介绍</h2><p>也是一篇在CTR预估中堆Deep层数的轮子文，先来了解一下：</p>
<ol>
<li><a href="Deep-in-out-Factorization-Machines-Series">DeepFM</a>：使用<code>FM</code>的特征组合能力灌给DNN进行joint-train</li>
<li><a href="Talk-About-CTR-With-Deep-Learning">Deep&amp;Cross</a>：根据首层和次层的依赖可以解决多阶特征组合的问题</li>
</ol>
<p>不过xDeepFM所提出的点是结合RNN和CNN的特性完成多阶特征的抽取，并且最终和和DNN以及Linear整合到一起完成显性特征的使用。<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聊聊CTR预估的中的深度学习]]></title>
    <link href="http://kubicode.me/2018/03/19/Deep%20Learning/Talk-About-CTR-With-Deep-Learning/"/>
    <id>http://kubicode.me/2018/03/19/Deep Learning/Talk-About-CTR-With-Deep-Learning/</id>
    <published>2018-03-19T02:59:05.000Z</published>
    <updated>2018-03-20T16:42:36.000Z</updated>
    <content type="html"><![CDATA[<h2 id="CTR预估">CTR预估</h2><p>CTR预估一直以来都是工业界搜索、广告和推荐中的核心，而传统的LR模型（逻辑回归）几乎可以被称为CTR界的神算法，虽然他结构非常简单，但是他计算速度特别快，并且在加以特征工程师的修饰，一样可以拿到很好的效果。<br>但是这样的操作毕竟特征的选择会起比较重要的作用，如果遇到不同任务需要重新提取不同类型的特征。在2014年Facebook通过GBDT的生成LR特征的方式，取得了不错的效果。众所周知，GBDT中的策略树将会有一定的特征选择功能，因此该方式先原先（未经过太多特征工程的特征过一把GBDT），将GBDT的叶子节点作为特征继续输入到LR模型中，最终对目标的CTR值进行预测。<br>除特征工程外，LR的另一个缺陷就是对于高阶的表达能力不足，从这两个出发点，结合公司中手头的一些工作，整了下最近比较经典的Paper来说说深度学习在CTR预估中的一些方法，主要有:<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>、<code>Deep&amp;Cross</code>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM" target="_blank" rel="external">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM" target="_blank" rel="external">NFM</a>.</p>
<a id="more"></a>
<h2 id="FNN">FNN</h2><p>上海交大张伟楠老师利用<code>FM</code>做特征Embedding，然后在上面叠加nn，提出了<code>FNN</code>模型。</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/fnn_arch.png" width="400px"></center>

<p>其实模型架构图还是蛮清晰的，看懂了<code>FM</code>那一层之后就很明了了:</p>
<ol>
<li>输入的是各种稀疏特征（可以是最简单的各种id）</li>
<li>接下来将会经过一个<code>已训练</code>的<code>FM</code>层，直接取到<code>FM</code>模型中对于特征的隐向量</li>
<li>通过隐向量可以构造出<code>NN</code>的输入层<code>z</code>:$z = (w_0,z_1,z_2,…,z_n)$,而$z_i=(w_i,v_i^1,v_i^2,…v_i^K)$,其中$w_i$为<code>FM</code>中的一阶权重,$v_i$为对应特征的隐向量</li>
<li>再接下来就是堆一个<code>NN</code>层来计算最终的目标值了。</li>
</ol>
<p><code>FNN</code>的最大优势就是不需要再去做特征工程了，其特征由<code>FM</code>的隐向量构建得到。同时其缺点就是需要<code>pre-train</code>才能让这个<code>FNN</code>给跑起来.</p>
<h2 id="PNN">PNN</h2><p>2016年，张伟楠老师他们又提出了一种名为<code>PNN</code>的模型，对<code>Embedding</code>向量做<code>innner/outer product</code>（其实就是对原来的<code>FNN</code>模型进行改吧改吧）。</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/pnn_arch.png" width="400px"></center>

<p>其中（<code>bottom-top</code>方向）:</p>
<ol>
<li>其中第一层是输入的离散特征<code>Field N</code></li>
<li>第二层是对离散特征的<code>Embedding</code>（这儿<code>Embedding</code>的方式有很多种，最经典的就是<code>TF</code>的<code>lookup_table</code>）</li>
<li>重点在第三层，就是模型的创新点<code>Product Layer</code>，这里分两部分，一部分是$z$，他是保持了原有<code>Embedding</code>向量的数据，另一部分是$p$,主要对上一层的向量数据进行<code>pairwise feature interaction</code>,也就是做<code>product</code>的工作</li>
<li>接下来又是继续走一波<code>NN</code>网络</li>
<li>最后对点击率进行预估计算</li>
</ol>
<p>上面的是整个<code>PNN</code>的模型架构，而根据$p$中可选<code>Inner Product</code>和<code>Outer Product</code>的两种方式提出<code>IPNN</code>和<code>OPNN</code>这两个模型，这两模型中$z$是一样的，先来看一下$z$:<br>$$l_z =(l_z^1,l_z^2,…,l_z^n,…,l_z^{D1})$$<br>而<br>$$l_z^n = W_z^n \odot z_n =  \sum_j^M (W_z^n)_{j} f_{n,j}$$</p>
<blockquote>
<p>这里的$f_i$为第$i$个特征的<code>Embedding</code></p>
</blockquote>
<p>因此可以看出$l_z$其实只是对原有的<code>Embedding</code>做了一层转换</p>
<p>在$p$部分:<br>$$l_p =(l_p^1,l_p^2,…,l_p^n,…,l_p^{D1})$$<br>并且$$p={p_{i,j}} ,i=1…N,j=1..N$$</p>
<blockquote>
<p>其中$p_{i,j} = g(f_i,f_j)$<br> $g$就是可以做<code>Inner Product</code>和<code>Outer Product</code></p>
</blockquote>
<p>这里再细节的东西就不贴了，感觉Paper里的符号的上下标有点乱(当然也有可能是我没完全看明白-_-)，其实<code>PNN</code>里面的主要贡献就是在<code>Embedding</code>的基础上再多做一些<code>Pairwise Product</code>的操作增强高阶/非线性效果。</p>
<h2 id="Wide&amp;Deep">Wide&amp;Deep</h2><p>相比对<code>FNN</code>和<code>PNN</code>，Google在2016年提出来的<code>Wide&amp;Deep</code>模型更加有名气和通用化一些，顾名思义，整个模型将分为<code>Wide</code>和<code>Deep</code>两个部分:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/wdl_arch.png" width="600px"></center>


<p>左边的<code>Wide</code>是传统的大规模特征+线性模型（也就是经典的LR模型），右边的<code>Deep</code>是一个<code>DNN</code>模型，而中间的<code>Wide&amp;Deep</code>把两个模型在最后一层做了组合。原文中其实是将两个模型的输出求和:<br>$$P(Y=1|x) = \sigma(W_{wide}^T[x,\phi(x)] + W_{deep}^T \alpha^{(lf)}+b)$$</p>
<p>很明显是一个分治的思想，<code>Wide</code>负责处理大规模离散特征，<code>Deep</code>负责处理连续特征，各自发挥自己的优势。再按文章的意思就是:</p>
<ol>
<li><code>Wide</code>可以达到<code>Memorization</code>功能，从训练数据中学习已经出现过的共现和相关性。</li>
<li><code>Deep</code>可以有Generalization：对于没有出现过的数据，需要从数据中学习到抽象的概念,也就是泛化性。</li>
</ol>
<p><code>Wide&amp;Deep</code>模型简单，扩展性更加强，而且运行效率上也比较可控，因此在实际业务中使用非常广泛，并且原生的TF也还提供了<code>Wide&amp;Deep</code>的接口:<a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="external">https://www.tensorflow.org/tutorials/wide_and_deep</a></p>
<p>另外在<code>DeepFM</code>中有一个图对比<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>的区别，非常的清晰:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/fnn_pnn_wdl.png" width="600px"></center>

<h2 id="Deep&amp;Cross">Deep&amp;Cross</h2><p><code>Wide&amp;Deep</code>虽然经典，但是仍旧么有解决特征组合问题，特征组合算法在<code>FM</code>系列的深度学习中也已经有不少研究:<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM" target="_blank" rel="external">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM" target="_blank" rel="external">NFM</a>.,<code>Google</code>在2017年又提出了一种名为<code>Deep&amp;Cross</code>的CTR预估算法(也简称<code>DCN</code>)，可以用级联的方式来深度的提取高阶的特征，同样先来看下模型的架构:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/dcn_arch.png" width="400px"></center>

<p>如上图:</p>
<ol>
<li><code>DCN</code>模型的输入基本为连续特征(<code>Dense Feature</code>)和id类的离散特征(<code>Sparse Feature</code>),同时将会离线特征处理成embedding特征，这样就可以通过理解为模型的输入是一个连续的向量$x_0$</li>
<li>接下来模型分为两部分:<ol>
<li>右侧部分是传统的DNN模型，其中每个全连接层都使用<code>RELU</code>激活函数, 把输入特征通过多个全连接层之后特征变得更加高阶:$$h_i=\text{ReLu}(w_{h,i}x_{i-1}+b_{h,i})$$</li>
<li>左侧部分则是DCN的核心<code>Cross</code>层,每一层的特征都由其上一层的特征进行交叉组合，并且会吧上一层的原始特征重新加回来。这样既能做特征组合，又能保留低阶原始特征，而且还随着<code>Cross</code>层的增加，是可以生成任意高阶的交叉组合特征$$x_{l+1} = x_0x_l^Tw_l+b_l+x_l = f(x_l,w_l,b_l)+x_l$$</li>
</ol>
</li>
<li>最终会将<code>DNN</code>模型和<code>Cross</code>模型输出的向量进行<code>concat</code>起来之后过一把<code>LR</code>进行点击率预测。</li>
</ol>
<p>其中<code>Cross</code>的特征组合层与<code>FM</code>相比，可以理解为<code>FM</code>只能做到两阶的特征组合（因为<code>FM</code>是嵌套方式的，如果是多阶的特征是指数上升的），而<code>Cross</code>里面的可以完成任意多阶的组合，阶数与<code>Cross</code>的深度一致，并且其参数复杂度与阶数是线性关系$$d \times L_c \times 2$$</p>
<blockquote>
<p>$d$为输入向量的大小，$L_c$为<code>Cross</code>的深度</p>
</blockquote>
<h2 id="总结">总结</h2><p>上面几种深度学习模型基本是在一个固有的<code>DNN</code>结构上，在输入层加东西或者在隔壁加额外层来结合。<br><code>FNN</code>和<code>PNN</code>算法在特征组合与深度学习的结合上都给出了不少启发，但是毕竟<code>Google</code>出品，必属精品，<code>Wide&amp;Deep</code>无疑是使用更加广泛,当然在目前机器资源越来越好的情况下，也将会有更多更加复杂的深度模型将会取尝试。<br>同时也有经验表明，在不断上各种复杂模型的前提下，<code>CTR</code>预估的效果还是会不断的提升。</p>
<h2 id="参考">参考</h2><p>[1]. He, Xinran, et al. “Practical lessons from predicting clicks on ads at facebook.” Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, 2014.<br>[2]. Zhang, Weinan, Tianming Du, and Jun Wang. “Deep learning over multi-field categorical data.” European conference on information retrieval. Springer, Cham, 2016.<br>[3]. Qu, Yanru, et al. “Product-based neural networks for user response prediction.” Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016.<br>[4]. Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, 2016.<br>[5]. Wang, Ruoxi, et al. “Deep &amp; Cross Network for Ad Click Predictions.” arXiv preprint arXiv:1708.05123 (2017).</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="CTR预估">CTR预估</h2><p>CTR预估一直以来都是工业界搜索、广告和推荐中的核心，而传统的LR模型（逻辑回归）几乎可以被称为CTR界的神算法，虽然他结构非常简单，但是他计算速度特别快，并且在加以特征工程师的修饰，一样可以拿到很好的效果。<br>但是这样的操作毕竟特征的选择会起比较重要的作用，如果遇到不同任务需要重新提取不同类型的特征。在2014年Facebook通过GBDT的生成LR特征的方式，取得了不错的效果。众所周知，GBDT中的策略树将会有一定的特征选择功能，因此该方式先原先（未经过太多特征工程的特征过一把GBDT），将GBDT的叶子节点作为特征继续输入到LR模型中，最终对目标的CTR值进行预测。<br>除特征工程外，LR的另一个缺陷就是对于高阶的表达能力不足，从这两个出发点，结合公司中手头的一些工作，整了下最近比较经典的Paper来说说深度学习在CTR预估中的一些方法，主要有:<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>、<code>Deep&amp;Cross</code>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM">NFM</a>.</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深入浅出Factorization Machines系列]]></title>
    <link href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/"/>
    <id>http://kubicode.me/2018/02/23/Deep Learning/Deep-in-out-Factorization-Machines-Series/</id>
    <published>2018-02-23T12:33:22.000Z</published>
    <updated>2018-09-17T12:26:00.689Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>近期使用<code>FM</code>系列完成了一个<code>CTR</code>预估的任务，本文是阅读了一些paper之后对于<code>FM</code>、<code>FFM</code>、<code>DeepFM</code>、<code>NFM</code>,<code>AFM</code>的一个理解和记录</p>
</blockquote>
<h2 id="FM">FM</h2><p><code>Factorization Machine(FM)</code>由Steffen Rendle在2010年提出，旨在解决系数数据下的特征组合的问题，目前该系列模型在搜索推荐领域被广泛使用。</p>
<h3 id="一个栗子">一个栗子</h3><p>先来看一个经典的电影评分问题</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/fm_case.png" width="400px"></center>

<a id="more"></a>
<p>问题就是需要对电影进行评分($y$项)，而$x$都是特征,其中:</p>
<ol>
<li>第一部分蓝色的为当前评分的用户</li>
<li>第二部分红色的为被评分的电影</li>
<li>第三部分黄色的为该用户曾经对其他电影的评分情况</li>
<li>第四部分绿色的为该用户当前评分的月数</li>
<li>第五部分棕色为该用户最新一次评分的电影</li>
</ol>
<p>这是一个经典的回归问题，最简单粗暴的方法就先上一个线性回归，其中对于绿色特征处理成binary，这样计算公式就是为<br>$$y_{lr} = w_0 + \sum_i^n w_i \cdot x_i$$</p>
<p>这样可能会过于简单粗暴，按照算法（特征）工程师的套路会对某些特征进行组合，这样为了方便，咱们就给他来一个全组合:<br>$$y_{lr-cross} = w_0 + \sum_i^n w_i \cdot x_i + \sum_i^n \sum_{j=i+1}^n w_{i,j}  x_i x_j$$</p>
<p>看似问题解决了，但是这样会存在这么几个问题:</p>
<ol>
<li>参数空间过大,这里为$O(n^2)$，在处理互联网数据时，特征两级别可能是亿级别的</li>
<li>需要人工经验，这里一般会选择某些特征来组合，此时人工/专家经验就会很重要</li>
<li>样本量过滤稀疏，实际上那这种方式拿到的特征会是很稀疏的，对于在训练样本中未出现过的组合该模型无能为力</li>
</ol>
<h3 id="FM解法">FM解法</h3><blockquote>
<p>定理:对于一个正定举证$W$，始终存在一个矩阵$V$使得$W=V \cdot V^t$成立（需要$V$的维数$k$足够大）</p>
</blockquote>
<p>但是在巨大稀疏矩阵的情况下，当$k$并不是很大时$V \cdot V^t$也可以很接近$W$，因此可以用<br>$$w_{i,j} = \left \langle v_i,v_j \right \rangle = \sum_f^k v_{i,f} \cdot v_{j,f}$$<br>其中这里$v$为长度$k$的一个向量,$\left \langle v_i,v_j \right \rangle$表示两个向量的点积，在<code>FM</code>中也称为隐向量,这样就有了<code>FM</code>的式子:<br>$$y := w_0 + \sum_i^n w_i \cdot x_i + \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j$$<br>到了这里<code>FM</code>的式子:</p>
<ol>
<li>可以解决稀疏向量问题，因为每个特征都有一个隐向量，就算是稀疏向量在训练样本没有出现过的组合在预测时也可以进行计算</li>
<li>同时参数空间也降低到了$O(n\cdot k)$</li>
</ol>
<p>但是他实际的运算复杂度并没有降低，反而还到了$O(kn^2)$,但是<code>FM</code>这里的二阶项并没有依赖其他模型参数除了$v_i$，这里就可以鬼斧神工的写为:<br>$$\begin{equation}\begin{split} \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j &amp;= \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \left \langle v_i,v_j \right \rangle x_i x_j - \frac{1}{2} \sum_{i=1}^n \left \langle v_i,v_i \right \rangle x_i x_i  \\<br>&amp;= \frac{1}{2} \left ( \sum_{i=1}^n \sum_{j=1}^n \sum_{f=1}^k v_{i,f} v_{j,f} x_i x_j - \sum_{i=1}^n \sum_{f=1}^k v_{i,f} v_{i,f} x_i x_i  \right ) \\<br>&amp;= \frac{1}{2} \sum_{f=1}^k \left[ \left ( \sum_{i=1}^n v_{i,f}x_i \right ) \left( \sum_{j=1}^n v_{j,f}x_j \right ) -\sum_{i=1}^n v_{i,f}^2 v_i^2 \right ] \\<br>&amp;= \frac{1}{2} \sum_{f=1}^k \left[ \left ( \sum_{i=1}^n v_{i,f}x_i \right )^2 -\sum_{i=1}^n v_{i,f}^2 v_i^2 \right ]<br>\end{split}\end{equation}$$</p>
<p>经过这样的转换之后，最终的模型计算复杂度将会降低到$O(kn)$，同时由于是巨大的稀疏场景，样本实际的特征量的平均值为$\bar{m}$并且$\bar{m}&lt;&lt;n$,最终的模型复杂度将会降低到$O(k \bar{m})$</p>
<h3 id="FM学习">FM学习</h3><p>在<code>FM</code>中模型的参数有$w_0$,$W$以及$V$，这些参数可以通过梯度下降法进行高效的计算，其中梯度为:<br>$$ \frac{\partial}{\partial  \theta}y(x)=\left\{<br>\begin{aligned}<br>1 &amp; \quad if \quad \theta = w_0 \\<br>x_i &amp; \quad if \quad \theta = w_i \\<br>x_i \sum_{j=1}^n v_{j,f}x_j-v_{i,f}x_i^2 &amp; \quad if \quad \theta = v_{i,f} \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>其中$\sum_{j=1}^n v_{j,f}x_j$部分与$i$相互独立，可以预先计算出来,另外<code>FM</code>在过拟合方面一般推荐使用<code>L2正则项</code></p>
</blockquote>
<p>所以在梯度计算方面可以在$O(1)$下进行计算<br>作者也提供了一个很强大的开源工具来训练<code>FM</code>:<a href="http://www.libfm.org" target="_blank" rel="external">http://www.libfm.org</a></p>
<h3 id="扩展">扩展</h3><p>其实对于经典的特征组合问题，也非常容易能想到使用万能的<code>SVM</code>来求解，比如一个二阶的多项式<code>SVM</code>可以写成这样:<br>$$y_{svm} = w_0 + \sqrt{2} \sum_{i=1}^n w_ix_i + \sum_{i=1}^n w_i^{(2)}x_i^2 + \sqrt{2} \sum_{i=1}^n \sum_{j=i+1}^n w_{i,j}^{(2)}x_ix_j$$</p>
<p>这样可以发现二阶多项式的<code>svm</code>和<code>FM</code>十分相似，只多了一项$\sum_{i=1}^n w_i^{(2)}x_i^2$，但是<code>SVM</code>对于未出现在训练样本的组合特征也是无法计算，同时他需要使用对偶才能进行求解,并且他在预测的时候还需要训练样本的支持向量。</p>
<p>另外<code>FM</code>还可以用于<code>tag</code>的推荐排序，问题描述是给定用户信息$U$，宝贝信息$I$，对于相应的标签<code>T</code>进行排序，在binary特征下面模型可以表述为:<br>$$n:= |U \cup I \cup T|, \quad x_i=\delta (j=i \vee j=u \vee j=t)$$<br>使用<code>FM</code>的计算为<br>$$y(x) = w_0 +w_u+w_i+w_t+\left \langle v_u,v_i \right \rangle + \left \langle v_u,v_t \right \rangle + \left \langle v_i,v_t \right \rangle $$<br>但是在排序问题上，当对于<code>tagA</code>,<code>tagB</code>进行排序时，他们的$w_0 +w_u+w_i+\left \langle v_u,v_i \right \rangle$分项计算其实是一样的，所以<code>FM</code>模型最终在<code>tag</code>排序的问题上可以简化为:<br>$$y(x):=w_t+ \left \langle v_u,v_t \right \rangle + \left \langle v_i,v_t \right \rangle$$<br>这样就是<a href="https://www.ismll.uni-hildesheim.de/pub/pdfs/Rendle2010-PITF.pdf" target="_blank" rel="external">PITF</a>模型极为相似了.</p>
<p>当然上面说的都是二阶<code>FM</code>，其实<code>FM</code>还是支持多阶的，只是由于性能/效率问题一般二阶就够了，感兴趣的同学可以去看原始paper</p>
<h2 id="FFM">FFM</h2><p><code>FFM</code>其实是在<code>FM</code>的基础上做了一些更加细致化的工作:作者Yuchin认为相同性质的特征归于同一field，而当前特征在不同field上的表现应该是不同的.<br>比如在广告领域中性别对于广告商(Advertiser)和投放地(Publisher)的作用就是不一样的，比如:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/ffm_case.png" width="400px"></center>

<p>这里的特征被分为了三类，有投放地(Publisher)，广告商(Advertiser)和性别(Gender),如果使用<code>FM</code>来预估这个点击率则是:<br>$$\left \langle v_{ESPN},v_{Nike} \right \rangle + \left \langle v_{ESPN},v_{Male} \right \rangle + \left \langle v_{Nike},v_{Male} \right \rangle$$</p>
<p>这里可以看出<code>FM</code>中隐向量对于不同类别的特征进行组合时都是使用同一个向量，而基于<code>Field-aware</code>的<code>FFM</code>就是对这点进行修改，认为当前向量对于每一个类别都有一个不同的隐向量，比如性别和投放地进行组合的时候使用的隐向量为$v_{Male,G}$,这样推广开来之后这个问题中<code>FFM</code>的二阶项就可以表述为:<br>$$ \left \langle v_{ESPN,A},v_{Nike,P} \right \rangle + \left \langle v_{ESPN,G},v_{Male,P} \right \rangle + \left \langle v_{Nike,G},v_{Male,A} \right \rangle$$</p>
<p>这样,<code>FFM</code>使用通用化的学习公式表达了之后为:<br>$$y_{FFM}(x) = w_0 + \sum_i^n w_i \cdot x_i + \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_{i,f_j},v_{j,f_i} \right \rangle x_ix_j$$</p>
<p>因为<code>FFM</code>的参数空间为$nfk$,其计算复杂度为$O(\bar{n}k)$,但是<code>FFM</code>都是在特定的field的中来学习训练隐向量的，所以一般来说:<br>$$k_{FFM} &lt;&lt; k_{FM}$$</p>
<blockquote>
<p>其实我实际试用下来这里的$&lt;&lt;$不是很严谨，<code>FM</code>的$k$也并没有比<code>FFM</code>多太多，也许只可能是一个8和4的差别。-_-!!</p>
</blockquote>
<p><code>FFM</code>的改进看上去还是有挺有道理的，但是其实最终实验做出来和<code>FM</code>的效果不相上下:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/ffm_v_fm.png" width="600px"></center>

<p>实验结果上<code>FFM</code>也只是在某几个数据集上略好于<code>FM</code>，但是由于<code>FFM</code>中的隐向量与field有关，无法直接转为<code>FM</code>中的$O(k\bar{n})$的运算式子，所以在工业界追求运行效率的时候<code>FM</code>还是首选，不过是比赛中<code>FFM</code>也是一个不错的选择.</p>
<blockquote>
<p>这里符一下<code>FFM</code>的开源工具代码:<a href="https://www.csie.ntu.edu.tw/~cjlin/libffm/" target="_blank" rel="external">https://www.csie.ntu.edu.tw/~cjlin/libffm/</a>,注意里面有有提供只含二阶项的版本和同时含线性计算的版本.</p>
</blockquote>
<h2 id="DeepFM">DeepFM</h2><p>受到<code>Wide&amp;Deep</code>的启发，Huifeng等人将FM和Deep深度学习结合了起来，简单的说就是将<code>Wide</code>部分使用<code>FM</code>来代替，同时FM的隐向量可以充当Feature的Embedding，非常巧妙:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/deepfm_arch.png" width="600px"></center>

<p><code>DeepFM</code>的架构其实特别清晰:</p>
<ol>
<li>输入的是稀疏特征的id</li>
<li>进行一层lookup 之后得到id的稠密embedding</li>
<li>这个embedding一方面作为隐向量输入到FM层进行计算</li>
<li>同时该embedding进行聚合之后输入到一个DNN模型(deep)</li>
<li>然后将FM层和DNN层的输入求和之后进行co-train</li>
</ol>
<p>因为最终计算的式子也是非常清晰的明了:<br>Fm部分:<br>$$y_{\text{FM}} = \left \langle W,X \right \rangle + \sum_i^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j$$<br>Deep部分:<br>$$a(0) =[e ,e ,…,e ] \\<br>a(l+1) = \sigma (W^{(l)}a^{(l)} + b^{(l)}) \\<br>y_{\text{DNN}} = \sigma (W^{(H+1)}a^{H} + b^{(H+1)})$$</p>
<blockquote>
<p>其中$e$表示初始的embedding,$H$表示网络的深度</p>
</blockquote>
<p>最终DeepFM可以表示为:<br>$$y_{\text{DeepFm}} = sigmoid(y_{FM} + y_{DNN})$$</p>
<p>这个结合非常有意思，充分将<code>FM</code>中隐向量含<code>element-wise product</code>的功能结合到了<code>DNN</code>中，公司有实测<code>DeepFM</code>的效果略好于的<code>Wide&amp;Deep</code>,因此该算法还是非常有实操性的，特别是在公司里面要出成（zhuang）果（bi）的时候。</p>
<blockquote>
<p><code>DeepFm</code>的非作者源码分享<a href="https://github.com/ChenglongChen/tensorflow-DeepFM" target="_blank" rel="external">https://github.com/ChenglongChen/tensorflow-DeepFM</a></p>
</blockquote>
<h2 id="NFM">NFM</h2><p><code>NFM(Neural Factorization Machines)</code>又是在<code>FM</code>上的一个改进工作，出发点是<code>FM</code>通过隐向量可以对完成一个很好的特征组合工作，并且还解决了稀疏的问题，但是<code>FM</code>对于它对于<code>non-linear</code>和<code>higher-order</code> 特征交叉能力不足，而<code>NFM</code>则是结合了<code>FM</code>和<code>NN</code>来弥补这个不足。模型框架如下(图里没画一阶的回归)：</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/nfm_arch.png" width="600px"></center><br>其中:<br>1. <code>Input Feature Vector</code>层是输入的稀疏向量，可以带权<br>2. <code>Embedding Layer</code>对输入的稀疏向量look up 成稠密的embedding 向量<br>3. <code>Bi-Interaction Layer</code>将每个特征embedding进行两两做element-wise product，<code>Bi-Interaction</code>的输出是一个 k维向量（就是隐向量的大小）,这层负责了特征之间second-order组合。$$f_{\text{Bi}}(V_x) = \sum_i^n \sum_{j=i+1}^n x_iv_i \odot  x_jv_j$$ 类似FM的式子转换，这里同样可以做如下转换将复杂度降低:$$f_{\text{Bi}}(V_x) = \frac{1}{2} \left [ (\sum_i^n x_iv_i)^2 - \sum_i^n(x_iv_i)^2 \right ]$$<br>4. <code>Hidden Layers</code>这里是多层学习高阶组合特征学习,其实就是一个DNN模块:$$z_1=\sigma_1(W_1 f_{\text{Bi}}(V_x) + b_1) \\ z_2 = \sigma_2(W_2z_1+b_2) \\ … \\ z_L=\sigma_L(W_L z_{L-1}+b_L)$$<br>5. <code>Prediction Score</code>层就是输出最终的结果:$$y_{\text{NFM}}(x) = w_0 + \sum_i^n w_ix_i + h^T \sigma_L(W_l(…\sigma_1(W_1 f_{\text{Bi}}(V_x) + b_1))+b_L)$$<br><br>FM可以看做是NFM模型 Hidden Layer层数为0一种特殊形式。<br>最终的实验效果看来<code>NFM</code>也还是可以带来一个不错的效果:<br><center><img src="/img/Deep-in-out-Wide-n-Deep-Series/nfm_result.png" width="600px"></center>

<blockquote>
<p><code>NFM</code>作者分享的源码<a href="https://github.com/hexiangnan/neural_factorization_machine" target="_blank" rel="external">https://github.com/hexiangnan/neural_factorization_machine</a></p>
</blockquote>
<h2 id="AFM">AFM</h2><p>而<code>AFM(Attentional Factorization Machines)</code>同样，是在<code>FM</code>上做了一些小<code>trick</code>,在传统的<code>FM</code>中进行特征组合时两两特征之间的组合都是等价的(只能通过隐向量的点积来区别)，这里趁着<code>Attention</code>的热度走一波,因为<code>AFM</code>的最大的贡献就是通过<code>Attention</code>建立权重矩阵来学习两两向量组合时不同的权重。下面就是<code>AFM</code>的框架图:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/afm_arch.png" width="600px"></center><br>从图中可以很清晰的看出,<code>AFM</code>比<code>FM</code>就是多了一层<code>Attention-based Pooling</code>，该层的作用是通过<code>Attention</code>机制生成一个$a_{i,j}$权重矩阵，该权重矩阵将会作用到最后的二阶项中，因此这里$a_{i,j}$的生成步骤是先通过原始的二阶点积求得各自的组合的一个score:<br>$${a}’_{i,j} = h^T \text{ReLu}(W(v_i \odot v_j)x_ix_j+b)$$<br><br>&gt; 其中$W \in \mathbb{R}^{t \times k},b \in \mathbb{R}^t , h \in \mathbb{R}^t$,这里$t$表示<code>Attention</code>网络的大小<br><br>然后对其score进行<code>softmax</code>的归一化:<br>$$a_{i,j} = \frac{exp({a}’_{i,j})}{\sum_{i,j} exp({a}’_{i,j})}$$<br>最后该权重矩阵再次用于二阶项的计算（也就是最终的<code>AFM</code>式子）:<br>$$y_{\text{AFM}}(x) = w_0+\sum_i^n w_i x_i + P^T \sum_{i=1}^n \sum_{j=i+1}^n a_{i,j} (v_i \odot v_j) x_ix_j$$<br><br>其实整个算法思路也是很简单，但是在实验上却有一个不错的效果:<br><center><img src="/img/Deep-in-out-Wide-n-Deep-Series/afm_result.png" width="400px"></center>

<blockquote>
<p>其实从实验效果来看<code>AFM</code>应该是优于<code>NFM</code><br><code>AFM</code>的作者源码分享<a href="https://github.com/hexiangnan/attentional_factorization_machine" target="_blank" rel="external">https://github.com/hexiangnan/attentional_factorization_machine</a></p>
</blockquote>
<h2 id="总结">总结</h2><ol>
<li><code>FMs</code>系列算法被广泛应用于ctr预估类的问题中，并且可以取得不错的效果，他最大特征是可以帮助解决特征组合问题</li>
<li>原始<code>FM</code>算法的运行性能最快，可以达到$O(k \bar{n})$,在工业中被适用最广最简单，其他带上神经网络的<code>FM</code>算法如果想在在线系统中使用得做很多离线计算和分解，比如<code>FFM</code>的现在复杂度是$O(k \bar{n}^2)$,将$O(\bar{n}^2)$中二阶计算的项尽可能的进行离线计算，在 在线的时候进行组合</li>
<li><code>FM</code>的二阶项部分很容易使用<code>TensorFlow</code>进行实现，这也意味了在实验上也很容易很其他复杂算法进行组合:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get the summed up embeddings of features.</span></span><br><span class="line">self.nonzero_embeddings = tf.nn.embedding_lookup(self.weights[<span class="string">'feature_embeddings'</span>], self.train_features, name=<span class="string">'nonzero_embeddings'</span>)</span><br><span class="line">self.summed_features_emb = tf.reduce_sum(self.nonzero_embeddings, <span class="number">1</span>, keep_dims=<span class="keyword">True</span>) <span class="comment"># None * 1 * K</span></span><br><span class="line"><span class="comment"># get the element-multiplication</span></span><br><span class="line">self.summed_features_emb_square = tf.square(self.summed_features_emb)  <span class="comment"># None * 1 * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># _________ square_sum part _____________</span></span><br><span class="line">self.squared_features_emb = tf.square(self.nonzero_embeddings)</span><br><span class="line">self.squared_sum_features_emb = tf.reduce_sum(self.squared_features_emb, <span class="number">1</span>, keep_dims=<span class="keyword">True</span>)  <span class="comment"># None * 1 * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ________ FM __________</span></span><br><span class="line">self.FM = <span class="number">0.5</span> * tf.subtract(self.summed_features_emb_square, self.squared_sum_features_emb, name=<span class="string">"fm"</span>)  <span class="comment"># None * 1 * K</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>摘自<code>AFM</code>源码</p>
</blockquote>
<h2 id="参考">参考</h2><p>[1]. Rendle, Steffen. “Factorization machines with libfm.” ACM Transactions on Intelligent Systems and Technology (TIST) 3.3 (2012): 57.<br>[2]. Juan, Yuchin, et al. “Field-aware factorization machines for CTR prediction.” Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 2016.<br>[3]. Guo, Huifeng, et al. “Deepfm: A factorization-machine based neural network for CTR prediction.” arXiv preprint arXiv:1703.04247 (2017).<br>[4]. He, Xiangnan, and Tat-Seng Chua. “Neural factorization machines for sparse predictive analytics.” Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017.<br>[5]. Xiao, Jun, et al. “Attentional factorization machines: Learning the weight of feature interactions via attention networks.” arXiv preprint arXiv:1708.04617 (2017).</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>近期使用<code>FM</code>系列完成了一个<code>CTR</code>预估的任务，本文是阅读了一些paper之后对于<code>FM</code>、<code>FFM</code>、<code>DeepFM</code>、<code>NFM</code>,<code>AFM</code>的一个理解和记录</p>
</blockquote>
<h2 id="FM">FM</h2><p><code>Factorization Machine(FM)</code>由Steffen Rendle在2010年提出，旨在解决系数数据下的特征组合的问题，目前该系列模型在搜索推荐领域被广泛使用。</p>
<h3 id="一个栗子">一个栗子</h3><p>先来看一个经典的电影评分问题</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/fm_case.png" width="400px"/></center>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深度神经网络中防止过拟合的利器-Dropout]]></title>
    <link href="http://kubicode.me/2017/06/05/Deep%20Learning/Dropout-in-Deep-Neural-Network/"/>
    <id>http://kubicode.me/2017/06/05/Deep Learning/Dropout-in-Deep-Neural-Network/</id>
    <published>2017-06-05T13:14:36.000Z</published>
    <updated>2018-09-19T02:41:22.035Z</updated>
    <content type="html"><![CDATA[<h2 id="Dropout_in_Deep_Network">Dropout in Deep Network</h2><p>在机器学习任务中一提到过拟合，<code>L1</code>和<code>L2</code>正则项绝对是两大利器，但是在深度神经网络中，<code>Hiton</code>老爷子在2014年提出了一种称为<code>Dropout</code>的方法来避免过拟合，方式对比<code>L1</code>和<code>L2</code>更为灵活也是非常高效。</p>
<p>深度神经网络中，在不限制计算的条件下，最佳的正则化方式就是将所有可能组合成的模型进行平均输出，就类似<code>stack</code>的模型融合一样，但是这种方式存在两大问题:</p>
<ol>
<li>在计算时需要将训练文件进行相应的分离，因为神经网络的训练本身就是需要极多的数据，这么一分离可能会导致数据不够的情况</li>
<li>深度神经网络中的计算量本身就很大，计算多个之后其耗时将会更多</li>
</ol>
<p>而<code>Dropout</code>却可以完美的解决上述两个缺陷，他的思想很简单:<br><a id="more"></a></p>
<p>在训练时对于神经网络的某些神经点击直接进行移除，包括他的入边和出边，而这个移除可以简单的根据一个概率p，这个p一般就是Dropout需要设置的参数</p>
<blockquote>
<p>这个参数$p$一般设置为0.5比较好，因为他这样就可能产生$2^n$中网络情况了，极大的增加的参数空间</p>
</blockquote>
<p>因此经过Dropout之后两个神经网络的对比如下:</p>
<center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-or-not.png" width="550px"></center><br>可以看到经过<code>Dropout</code>之后<code>(b)</code>中很多单元节点直接被进行了移除（注意这里是一次<code>min-batch</code>走一次<code>Dropout</code>），使用了<code>Dropout</code>在预测时也是极其的简单:<br>在预测时这些曾经过移除过的节点仍然正常计划，唯一的差别就是在下一次的权重中乘以概率$p$<br><br><center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-layer.png" width="550px"></center>

<p>因此针对一个标准深度神经网络,当前层使用$l$来表示，$w$为需要训练的权重,$y$就是各个层的输出，$b$为各个层的偏置，则每一层的标准计算为:<br>$$z_i^{l+1} = w_i^{l+1}y^l + b_i^{l+1} \\<br>y_i^{l+1} = f(z_i^{l+1})$$</p>
<blockquote>
<p>其中$f$为激活函数</p>
</blockquote>
<p>而经过了<code>Dropout</code>之后整个计算过程就会变为这样:<br>$$r_j^l \sim \text{Bernoulli}(p) \\<br>\tilde{y}^l = r_j^l y^l \\<br>z_i^{l+1} = w_i^{l+1}\tilde{y}^l + b_i^{l+1} \\<br>y_i^{l+1} = f(z_i^{l+1})$$</p>
<p>也就是下图的样纸:</p>
<p><center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-calc.png" width="550px"></center><br>而在预测的时候，只需要在<code>Dropout</code>层输出的权重上乘$p$即可:$w_{test}^l = pw^l$</p>
<p>关于使用了<code>Dropout</code>之后，如果使用<code>SGD</code>进行优化的话其梯度仍旧可以按照来的方式计算，不过他是在一次<code>min-batch</code>来计算一次<code>Dropout</code></p>
<blockquote>
<p>也就在同一次<code>min-batch</code>中，<code>Dropout</code>层中的点击移除与否的分布是一样的，不同的<code>Dropout</code>中是可能不一样的</p>
</blockquote>
<p>文献的实验正常传统的深度神经网络中加入了<code>Dropout</code>之后在训练集上面的误差可能会增大，但是在测试集上其误差会变小，也就是降低的过拟合的程度</p>
<h2 id="Dropout_in_Recurrent_Network">Dropout in Recurrent Network</h2><p>虽然<code>Dropout</code>中在传统的深度网络中很好使，但是直接用于<code>RNN</code>这类递归型的神经网络却不是很好使，原因是如果直接将<code>Dropout</code>层防止在<code>Memory Cell</code>中,循环会放大噪声，扰乱它自己的学习。<br><i>Wojciech Zaremba</i>针对此问题提出的核心解决方法就是在输入和输出层加<code>Dropout</code>:<br>$$\begin{pmatrix}<br>i\\<br>f\\<br>o\\<br>g<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>sigm\\<br>sigm\\<br>sigm\\<br>tanh<br>\end{pmatrix}<br>T_{2n,4n}<br>\begin{pmatrix}<br>D(x_t)\\<br>h_{t-1}^l<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>上面是一个<code>LSTM</code>的式子，计算三个门单元以及当前信息单元，$D$就是<code>Dropout</code>层,这里是加在了输入层</p>
</blockquote>
<h2 id="文献">文献</h2><ol>
<li>Srivastava, Nitish, et al. “Dropout: A simple way to prevent neural networks from overfitting.” The Journal of Machine Learning Research 15.1 (2014): 1929-1958.</li>
<li>Zaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. “Recurrent neural network regularization.” arXiv preprint arXiv:1409.2329 (2014).</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Dropout_in_Deep_Network">Dropout in Deep Network</h2><p>在机器学习任务中一提到过拟合，<code>L1</code>和<code>L2</code>正则项绝对是两大利器，但是在深度神经网络中，<code>Hiton</code>老爷子在2014年提出了一种称为<code>Dropout</code>的方法来避免过拟合，方式对比<code>L1</code>和<code>L2</code>更为灵活也是非常高效。</p>
<p>深度神经网络中，在不限制计算的条件下，最佳的正则化方式就是将所有可能组合成的模型进行平均输出，就类似<code>stack</code>的模型融合一样，但是这种方式存在两大问题:</p>
<ol>
<li>在计算时需要将训练文件进行相应的分离，因为神经网络的训练本身就是需要极多的数据，这么一分离可能会导致数据不够的情况</li>
<li>深度神经网络中的计算量本身就很大，计算多个之后其耗时将会更多</li>
</ol>
<p>而<code>Dropout</code>却可以完美的解决上述两个缺陷，他的思想很简单:<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[长短期记忆模型-LSTM]]></title>
    <link href="http://kubicode.me/2017/05/22/Deep%20Learning/Long-Short-Term-Memory-Model-LSTM/"/>
    <id>http://kubicode.me/2017/05/22/Deep Learning/Long-Short-Term-Memory-Model-LSTM/</id>
    <published>2017-05-22T01:50:40.000Z</published>
    <updated>2017-06-05T03:47:28.000Z</updated>
    <content type="html"><![CDATA[<h2 id="RNN的缺点">RNN的缺点</h2><p><code>RNN</code>的特点毋庸置疑就是在训练/预测当前层节点时可以拿到先前层的数据来进行辅助计算，因此对于序列的学习非常有效。但事实上这个利用前面全部的信息并不是非常有效。比如看下面两个<code>language mdoel</code>:</p>
<pre><code><span class="operator">the</span> clouds are <span class="operator">in</span> <span class="operator">the</span> sky
</code></pre><p>这里要预测的<code>sky</code>只需要依赖前前面几个<code>term</code>即可</p>
<p>再看看另一个句子:    </p>
<pre><code><span class="keyword">I</span> grew up in France… <span class="keyword">I</span> speak fluent French.
</code></pre><p>这里在预测<code>French</code>的时候需要前面较长的信息，甚至已经跨到前面一句话了。<br>因此是可以看出就算在<code>Language Model</code>中不同样本下可能是需要不同的长度的历史信息的，而对于<code>RNN</code>而言他并不能控制历史信息的长度.</p>
<a id="more"></a>
<h2 id="LSTM的计算">LSTM的计算</h2><p>而<code>LSTM</code>的设计之初就是为了解决<code>RNN</code>这种长期依赖的问题，一个最标准的<code>RNN</code>中每一个单元/层他是经过过一个<code>tanh</code>，结构是长这样的:</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-SimpleRNN.png" width="450px"></center>

<p>而<code>LSTM</code>的复杂很多，展开之后他是长这样的:</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-chain.png" width="450px"></center><br>&gt;<code>LSTM</code>中最核心的就是门(<code>gate</code>)结构了，每一个<code>gate</code>经过一个<code>sigmoid</code>($\sigma$)结果输出一个<code>0~1</code>的输，可以精确的控制每一股的数据流量大小.<br><br>接下来一步一步解析<code>LSTM</code>单元内的每个小组件:<br><code>第一步</code>是决定哪些历史信息需要流入到当前的单元中，<br>这里会经过<code>遗忘门</code>(<code>forget gate layer</code>)，作用对于历史信息的遗忘程度:<br><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-f.png" width="450px"></center>

<p>这个门的输入为上一层的隐含层信息($h_{t-1}$)和当前层的输入数据($x_t$),输出一个<code>0~1</code>的数字用于$C_{t-1}$，如果通过<code>遗忘门</code>之后输出1，则表示所有$C_{t-1}$的数据都保留，如果输出的0，则相当于$C_{t-1}$的数据经会被重置为0.</p>
<p><code>第二步</code>是当前哪些信息数据需要流入到当前的组件中，首先会经过<code>输入门</code>(<code>input gate layer</code>)会决定哪些输入值需要更新，其次再经过一个$tanh$函数来生成一个新的$\tilde{C}_t$来与原先的$C_{t-1}$进行求和合并.</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-i.png" width="450px"></center>

<p><code>第三步</code>是生成一个新的$C_t$值，它是综合$C_{t-1}$的遗忘信息以及当前新保留的$\tilde{C}_t$信息</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-C.png" width="450px"></center>

<p><code>最后</code>就是控制输出的数据了（就是输出隐含层单元的信息）</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-o.png" width="450px"></center><br>最终的输出是依赖当前的单元信息$C_t$，它经过一个$tanh$函数之后将数据scale到<code>-1~1</code>，然后再通过一个输出门来控制需要数据的信息.<br>上述4步是每个单元内的计算步骤，实际对于train目前应该还有一步$y_t=f(h_t)$,如果是<code>Language Model</code>的话$f$就是<code>softmax</code><br><br><br><br>综合上面的图解，一个完整的<code>LSTM</code>的单元里面的计算流程是这样:<br>1. 遗忘门的计算:<br>    $$f_t=\sigma(W_f \cdot [h_{t-1},x_t],b_f)$$<br>2. 输入门的计算:<br>    $$f_i=\sigma(W_i \cdot [h_{t-1},x_t],b_i)$$<br>3. 当前单元信息的计算:<br>    $$\tilde{C}_t=tanh(W_c \cdot[h_{t-1},x_t]+b_C)$$<br>4. 根据先前的单元信息$C_{t-1}$和当前的单元信息$\tilde{C}_t$，以遗忘门$f_t$和输入门$f_i$作为因子得到新的单元信息:<br>    $$C_t = f_t \cdot C_{t-1} + f_i \cdot \tilde{C}_t$$<br>5. 输出门的计算:<br>    $$f_o=\sigma(W_o \cdot [h_{t-1},x_t],b_o)$$<br>6. 根据新的单元信息$C_t$以及输出门$f_o$计算要输出的隐含单元信息:<br>    $$h_t = o_t \cdot tanh(C_t)$$<br>7. 根据隐含单元信息计算训练/预测的目标:<br>    $$y_t = f(h_t)$$<br>8. 一个单元计算完毕，回到<code>1</code>进入下一个单元的计算<br><br><br>## LSTM变种<br><br>上面描述的<code>LSTM</code>结果其实还复杂的，比标准的<code>RNN</code>至少多了三个门单元($f_t,f_i,f_o$)以及单元信息$C$，多了这么多信息之后随之而言的就是计算量会增加许多，同时事实上很多任务中比不需要这么多信息，因此就会有较多的$LSTM$变种出现:<br>下面这个<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="external">变种</a>是将<code>遗忘门</code>去掉，其值改为$1-f_t$<br><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-var-tied.png" width="450px"></center>

<p>另外一个非常著名的变种就是<a href="https://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="external">GRU</a>了</p>
<p><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-var-GRU.png" width="450px"></center><br>他将:</p>
<ol>
<li><code>遗忘门</code>和<code>输入门</code>合并为了<code>更新门</code></li>
<li>同时将<code>单元信息</code>(<code>cell state</code>)和<code>隐含信息</code>(<code>hidden state</code>)进行了合并</li>
</ol>
<p>从计算式子就可以看出整个单元的计算对比$LSTM$进行了极大的简化，但是其效果却几乎不降低。<br>当然还有很多其他的变种不再一一描述，可以参见<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">参考</a></p>
<h2 id="参考">参考</h2><ol>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="RNN的缺点">RNN的缺点</h2><p><code>RNN</code>的特点毋庸置疑就是在训练/预测当前层节点时可以拿到先前层的数据来进行辅助计算，因此对于序列的学习非常有效。但事实上这个利用前面全部的信息并不是非常有效。比如看下面两个<code>language mdoel</code>:</p>
<pre><code><span class="operator">the</span> clouds are <span class="operator">in</span> <span class="operator">the</span> sky
</code></pre><p>这里要预测的<code>sky</code>只需要依赖前前面几个<code>term</code>即可</p>
<p>再看看另一个句子:    </p>
<pre><code><span class="keyword">I</span> grew up in France… <span class="keyword">I</span> speak fluent French.
</code></pre><p>这里在预测<code>French</code>的时候需要前面较长的信息，甚至已经跨到前面一句话了。<br>因此是可以看出就算在<code>Language Model</code>中不同样本下可能是需要不同的长度的历史信息的，而对于<code>RNN</code>而言他并不能控制历史信息的长度.</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[初识递归神经网络-RNN]]></title>
    <link href="http://kubicode.me/2017/05/15/Deep%20Learning/Understanding-about-RNN/"/>
    <id>http://kubicode.me/2017/05/15/Deep Learning/Understanding-about-RNN/</id>
    <published>2017-05-15T01:17:48.000Z</published>
    <updated>2017-06-05T01:12:31.000Z</updated>
    <content type="html"><![CDATA[<h2 id="RNN是啥?">RNN是啥?</h2><p>当需要处理一些输入或者输出有相互依赖的任务时，传统的神经网络已经不再适用，比如在<code>Language Model</code>中在给定几个单词的情况下来预测下面将会出什么单词的时候。<br>这时候RNN就有用武之地了，RNN在预测/训练当前节点的时候可以获取前面节点的记忆（memory）信息，这样就可以很自然的完成序列任务的学习了。<br>一图胜千言，经典的RNN结构是长这样纸的:<br><a id="more"></a></p>
<center><img src="/img/Understanding-about-RNN/rnn.jpg"></center>

<p>上图的左侧是一个未展开的RNN结构图，可以看出通过<code>W</code>来完成一个自循环，将其展开之后就很好理解了，展开后可以看做是一个横向的神经网络，每一层都有一个自己的输入，RNN的整个训练或者主要是为了计算<code>U</code>、<code>W</code>、<code>V</code>这三个矩阵，其训练时前向传播的步骤如下:</p>
<ol>
<li>$x_t$表示第$t$层/步的输入，输入的数据可以是一个<code>one-hot</code>的向量或者一个其他的<code>pre-train</code>的向量</li>
<li>$s_t$表示当前$t$的隐含状态,也就是整个网络中拥有<code>记忆</code>的那一块，他是根据上一层的隐含状态$s_{t-1}$以及当前层的输入$x_t$计算得到的，$s_t=f(Ux_t+Ws_{t-1})$， 其中$f(\cdot)$为激活函数，一般可以为<code>tanh</code>或者<code>ReLu</code>，另外$s_{-1}$为初始化的隐含状态，一般来说可以都初始化为<code>0</code></li>
<li>$o_t$就是每一步的输出了，计算公式为$o_t = f(Vs_t)$，比如在<code>Language Model</code>中每一步的输出就是预测到下一个词的概率，这输出的就是在<code>vocabulary</code>维度的一个概率向量$o_t=\text{softmax}(Vs_t)$</li>
</ol>
<p>另外还有几点要说的:</p>
<ol>
<li>$s_t$为整个网络的记忆，但是在实际中,$s_t$的记忆功能是有限的，并不能捕捉$s_t$步之前的全部信息</li>
<li>在传统的深度神经网络中，每一层都有自己的参数，但是RNN与之不同，所有层之间都是共享<code>U</code>、<code>W</code>、<code>V</code>这三个参数的</li>
<li>另外关于输出，上面说到的是每一层是一个输出，但是并不是非得这样，有一些其他的变种可以仅在最后一层有一个输出。</li>
</ol>
<h2 id="RNN的训练">RNN的训练</h2><p>将<code>RNN</code>进行展开之后可以看做一个横向的神经网络，因为<code>RNN</code>也可以按神经网络的方式进行训练和预测，这里以一个实际的语言模型来回顾一下<code>RNN</code>的前向预测:</p>
<ol>
<li>$s_t= \text{tanh}(Ux_t+Ws_{t-1})$</li>
<li>$o_t = \text{softmax}(Vs_t)$</li>
</ol>
<p>对于<code>RNN</code>的参数我们就是需要求<code>U</code>、<code>W</code>和<code>V</code>这三个矩阵，这里可以使用<code>SGD</code>来进行模型参数的优化，同时其梯度可以用一种叫做<code>BPTT</code>的当时来求得<br>我们使用交叉熵来定义<code>RNN</code>模型每一层的损失:<br>$$E_t(o_t,\hat{o}_t) = -o_t\log \hat{o}_t$$<br>则整个模型的损失通过累加可以求得:<br>$$E=\sum_t E_t(o_t,\hat{o}_t) = -\sum_t o_t\log \hat{o}_t$$</p>
<blockquote>
<p>这里的$t$表示当前的步数(层数),$\hat{o}_t$为第$t$的预测值.</p>
</blockquote>
<p>这里的梯度使用<code>BP</code>来计算，为了计算方便，以$t=3$为例<br>$$\begin{equation}\begin{split} \frac{\partial E_3}{\partial V}&amp;= \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial V} \\<br>&amp;= \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial z_3} \frac{\partial z_3}{\partial V}  \\<br>&amp;= \frac{\partial E_3}{\partial z_3} \frac{\partial z_3}{\partial V}  \\<br>&amp;= (\hat{o}_3-o_3)s_3 \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>辅助推导:<br>$$\begin{equation}\begin{split} \frac{\partial E}{\partial z^j}&amp;= \frac{\partial -o\text{log}\hat{o}}{\partial z^j} \\<br>&amp;= \frac{\partial -\sum_k o^k\text{log}\hat{o}^k}{\partial V^js}  \\<br>&amp;=  -\frac{1}{s} \sum_k o^k \cdot \frac{1}{\hat{o}^k} \frac{\partial \hat{o}^k}{V_j} \\<br>&amp;= \text{使用softmax推导} \\<br>&amp;=   -\frac{1}{s} \left( o^j  \frac{1}{\hat{o}^j} s \hat{o}^j(1-\hat{o}^j) + \sum_{k:k \neq j} o^k  \frac{1}{\hat{o}^k} \cdot(-s\hat{o}^j\hat{o}^k )   \right) \\<br>&amp;= -\left( o^j-o^j\hat{o}^j - \sum_{k:k \neq j} o^k \hat{o}^j \right) \\<br>&amp;= -\left( o^j - \hat{o}^j \sum_ko^k \right) \\<br>&amp;= \hat{o}^j-o^j \\<br>\end{split}\end{equation}$$<br>其中$z_3=Vs_3$,$z^j=V^js$,$V^j$为第$j$个类别的向量权重</p>
</blockquote>
<p>可以看到损失函数对$V$求梯度时最后式子是极其简单，只需要计算当前预测的$o$以及当前隐含层的$s$即可,<br>现在来看下对于$W$的求导，这里会有稍微的不同:<br>$$\frac{\partial E_3}{\partial W}=\frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial s_3} \frac{\partial s_3}{\partial W}$$<br>而这里$s_3$时依赖$s_2$的<br>$$s_3=tanh(W s_2 + Ux_3)$$<br>而同时$s_2$还是依赖$s_1$的,因此在对于$E_3$求$W$的导数的时候并不能将$s_2$作为一个常量进行简单的求导,这样我们再次根据链式法则将会有如下:<br>$$\frac{\partial E_3}{\partial W} = \sum_{k=0}^3 \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial s_3} \frac{\partial s_3}{\partial s_k} \frac{\partial s_k}{\partial W}$$<br>因为这里的$W$是共享的，每一步输出都有用到，因此对于$W$的求导只需要将每一步($t=0..3$)的梯度加起来即可</p>
<center><img src="/img/Understanding-about-RNN/rnn-bptt-with-gradients.png" width="450px"></center>

<p>由于$U$的参与前向计算的式子也$W$的类似，因此关于$\frac{\partial E}{\partial U}$也可以用上述方式来求导。<br>这三个参数的梯度计算与普通的BP计算类似，最大的区别是这三个参数在每一层都是共享的。</p>
<p>由于在求导时需要向后计算，如果层数很多就会遇到经典的梯度消失问题，所以实际的<code>RNN</code>中每一个链可能都会做一个一定长度限制的截断。另外关于梯度消失的问题可以参考<code>RNN</code>的其他变种<code>LSTM</code>和<code>GRU</code>等.</p>
<h2 id="总结">总结</h2><p><code>RNN</code>与传统的神经网络最大的特别就是在每一层计算的时候可以拿到前面几层的信息，这样特别可以有效适用于序列相关的学习，当然在实际操作中效果可能没有这么好~-_-!!</p>
<h2 id="参考:">参考:</h2><ol>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</a></li>
<li><a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" target="_blank" rel="external">http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="RNN是啥?">RNN是啥?</h2><p>当需要处理一些输入或者输出有相互依赖的任务时，传统的神经网络已经不再适用，比如在<code>Language Model</code>中在给定几个单词的情况下来预测下面将会出什么单词的时候。<br>这时候RNN就有用武之地了，RNN在预测/训练当前节点的时候可以获取前面节点的记忆（memory）信息，这样就可以很自然的完成序列任务的学习了。<br>一图胜千言，经典的RNN结构是长这样纸的:<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[学习记录一下深度语义匹配模型-DSSM]]></title>
    <link href="http://kubicode.me/2017/04/21/Deep%20Learning/Study-With-Deep-Structured-Semantic-Model/"/>
    <id>http://kubicode.me/2017/04/21/Deep Learning/Study-With-Deep-Structured-Semantic-Model/</id>
    <published>2017-04-21T14:53:03.000Z</published>
    <updated>2018-01-22T02:41:35.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>DSSM这篇paper发表在cikm2013，短小但是精炼，值得记录一下<br>ps:后来跟了几篇dssm的paper，一并记录在这里</p>
</blockquote>
<h2 id="DSSM">DSSM</h2><h3 id="DSSM的结构">DSSM的结构</h3><p><code>DSSM</code>最大的卖点在检索场景下  使用点击数据来训练语义层次的匹配，简单的来说，传统检索场景下的匹配主要有:</p>
<ol>
<li>字面匹配:<code>TFIDF</code>、<code>BM25</code>等</li>
<li>使用<code>LSA</code>类模型进行语义匹配，但是效果不好</li>
</ol>
<p>而DSSM训练出来之后，检索场景下用户输入query之后，可以根据该query计算各个doc的语义相似度。</p>
<p>这里上图最直接:</p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_arch.png"></center>

<a id="more"></a>
<p>上面是<code>DSSM</code>训练的架构图:</p>
<ol>
<li>输入的是一个<code>query</code>和这个query相关的<code>doc</code>，这里的输入特征可以是最简单的<code>one-hot</code>,而需要<code>train</code>的是这个query下各个doc的相关性(<code>DSSM</code>里面使用点击率来代替相关性)</li>
<li><p>由于这种<code>one-hot</code>的输入可能会有两个问题:</p>
<ol>
<li>导致<code>vocabulary</code>太大</li>
<li><p>会出现<code>oov</code>的问题</p>
<p>因此输入特征之后的第一层是做一个叫做<code>Word Hashinging</code>的操作</p>
</li>
</ol>
</li>
<li>接下来就是传统的神经网络了<br> $$l_i=f(W_il_{i-1}+b_i),i = 2,…,N-1 \\<br> y=f(W_Nl_{N-1}+b_N) $$<blockquote>
<p>这里的<code>f</code>是激活函数，文中使用$tanh$来计算:$f(x)=\frac{1-e^{-2x}}{1+e^{-2x}}$</p>
</blockquote>
</li>
<li>得到的$y$就是语义特征了,query和doc之间的相关性就可以直接使用特想之间的相似性来度量，这里使用cosine来计算<br> $$R(Q,D)=cosine(y_Q,y_D) = \frac{y_Q^Ty_D}{||y_Q||||y_D||}$$</li>
<li>最终得到的相似度就可以去训练query和doc的相关性了</li>
</ol>
<p>因此整个结构就可以看做做了一层<code>Word Hashing</code>之后去训练<code>DNN</code>网络</p>
<h3 id="Word_Hashing">Word Hashing</h3><p><code>Word Hashing</code>是paper非常重要的一个<code>trick</code>，以英文单词来说，比如<code>good</code>，他可以写成<code>#good#</code>，然后按tri-grams来进行分解为<code>#go goo ood od#</code>，再将这个tri-grams灌入到<code>bag-of-word</code>中，这种方式可以非常有效的解决<code>vocabulary</code>太大的问题(因为在真实的web search中vocabulary就是异常的大)，另外也不会出现<code>oov</code>问题，因此英文单词才26个，3个字母的组合都是有限的，很容易枚举光。<br>那么问题就来了，这样两个不同的单词会不会产出相同的tri-grams，paper里面做了统计，说了这个冲突的概率非常的低，500K个word可以降到30k维，冲突的概率为0.0044%</p>
<blockquote>
<p>但是在中文场景下，这个<code>Word Hashing</code>估计没有这么有效了<br>因为直接使用了word hashing，因为无法记录上下文信息</p>
</blockquote>
<h3 id="训练DSSM">训练DSSM</h3><p>上面是前向计算过程，在进行训练的时候需要计算给定<code>Query</code>下与<code>Doc</code>的相关性:<br>    $$P(D|Q) = \frac{exp(\gamma R(Q,D))}{\sum_{d_i \in D} exp(\gamma R(Q,D))}$$</p>
<p>最终他需要优化的损失函数为:<br>    $$L(\Lambda) = - \text{log} \prod_{(Q,D^+)} P(D^+|Q)$$</p>
<blockquote>
<p>$D^+$表示被点击的文档，这里就是最大化点击文档的相关性的最大似然</p>
</blockquote>
<h2 id="CDSSM">CDSSM</h2><p><code>CDSSM</code>(又称<code>CLSM</code>:Convolutional latent semantic model)在一定程度上他可以弥补<code>DSSM</code>会丢失上下文的问题,他的结构也很简单，主要是将<code>DNN</code>替换成了<code>CNN</code></p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/cdssm_arch.png" width="400px"></center><br>他的前向步骤主要计算如下:<br>1. 使用指定滑窗大小对输入序列取窗口数据（称为<code>word-n-gram</code>）<br>2. 对于这些<code>word-n-gram</code>按<code>letter-trigram</code>进行转换构成representation vector(其实就是<code>Word Hashing</code>)<br>3. 对窗口数据进行一次卷积层的处理(窗口里面含有部分上下文)<br>4. 使用<code>max-pooling</code>层来取那些比较重要的<code>word-n-gram</code><br>5. 再过一次FC层计算语义向量<br>6. 他最终输出的还是128维<br><br>&gt; 因为使用<code>CDSSM</code>来做语义匹配的工作也是比较合适的<br><br>## DSSM-LSTM<br>既然是为了记录输入句子的上下文，这个无疑是<code>Lstm</code>这个模型更为擅长，因此又有了一种<code>Lstm</code>来构造的<code>DSSM</code>模型<br><center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_lstm_arch.png" width="400px"></center>

<p>这篇相对于<code>CDSMM</code>来说改的更为简单，其实就是将原始<code>DSSM</code>的模型替换为了<code>LSTM</code>模型…</p>
<h2 id="MV-DSSM">MV-DSSM</h2><p><code>MV-DSSM</code>里面的<code>MV</code>为<code>Multi-View</code>，一般可以理解为多视角的<code>DSSM</code>，在原始的DSSM中需要训练的有<code>Query</code>和<code>Doc</code>这两类的embedding,同时里面<code>DNN</code>的所有权重都是共享的，而<code>MV-DSSM</code>他可以训练不止两类的训练数据，同时里面的深度模型的参数是相互独立:</p>
<p><center><img src="/img/Study-With-Deep-Structured-Semantic-Model/mv_dssm_arch.png" width="400px"></center><br>基于<code>Multi-View</code>的<code>DSSM</code>是的参数变多了，由于多视角的训练，输入的语料也可以变得不同，自由度也更大了，但是随之带来的问题就是训练会变得越来越困难^_^</p>
<h2 id="总结">总结</h2><p><code>DSSM</code>类的模型其实在计算相似度的时候最后一步除了使用Cosine，可能再接入一个MLP会更加好，因为Cosine是完全无参的。</p>
<p><code>DSSM</code>的优势:</p>
<ol>
<li><code>DSSM</code>看起来在真实检索场景下可行性很高，一方面是直接使用了用户天然的点击数据，出来的结果可行度很高，另一方面文中的doc可以使用title来表示，同时这个部分都是可以离线进行语义向量计算的，然后最终query和doc的语义相似性也是相当诱人</li>
<li><code>DSSM</code>出的结果不仅可以直接排序，还可以拿中间见过做文章:<code>semantic feature</code>可以天然的作为<code>word embedding</code>嘛</li>
</ol>
<p><code>DSSM</code>的劣势:</p>
<ol>
<li>用户信息较难加入(不过可以基于<code>MVDSSM</code>改造)</li>
<li>貌似训练时间很长啊</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>Huang P S, He X, Gao J, et al. Learning deep structured semantic models for web search using clickthrough data[C]// ACM International Conference on Conference on Information &amp; Knowledge Management. ACM, 2013:2333-2338.</li>
<li>Shen, Yelong, et al. “A latent semantic model with convolutional-pooling structure for information retrieval.” Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. ACM, 2014.</li>
<li>Palangi, Hamid, et al. “Semantic modelling with long-short-term memory for information retrieval.” arXiv preprint arXiv:1412.6629 (2014).</li>
<li>Elkahky, Ali Mamdouh, Yang Song, and Xiaodong He. “A multi-view deep learning approach for cross domain user modeling in recommendation systems.” Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2015.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>DSSM这篇paper发表在cikm2013，短小但是精炼，值得记录一下<br>ps:后来跟了几篇dssm的paper，一并记录在这里</p>
</blockquote>
<h2 id="DSSM">DSSM</h2><h3 id="DSSM的结构">DSSM的结构</h3><p><code>DSSM</code>最大的卖点在检索场景下  使用点击数据来训练语义层次的匹配，简单的来说，传统检索场景下的匹配主要有:</p>
<ol>
<li>字面匹配:<code>TFIDF</code>、<code>BM25</code>等</li>
<li>使用<code>LSA</code>类模型进行语义匹配，但是效果不好</li>
</ol>
<p>而DSSM训练出来之后，检索场景下用户输入query之后，可以根据该query计算各个doc的语义相似度。</p>
<p>这里上图最直接:</p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_arch.png" /></center>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Federated Search Papers学习笔记]]></title>
    <link href="http://kubicode.me/2017/01/09/Search%20Engine/The-Recorder-for-some-Federated-Search-Papers/"/>
    <id>http://kubicode.me/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/</id>
    <published>2017-01-09T01:58:31.000Z</published>
    <updated>2017-01-13T04:03:17.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px"></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br><a id="more"></a><br>下面就是<code>Federated Search</code>的链路架构<br><center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/architecture.png" width="500px" height="500px"></center>

<p>其<code>Federated Search</code>可以分解为两个任务:</p>
<ol>
<li><code>Resource Selection</code>:也叫<code>Vertical Selection</code>，就是选择不同的<code>Vertical Resource</code>去进行排序</li>
<li><code>Merge Result</code>:也有叫<code>Aggegate Content</code>，在拿到不同<code>Vertical</code>之后进行合并排序</li>
</ol>
<p>其中<code>Resource Selection</code>的难点有:</p>
<ol>
<li>待选择的<code>Vertical</code>可能是黑盒（比如第三方的引擎），没有里面细致的数据（这个点已经就很难了）</li>
<li>待选择的<code>Vertical</code>一般都是异构的</li>
</ol>
<p>另外<code>Merge Result</code>的难点有:</p>
<ol>
<li>各种<code>Vertical</code>出来都是异构的，也就是里面的特征会不一致</li>
<li>就算特征一直，同特征的分布范围还不一致，所以无法用单一的模型去解决这个事情</li>
</ol>
<h2 id="[RS&amp;MR]CORI2">[RS&amp;MR]CORI<sup>2</sup></h2><blockquote>
<p><code>CORI</code>该算法包含了<code>Resource Selection</code>和<code>Merge Result</code></p>
</blockquote>
<p>在给定$Q$、观察到资源类别$C_i$,每个资源根据$P(Q|C_i)$来进行排序</p>
<p>$$T=\frac{df}{df+50+150*cw/avg\_{cw}} \\<br>I=\frac{log(|DB|+0.5)/cf}{log(|DB|+1.0)} \\<br>p(r_k|C_i)=b+(1-b)*T*I<br>$$</p>
<p>其中:</p>
<ul>
<li>$r_k$为$Q$中的第$k$个term</li>
<li>$df$为资源$C_i$中包含$r_k$的文档数量</li>
<li>$cf$为包含$r_k$的资源数量</li>
<li>$|DB|$为需要排序的资源数量</li>
<li>$cw$为在资源$C_i$中出现$r_k$的频次</li>
<li>$avg\_cw$某个$C_i$的平均$cw$</li>
<li>$b$默认值 一般为0.4</li>
</ul>
<p>在合并的时候可以使用类似这种方式进行<code>resultmerge</code>:<br>$$C_i^{*} = \frac{(C_i-C_{min})}{(C_{max}-C_{min})} \\<br>D_i^{*} = \frac{(D_i-D_{min})}{(D_{max}-D_{min})}$$<br>最终归一化的score为(其实这儿就是做了一个映射):<br>$$D^{**} = \frac{D^{*} + 0.4*D^{*}*C_i^{*}}{1.4}$$</p>
<h2 id="[MR]Semisupervised_Learning(SSL)3">[MR]Semisupervised Learning(SSL)<sup>3</sup></h2><blockquote>
<p>这个算法主要用于<code>Merge Result</code>阶段</p>
</blockquote>
<p>用户在输入query时，希望会将该query分发到各个需要排序的引擎(database-specific)上面,此时同时会将query分发到一个中心的涵盖所有的资源的单独引擎上面(database-independent)</p>
<p>这个时候会出两个score:</p>
<ol>
<li><code>database-specific-scorer</code>:不同资源引擎排序的score，不同资源之间的维度不一样</li>
<li><code>database-independent -scroer</code>：中心独立引擎上面，不同资源建所计算的score在同一个维度(估计这里只能用一个common的特征的排序)</li>
</ol>
<p>同时会有讲个假设:</p>
<ol>
<li>同一个query出现在<code>database-specific</code>上面的大部分也会出现在<code>database-independent</code>中</li>
<li><code>database-specific</code>与<code>database-independent</code>两者的overlap的doc拿到的score对使用机器学习方式可计算出一个映射</li>
</ol>
<p>此时假设对于overlap的doc有如下score的pair对$s_{ind},s_{spe}$<br>需要做的就是使用线性回归的方式对两个score简建立一个映射<br>$$s_{ind} = w*s_{spe}+b$$<br>其需要优化的是:</p>
<p>$$argmin_w \sum_i (f(w,s_{spe})-s_{ind})^2$$</p>
<p>这样在各个混排引擎出来的时候就使用归一到同一纬度的score了，并且线性函数的运算很快<br>当然在训练数据不足的时候可以退化为<code>CORI</code></p>
<p>但是他也有其他的缺点：</p>
<ol>
<li>需要额外维护一个中心引擎</li>
<li>中心引擎出的score是同一纬度的算分，也是各个混排引擎的训练目标，但是如果他算分计算不准确，这个训练的结果将会很尴尬</li>
</ol>
<h2 id="[RS]REDDE4">[RS]REDDE<sup>4</sup></h2><blockquote>
<p>主要是做<code>Resource Selection</code>，但是预先先做了<code>Resource Sampling</code></p>
</blockquote>
<h3 id="Sample-Resample">Sample-Resample</h3><p>首先需要使用<code>sample-resample</code>对未知的垂直资源进行一个数据量大小的估计:</p>
<ol>
<li>先从已采样的垂直资源中随机选几个query-term</li>
<li>然后使用<code>query-term</code>再去请求垂直资源拿到返回的请求数以及<code>top rank</code>的部分doc</li>
</ol>
<p>其中</p>
<ul>
<li>$C_j$表示某个垂直资源/数据库</li>
<li>$\tilde{C}_j$表示该垂直资源的采样数据集</li>
<li>$N_{C_j}$表示垂直资源里面的数据大小(条数)[未知]</li>
<li>$N_{\tilde{C}_j}$表示采样垂直资源里面的数据大小条数</li>
<li>$q_i$表示垂直资源中被选择出来的某个<code>query term</code></li>
<li>$df_{q_iC_j}$表示垂直资源$C_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>$df_{q_i\tilde{C}_j}$表示采样垂直资源$\tilde{C}_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>事件$A$表示从垂直资源中采样的某个文档包含$q_i$</li>
<li>事件$B$表示垂直资源中某个文档包含$q_i$</li>
</ul>
<p>则有:<br>$$P(A) = \frac{df_{q_i\tilde{C}_j}}{N_{\tilde{C}_j}} \\<br>P(B) = \frac{df_{q_iC_j}}{N_{C_j}}$$<br>假设采样可以很好的表示整个数据库/垂直资源，因此有$P(A) \approx  P(B)$,则近似的有：<br>$$\hat{N}_{C_j} =  \frac{N_{\tilde{C}_j} *df_{q_iC_j} }{df_{q_i\tilde{C}_j}}$$</p>
<p>最终是使用全部估计的均值来表示的</p>
<h3 id="Resource_Selection">Resource Selection</h3><p>在给定查询词$q$下对于$C_j$的相关性估计为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in C_j}P(rel|d_i) * P(d_i|C_j) * N_{C_j}$$</p>
<p>其中:</p>
<ul>
<li>$N_{C_j}$为资源$C_j$的总文档量，我们使用$\hat{N}_{C_j}$来近似</li>
<li>$P(d_i|C_j)$这个概率将会是$\frac{1}{N_{C_j}}$</li>
</ul>
<p>相应的，相关性的估计将可以被写为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in \tilde{C}_j} P(rel|d_i) \frac{1}{\tilde{N}_{C_j}}  * \hat{N}_{C_j}$$</p>
<p>这样唯一剩下未知就是文档$d_i$与$q$的相关性了$P(rel|d_i)$<br>该paper并没有直接对其相关性做深入的研究，假如目前有一个中心数据库包含了所有的垂直资源，对其中心数据库来检索，则其相关性可以为:<br>$$P(rel|d_i)=\left\{<br>\begin{aligned}<br>C_q &amp; \quad if Rank\_central(d_i) &lt; ratio * \hat{N}_{all} \\<br>0 &amp; \quad \text{otherwise} \\<br>\end{aligned}<br>\right.$$</p>
<p>其中:</p>
<ul>
<li>$Rank\_central(d_i) $为中心数据库中对于$d_i$的排序</li>
<li>$ratio$为一个阈值，指示关注top多少的一个阈值(0.002~0.005表示合适)</li>
<li>$\hat{N}_{all}$为中心数据中所有文档量的一个估计值</li>
<li>$C_q$是一个独立于$q$的常量</li>
</ul>
<p>这种完备的中心数据库其实建立起来不大可行，但是我们可以使用采样的中心数据库.<br>现在向采样的中心进行query检索，可以根据其返回结果来推断出实际中心数据库中各个文档的排序的位置:<br>$$Rank\_central(d_i) = \sum_{d_j | Rank\_S(d_j) &lt; Rank\_S(d_i)} \frac{\hat{N}_{c(d_j)}}{\tilde{N}_{c(d_j)}}$$</p>
<p>这样最终$\hat{Rel}_q(j) $就可以计算出来了，最终在资源选择分布时可以按比例来:<br>$$\hat{Rank\_Rel}_q(j) = \frac{\hat{Rel}_q(j)}{\sum_i \hat{Rel}_q(i)}$$</p>
<h2 id="[RS]Adaptation_of_Offline_Vertical_Selection5">[RS]Adaptation of Offline Vertical Selection<sup>5</sup></h2><p>原本最常用的垂直资源选择是使用<code>one_vs_all</code>的分类分类方法，其中$k$个垂直资源，这样就需要分$k+1$个类别，训练完预测的时候选择类别概率高的来进行展现</p>
<p>而这篇paper主要是在输入类别概率之后还将用户反馈加入了进来再计算:</p>
<h3 id="Multiple_Beta_Prior">Multiple Beta Prior</h3><p>$p_q^v$可以用来表示某个Query下对于某个垂直资源类别v的相关概率，并且它是呈现<code>beta</code>分布的:<br>$$p_q^v \text{~} Beta(a_q^v,b_q^v)$$</p>
<p>其中$\pi_q^v$为离线模型概率，$\mu$为控制因子<br>$$a_q^v=\mu \pi_q^v \quad \quad b_q^v=\mu (1-\pi_q^v)$$</p>
<p>最后我们可以将相关性的后验写为<br>$$\tilde{p}_q^v = \frac{R_q^v + \mu \pi_q^v}{V_q^v + \mu}$$</p>
<blockquote>
<p>$R_q^v$为$q$下展现$v$同时被点击的数量,$\bar{R}_q^v$表示展现了  但是未被点击的数量,$V_q^v$则表示一共展现的数量</p>
</blockquote>
<h3 id="Logistic_Normal_Prior">Logistic Normal Prior</h3><p>其先验为<br>$$p_q^v = \frac{exp(W_{tv})}{exp(W_{tv}) + exp(\bar{W}_{tv})}$$</p>
<blockquote>
<p>$W$和$\bar{W}$是$t \times k$的随机矩阵，并且服从$W,\bar{W} ~ N_{2tk}(\eta,\sum)$,$\sum$为一个协方差矩阵</p>
</blockquote>
<p>则其后验可以转为:<br>$$\tilde{p}_q^v = \frac{\pi_q^v exp(a_q^v)}{\pi_q^v exp(a_q^v) + (1-\pi_q^v) exp(b_q^v)}$$</p>
<p>最终关于$a_q^v,b_q^v$都是可以被计算出来的:<br>$$a_q^v = R_q^v+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} \bar{R}_q^{v’}$$<br>$$b_q^v =  \bar{R}_q^{v’}+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} R_q^v $$<br>其中:</p>
<ol>
<li>$R_q^v$表示$q$与$v$相关的对数</li>
<li>$V_q^v$表示$q$与$v$共现的总次数</li>
</ol>
<h3 id="Similar_Queries">Similar Queries</h3><p>假设某个query1下知道他对于不同垂直资源的偏好，此时有一个query2与query1很相似，那么他关于垂直类目的偏好也会很相似<br>这个也是利用beta分布来估计的，算的是这个Bhattacharyya相似性，感兴趣自己去看paper</p>
<h3 id="Randomizing_Decisions">Randomizing Decisions</h3><p>对于偏好概率很低的垂直资源也会有某个概率$\varepsilon $进行选择它，加了这个概率波动的之后，最后在选择垂直资源是这么计算的，其相关性为：$$P(v)=\frac{1}{Z} exp(\frac{\tilde{p}_q^v}{\tau})$$<br>它是符合<code>Boltzmann</code>分布,其中:</p>
<ol>
<li>$\tilde{p}_q^v$为后验概率</li>
<li>$Z=\sum_vexp(\frac{\tilde{p}_q^v}{\tau})$</li>
<li>$\tau$是一个大于0的值，如果$\tau$趋向于正无穷，那么$P(v)$将会更加随机化，如果$\tau$接近于0，$P(v)$的选择将会更加贪婪（也就是哪个大选哪个）</li>
</ol>
<h2 id="[RS]Vertical_Selection_Evidence6">[RS]Vertical Selection Evidence<sup>6</sup></h2><p>使用分类的方法来进行资源类别选择，里面讲的主要是各种特征</p>
<p>评估指标为:<br>$$P=\frac{1}{|Q|} \left( \sum_{q \in Q | V_q \neq \varnothing } I(\tilde{v}_q \in V_q) + \sum_{q \in Q | V_q = \varnothing } I(\tilde{v}_q = \varnothing)   \right)$$</p>
<p>其中:</p>
<ol>
<li>$V$表示所有垂直资源的集合</li>
<li>$Q$表示所有Query的集合</li>
<li>$V_q$为与某个$q$相关的垂直资源集合</li>
<li>$\tilde{v}_q$表示对于$q$预测的与其相关的一个垂直资源</li>
<li>$I(\cdot)$表示示性函数，应该就是${0,1}$的二值函数吧</li>
</ol>
<p>下面是三大类特征<code>Query String</code>、<code>Query Logs</code>、<code>vertical corpora</code>:</p>
<h3 id="1-Query_String">1.Query String</h3><blockquote>
<p>该特征是为了利用Query中的一些关键短语与垂直资源的内容进行一些匹配</p>
</blockquote>
<h4 id="Rule-based_vertical_triggers(基于规则的触发)">Rule-based vertical triggers(基于规则的触发)</h4><p>文章中一共建立了45类别的属性来刻画query的垂直意图（其实就像类目，比如,local<br>phone, product, person, weather, movies, driving direction,<br>music artist）<br>同时这45类触发将会有三种规则：</p>
<ol>
<li><code>一对一触发</code>:<code>movies → movies, autos→ autos</code></li>
<li><code>一对多触发</code>:<code>{sports players,sports} → sports, {product review, product} → shopping</code></li>
<li><code>不显示对应</code>：但是会提供一些<code>positive或者negative</code>的标志用于分类器,比如, <code>patent, events, weather</code></li>
</ol>
<p>里面的触发类别都是用过正则表达来提出取来，另外一个query可能关联到多个类别，一个触发器至少会匹配到一个query</p>
<h4 id="Geographic_features(地理特征)">Geographic features(地理特征)</h4><p>在输入query下提取地理特征，并且会形成一个指定维护的概率向量:<code>airport,colloquial,continent,town,</code>等，将会与垂直资源中常常提到的这些地理词进行匹配</p>
<h3 id="2-_Query-Log_Features">2. Query-Log Features</h3><p>使用<code>Query-log</code>建立一个一元的语言模型<br>$$QL_q(V_i) = \frac{1}{Z}P(q|\theta_{v_i}^{qlog})$$<br>其中$\theta_{v_i}^{qlog}$为垂直资源$V_i$的语言模型，另外<br>$$Z=\sum_{v_j \in V}P(q|\theta_{v_j}^{qlog})$$</p>
<h3 id="3-Corpus_Features">3.Corpus Features</h3><blockquote>
<p>垂直资源的语料特征</p>
</blockquote>
<h4 id="垂直资源采样">垂直资源采样</h4><blockquote>
<p>应该是这儿的垂直资源可能是分布到各种不同的引擎里面的（第三方），作者并无法取到全部的离线数据，所以在进行语料相关特征计算的时候需要拿到具有代表性的资源文档数据</p>
</blockquote>
<p>在采样的时候使用垂直资源的top-query取访问垂直引擎，拿到文档再去统计，另一次关于垂直资源的语料去Wikipedia获取也是一种相当好的方式，因为里面都做好了结构化</p>
<h4 id="基于语料的特征">基于语料的特征</h4><p>1). <strong>Retrieval Effectiveness Features</strong></p>
<p>$$Clarity_q(C) = \sum_{w \in V} P(w|\theta_q) \text{log} \frac{P(w|\theta_q)}{P(w|\theta_C)}$$</p>
<p>其中:</p>
<ul>
<li>$V$是垂直资源$C$的语料/word</li>
<li>$P(w|\theta_q)$和$P(w|\theta_C)$分别是query和垂直资源的语言模型<br>  $$P(w|\theta_q) = \frac{1}{Z} \sum_{d \in R_{100}} P(w|\theta_d) P(w|\theta_d)$$<br>  $P(q|\theta_d)$为文本$d$的query似然分数，另外$Z=\sum_{d \in R_{100}}P(q|\theta_d)$</li>
</ul>
<blockquote>
<p><code>Clarity</code>分数越小表示检索效果越差</p>
</blockquote>
<p>最终各个资源也是按比例分数来计算的<br>$$Clarity_q^*(V_i) = \frac{1}{Z^*} Clarity_q(S_i^*)$$</p>
<p>2). ReDDE Features.<br>该Feature其实就是Luo.si  2003paper里面的计算方式<br>$$ReDDE_q^*(V_i) = |V_i| \sum_{d \in R_{100}} I(d \in S_i^*) P(q|\theta_d) P(d|S_i^*)$$<br>其中<br>$$P(d|S_i^*) = \frac{1}{S_i^*}$$</p>
<p>3). Soft.ReDDE Features<br>使用Bhattacharyya correlation<br>$$B(d,V_i) = \sum_{w \in top query}\sqrt{P(w|\theta_d) P(w|\theta_{V_i})} $$<br>其中<br>$$\phi(d,V_i) = \frac{B(d,V_i)}{\sum_{V_j \in V}B(d,V_j)}$$<br>最终soft针对文档的$B$进行求和，同时使用$P(q|\theta_d)$来加权:<br>$$Soft.ReDDE_q(V_i) = \sum_{d \in R_{100}} \phi(d,V_i) \times P(q|\theta_d)$$</p>
<p><code>Soft.ReDDE</code>有两大好处：</p>
<ol>
<li>每个文档在他的资源类别排序中多多少少都有贡献</li>
<li>不需要手动做文档到资源类别的映射(这个不懂….)</li>
</ol>
<p>4). Categorical Features<br>最大熵求取多级类目特征</p>
<h2 id="[MR]_Aggregate_Vertical_Results7">[MR] Aggregate Vertical Results<sup>7</sup></h2><p><code>Aggregate Vertical Results</code>(就是最终多源搜索结果的合并)有两大难处：</p>
<ol>
<li>不同来源的特征不一致</li>
<li>就是特征一直，同一个特征的值的分布也是不一致的</li>
</ol>
<p>因此无法直接使用一个ML算法去学习他们的排序,需要一种算法去学习这种不一致的特征排序任务（好像是用了某些特征关系映射）<br>整个<code>Aggregate Result</code>有如下的假设:</p>
<ol>
<li>相同的垂直资源应该是被排到一起的</li>
<li>垂直资源只能被嵌入到指定的坑位</li>
<li>网页结果往往都是主排序</li>
<li>不同的垂直资源是需要有关联的（这个有点难吧）</li>
<li>我们假设用户不会去看那些不相关的垂直资源</li>
</ol>
<p>这儿做的叫做<code>block-rank</code>坑位排序，比如有坑位<code>1~3(w1)</code>、<code>4~6(w2)</code>、<code>7~10(w3)</code>等，其中任务是预测排序顺序$\sigma(q)$与$\sigma^*(q)$尽量相似，其相似度可以使用$\text{Kendall’s} \tau$ 来衡量。<br>另外为了防止某些不相关性的<code>block</code>也被展现，所以有一个叫做<code>end of search result</code>(eos)的模块，如果被预测到这个模块，将会被放置到最下面并且不会展现</p>
<p>先说一下ML所使用到的特征<code>Pre-retrieval Features</code>和<code>Post-retrieval Features</code></p>
<p>1) <strong>Pre-retrieval Features</strong></p>
<blockquote>
<p>在检索到垂直引擎之前的提取的特征</p>
</blockquote>
<ul>
<li><code>Named-Entity Type Features</code></li>
<li><code>Category Features.</code></li>
<li><code>Click-through Features</code></li>
<li><code>Vertical-Intent Features.</code>(这个意图识别还是较难较重)</li>
</ul>
<p>2) <strong>Post-retrieval Features</strong></p>
<blockquote>
<p>这个为在检索到垂直引擎之后提取的特征</p>
</blockquote>
<ul>
<li><code>Hit Count Features</code>:垂直引擎的召回量</li>
<li><code>Temporal Features</code>:时间性相关的特征（时效性）</li>
<li><code>Text-Similarity Features.</code></li>
</ul>
<h3 id="BLOCK-RANKING_APPROACHES">BLOCK-RANKING APPROACHES</h3><blockquote>
<p>下面是实际的排序方法了</p>
</blockquote>
<p>1) <strong>Classification Approach</strong><br>每个垂直资源都有一个自己的分类器(这是使用的LR这个二分类器)<br>这里每个坑位都有一个阈值(除上面<code>w1~3</code>之外，还有一个eos的<code>w4</code>)<br>预测的是这个概率:<br>$$P(\sigma_q(v) &lt; \sigma_q(eos))$$<br>也就是是否要被展现的概率，最终按这种方式进行填坑<br>$$P(\sigma_q(v) &lt; \sigma_q(eos)) &gt; \tau_y \forall x&lt;y $$<br>这样就可以填入<code>x</code>坑位了（$\tau_y$是<code>1~4</code>坑位的阈值）</p>
<p>2) <strong>Voting Approach</strong><br>这里也是使用独立的分类模型,但是他的分类对象是<br>$$P(\sigma_q(i)) &lt; P(\sigma_q(j))$$<br>也就是pair，预测垂直资源$i$是否排在$j$前面，同时由于不同资源特征的限制,不同的$i,j$比较都是需要单独训练一个模型，最终使用投票的方式来确定哪个排在前面</p>
<blockquote>
<p>这种方式将会训练大量模型，虽然paper中将某些<code>block</code>因素归一了，但是训练的模型量还是巨大的</p>
</blockquote>
<p>3) <strong>Learning to Rank Approaches</strong><br>使用<code>RankSvm</code>进行排序,但是会遇到不同类别的特征体系不一致的问题，通过下面三种方式解决</p>
<ol>
<li><code>Equally Correlated Features</code>:针对部分common特征可以合并起来</li>
<li><code>Uniquely Correlated Features.</code>:对类别相关的特征进行copy和平铺出来，比如不同类别下同一个相关性特征可能会写两遍，但是都是时间特征在某些类别下只需要写一遍</li>
<li><code>Equally and Uniquely Correlated Features.</code>:结合上面两种特征</li>
</ol>
<p>但是上面的操作可能会导致过拟合，所以需要比较多的训练样本</p>
<h2 id="[MR]Merging_Multiple_Result_Lists8">[MR]Merging Multiple Result Lists<sup>8</sup></h2><p>用<code>LambdaMerge</code>的方法，其中好多使用了DNN，其框架为:</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/lambdamerge.png" width="500px" height="500px"></center>


<p>其中</p>
<ul>
<li>$f(x_{i,j}^d;\theta)$为文档相关的算法，前面那层的DNN,$x_{i,j}^d$为文档特征</li>
<li>$g(z_i;\eta)$为不同搜索引擎相关的特征（比如google、bing等）,$g(z_i;\eta)$也搜索引擎相关的特征,也是用DNN过了一层</li>
<li>$h(y_j;\phi)$为不同资源相关的特征,$y_j$为特征，也用dnn过了一层</li>
</ul>
<p>最终使用<code>lambdarank</code>来解，感觉这种方法写paper可以，但是实际使用起来代价有点高的</p>
<h2 id="[MR]Federated_Search_at_LinkedIn9">[MR]Federated Search at LinkedIn<sup>9</sup></h2><blockquote>
<p>这篇文章讲了混排在LinkedIn的实践，虽然没有高深的算法，但是讲的实在</p>
</blockquote>
<p>在Linked中的，混排的对象有Job、People、Companies、post等，但是没有一个主要的排序对象（web search中一般网页都是主要排序对象）<br>下面是他们的混排框架</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/linkedin1.png" width="500px" height="500px"></center>


<ol>
<li>用户输入一个query</li>
<li>希望向各个垂直引擎进行请求</li>
<li>请求完了之后各自引擎算完相关性得到top result（用LR进行计算的）</li>
<li>根据top result中各个得分选出主要的资源P,其他的资源都称为C</li>
<li>里面会对P和C的混排分进行一个归一化(没有细讲)</li>
<li>然后以$P_i$为主，将其$C_i$与$P_i$比大小进行插入完成混排</li>
</ol>
<p>其中排序选取的特征有:</p>
<ol>
<li><code>Searcher Intent</code>:用户自身的意图（稳定的，一天跑一把）</li>
<li><code>Keyword Intent</code>:query的意图 实时概率预测</li>
<li><code>Base Ranking Features</code>：基础特征了</li>
</ol>
<p>整个算法简单粗暴，效果还可以，主要实现起来快，而且各个大引擎主要跑一次</p>
<h2 id="[RS]2013-TREC10">[RS]2013-TREC<sup>10</sup></h2><blockquote>
<p>2013年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="resource_selection-Krisztian_Balog">resource selection-Krisztian Balog</h3><p>使用语言模型进行估计:<br>两种方式，将一种资源统一看成一种文档:<br>$$P(q|c) = \prod_{t \in q}\left\{ (1-\lambda)\left(\sum_{d \in c}P(t|d)P(d|c)\right) + \lambda P(t)\right\}^{n(t,q)}$$</p>
<ul>
<li>$t$为$q$中出现的term</li>
<li>$n(t,q)$表示$q$中出现$t$次数</li>
<li>$P(t|d)$和$P(t)$为给定文档下面的最大似然估计</li>
<li>$\lambda$为平滑因子</li>
<li>$P(d|c) = \frac{1}{|c|}$看成均匀分布式</li>
</ul>
<p>另一种方式是看一种资源看成多个文档<br>$$P(q|c) = \sum_{d \in c} P(d|c) \prod_{t \in q} \left( (1-\lambda)P(t|d)+\lambda P(t) \right)^{n(t,q)}$$</p>
<p>最终将两个分数进行一个合并<br>$$P(q|c) = \beta P_{cc}(q|c) + (1-\beta)P_{dc}(q|c)$$</p>
<h3 id="resource_selection-Emanuele_Di_Buccio">resource selection-Emanuele Di Buccio</h3><p>使用两个因子:</p>
<ol>
<li>Inverse Resource Frequency (IRF)   类似逆文档频率<br>$$IRF_t^{(z)} = \text{log} \frac{N^{(z)}}{n_t^{(z)}}$$</li>
</ol>
<ul>
<li>$t$表示term</li>
<li>$N^{(z)}$表示在$z$级别包含$t$的量</li>
<li>$n_t^{(z)}$表示具体某个资源包含$t$的量</li>
</ul>
<blockquote>
<p>关于$z$有是有三个级别:: (1) document, (2) search engines and (3) the set of search engine</p>
</blockquote>
<ol>
<li>Term Weighted Frequency (TWF)<br>$$w_{i,t}^{(z)} = TWF_{i,t}^{(z)} \cdot IRF_t^{(z-1)} $$<br>同时<br>$$TWF_{i,t}^{(z)} = \sum_{r \in R_i^z} TWF_{i,t}^{(z-1)} \cdot IRF_t^{(z-1)}$$</li>
</ol>
<p>这儿是一个递归的方式</p>
<h2 id="[RS]2014-TREC-Federated_Search11">[RS]2014-TREC-Federated Search<sup>11</sup></h2><blockquote>
<p>2014年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="1-resource_selection_-_Qiuyue_Wang">1.resource selection - Qiuyue Wang</h3><p>使用LDA来进行Resource和query的分布<br>由于query很短，作者的处理是用query查询google api取得top 50的文档的摘要，用组成的摘要来训练LDA，最终使用KL距离来衡量相似性</p>
<h2 id="总结">总结</h2><p>看了一些<code>Federated Search</code>相关的<code>Paper</code>（当然还有两个综述也讲的很好[12],[13]），其中</p>
<ul>
<li><code>Resource Selection</code>主要从<code>统计学</code>、<code>相似度计算</code>、<code>概率生成模型</code>以及<code>分类模型来完成</code></li>
<li><code>Merge Result</code>有使用<code>多源归一化</code>，<code>回归模型</code>、<code>LTR模型</code>来完成，同时在算分最后大多使用<code>Slot Filling</code>的方法来做</li>
</ul>
<p><code>Resource Selection</code>目前的方法中好的<code>Resource</code>将会被更多的选择则，该阶段尝试加入<code>Bandit</code>相关策略也许会有比较好的效果,<br>另外<code>Resource Selection</code>和<code>Merge Result</code>目前在优化中其实并没有太大的联系，有没有可能有一种方法能将两个阶段联合起来进行全局优化?</p>
<h2 id="参考文献">参考文献</h2><ol>
<li>Arguello, Jaime, Fernando Diaz, and Milad Shokouhi. “Integrating and ranking aggregated content on the web.” Proc. WWW 2012 (2012).</li>
<li>Callan, James P., Zhihong Lu, and W. Bruce Croft. “Searching distributed collections with inference networks.” Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1995.</li>
<li>Sushmita, Shanu, et al. “Factors affecting click-through behavior in aggregated search interfaces.” Proceedings of the 19th ACM international conference on Information and knowledge management. ACM, 2010.</li>
<li>Si, Luo, and Jamie Callan. “Relevant document distribution estimation method for resource selection.” Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 2003.</li>
<li>Diaz, Fernando, and Jaime Arguello. “Adaptation of offline vertical selection predictions in the presence of user feedback.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, et al. “Sources of evidence for vertical selection.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, Fernando Diaz, and Jamie Callan. “Learning to aggregate vertical results into web search results.” Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 2011.</li>
<li>Lee, Chia-Jung, et al. “An Optimization Framework for Merging Multiple Result Lists.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015</li>
<li>Arya, Dhruv, Viet Ha-Thuc, and Shakti Sinha. “Personalized Federated Search at LinkedIn.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.</li>
<li><a href="http://trec.nist.gov/pubs/trec22/trec2013.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec22/trec2013.html</a></li>
<li><a href="http://trec.nist.gov/pubs/trec23/trec2014.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec23/trec2014.html</a></li>
<li>Shokouhi, Milad, and Luo Si. “Federated search.” Foundations and Trends in Information Retrieval 5.1 (2011): 1-102.</li>
<li>Kopliku, Arlind, Karen Pinel-Sauvagnat, and Mohand Boughanem. “Aggregated search: A new information retrieval paradigm.” ACM Computing Surveys (CSUR) 46.3 (2014): 41.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px" /></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[最大熵模型]]></title>
    <link href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/"/>
    <id>http://kubicode.me/2016/12/12/Machine Learning/Maximum-Entropy-Model/</id>
    <published>2016-12-12T01:39:30.000Z</published>
    <updated>2017-01-03T13:16:38.000Z</updated>
    <content type="html"><![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br><a id="more"></a></p>
<center><img src="/img/Maximum-Entropy-Model/binary_ent.png" width="400px"></center>

<blockquote>
<p>上图是两个类别的示例，可以看到这两个类别的<code>概率一样</code>时其熵值最大</p>
</blockquote>
<p>在机器学习领域，我们通常以最小化风险为目标，其实就是将熵进行最大化.<br>最大熵模型亦是如此，直观的说，<code>最大熵模型就是在满足现有的约束条件之下，将那部分不确定的都设为等可能（熵最大）</code>，<br>下面看一个简单的例子:<br>假设现在有一个随机变量$X$可能取值为$\{A,B,C\}$,现在需要来估计各个值的概率:$P(A)$,$P(B)$,$P(C)$</p>
<p>其实这些概率值肯定会满足如下条件:<br>$$P(A)+P(B)+P(C)=1$$<br>但是满足这个约束条件的概率分布有无限多个，如果没有其他信息的条件下，则取值风险最小的方法是:<br>$$P(A)=P(B)=P(C)=\frac{1}{3}$$<br>现告诉你取$P(A)$的概率为$\frac{1}{2}$,则根据熵最大的原理其他两个概率取值将会为<br>$$P(B) = P(C) = \frac{1}{4}$$<br>也就是$B$和$C$是等概率的，假如接下来还有其他可知的约束条件的话，在满足其他约束条件的情况下继续进行等概率分布.上面的整个划分的过程也就是遵循了<code>最大熵原理</code></p>
<p>现假如用欧式空间的单纯形来表示随机变量$X$的话，定义单纯形中的任意一点到$x$到达相应顶点对应边的距离为取值概率，并且三边距离之和为1，这两种取值情况:<br>$$P(A)=1,P(B)=P(C)=0 \\<br>P(A)=P(B)=P(C)=\frac{1}{3}$$<br>可以依次使用下面两个图来表示</p>
<center><img src="/img/Maximum-Entropy-Model/complex1.png" width="400px"></center>

<p>知道了上面单纯形的表示方法之后，根据下图其最大熵原理可以得到如下的刻画:</p>
<ol>
<li>不加任何约束的时候，可以用图(a)表示，整个取值空间为单纯形上的任何一点，只需要找到熵最大的情况即可</li>
<li>当添加约束<code>C1</code>的时候，将需要在满足<code>C1</code>的情况下再寻找熵最大的取值(也就是图(b))</li>
<li>图(c)表示在图(b)的<code>C1</code>基础上继续增加了<code>C2</code>的约束，此时对两个约束进行了满足之后取值空间将会被固定在<code>C1</code>和$C2$的交点上，只有一个唯一解</li>
<li>假设图(d)里面在<code>C1</code>的基础了增加了<code>C2</code>，但是此时<code>C1</code>和<code>C2</code>并无交点，在这两者约束下将会无解<center><img src="/img/Maximum-Entropy-Model/complex2.png"></center>

</li>
</ol>
<h2 id="最大熵模型介绍">最大熵模型介绍</h2><blockquote>
<p>最大熵模型其实就是在<code>满足已有约束的条件下求得熵最大的过程</code>,最终会转为一个<code>解约束最优化</code>的问题</p>
</blockquote>
<p>现将最大熵原理应用到分类的最大熵模型:<br>假设现有训练数据集<br>$$T=\{(x_1,y_1),(x_2,y_2),….(x_n,y_n)\}$$<br>最大熵模型就是分别根据已有的输入$X$和输出$Y$集合去学习训练数据的条件概率分布$P(y|x)$，应用最大熵原理去学习分类能力最好的模型.<br>根据最大熵原理，是需要在满足约束的情况对已有数据求得熵最大，那在最大熵分类模型里面的<code>约束条件</code>又是啥呢？</p>
<p>对于给定的训练数据集，我们可以确定联合分布$P(X,Y)$的<code>经验分布</code>$\tilde{P}(X,Y)$以及边缘分布$P(X)$的<code>经验分布</code>$\tilde{P}(X)$，即:<br>$$\tilde{P}(X=x,Y=y)=\frac{count(X=x,Y=y)}{N} \\ \tilde{P}(X=x) = \frac{count(X=x)}{N}$$</p>
<blockquote>
<p>其中$count(\cdot)$表示满足条件在样本中的计数，$N$表示总的训练样本容量</p>
</blockquote>
<p>现在引入<code>特征函数</code>$f(x,y)$，它是描述输入$x$与输出$y$之间满足的某一事实，为了方便起见，我们将$f(x,y)$定义为二值函数:<br>$$ f(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{x,y满足某一事实} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>上面的特征函数比较抽象，下面借用别人的栗子来说明一下:<br>假设我们需要来判断<code>打</code>字是量词还是动词，目前有下面的训练数据集:<br>$$<br>(x_1,y_1) = (\text{一打火柴},\text{量词}) \\<br>(x_2,y_2) = (\text{三打啤酒},\text{量词}) \\<br>(x_3,y_3) = (\text{五打袋子},\text{量词}) \\<br>(x_4,y_4) = (\text{打电话},\text{动词}) \\<br>(x_5,y_5) = (\text{打篮球},\text{动词})<br>$$<br>通过观察我们可以发现<code>打</code>前面位<code>数字</code>时，<code>打</code>为<code>量词</code>，如果<code>打</code>后面跟着的是<code>名词</code>,则打为<code>动词</code>，为基于刚刚观察的两个实时我们用特征函数来表示则为:<br>$$ f_1(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的前面为数字} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>$$ f_2(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的后面为名词} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>有了特征函数之后，我们将现有的数据代入这两个特征函数即有:<br>$$f_1(x_1,y_1) = f_1(x_2,y_2) = f_1(x_3,y_3) = 1,f_1(x_4,y_4) = f_1(x_5,y_5) = 0 \\<br>f_2(x_1,y_1) = f_2(x_2,y_2) = f_2(x_3,y_3) = 0,f_2(x_4,y_4) = f_2(x_5,y_5) = 1<br>$$</p>
</blockquote>
<p>对于任意的特征函数$f(x,y)$,<br>现记$E_{\tilde{P}}(f)$表示特征函数$f$在训练数据集$T$上关于$\tilde{P}(x,y)$的数学期望，有:<br>$$E_{\tilde{P}}(f) = \sum_{x,y} \tilde{P}(x,y) f(x,y)$$<br>另记$E_{P}(f)$表示特征函数$f$在训练数据集$T$上关于$P(x,y)$的数学期望，有:<br>$$E_{P}(f) = \sum_{x,y} P(x,y) f(x,y)$$<br>但是$P(x,y)$是未知的，而我们的目标是为了计算$P(y|x)$，根据<code>Bayes</code>我们可以做如下转换<br>$$P(x,y) = P(y|x) \cdot p(x)$$<br>虽说$p(x)$仍为未知，但是我们此时可以使用$\tilde{P}(x)$进行近似,也就是最终有:<br>$$E_{P}(f) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>我们希望上述两个期望值是一值的（应该也是符合既定事实的吧?），这样就会有:<br>$$E_{\tilde{P}}(f) = E_{P}(f)$$<br>或者<br>$$ \sum_{x,y} \tilde{P}(x,y) f(x,y) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>上述式子就可以作为模型的<code>约束条件</code>，假如有$n$个特征函数，则就会有$n$个约束条件(实际中一般特征的维度就是约束条件的个数)<br>用$C$来表示满足约束的模型集合:<br>$$C=\{P|E_{\tilde{P}}(f) = E_{P}(f),I=1,2,3..n\}$$<br>满足约束条件同时使用$P(y|x)$的熵最大的模型即为最大熵模型~</p>
<p>到了这里我们还差一个熵的定义，我们的目标是为了获取条件概率的分布，因为也使用了相应的<code>条件熵</code><br>$$H(P)= - \sum_{x,y}  \tilde{P}(x) P(y|x) log P(y|x)$$</p>
<blockquote>
<p>向上面一样,$P(x)$用$\tilde{P}(x)$进行了近似</p>
</blockquote>
<p>这样我们就可以给出最大熵模型的完成公式描述了:<br>$$<br>\begin{align}<br>\underset{P \in C}{max} &amp;\quad H(P) = - \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad E_{P}(f) = E_{\tilde{P}}(f),I=1,2,3..n \\<br>&amp;\quad \sum_y P(y|x)=1<br>\end{align}<br>$$</p>
<h2 id="最大熵模型学习">最大熵模型学习</h2><p>最大熵模型的学习就是求解最大熵的过程，按照优化的习惯，我们一般会将<code>最大化</code>问题转为<code>最小化</code>再进行优化:<br>$$<br>\begin{align}<br>\underset{P \in C}{min} &amp;\quad -H(P) =  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad  E_{\tilde{P}}(f)- E_{P}(f) = 0,I=1,2,3..n \\<br>&amp;\quad 1-\sum_y P(y|x)=0<br>\end{align}<br>$$</p>
<p>接下来我们求解的思路是:</p>
<ol>
<li>接下来的求解方式是利用拉格朗日乘子将带约束的最优化问题转为等价无约束优化，它是一个<code>极小极大问题</code></li>
<li>然后利用对偶的等价性，将上述<code>极小极大问题</code>转为对偶的<code>极大极小问题</code></li>
</ol>
<h3 id="原始问题与对偶问题">原始问题与对偶问题</h3><p>首先我们引入拉格朗日乘子$w_0,w_1,w_2….w_n$,定义拉格朗日函数为$L(P,W)$<br>$$<br>\begin{align}<br>L(P,W) &amp;= -H(P) + w_0\left(1-\sum_y P(y|x) \right) + \sum_{i=1}^n w_i\left( E_{\tilde{P}}(f)- E_{P}(f) \right) \\<br> &amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right)<br>\end{align}<br>$$</p>
<p>则最优化的原始问题为:<br>$$\underset{P \in C}{\text{min}}  \underset{W}{\text{max}} L(P,W)$$<br>则转为等价的对偶问题为:<br>$$ \underset{W}{\text{max}} \underset{P \in C}{\text{min}} L(P,W)$$</p>
<p>其中$L(P,W)$是关于$P$的凸函数,那我们首先求对偶的极小化部分$ \underset{P \in C}{\text{min}} L(P,W)$,它是关于$W$的函数，将其记为:<br>$$\varphi(w) =  \underset{P \in C}{\text{min}} L(P,W) = L(P_w,W)$$<br>其中<br>$$P_w = \underset{P \in C}{\text{argmin}} L(P,W) = P_w(y|x)$$</p>
<blockquote>
<p>关于这里，我认为我们需要求解的是$P(y|x)$，同时可以将$L(P,W)$看为关于$P(y|x)$的函数,所以为了上面的解，需要下面的偏导~</p>
</blockquote>
<h3 id="指数形式求解">指数形式求解</h3><p>先对$L(P,W)$求$P(y|x)$的偏导,<br>$$<br>\begin{align}<br>\frac{\delta L(P,W)}{\delta P(y|x)} &amp;=  \left( \sum_{x,y}  \tilde{P}(x)  \text{log} P(y|x) + \sum_{x,y}  \tilde{P}(x)  \right) - \sum_yw_0 -\sum_{i=1}^n w_i \tilde{P}(x) f_i(x,y) \\<br> &amp;=  \sum_{x,y} \tilde{P}(x) \left( \text{log} P(y|x) + 1-w_0- \sum_{i=1}^n w_i  f_i(x,y) \right)<br> \end{align}<br>$$</p>
<p>这里对于$\tilde{P}(x)&gt;0$，在求最小值是其偏导数为0，因此会有:<br>$$P(y|x) = e^{\sum_{i=1}^n w_i  f_i(x,y)+w_0-1} = \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{e^{1-w_0}}$$</p>
<p>因为有$\sum_yP(y|x)=1$,则可以有:<br>$$e^{1-w_0} = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>最终我们可以将$P_w(y|x)$表示为:<br>$$P_w(y|x) = \frac{1}{Z_w(x)} e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>其中<br>$$Z_w(x) = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)}$$</p>
<blockquote>
<p>$Z_w(x)$被称为规范化因子，上面样式的算分与逻辑回归非常相似，所以又称为<code>对数线性模型</code>，同时又经过了规范化因子之后可以发现其最后的算分与<code>Softmax</code>极其相似</p>
</blockquote>
<p>这里上面两个式子就是表示$P_w = P_w(y|x)$的最大熵模型，其中向量$W$即为模型的参数<br>现在求解了内部的极小化之后，还需要求解外部的极大化<br>$$\underset{w}{\text{max}} \varphi(W) $$<br>其解标记为$W^{*}$<br>$$W^{*} = \underset{w}{\text{max}} \varphi(W) $$<br>模型参数$W^{*}$就是对对偶的极大化，得到的$W^{*}$可以表示为$W^{*} \in C$，最终$P_{w^{*}} = P_{w^{*}}(y|x)$即为模型的最终解。也就是最大熵模型需要解对偶函数 $\varphi(W)$的极大化~</p>
<h3 id="最大似然估计">最大似然估计</h3><p>在求解上面极大化之前，我们先来看下最大熵模型的极大似然法:<br>已知其经验概率分布$\tilde{P}(X,Y)$和其条件概率分布$P(Y|X)$，可以得到其对数似然函数为:<br>$$<br>\begin{align}<br>LL_{\tilde{P}}(P_w) &amp;=  \text{log} \prod_{x,y} P(y|x)^{\tilde{P}(x,y)} \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} P(y|x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{Z_w(x)}  \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} e^{\sum_{i=1}^n w_i  f_i(x,y)} - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x) \tilde{P}(y|x) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y \tilde{P}(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) \text{log} Z_w(x) \quad    \text{利用} {\color{Blue} {\sum_y \tilde{P}(y|x)=1}}<br> \end{align}<br>$$</p>
<p>回头再将$P(y|x)$的解代入到对偶函数$\varphi(W)$中:<br>$$<br>\begin{align}<br>\varphi(w) &amp;=  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \left(\sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x) \right) \\<br>&amp;\quad +  \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= {\color{Red}{\sum_{x,y}  \tilde{P}(x) P(y|x) \sum_{i=1}^n w_i f_i(x,y)}}  - \sum_{x,y}  \tilde{P}(x) P(y|x)\text{log}Z_w(x) \\<br>&amp;\quad +  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y)- {\color{Red}{\sum_{i=1}^n w_i \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)}}  \\<br>&amp;=  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y P(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y)\sum_{i=1}^n w_i f(x,y) - \sum_x \tilde{P}(x)\text{log} Z_w(x)<br> \end{align}<br>$$</p>
<blockquote>
<p>上面第一步的换算是借助了$\text{log} P(y|x) = \sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x)$，同时还有$\sum_y P(y|x)=1$</p>
</blockquote>
<p>现在再来对比$\varphi(w)$与$LL_{\tilde{P}}(P_w)$最终的表达式，可以惊奇的发现:<br>$$\varphi(w) = LL_{\tilde{P}}(P_w)$$<br>于是就证明了对偶函数的极大化等于模型极大似然估计这一事实，这样模型学习就可以在给定训练数据条件下进行极大化似然估计~</p>
<h2 id="总结">总结</h2><blockquote>
<p>关于具体的解就不再详说了，既然是可以用最大似然法解，则其常用的解法有<code>梯度下降法</code>、<code>牛顿法</code>或者还有专门的<code>GIS</code>法等，参考[2]</p>
</blockquote>
<p>关于最大熵模型:</p>
<ol>
<li>利用最大熵原理<code>熵越大事物越混乱，其分类风险越小</code></li>
<li>为了防止其解空间太大，利用<code>特征函数</code>建立起约束</li>
<li>在求解模型时使用对偶的方式进行求解，先解最小化的负熵，再求极大化的对偶函数</li>
<li>解最小化负熵时可以得到最大熵模型最后的形式是指数形式，类似逻辑回归</li>
<li>又在求极大化对偶函数时，可以发现其对偶函数与模型的极大似然法形式一致</li>
<li>因此最终可以按极大似然法的方式去解决模型</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://www.cnblogs.com/ooon/p/5677098.html" target="_blank" rel="external">最大熵模型 Maximum Entropy Model</a></li>
<li>《统计学习方法》.李航 第6章</li>
<li><a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="external">最大熵学习笔记</a></li>
<li>1996-A Maximum Entropy Approach</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Softmax的二三事]]></title>
    <link href="http://kubicode.me/2016/11/27/Machine%20Learning/Something-for-Softmax/"/>
    <id>http://kubicode.me/2016/11/27/Machine Learning/Something-for-Softmax/</id>
    <published>2016-11-27T08:24:28.000Z</published>
    <updated>2018-03-21T01:39:10.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All" target="_blank" rel="external">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One" target="_blank" rel="external">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯" target="_blank" rel="external">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li><a href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/" target="_blank" rel="external">最大熵模型</a></li>
<li>。。。</li>
</ol>
<a id="more"></a>
<p>同时本文要说到的<code>Softmax</code>是一个是<code>Logistic</code>模型上的一个扩展，可以轻松的完成多分类任务，它是一个有监督的学习，不过可以和相当热门的神经网络可以轻松结合起来.</p>
<h2 id="Logistic回顾">Logistic回顾</h2><p><code>Logistic</code>模型是一个非常基础而又高效的<code>二分类</code>模型，并且由于其最终值会归一化到0~1，因此也很多场景下也会作为<code>回归</code>模型使用，比如<code>ctr预估</code>。<br><code>Logistic</code>的输入数据是<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>其中$x^i$为输入的特征向量，$y^i$即为要训练的目标，在<code>二分类</code>中，一般$y^i \in \{0,1\}$，则<code>Logistic</code>的算分函数为<br>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^Tx}}$$</p>
<p>使用最大似然法进行参数估计,其似然函数为<br>$$\prod h_{\theta}(x^i)^{y^i} \times (1-h_{\theta}(x^i))^{(1-y^i)}$$</p>
<p>对其进行负的对数转换之后则最终的损失函数为<br>$$ J(\theta) = -\frac{1}{m} \sum_{i=1}^m \left [ y^i \text{log}h_{\theta}(x^i) + (1-y^i)\text{log}(1-h_{\theta}(x^i)) \right ]    $$</p>
<p>在<code>Logistic</code>模型中我们可以发现我们最终需要求的是$\theta$向量.</p>
<h2 id="Softmax_模型">Softmax 模型</h2><p>在<code>Softmax</code>模型中，其输入也是类似向量的设计<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>只是这个的$y^i \in \{1,2,…k\}$有$k$个类别，而最终要求的应该是这个值<br>$$P(y=k_j | x)$$<br>也就是类别$k_j$可能的概率，也就是会形成一个$k$维的输出<br>$$<br>h_{\theta}(x^i)=\begin{bmatrix} P(y^i=1|\theta_1,x_i)<br>\\ P(y^i=2|\theta_2,x_i)<br>\\ …<br>\\ P(y^i=k|\theta_k,x_i)<br>\end{bmatrix}<br>=<br>\frac{1}{\sum_{s=1}^k e^{\theta_s^Tx_i}}<br>\begin{bmatrix} e^{\theta_1^Tx_i}<br>\\ e^{\theta_2^Tx_i}<br>\\ …<br>\\ e^{\theta_k^Tx_i}<br>\end{bmatrix}<br>$$</p>
<p>则我们整个模型最终要求的是一个$\theta$<code>矩阵</code>(注意,在<code>Logistic</code>中求是一个向量),矩阵的每一行$\theta_i$其实就是与输入参数$x$相乘的向量~</p>
<blockquote>
<p>注意:分子$\frac{1}{\sum_{s=1}^k e^{\theta_s^Tx_i}}$是为了让最终所有类别的概率之和为<code>1</code></p>
</blockquote>
<p>每个类别j的概率为:<br>$$p_j=\frac{e^{\theta_j^Tx}}{\sum_{s=1}^k e^{\theta_s^Tx}}$$</p>
<h2 id="Softmax的损失函数">Softmax的损失函数</h2><p>同样,<code>Softmax</code>使用最大似然法进行参数的估计,则似然函数为<br>$$\prod_i^m \prod_{j=1}^k p_j^{I\{y^i = k_j\}}$$</p>
<blockquote>
<p>其中$I\{y^i = k_j\}$为二值函数，当且仅当$y^i == k_j$时为1，否则为0</p>
</blockquote>
<p>对其<code>取负的对数</code>可以得到其损失函数:<br>$$J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \text{log} p_j \right]$$</p>
<p>假设我们使用梯度下降法对损失函数进行优化，因此对$\theta$进行求导,在求导之前先算下面这个:<br>$$ \frac{\delta p_j}{\delta \theta_i}=\left\{<br>\begin{aligned}<br>\frac{\frac{e^{\theta_j^Tx}}{\delta \theta_{\color{Red} j}}\sum_{s=1}^k e^{\theta_s^Tx}-\frac{\sum_{s=1}^k e^{\theta_s^Tx}}{\delta \theta_{\color{Red} j}}e^{\theta_j^Tx}}{(\sum_{s=1}^k e^{\theta_s^Tx})^2} &amp;= x p_j(1-p_j)  &amp; \quad if i=j \\<br>\frac{\frac{e^{\theta_j^Tx}}{\delta \theta_{\color{Red} i}}\sum_{s=1}^k e^{\theta_s^Tx}-\frac{\sum_{s=1}^k e^{\theta_s^Tx}}{\delta \theta_{\color{Red} i}}e^{\theta_j^Tx}}{(\sum_{s=1}^k e^{\theta_s^Tx})^2} &amp;= x p_ip_j &amp; \quad if i \neq j\\<br>\end{aligned}<br>\right.$$</p>
<p>有了上面的基础之后，我们对于$J(\theta)$进行求导，就可以得到如下的梯度:</p>
<p>$$\begin{equation}\begin{split} \triangledown_{\theta_j}J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \frac{1}{p_j} \frac{\delta p_j}{\delta \theta_j  }  \right]\\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \left ( I\{y^i = k_i\} \frac{1}{p_i} x^i p_i(1-p_i) -  \sum_{j=1,j \neq i}^k I\{y^i = k_j\} \frac{1}{p_j} x^i p_i p_j \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_i\} (1-p_i) -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} i}\} - I\{y^i = k_i\}p_i -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} j}\} -  \sum_{j=1}^k I\{y^i = k_j\} p_i \right )  \right ]  \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_j\} - p_i \right )  \right ]<br>\end{split}\end{equation}$$</p>
<p>注意有:</p>
<ul>
<li>$\sum_{j=1}^k I\{y^i = k_j\} = 1 $ ,因为样本必定会落到一个类别上</li>
<li>同时上面式子里面红色的${\color{Red} j}$是因为左侧分离出来,其中分离的条件是$i=j$</li>
</ul>
<p>上面的梯度最终将会是一个向量的形式,$\frac{\delta J(\theta)}{\delta \theta_{j,l}}$表示第$j$的类别的第$l$个特征的梯度方式，有了该梯度了之后，最终可以得到如下的参数更新:<br>$$\theta_j = \theta_j - \alpha \triangledown_{\theta_j}J(\theta) \quad j \in \{1,…k\}$$</p>
<p>到了这一步，整体看到就和二分类的<code>Logistic</code>很像了，上面是使用梯度下降法的求解，当然还可以使用类似<code>L-BFGS</code>算法进行优化~<br>另外关于其<code>L1</code>和<code>L2</code>的正则项也是可以参考<code>Logistic</code></p>
<h2 id="Softmax与Logistic的联系">Softmax与Logistic的联系</h2><p>在<code>Softmax</code>的$k=2$时(其实就是二分类了)，再来观察<code>Softmax</code>的一些式子</p>
<h3 id="算分函数">算分函数</h3><p>$$\begin{equation}\begin{split} h_\theta(x^i) &amp;= \frac{1}{e^{\theta_1^Tx_i}+e^{\theta_2^Tx_i}}<br>\begin{bmatrix} e^{\theta_1^Tx_i}<br>\\ e^{\theta_2^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \frac{1}{e^{(\theta_1-\theta_1)^Tx_i}+e^{(\theta_2-\theta_1)^Tx_i}}<br>\begin{bmatrix} e^{(\theta_1-\theta_1)^Tx_i}<br>\\ e^{(\theta_2-\theta_1)^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\\ \frac{e^{(\theta_2-\theta_1)^Tx_i}}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\\ 1- \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>在上面第一到第二步减去$\theta_1$任成立的原因是，<code>Softmax</code>的参数过多，是一个大矩阵，里面存在着冗余的参数:<br>$$\begin{equation}\begin{split} h_{\theta_j}(x^i) &amp;= \frac{e^{\theta_jx^i}}{\sum_{s=1}^k e^{\theta_sx^i}} \\<br>&amp;= \frac{e^{(\theta_j-\phi)x^i}}{\sum_{s=1}^k e^{(\theta_s-\phi)x^i}} \\<br>&amp;= \frac{e^{\theta_jx^i}e^{-\phi x^i}}{\sum_{s=1}^k e^{\theta_sx^i}e^{-\phi x^i}} \\<br>&amp;= \frac{e^{\theta_jx^i}}{\sum_{s=1}^k e^{\theta_sx^i}}<br>\end{split}\end{equation}$$<br>因此，参数矩阵中减去同一个<code>向量</code>并不会影响最终的优化结果~关于参数过度化问题可以参考<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">这里</a></p>
</blockquote>
<p>所以当$k=2$时<code>Softmax</code>的算分函数其实就是<code>Logistic</code>的变形~</p>
<h3 id="损失函数">损失函数</h3><p><code>Softmax</code>的损失函数为<br>$$\begin{equation}\begin{split} J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^2 I\{y^i = k_j\} \text{log} p_j \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + I\{y^i = k_2\} \text{log} p_2  \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + (1-I\{y^i = k_1\}) \text{log} (1-p_1)  \right]  \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>因为:$I\{y^i = k_1\} + I\{y^i = k_2\}  =1$ 以及 $p_1+p_2=1$</p>
</blockquote>
<p>最终也就变成了<code>Logistic</code>的损失函数形式了</p>
<h2 id="总结">总结</h2><ol>
<li><code>Softmax</code>模型其实是<code>Logistic</code>对于多分类上面的扩展</li>
<li><code>Softmax</code>最终产出的每一类的概率之和为1</li>
<li><code>Softmax</code>其实并不是一个损失函数（因为看到很多文章中都会很自然的写道<code>Softmax损失函数</code>）,它自己求优化时还是使用者交叉熵的这一套</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">Softmax回归 ufldl</a><blockquote>
<p>文本大致组织按这个参考来的，因为它写的实在太好了，自己在造一遍轮子，以便记忆^_^</p>
</blockquote>
</li>
<li><a href="http://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function" target="_blank" rel="external">Derivative of Softmax loss function</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li><a href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/">最大熵模型</a></li>
<li>。。。</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用点击图来计算Query-Doc的文本相关性]]></title>
    <link href="http://kubicode.me/2016/11/03/Search%20Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/"/>
    <id>http://kubicode.me/2016/11/03/Search Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/</id>
    <published>2016-11-03T12:07:18.000Z</published>
    <updated>2016-11-07T01:59:53.000Z</updated>
    <content type="html"><![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br><a id="more"></a></p>
</blockquote>
<h2 id="已有点击行为的向量计算">已有点击行为的向量计算</h2><p>在搜索场景下用户输入query，对搜索的结果进行点击反馈，将所有用户的搜索行为收集起来之后可以形成一张大的<code>Click-Graph</code>，为了简单，我们使用二部分来表示，其中左侧为$Query$，右侧为$Doc$，如果$q_i$到$d_j$存在点击行为，则左右侧将会有一条边连接，连上的权重及<code>点击的次数</code></p>
<center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/co-click-graph.png" width="400px"></center>

<p>现在假设语料的长度为$V$,则$Query$构成的矩阵为$|Query| \times V$，以及$Doc$构成的矩阵为$|Doc| \times V$，那么现在的任务就是如何计算这两个矩阵!</p>
<blockquote>
<p>其实这个语料就是上面所说道的$Query$和$Doc$同处的向量空间,一般值$Query$里面抠出来的<code>Term</code>或者$Doc$里面的<code>title</code>/<code>content</code>抠出来的<code>term</code>.</p>
</blockquote>
<p>这里使用的是<code>向量传播</code>来对$Query$和$Doc$进行计算，计算之前有这么这个假设:</p>
<ol>
<li><code>点击二部图</code>上的边连接的$q_i$和$d_i$是有相关性的(或者说有较高的相关性)</li>
<li>$q_i$上的<code>term</code>与$d_i$上的<code>title</code>/<code>content</code>的<code>term</code>应该是存在联系的</li>
</ol>
<p>目前暂不考虑缺少行为的$Query$和$Doc$，向量传播模型的步骤为:</p>
<ol>
<li>随意选择一侧进行向量初始化（$Query$和$Doc$端均可），我们使用$Query$向量来进行初始化$Q_i^0$,其中$Q_i^0$使用<code>one-hot</code>来表示，同时用$L2$进行归一化<blockquote>
<p>$i$表示第$Query$中的第$i$个,$0$表示第1次迭代（也就是初始化~）</p>
</blockquote>
</li>
<li>则第$D_j^n$个值($n&gt;=1$)的更新根据被点击$Query$的向量进行加权求和即可:<br> $$D_j^n=\frac{1}{||\sum_{i=1}^{|Query|}C_{i,j} \cdot Q_i^{n-1}||_2} \sum_{i=1}^{Query}C_{i,j} \cdot Q_i^{n-1}$$<blockquote>
<p>其中$Q_i^n$就是上一次迭代的$Query$向量，同样$D_j^n$也会进行一个$L2$正则化。</p>
</blockquote>
</li>
<li>$Doc$的向量表示进行了一次迭代更新之后继续更新$Query$的向量，这里是根据$Query$下公共点击的文档信息进行更新，其方式与$Doc$的更新是一样的:<br> $$Q_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}C_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}C_{i,j} \cdot D_i^{n-1}$$</li>
<li>按<code>2</code>、<code>3</code>的步骤不断进行迭代，直至收敛，其产出的$Query$的$Doc$的向量就都在一个空间内，同时还可以计算相似度/相关性</li>
</ol>
<p>这里以上的图为例再说一下计算过程:</p>
<ol>
<li>初始化$Query$的向量:<ul>
<li>$Q_1:\{yahoo:\frac{1}{\sqrt{2}},finance:\frac{1}{\sqrt{2}},mail:0\}$</li>
<li>$Q_2:\{yahoo:1,finance:0,mail:0\}$</li>
<li>$Q_3:\{yahoo:\frac{1}{\sqrt{2}},finance:0,mail:\frac{1}{\sqrt{2}}\}$<blockquote>
<p>因为图中$Query$的语料三个<code>term</code>，所以这里初始化为3维.</p>
</blockquote>
</li>
</ul>
</li>
<li>根据上一次$Query$的迭代信息以及与$Doc$的点击信息来更新$Doc$的向量:<ul>
<li>$D_1=\frac{(\frac{3}{8}Q_1 + \frac{5}{8}Q_2)}{||\frac{3}{8}Q_1 + \frac{5}{8}Q_2||_2}$</li>
<li>$D_2=\frac{(\frac{1}{5}Q_2 + \frac{4}{5}Q_3)}{||\frac{1}{5}Q_2 + \frac{4}{5}Q_3||_2}$</li>
</ul>
</li>
<li>然后就是不断的迭代就行了，这样已经很清晰了</li>
</ol>
<p>了解过一些信息检索或者链接分析的朋友可能会马上想到，咦~这好像<code>Hits</code>这个算法。的确是的，在计算过程中极为相似，不过<code>Hits</code>权重主要是计算<code>Hubs</code>与<code>Authority</code>两端的权重，而[1]中迭代完得到的是各个向量，有异曲同工之妙~<br>另外在实际的query量级一般都是百万以上，这样$Query$的语料的量就很大了,而搜索引擎中需要计算的性能要求极高，，所以一般进行稀疏存储，并且只取一些重要的<code>term</code>来对$Query$进行表示</p>
<h2 id="缺少点击行为的向量计算">缺少点击行为的向量计算</h2><p>但是实际应用中用户搜索之后带来了点击行为的只是一小部分就，如果仅按照上述点击传播的方式来计算的话无query点击的文档将会将会无法得到正常的向量，同时一些新的$\hat{Query}$（从未有用户搜索过的query）也就无法得到正常的向量数据，所以需要一种对于这种缺失行为的$\hat{Query}$和$\hat{Doc}$进行向量表示估计.</p>
<p>由于在线计算相关性时对于已有行为的$Query-Doc$和缺失行为的是一视同仁的，因此为了在线计算时不应该因为训练数据产生偏差，所以需要与已有行为的$Qeury-Doc$向量在同一个空间内，同时考虑已有行为的$Query$和$Doc$的向量均已计算得到，我们还借助这些数据来预估缺失行为的向量.</p>
<h3 id="提取Unit向量">提取Unit向量</h3><p>既然未行为的$\hat{Query}$与$\hat{Doc}$之间没有任何边向量，那我们可以通过有行为的$Query$进行造边，先将$\hat{Query}$分解为各种<code>Unit</code>，这样就有$u_i \in unit(q_i)$,如果存在$Query$含有$u_i$，则将$u_i$对对应的$Query$之间形成一条虚拟的边,同时称含有$u_i$的所有$Query$的集合为$O_{u_i}$</p>
<blockquote>
<p>这里分解时可以按<code>n-gram</code>进行分解，但是某个$Query$进行分解之后不能有<code>overlap</code></p>
</blockquote>
<p><center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/absent_graph.png" width="700px"></center><br>这种边的构建方式如上图，$q_1$、$q_2$和$q_3$均都包含了<code>yahoo</code>这个词，则在他们之间形成这条虚线的边。<br>接下来我们可以理解$Query-Doc$之间的向量传播方法，我们当然也可以完成$Unit-Doc$的传播.<br>$u_i$会有$q_i$有边相连，而$q_i$与$d_i$又有变相连，因此我们可以间接认为$u_i$与$d_i$也是有边相连。<br>现假设$q_k$包含了$u_i$，同时$q_k$与$d_j$存在点击行为，$P_{i,k,j}$表示为这个二折线的权重，则该权重其实为$q_k$与$d_j$的点击次数，那么我们就会有<br>$$P_{i,j} = \sum_{k=1}^{|O_{u_i}|} P_{i,k,j}$$<br>其演示就是上图的右侧部分，<code>yahoo</code>与$d_1$之间的权重为8，与$d_2$之间的权重为5，既然到了这一步，我们就可以按照上一小节的传播方式来计算,这样就可以巧妙的得到$U_i$的向量:<br>$$U_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}P_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}P_{i,j} \cdot D_i^{n-1}$$</p>
<p>上面得到的是关于$\hat{Query}$上<code>unit</code>的向量，同样的我们也可以从$\hat{Doc}$这一侧出发，来计算$\hat{Doc}$<br>相关的<code>unit</code></p>
<h3 id="计算Unit向量权重">计算Unit向量权重</h3><p>有了<code>unit</code>的向量之后，接下来要解决的问题就是如何得到$\hat{Query}$或者$\hat{Doc}$的向量了，其实最简单的方法就是将他们各自的<code>unit</code>进行平均即可,不过[1]使用线性回来来解决该权重问题，在进行权重训练时使用最小平方差:<br>$$\underset{w}{min} \sum_{i=1}^{|T|} || T_i-\sum_{u_j \in U_{T_i}^{all}} W_j \cdot U_j||_2^2$$</p>
<blockquote>
<p>$T_i$是使用有点击行为的$Query$计算得到的向量，也就是我们所认为的<code>gold-set</code><br>这样求出来的$W$就是各个$unit_i$不同的权重</p>
</blockquote>
<h3 id="预估向量">预估向量</h3><p>根据上面两个步骤得到的<code>unit</code>的向量和权重之后，得到整体的$\hat{Query}$或者$\hat{Doc}$就很方便了，由于<code>unit</code>本身就是$\hat{Query}$或者$\hat{Doc}$分解出来的，这里基础数据也都已经计算完成了，所以直接进行加权求和即可:<br>$$q_v=\sum_{u_i \in u_q} W_iU_i$$<br>和<br>$$d_v=\sum_{u_i \in u_d} W_iU_i$$</p>
<p>这样一来缺失形式的向量数据也都可以计算出来了</p>
<h2 id="总结">总结</h2><p>该方法成功的借助了点击日志对于相关性进行估计（其实我觉得这种方式得到的文本相关性与ctr的预估会有部分重叠了），并且在实现上:</p>
<ol>
<li>已有点击数据的$Query$和$Doc$的向量直接离线就按完成</li>
<li>缺失点击的$\hat{Query}$和$\hat{Doc}$可以利用离线计算的<code>unit</code>向量在线直接进行加权求和即可</li>
<li>对于在线存储均使用稀疏方式并只存<code>top-k</code>，因此存储并不是问题</li>
<li>在线计算相关性可以直接按相似度计算，复杂度为$k log k$所以并不是很高~</li>
</ol>
<p>可实现性还是比较强的，但是对于一些未登录词就无能为力了….</p>
<blockquote>
<p>关于改算法的最终实现结果去看paper吧，效果自然是还可以的</p>
</blockquote>
<p>看了这篇paper，其实还是有点其他启发:</p>
<ol>
<li>如果搜索了query之后对于未点击的文档是不是可以进行降权（因为点击的文档是进行加权的）</li>
<li>再想想，~其实直接使用来计算文本相关性风险还是挺大</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>2016-Learning Query and Document Relevance from a Web-scale Click Graph</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br>]]>
    
    </summary>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[语言模型在信息检索中的平滑方法]]></title>
    <link href="http://kubicode.me/2016/10/24/Machine%20Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/"/>
    <id>http://kubicode.me/2016/10/24/Machine Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/</id>
    <published>2016-10-24T11:58:01.000Z</published>
    <updated>2016-11-05T16:33:15.000Z</updated>
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br><a id="more"></a><br>由于在给定$q$下，不同文档的$p(q)$是一样的，这里关注的是排序，所以可以直接将$p(q)$进行移除，另外式子右侧的$p(d)$为文档$d$对于任何$q$的相关性先验，在$p(q|d)$就是在给定$d$下生成$q$的概率，也就是文档$d$到$q$的匹配程度.<br>为了简单起见，我们假设$p(d)$是均匀分布的，这样的话$p(d)$就不会影响排序，那么信息检索的问题就会转为一个一元语言模型:<br>$$p(q|d) = \prod_i p(q_i|d)$$<br>大多数平滑的方法都会使用两类分布:</p>
<ol>
<li>一类是对于在文档中出现的词的模型$p_s(w|d)$</li>
<li>另一个是没有出现在文档中的词的模型$p_u(w|d)$</li>
</ol>
<p>这样的话在一个$q$中根据词在文档中的出现与否可以写为:<br>$$\begin{equation}\begin{split}log p(q|d)&amp;= \sum_i log p(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) - \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i|d)&gt;0} log \frac{p_s(q_i|d)}{p_u(q_i|d)} + \sum_i log p_u(q_i|d) \\<br>\end{split}\end{equation}$$</p>
<p>其中未在文档中出现的词的概率典型的表示方法就是该词在所有集合中出现的频率:<br>$$p_u(q_i|d) = \alpha_d p(q_i|C)$$</p>
<blockquote>
<p>其中$\alpha_d$为独立于文档的一个常量，$p(q_i|C)$为集合中的语言模型，这样我们就会有</p>
</blockquote>
<p>$$log p(q|d) = \sum_{i:c(q_i:d)&gt;0} log \frac{p_s(q_i|d)}{\alpha_d p(q_i|C)} + n log \alpha_d + \sum_i log p(q_i|C)$$</p>
<blockquote>
<p>其中$n$为$q$的长度，上面式子的右侧与$d$并没有关系，所以直接去掉也不会影响排序</p>
</blockquote>
<p>这样的话检索函数就变成了两部分，第一部分为$q$与$d$相匹配<code>term</code>的权重，第二部分为与$q$无关的一个常量，一般是用于对非匹配<code>term</code>的平滑。</p>
<p>这时候再看下第一部分，其实可以上面$p(q_i|C)$大致可以看为<code>IDF</code>,而$p_s(q_i|d)$又非常向tf,因为上面的Language Model与<code>tf*idf</code>路线还是挺像的。</p>
<h2 id="Smoothing_Methods">Smoothing Methods</h2><p>看了上面的描述，接下来主要讲一下对于$p(w|d)$的估计，最简单的使用数数的方式，最大似然法进行估计为:<br>$$p_{ml}(w|d) = \frac{w;d}{\sum_w c(w;d)}$$</p>
<blockquote>
<p>其实就是词在文档中出现的频率</p>
</blockquote>
<p>这种方式对于没出现在文档中的词将会低估（其实就是没值了），因为对于没有在文档中出现的词会给予一个非0概率的平滑。<br>通常我们会对出现在文档中的词的概率进行一个折损，同时对于未出现在文档中的词的概率给予一个额外的值:<br>$$ p(w|d)=\left\{<br>\begin{aligned}<br>p_s(w|d) &amp; \quad if \quad word \quad w \quad is \quad seen \\<br>\alpha_d p(w|C) &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>同时$\alpha_d$将会依赖$d$，如果$p(w|d)$给定的情况下，我们将会有:<br>$$\alpha_d = \frac{1-\sum_{w:c(w:d)&gt;0} p_s(w|d)}{1-\sum_{w:c(w:d)&gt;0}p(w|C)}$$</p>
<p>因此这里最大的问题是需要计算$p_s(w|d)$,因为在信息检索中对于性能的要求将其高，因此为考虑性能和效果，下面主要简单的介绍三种平滑方式</p>
<h3 id="Jelinek-Mercer">Jelinek-Mercer</h3><p>这种方式是融合了最大似然发以及一个置信因子来控制各个模型<br>$$p_{\lambda} = (1-\lambda)p_{ml}(w|d) + \lambda p(w|C)$$</p>
<blockquote>
<p>这种方式非常的高效</p>
</blockquote>
<h3 id="Dirichlet">Dirichlet</h3><p>他其实是贝叶斯平滑，然后使用了<code>Dirichlet</code>先验，使用这种可以得到<br>$$p_{\mu}(w|d) = \frac{c(w;d) + \mu p(w|C)}{\sum_w c(w;d)+ \mu}$$</p>
<h3 id="Absolute_discount">Absolute discount</h3><p>这种方式主要是通过降低可见词的概率来完成的,类似<code>Jelinek-Mercer</code>方法,与$1-\lambda$不同的是  使用减去一个常量来完成:<br>$$p_{\delta } = \frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \sigma p(w|C)$$</p>
<blockquote>
<p>其中$\delta \in [0,1]$,为一个折损常量，$\sigma = \delta|d|_u/|d|$,所以所有的概率之和为1，$|d|_u$为文档中不同<code>term</code>的数量,$|d|$为文档中<code>term</code>的总数量</p>
</blockquote>
<p>另外注意$max(c(w:d)-\delta,0)$中的$c(w:d)$应该是归一化0~1了，这样才可以和$\delta$相减</p>
<p>对于这三种平滑方式的一个表格表示（非常清晰）:</p>
<table>
<thead>
<tr>
<th style="text-align:center">平滑方法</th>
<th style="text-align:center">$p_s(w &#124; d)$</th>
<th style="text-align:center">$\alpha_d$</th>
<th style="text-align:center">参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Jelinek-Mercer</code></td>
<td style="text-align:center">$(1-\lambda)p_{ml}(w &#124; d) + \lambda p(w &#124; C)$</td>
<td style="text-align:center">$\lambda$</td>
<td style="text-align:center">$\lambda$</td>
</tr>
<tr>
<td style="text-align:center"><code>Dirichlet</code></td>
<td style="text-align:center">$\frac{c(w;d) + \mu p(w &#124; C)}{\sum_w c(w;d)+ \mu}$</td>
<td style="text-align:center">$\frac{\mu}{\sum_w c(w;d)+\mu}$</td>
<td style="text-align:center">$\mu$</td>
</tr>
<tr>
<td style="text-align:center"><code>Absolute discount</code></td>
<td style="text-align:center">$\frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} p(w &#124; C)$</td>
<td style="text-align:center">$\frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} $</td>
<td style="text-align:center">$\delta$</td>
</tr>
</tbody>
</table>
<p>看上面三种平滑的计算方式都是非常的简单，并且$\alpha$都是可以离线计算，其最终的复杂度为$O(k|q|)$,$k为文档的平均长度$</p>
<blockquote>
<p>其实复杂度不用这么多，如果在线查找term时使用二分的话  复杂度仅为$O(log(k)|q|)$</p>
</blockquote>
<h2 id="总结">总结</h2><p>这三种方法比较经典，并且可实现性强，$p_s(w|d)$和$\alpha_d$全部都可以离线计算完成，在线只需要进行简单的求和即可,值得一试~</p>
<h2 id="参考">参考</h2><ol>
<li>Zhai, Chengxiang, and John Lafferty. “A study of smoothing methods for language models applied to ad hoc information retrieval.” Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2001.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Python画ROC曲线以及AUC值]]></title>
    <link href="http://kubicode.me/2016/09/19/Machine%20Learning/AUC-Calculation-by-Python/"/>
    <id>http://kubicode.me/2016/09/19/Machine Learning/AUC-Calculation-by-Python/</id>
    <published>2016-09-18T16:02:43.000Z</published>
    <updated>2016-09-18T16:39:41.000Z</updated>
    <content type="html"><![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/" target="_blank" rel="external">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br><a id="more"></a></p>
<h2 id="AUC计算">AUC计算</h2><p><code>AUC</code>的计算分为下面三个步骤：</p>
<ol>
<li>计算数据的准备，如果模型训练时只有训练集的话一般使用交叉验证的方式来计算，如果有评估集(<code>evaluate</code>)一般就可以直接计算了，数据的格式一般就是需要预测得分以及其目标类别（注意是目标类别，不是预测得到的类别）</li>
<li>根据阈值划分得到横（X:<code>False Positive Rate</code>）以及纵（Y:<code>True Positive Rate</code>）点</li>
<li>将坐标点连成曲线之后计算其曲线下面积,就是<code>AUC</code>的值</li>
</ol>
<p>直接上python代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! -*- coding=utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log,exp,sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluate_result=<span class="string">"you file path"</span></span><br><span class="line">db = []  <span class="comment">#[score,nonclk,clk]</span></span><br><span class="line">pos, neg = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">with</span> open(evaluate_result,<span class="string">'r'</span>) <span class="keyword">as</span> fs:</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">		nonclk,clk,score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		nonclk = int(nonclk)</span><br><span class="line">		clk = int(clk)</span><br><span class="line">		score = float(score)</span><br><span class="line">		db.append([score,nonclk,clk])</span><br><span class="line">		pos += clk</span><br><span class="line">		neg += nonclk</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">db = sorted(db, key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算ROC坐标点</span></span><br><span class="line">xy_arr = []</span><br><span class="line">tp, fp = <span class="number">0.</span>, <span class="number">0.</span>			</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(db)):</span><br><span class="line">	tp += db[i][<span class="number">2</span>]</span><br><span class="line">	fp += db[i][<span class="number">1</span>]</span><br><span class="line">	xy_arr.append([fp/neg,tp/pos])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算曲线下面积</span></span><br><span class="line">auc = <span class="number">0.</span>			</span><br><span class="line">prev_x = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> xy_arr:</span><br><span class="line">	<span class="keyword">if</span> x != prev_x:</span><br><span class="line">		auc += (x - prev_x) * y</span><br><span class="line">		prev_x = x</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"the auc is %s."</span>%auc</span><br><span class="line"></span><br><span class="line">x = [_v[<span class="number">0</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">y = [_v[<span class="number">1</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">pl.title(<span class="string">"ROC curve of %s (AUC = %.4f)"</span> % (<span class="string">'svm'</span>,auc))</span><br><span class="line">pl.xlabel(<span class="string">"False Positive Rate"</span>)</span><br><span class="line">pl.ylabel(<span class="string">"True Positive Rate"</span>)</span><br><span class="line">pl.plot(x, y)<span class="comment"># use pylab to plot x and y</span></span><br><span class="line">pl.show()<span class="comment"># show the plot on the screen</span></span><br></pre></td></tr></table></figure></p>
<p>输入的数据集可以参考<a href="/img/AUC-Calculation-by-Python/evaluate_result.txt">svm预测结果</a><br>其格式为:</p>
<pre><code>nonclk <span class="string">\t</span> clk <span class="string">\t</span> score
</code></pre><p>其中：</p>
<ol>
<li><code>nonclick</code>:未点击的数据，可以看做负样本的数量</li>
<li><code>clk</code>:点击的数量，可以看做正样本的数量</li>
<li><code>score</code>:预测的分数，以该分数为group进行正负样本的预统计可以减少<code>AUC</code>的计算量</li>
</ol>
<p>运行的结果为:</p>
<center><img src="/img/AUC-Calculation-by-Python/auc.png" width="500px"></center>


<blockquote>
<p>如果本机没安装<code>pylab</code>可以直接注释依赖以及画图部分</p>
</blockquote>
<h2 id="注意">注意</h2><p>上面贴的代码:</p>
<ol>
<li>只能计算二分类的结果（至于二分类的标签随便处理）</li>
<li>上面代码中每个<code>score</code>都做了一次阈值，其实这样效率是相当低的，可以对样本进行采样或者在计算横轴坐标时进行等分计算</li>
</ol>
<h2 id="参考">参考</h2><ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm" target="_blank" rel="external">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm</a></li>
</ul>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LambdaRank-支持非平滑损失函数的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/08/28/Machine%20Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/"/>
    <id>http://kubicode.me/2016/08/28/Machine Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/</id>
    <published>2016-08-28T14:44:59.000Z</published>
    <updated>2016-09-06T15:59:12.000Z</updated>
    <content type="html"><![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br><a id="more"></a></p>
<p><center><img src="/img/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/rank.png" alt=""><br>图1</center><br>如图1，每个线条表示一个文档，位置越上面表示排序越靠前，其中蓝色线条表示相关的文档，灰色则是不相关的文档，计算左侧得到的<code>Pairwise Error</code>为13，此时将最上面的蓝色线条下移3个位置，将下面的蓝色线条上移5个位置，则其<code>Pairwise Error</code>下降到了11。然而传统的排序评估指标<code>NDCG</code>或者<code>ERR</code>都是比较关心靠前的位置，类似刚刚右侧的变化并不希望出现。<br>而<code>LambdaRank</code>可以支持对这种非平滑的评估指标(比如<code>NDCG</code>)进行直接的优化.</p>
<h2 id="LambdaRank原理">LambdaRank原理</h2><p>在图1右侧中，我们用$D_i$和$D_j$分别表示上下两个相关的文档，对于训练时下一次的移动中，我们更加愿意看到红色箭头的变化，因为此时$D_i$移动头部比$D_j$移动到头部明显代价更小，并且同样能减少损失函数.<br>对于$i &lt;&lt; j$这种情况($D_i$排在前面)，<code>LambdaRank</code>将会有:<br>$$|\frac{\partial C}{\partial o_i}| &gt;&gt; |\frac{\partial C}{\partial o_j}|$$</p>
<p>同时，<code>LambdaRank</code>并不是显示对的优化函数进行求导在求最优，而是<br>$$\frac{\partial C}{\partial o_i} = -\lambda_i(o_1,l_1…o_n,l_n)$$，</p>
<blockquote>
<p>$o_i$表示给定query下文档的打分值,$l_i$表示该文档对应的标签</p>
</blockquote>
<p>可以看到这个梯度是依赖<code>query</code>下全部文档的分数以及其标签,这也应该是算一个<code>ListWise</code>的学习方法了,其中式子中带了符号表示$\lambda_i$为正数时将会在排序列表中向上移动同时会降低损失函数的值.<br>那么问题来了，这个$\lambda$函数该如何选呢?</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的神经网络加速算法中，其<br>$$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} =  -\frac{1}{1+e^{o_i-o_j}} $$</p>
<blockquote>
<p>这里目标概率$\overline{P}_{i,j}=1$</p>
</blockquote>
<p><code>LambdaRank</code>的机智之处就是在计算$\lambda_{i,j}$的时候引入了优化指标的梯度,变成了<br>$$\lambda_{i,j} =  -\frac{1}{1+e^{o_i-o_j}} |\Delta Z|$$<br>其中$\Delta Z$表示将文档$D_i$和$D_j$的位置相关调换之后重新计算得到的评估指标的差值（此时其他的文档顺序是不变的）<br>即可从新计算得到$\lambda_i$为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$<br>这个$\lambda$可以理解为上面图中的箭头<code>方向和强度</code></p>
<ol>
<li>符号表示方向，正好为向上移动</li>
<li>大小表示强度，绝对值越大，表示移动的距离越大</li>
</ol>
<p>接下来<code>LambdaRank</code>具体的训练和使用方式就即可和<code>RankNet</code>一致了.</p>
<p>这个的$\Delta Z$可以替换成任何评估指标(比如<code>NDCG</code>、<code>ERR</code>)了，这样的话其实$LambdaRank$就可以变相的直接对学习排序的评估指标进行优化了，解决了之前评估指标由于是非凸无法进行优化的问题</p>
<blockquote>
<p>这个具体的证明要看去原始paper了[1],是一个不是很容易理解的东西 -_-||</p>
</blockquote>
<h2 id="总结">总结</h2><p>$LambdaRank$其实是做了两个大贡献:</p>
<ol>
<li>一是对传统的<code>RankNet</code>提出了一个加速算法（我直接将其丢了<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的学习中）</li>
<li>二是在<code>RankNet</code>的优化目标的基础上添加了一个基于评估指标的梯度$\Delta Z$因子，可以变相的直接对学习排序的评估指标进行优化</li>
</ol>
<p>虽然貌似没有见一些其他工业上说明使用了该算法，但是该算法对于鼎鼎大名的<code>LambdaMart</code>的启发无疑是最大的。</p>
<h2 id="参考">参考</h2><ol>
<li>Schölkopf, B, Platt, J, Hofmann, T. Learning to Rank with Nonsmooth Cost Functions[C]// MIT Press, 2007:193 - 200.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankNet:基于梯度下降的学习排序]]></title>
    <link href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/"/>
    <id>http://kubicode.me/2016/05/30/Machine Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/</id>
    <published>2016-05-30T11:51:21.000Z</published>
    <updated>2016-09-22T17:33:19.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>
<a id="more"></a>
<p>我们现在将$P(D_i \triangleright D_j)$前后顺序的预测概率表示为$P_{i,j}$,同时定义$o_i \equiv f(x_i)$ 以及 $o_{i,j}=f(x_i)-f(x_j)$，则我们可以<code>logistic</code>函数来表示$P_{i,j}$:<br>$$P_{i,j} \equiv \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} \equiv \frac{1}{1+e^{-o_{i,j}}}$$</p>
<p>为了衡量预测概率$P_{i,j}$与期望/目标概率$\bar{P}_{i,j}$的接近程度，这里使用<code>Cross Entropy</code>作为损失函数:<br>$$C_{i,j} = -\bar{P}_{i,j} log P_{i,j} - (1-\bar{P}_{i,j}) log (1-P_{i,j})$$</p>
<p>将$P_{i,j}$代入损失函数$C_{i,j}$之后即可得到:<br>$$\begin{equation}\begin{split}C_{i,j}&amp;=-\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (1-\frac{e^{o_{i,j}}}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (\frac{1}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} \left( log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - log (\frac{1}{1+e^{o_{i,j}}}) \right) - log (\frac{1}{1+e^{o_{i,j}}})  \\<br>&amp;= -\bar{P}_{i,j}  o_{i,j} + log(1+e^{o_{i,j}})<br>\end{split}\end{equation}$$</p>
<p>下面的图是当$\bar{P}_{i,j} \in \{0,0.5,1\}$时的损失函数情况:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/lossfunction.png" style="align:center;margin:0 auto" width="400px"></p>
<p>当$\bar{P}_{i,j} = 1$的时候，<code>Cross Entropy</code>的损失函数将会变为:$$C_{i,j}=log(1+e^{-o_{i,j}})$$<br>直接会变为一个<code>log</code>型的损失函数，其中$o_i-o_j$越大，损失函数的值也就会越小，这也是我们所期望训练的结果(表示我们的样本全部成立)</p>
<p>现我们损失函数$C_{i,j}$求$o$的偏导:<br>$$\frac{ \partial{C}}{ \partial{o_i}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) =\left( -\bar{P}_{i,j}+P_{i,j} \right) = -\frac{ \partial{C}}{ \partial{o_j}}$$</p>
<blockquote>
<p>其实可以发现就是在$-\bar{P}_{i,j}+P_{i,j}=0 $时就是我们的目标<br>另外请注意这里的$P_{i,j}$其实就是<code>文献2</code>中的$S_{i,j}$，但是由于他们的取值范围不一致 $P_{i,j} \in \{0,0.5,1\}$,$S_{i,j} \in \{-1,0,1\}$，因此导致了<code>文献2</code>中对于<code>C</code>的偏导与本文的有微小的偏差</p>
</blockquote>
<p>现我们认为$w$为$o=f(x:w)$的一个权重,也就是我们最终希望求解的值，而这个参数我们就可以使用<code>随机梯度下降法来求解</code>:<br>$$w_k \rightarrow  w_k - \eta \frac{\partial{C}}{\partial{w_k}} = w_k - \eta \left( \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}} \right)$$</p>
<p>其中$\eta$表示学习率，一般取一个比较小的数（比如:$1e-3$,$1e-5$）<br>另外我们可以求得$C$的增量变化:<br>$$\Delta C = \sum_k \frac{\partial{C}}{\partial{w_k}} \Delta w_k = \sum_k \frac{\partial{C}}{\partial{w_k}} \left( - \eta \frac{\partial{C}}{\partial{w_k}} \right) = - \eta \sum_k \left( \frac{\partial{C}}{\partial{w_k}} \right)^2  &lt; 0 $$</p>
<ol>
<li>$\Delta C &lt; 0 $表示随着权重参数$w$的沿着负梯度的变化，损失函数$C$会越来越小</li>
<li>另外当梯度$\frac{\partial{C}}{\partial{w_k}} = 0$时，才会让损失函数达到最小值</li>
</ol>
<p>上面的式子告诉我们通过梯度下降法求解<code>RankNet</code>时，就算<code>算分</code>函数没有好的梯度或者不可求导时任可以进行权重的更新（直接对$o$进行梯度下降，但是其梯度方向需要自己指定，并且要求权重$w$与最终的算法$o$是相关的）。</p>
<h2 id="合并概率">合并概率</h2><p>理想的情况下，$\bar{o}$的输出得到的模型应该是这样纸的:$$\bar{P}_{i,j}=\frac{e^{\bar{o}_{i,j}}}{1+e^{\bar{o}_{i,j}}}$$</p>
<blockquote>
<p>其中$\bar{o}_{i,j}=\bar{o}_i-\bar{o}_j$</p>
</blockquote>
<p>上面的模型需要$\bar{P}_{i,j}$保持一致性，也就是如果$D_i$的相关性要高于$D_j$,$D_j$的相关性同时也是要高于$D_k$，则$D_i$的相关性也是一定要高于$D_j$，如果没有保持一致性，其实上面的理论就不好使了。。。<br>现给定$\bar{P}_{i,j}$和$\bar{P}_{j,k}$时会有:</p>
<p>$$\begin{equation}\begin{split} \bar{P}_{i,k}&amp;= \frac{e^{\bar{o}_{i,k}}}{1+e^{\bar{o}_{i,k}}}\\<br>&amp;= \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}} \\<br>&amp;= \frac{ \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})} }{ \frac{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{\frac{(1+e^{\bar{o}_{i,j}}+e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})+(2e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{i,j}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{1+2\bar{P}_{i,j}\bar{P}_{j,k}-\bar{P}_{i,j}-\bar{P}_{j,k}}<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>其中第一步是基于这个来的:$$\begin{equation}\begin{split}e^{\bar{o}_{i,k}}&amp;=e^{\bar{o}_i-\bar{o}_k} \\<br>&amp;= e^{\bar{o}_i-\bar{o}_j+\bar{o}_j-\bar{o}_k}\\<br>&amp;= e^{\bar{o}_{i,j}+\bar{o}_{j,k}}  \\<br>&amp;= e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}}<br>\end{split}\end{equation}$$</p>
</blockquote>
<p>当$\bar{P}_{i,j}=\bar{P}_{i,k}=P$时，其$\bar{P}_{i,k}$的取值情况为:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/pik.png" width="400px"></p>
<ol>
<li>$P=0$时，有$\bar{P}_{i,k}=P=0$ 表示:$D_i$排$D_j$后面,$D_j$排$D_j$的后面，则$D_i$也一定排$D_j$的后面</li>
<li>$0 &lt; P &lt; 0.5$时，$\bar{P}_{i,k} &lt; P$</li>
<li>$P=0.5$时，有$\bar{P}_{i,k}=P=0.5$ 表示:$D_i$有一般概率排$D_j$前面,$D_j$也有一半的概率排$D_j$的前面，则$D_i$同样也是一半的概率排$D_j$的前面</li>
<li>$0.5 &lt; P &lt; 1$时，$\bar{P}_{i,k} &gt; P$</li>
<li>$P=1$时，有$\bar{P}_{i,k}=P=1$ 表示:$D_i$排$D_j$前面,$D_j$排$D_j$的前面，则$D_i$也一定排$D_j$的前面</li>
</ol>
<blockquote>
<p>从上面的图中可以看到，其实目标概率是都可以保持一致性的.</p>
</blockquote>
<h2 id="神经网络训练">神经网络训练</h2><p><code>RankNet</code>使用的是一个2层的神经网络作为算分模型$f(x:w,b)$,他在排序分数的公式是:<br>$$o = f(x:w,b) = f^{(2)}  \left( \sum_l w_l^{(2)} \cdot f^{(1)}  \left( \sum_k w_{lk}^{(1)}x_k +b^{(1)} \right) +b^{(2)} \right)$$</p>
<p>其中:</p>
<ol>
<li>$x_k$表示输入的$k$个特征元素</li>
<li>$w$表示每一层的权重,$b$表示每一层的偏置，上标$(\cdot)$表示当前所属的神经网络的层数</li>
<li>下标$l$表示第一层的单元数量</li>
<li>$f$使用<code>sigmoid</code>作为激活函数</li>
</ol>
<p>在对于上面的二层神经网络求解时:<br>$$\frac{\partial{C}}{\partial{b^{(2)}}} = \lambda_{i,j}({f’}_i^{(2)}-{f’}_i^{(2)}) = \Delta_i^{(2)} - \Delta_j^{(2)} \\<br>\frac{\partial{C}}{\partial{w^{(2)}}} = \Delta_i^{(2)}f_i^{(1)}  - \Delta_j^{(2)}f_j^{(1)} \\<br>\frac{\partial{C}}{\partial{b^{(1)}}} = \Delta_i^{(2)}f_i^{(1)}w^{(2)}   - \Delta_j^{(2)}f_j^{(1)}w^{(2)} \\<br>\frac{\partial{C}}{\partial{w_k^{(1)}}} = \Delta_i^{(2)} x_{i,k} - \Delta_j^{(2)} x_{j,k}<br>$$<br>这样神经网络就可以使用<code>前向预测</code>和<code>后向反馈</code>来进行训练了,只是其后向反馈阶段是需要通过<code>pair</code>进行计算的。</p>
<h2 id="神经网络加速">神经网络加速</h2><p>这里我们输入的样本是<code>pair</code>对$\{(x_i,x_j),\bar{P}_{i,j}\}$,其中$\bar{P}_{i,j}$就是我们的目标概率,根据第一小节(算法原理)中指到的，使用梯度下降法进行求解:<br>$$\begin{equation}\begin{split} \frac{\partial{C}}{\partial{w_k}} &amp;= \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}}  \\<br>&amp;=  \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right)\\<br>&amp;=  \lambda_{i,j} \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right) \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>记$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) $</p>
</blockquote>
<p>上面的是对于每一对<code>pair</code>都会进行一次权重的更新，其实是可以对同一个query下的所有文档<code>pair</code>全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数，其更新的公式为:</p>
<p>$$\Delta w_k = -\eta \sum_{\{i,j\}\in I}  \left(\lambda_{i,j} \frac{\partial{o_i}}{\partial{w_k}} - \lambda_{i,j} \frac{\partial{o_j}}{\partial{w_k}}\right) = -\eta \sum_i \lambda_i \frac{\partial{o_i}}{\partial{w_k}} $$</p>
<blockquote>
<p>$I$表示某个<code>query</code>下所有不同排序的<code>pair</code>出现一次的集合，$\{i,j\}$表示两个文档满足$D_i \triangleright D_j$,也就是$\bar{P}_{i,j}=1$</p>
</blockquote>
<p>这里要着重介绍一下$\lambda_i$:</p>
<p>$\lambda$可以理解为某个给定query（给定排序）下第$i$个文档$D_i$的一个<code>值</code>,为了计算$\lambda_i$，需要找到这个排序下所有排在$D_i$前面的文档$D_j$（此时有$\{i,j\} \in I$），以及所有排在$D_i$后面的文档$D_k$（有$\{k,i\} \in I$）,同时针对$\lambda_{i,j}$的文档进行累加，对于$\lambda_{k,i}$的文档进行累减.</p>
<blockquote>
<p>比如  当前排序下只有一个pair,有$I=\{\{1,2\}\}$，则有$\lambda_1 = \lambda_{1,2} = -\lambda_2$<br>又比如，当前排序下有三个pair，有$I=\{\{1,2\},\{1,3\},\{2,3\}\}$,则有$\lambda_1 = \lambda_{1,2}+\lambda_{1,3}$、$\lambda_2 = \lambda_{2,3}-\lambda_{1,2}$、$\lambda_3 = -\lambda_{1,3}-\lambda_{2,3}$</p>
</blockquote>
<p>对于表示成式子为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$</p>
<p>因此，我们可以认为$\lambda_i$为在某个给定<code>query</code>的$D_i$需要移动的方向以及移动的强度,另外这种方式可以看做是一种mini-batch的梯度下降算法，不要将全部的<code>pair</code>进行反向传播,其复杂度可以降到$O(n_q)$可以大大加快原始的神经网络训练.这也为<code>LambdaRank</code>奠定了基础（其实很多在<code>LambdaRank</code>的paper提出来的）</p>
<h2 id="总结">总结</h2><p><code>RankNet</code>训练希望文档<code>pair</code>对的前后排序概率与目标概率一致，用交叉熵作为损失函数，在实际排序中使用了神经网络作为算分排序函数，同时可以有<code>min-batch</code>的批量训练方法。据说微软的<code>Bing</code>之前使用着他.</p>
<h2 id="参考">参考</h2><ol>
<li>Burges, Chris, et al. “Learning to rank using gradient descent.” Proceedings of the 22nd international conference on Machine learning. ACM, 2005.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GBRank:一种基于回归的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/05/08/Machine%20Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/"/>
    <id>http://kubicode.me/2016/05/08/Machine Learning/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/</id>
    <published>2016-05-08T09:30:39.000Z</published>
    <updated>2016-05-08T15:27:47.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting" target="_blank" rel="external">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/" target="_blank" rel="external">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br><a id="more"></a></p>
<p>从$R(h)$可以知道知道每个<code>pair</code>对$\left \langle x_i,y_i \right \rangle$的cost为:</p>
<p><center><img src="/img/GBRank-A-PairWsie-LTR-Base-on-Regression-Framework/cost_function.png" width="400px"></center><br>可以发现当:</p>
<ol>
<li>$h(x_i) \geq h(y_i)$，cost代价为0，也就是并不会对最终的风险函数的值产生影响</li>
<li>$h(x_i) &lt; h(y_i)$，cost代价为其差值的平方</li>
</ol>
<p>上述风险函数直接优化比较困难，这里一个巧妙的解决方案时使用回归的方法，也就是$x_i$或者$y_i$去拟合他们另个预测值目标。<br>为了避免优化函数$h$是一个常量，风险函数一般情况下会加上一个平滑项$\tau$($0 &lt; \tau \leq 1$)：$$R(h,\tau ) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)+\tau \} \right)^2 -\lambda \tau^2 $$</p>
<blockquote>
<p>因为当$h$为常量函数时，先前的$R(h)=0$就没有再优化的空间了<br>其实加了平滑项就变相的转为:如果希望$x_i \succ y_i$，就得有$h(x_i) &gt; h(y_i)+\tau$，也就是更为严格了，多了一个<code>gap</code></p>
</blockquote>
<p>对于$R(h)$计算$h(x_i)$和$h(y_i)$的负梯度为:$$max\{0,h(y_i)-h(x_i)\} \quad,\quad -max\{0,h(y_i)-h(x_i)\}$$<br>可以发现当<code>pair</code>对符合$\left \langle x_i,y_i \right \rangle$的顺序时，上述的梯度均为0，对于这类<code>case</code>就没有必要在去优化了(以为已经满足目标了)，但是对于另一类，如果$h$不满足<code>pair</code>$\left \langle x_i,y_i \right \rangle$，他们对应的梯度为:$$h(y_i)-h(x_i) \quad,\quad h(x_i)-h(y_i)$$</p>
<blockquote>
<p>因为此时$h(y_i)&gt;h(x_i)$<br>还有对于上面两个梯度的后面那个式子存在的意义不是很理解-_-</p>
</blockquote>
<p>到了这儿，我们知道所谓的训练样本就是对于$x_i \succ y_i$但是$h(y_i) &gt; h(x_i)$，并且使用的是回归方法，<code>GBRank</code>为其巧妙的找了训练的目标:$x_i$的目标为$h(y_i)+ \tau$以及$y_i$的目标为$h(x_i)- \tau$，也就是在每次迭代是将会构建以下训练集:$$\{(x_i,h(y_i)+\tau),(y_i,h(x_i)-\tau)\}$$</p>
<h2 id="算法步骤">算法步骤</h2><p><code>GBRank</code>使用<code>GBT</code>为回归函数，所以整个<code>GBRank</code>的算法过程为:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集,真实的排序pair对$S=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>迭代的次数:$K$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$h(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>随机初始化为一个函数$h_o$</li>
<li>循环$k \in \{1….K\}$<ol>
<li>使用$h_{k-1}$作为近似的$h$函数,我们将对样本的计算结果分到两个不相交的集合:$$S^+=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) \geq h_{k-1}(y_i)+\tau \}$$和$$S^-=\{\left \langle x_i,y_i \right \rangle \in S | h_{k-1}(x_i) &lt; h_{k-1}(y_i)+\tau \}$$</li>
<li>使用<code>GBT</code>对下面的数据集拟合一个回归函数$g(x)$:$$\{(x_i,h_{k-1}(y_i)+\tau),(y_i,h_{k-1}(x_i)-\tau) | (x_i,y_i) \in S^- \}$$</li>
<li>进行模型的更新:$$h_k(x) = \frac{kh_{k-1}(x)+\eta g_k(x)}{k+1}$$其中$\eta$为收缩因子</li>
</ol>
</li>
<li>输出最终的模型$h_k(x)$</li>
</ol>
<blockquote>
<p>注意了，其实这里的回归函数还可以使用其他的回归函数来代替，比如$Linear Regression$之类的</p>
</blockquote>
<h2 id="总结">总结</h2><p>$h(x)$为最终的排序函数，<code>GBRank</code>在训练时每次迭代中将$h_k(x)$的排序结果与真实结果不一样的样本（就是分错的样本）单独拿出来做训练样本，并且其训练目标为<code>pair</code>的另一个预测值作为回归目标，非常巧妙。<br>此时重新看这个<code>GBRank</code>模型与<code>AdaBoost</code>、<code>GBT</code>其实很大同小异，都是将上一次训练中分错的样本再拿来训练，也是一个提升的模型</p>
<p>在其paper中的实验结果也是要略好于$RankSvm$，但是其比较疼的时其训练还是比较复杂的，或者说比较耗时,其预测也会比较麻烦一点，所以使用时得慎重~</p>
<h2 id="参考">参考</h2><p>[1]. 2007-GBRank-A Regression Framework for Learning Ranking Functions Using Relative Relevance Judgments</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>GBRank</code>是一种<code>pairwise</code>的学习排序算法，他是基于回归来解决<code>pair</code>对的先后排序问题。在<code>GBRank</code>中，使用的回归算法是<code>GBT(Gradient Boosting Tree)</code>，可以参考<a href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/#Gradient_tree_boosting">这个</a>，<code>pairwise</code>相关的可以参考<a href="http://kubicode.me/2016/04/10/Machine%20Learning/LTR-Pairwise-Study/">这个</a></p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>一般来说在搜索引擎里面，相关性越高的越应该排在前面。现在<code>query-doc</code>的特征使用向量$x$或者$y$表示，假设现在有一个文档对$\left \langle x_i,y_i \right \rangle$，当$x_i$排在$y_i$前面时，我们使用$x_i \succ y_i$来表示。</p>
<p>我们含顺序的<code>pair</code>对用如下集合表示(也就是真的$x_i$真的排在$y_i$前面):$$S=\{ \left \langle x_i,y_i \right \rangle | x_i \succ y_i,i = 1…N \}$$</p>
<p>现假设学习的排序函数为$h$，我们希望当$h(x_i)&gt;h(y_i)$时，满足$x_i \succ y_i$的数量越多越好.<br>现在将$h$的风险函数用如下式子表示:$$R(h) = \frac{1}{2} \sum_{i=1}^N \left( max\{0,h(y_i)-h(x_i)\} \right)^2$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在CentOS上自己安装python]]></title>
    <link href="http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/"/>
    <id>http://kubicode.me/2016/04/29/Python/Python-Install-on-CentOS/</id>
    <published>2016-04-29T07:50:41.000Z</published>
    <updated>2016-08-29T08:22:44.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id="下载python2-6-5">下载python2.6.5</h3><p>直接在这个地址进行下载即可<a href="https://www.python.org/download/releases/2.6.5/" target="_blank" rel="external">https://www.python.org/download/releases/2.6.5/</a></p>
<h3 id="进行解压">进行解压</h3><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">tar</span> xvf Python-<span class="number">2</span>.<span class="number">6</span>.<span class="number">5</span>.tgz</span><br></pre></td></tr></table></figure>
<h3 id="编译安装">编译安装</h3><p>先配置安装的前缀<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.<span class="regexp">/configure --prefix=/u</span>sr<span class="regexp">/local/</span>python2.<span class="number">6.5</span></span><br></pre></td></tr></table></figure></p>
<p>然后真正的执行编译安装<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make</span></span><br><span class="line"><span class="built_in">make</span> install</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意如果是非管理员用户 请在两个<code>make</code>前面都加上<code>sudo</code></p>
</blockquote>
<h3 id="添加快捷方式">添加快捷方式</h3><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -sf <span class="regexp">/usr/</span>local<span class="regexp">/python2.6.5/</span>bin<span class="regexp">/python /u</span>sr<span class="regexp">/bin/</span>python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果原来快捷方式存在  那么先删除，再添加</p>
</blockquote>
<h3 id="完工">完工</h3><pre><code><span class="keyword">python</span> --<span class="keyword">version</span>
Python <span class="number">2.6</span>.<span class="number">5</span> 
</code></pre><h3 id="参考">参考</h3><p><a href="http://blog.csdn.net/jationxiaozi/article/details/7665691" target="_blank" rel="external">CentOS5.5下安装python2.6</a>   实用，但是排版太难看了-_-</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>CentOS</code>自带的<code>python</code>一般都是<code>2.4.3</code>，因为某些特殊的需求需要将其升级到<code>2.6.2</code></p>
</blockquote>
<h3 id=]]>
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从Gradient Boosting 到GBT]]></title>
    <link href="http://kubicode.me/2016/04/24/Machine%20Learning/From-Gradient-Boosting-to-GBT/"/>
    <id>http://kubicode.me/2016/04/24/Machine Learning/From-Gradient-Boosting-to-GBT/</id>
    <published>2016-04-24T15:51:08.000Z</published>
    <updated>2016-05-02T15:48:21.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br><a id="more"></a></p>
<p>现在假如训练完$G_{m+1}$可以得到完美的$f_{m+1}$，那么也就是有:$$f_{m+1} = f_m+G_{m+1}=y$$<br>这个式子可以写成$$G_{m+1}=y-f_m$$ 其中$y-f_m$表示上一次迭代得到分类器预测结果与真实结果的差值，我们一般称之为的<code>残差</code>(residual)，因此也可以理解为<code>Gradient Boosting</code>在每一轮训练新的分类器将会拟合<code>残差</code>进行最优化</p>
<h2 id="Gradient_Boosting算法">Gradient Boosting算法</h2><p>假设现有训练集$\left\{ (x_1,y_1),(x_2,y_2)…(x_n,y_n)  \right\}$，其中$x$是特征向量，$y$是相应的训练目标，在给定相应的损失函数$L(y,f(x))$,我们的目标是找到一个近似的函数$f(x)$使得与真实函数$f^*(x)$的损失最小期望值最接近:$$f^* = \underset{f}{argmin} E_{x,y} \left[ L(y,f(x)) \right]$$</p>
<p><code>Gradient Boosting</code>方法假设$y$是一个实值，而$f(x)$近似目标函数是一个弱分类器$G_m(x)$加权求和的形式$$f(x)=\sum_{m=1}^M \gamma_mG_m(x)+const$$ 根据经验风险最小化的原则，近似函数$f(x)$将会尝试对训练集上的平均损失函数进行最小化，它从一个常量函数进行起步，并且通过贪心的方式进行逐步优化<br>$$<br>f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) \\<br>f_m(x) = f_{m-1}(x) + \underset{G \in H}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+G_m(x_i) \right)<br>$$<br>然而，对于$L$为任意的损失函数时,在选择每一步最佳的$G_m(x_i)$时将会很难优化。<br>这里使用最速下降法(<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">steepest descent</a>)来解决这个问题<br>,在使用这种方法时，对于损失函数$L(y,G)$不要将其看做一个函数，而是将其看做通过函数得到的值的向量$G(x_1),G(x_2)…G(x_n)$,那么这样的话我们就可以将模型的式子写成如下的等式:<br>$$<br>f_m(x) = f_{m-1}(x) - \gamma_m \sum_{i=1}^n \triangledown_G L \left( y_i,f_{m-1}(x_i) \right) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left ( y_i,f_{m-1}(x_i)-\gamma \frac{\partial L(y_i,f_{m-1}(x_i))}{\partial G(x_i)}  \right )<br>$$<br>上面第一个式子表示根据梯度的负方向进行更新,第二个式子表明了$\gamma$使用线性搜索进行计算。</p>
<p>下面就是具体的<code>gradient boosting</code>步骤:<br><strong>Input</strong>:</p>
<ul>
<li>训练数据集$T=\{(x_1,y_1),(x_2,y_2)…(x_N,y_N)\}$</li>
<li>可导的损失函数:$L(y,f(x))$</li>
<li>迭代的次数:$M$</li>
</ul>
<p><strong>Output</strong>:</p>
<ul>
<li>最终模型$f(x)$</li>
</ul>
<p><strong>Procedure</strong>:</p>
<ol>
<li>使用一个常量进行模型的初始化$$f_0(x) = \underset{\gamma}{argmin} \sum_{i=1}^n L(y_i,\gamma) $$</li>
<li>循环$m \in \{1….M\}$<ol>
<li>计算残差$$r_{im}=-\left[ \frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}  \right]_{f(x_i)=f_{m-1}(x_i)} \quad i=1…n$$</li>
<li>使用训练集$\{ (x_i,r_{im}) \}$对弱分类器$G_m(x)$进行拟合</li>
<li>通过线性搜索进行乘子$\gamma_m$的计算$$\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)$$</li>
<li>进行模型的更新:$$f_m(x) = f_{m-1}(x)+\gamma_m G_m(x)$$</li>
</ol>
</li>
<li>输出最终的模型$f_M(x)$</li>
</ol>
<p>下面是来自[2]中的对于不同损失函数下不同残差的计算<br><img src="/img/From-Gradient-Boosting-to-GBT/loss_functions.png" width="500px"><br>可以发现当损失函数为最小平方差时残差就是真实值与预测值的差值</p>
<h2 id="Gradient_tree_boosting">Gradient tree boosting</h2><p>提升树(Gradient tree boosting)故名思议就是使用决策树(一般使用<code>CART</code>树)来作为弱分类器.<br>提升树在第$m$步迭代时将会使用决策树$G_m(x)$来集合残差，现在假设这棵树有$J$个叶子节点，则决策树将会将空间划分为$J$个不相交的区域$R_{1m},R_{2m}…R_{3m}$，以及每个区域都是预测一个常量值，则树模型$G_m(x)$对于特征$x$的输入将可以写成$$G_m(x)=\sum_{j=1}^J b_{jm}I(x \in R_{jm})$$，其中$b_{jm}$表示每个区域的预测值，上面的介绍可以用下图来表示:</p>
<center><img src="/img/From-Gradient-Boosting-to-GBT/cart.png" width="400px"></center>

<p>在实际使用时，$b_{jm}$也会与一个乘子$\gamma_m$相乘,最终模型的训练与上面一小节的介绍一致:<br>$$<br>f_m(x)=f_{m-1}(x)+\gamma_mG_m(x) \\<br>\gamma_m = \underset{\gamma}{argmin} \sum_{i=1}^n L \left(y_i,f_{m-1}(x_i)+\gamma_m G_m(x_i) \right)<br>$$</p>
<blockquote>
<p>可以发现树的模型是关键，一般来时$4 \leq J \leq 8$比较合适，有时候$J=2$就足够了，并且$j &gt; 10$比较少用</p>
</blockquote>
<h2 id="正则化">正则化</h2><blockquote>
<p>其实用过<code>Gradient Boosting</code>的同学应该有同感，<code>Gradient Boosting</code>类型的模型(<code>GBDT</code>)调参很重要-_-，大致可以发现这些参数就是正则化的关键</p>
</blockquote>
<h3 id="调整树的个数">调整树的个数</h3><p>树的个数$M$越多，过拟合的情况可能越为严重，这里树的个数一般使用交叉验证的误差来调整确定</p>
<h3 id="Shrinkage">Shrinkage</h3><p><code>Shrinkage</code>又称学习率，是指在<code>Gradient Boosting</code>训练时不训练全部的残差，而是:$$f_m(x)=f_{m-1}(x)+v \cdot \gamma_mG_m(x) \quad 0 &lt; v \leq 1$$<br>经验表明较小的学习率($v &lt; 0.1$)将会取得较为明显的正则化效果，但是学习率太小会导致训练次数增加..</p>
<blockquote>
<p>感觉这个大致可以这么理解，如果$v=1$，弱分类器犯错一次真的就错了，但是如果$v &lt; 1$时，如果某个分类器犯错了，其他的的弱分类器可能还可以补救^_^</p>
</blockquote>
<h3 id="Stochastic_gradient_boosting">Stochastic gradient boosting</h3><p>随机梯度提升法，表示每一轮迭代时并不是拿所有的数据进行训练，所以按无放回的随机取一定的比率$\eta$进行训练，这里的$ 0.5 &lt; \eta &lt; 0.8$将会取得较为不错的正则化效果，同时随机取样本进行训练还能加快模型的训练速度，并且每次迭代中未被抽中的样本还可以作为(out of bag)[<a href="https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计" target="_blank" rel="external">https://en.wikipedia.org/wiki/Out-of-bag_error]进行估计</a></p>
<h3 id="叶子节点的数量">叶子节点的数量</h3><p>一般这个叶子节点的数量不宜太多（其实可以理解为节点数越多，模型复杂度越高…）</p>
<h3 id="使用惩罚项">使用惩罚项</h3><p>额~貌似<code>L2</code>之类的惩罚项也是可以被加入进去</p>
<h2 id="总结">总结</h2><p><code>Gradient Boosting</code>是非常金典而又重要的提升方法，他与<a href="http://kubicode.me/2016/04/18/Machine%20Learning/AdaBoost-Study-Summary/" target="_blank" rel="external">AdaBoost</a>一样都是讲弱分类器合成强分类，但是其大致区别有:</p>
<ol>
<li><code>Gradient Boosting</code>通过残差来变量的改变错误分类的权重,而<code>AdaBoost</code>就真的直接去修改分类错误的训练权重了</li>
<li><code>Gradient Boosting</code>接入的分类器一般完整的决策树居多，但是<code>AdaBoost</code>一般使用二层决策树</li>
</ol>
<p><code>Gradient Boosting</code>中最有代表性的就是<code>GBDT</code>,该模型虽好，可不要贪杯~使用时理解数据以及正确调参才是王道</p>
<h2 id="参考">参考</h2><p>[1]. <a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="external">wiki Gradient boosting</a><br>[2]. The Elements of Statistical Learning<br>[3]. 《统计学习方法》.李航.第八章</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>本文大部分参考(译)自wiki[1]<br>如果说<code>Gradient Boosting</code>是一种机器学习算法框架的话，我想<code>GBT(Gradient Boosting Tree)</code>看做它的实现更为合适</p>
</blockquote>
<h2 id="Gradient_Boosting原理">Gradient Boosting原理</h2><blockquote>
<p>与其他<code>Boosting</code>方法一样，<code>Gradient Boosting</code>通过迭代将弱分类器合并成一个强分类器的方法。</p>
</blockquote>
<p>对于标准的$(x_i,y_i)$训练集，<code>Gradient Boosting</code>在迭代到第$m$次时，可能会得到一个分类能力不是很强的$f_m$模型，但是他下次迭代并不改变$f_m$，而是生成一个这样的新模型:$$f_{m+1} = f_m+G_{m+1}$$使得$f_{m+1}$较$f_m$而言拥有更为强大的分类能力，那么问题来了,这个$G_{m+1}$该如何训练呢?<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解决在使用scikit-learn时出现ValueError: numpy.dtype has the wrong size的错误]]></title>
    <link href="http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/"/>
    <id>http://kubicode.me/2016/04/22/Python/Solve-numpy-dtype-In-ValueError-when-using-scikit-learn/</id>
    <published>2016-04-22T01:33:55.000Z</published>
    <updated>2016-04-22T01:51:20.000Z</updated>
    <content type="html"><![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br><a id="more"></a><br>网上给的建议大都是直接卸载再全部重装，将<code>numpy</code>、<code>scipy</code>和<code>scikit-learn</code>全部卸载了，然后</p>
<pre><code>pip <span class="keyword">install</span> -U numpy scipy scikit-learn
</code></pre><p>装起来。结果一样有问题-_-</p>
<p>继续查资料时终于发现有用的方法了:<br><a href="http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling" target="_blank" rel="external">http://scikit-learn-general.narkive.com/kMA6mRCk/valueerror-numpy-dtype-has-the-wrong-size-try-recompiling</a></p>
<p>就是不用使用<code>pip install scikit-learn</code>安装，卸载之后直接使用git上<code>https://github.com/scikit-learn/scikit-learn</code>的自己安装</p>
<pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/scikit-learn/scikit-learn
<span class="keyword">make</span>
sudo <span class="keyword">python</span> setup.<span class="keyword">py</span> install
</code></pre><p>ps：这个时候直接安装可能会出</p>
<pre><code><span class="attribute">RuntimeError</span>: <span class="string">Running cythonize failed!</span>
</code></pre><p>Error提示,这时候安装一下<code>cpython</code>即可</p>
<pre><code>pip <span class="keyword">install</span> cython
</code></pre><p>最后全部安装完之后就可以正常使用了^_^</p>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<p>今天在尝试使用scikit-learn的<code>AdaBoost</code>模型时一直报错，</p>
<pre><code>Traceback (most recent call last):
File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/__init__.py"</span>, line <span class="number">57</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.base</span> import clone
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/base.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.utils</span><span class="class">.fixes</span> import signature
File <span class="string">"/Library/Python/2.7/site-packages/sklearn/utils/__init__.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;
from <span class="class">.murmurhash</span> import murmurhash3_32
File <span class="string">"numpy.pxd"</span>, line <span class="number">155</span>, <span class="keyword">in</span> init sklearn<span class="class">.utils</span><span class="class">.murmurhash</span> (sklearn/utils/murmurhash<span class="class">.c</span>:<span class="number">5029</span>)
ValueError: numpy<span class="class">.dtype</span> has the wrong size, try recompiling
</code></pre><p>以为是<code>numpy</code>包的问题:卸载重装之后还是照样有问题-_-<br>]]>
    
    </summary>
    
      <category term="Python" scheme="http://kubicode.me/tags/Python/"/>
    
      <category term="Python" scheme="http://kubicode.me/categories/Python/"/>
    
  </entry>
  
</feed>