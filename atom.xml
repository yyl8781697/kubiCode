<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Kubi Code'Blog]]></title>
  <subtitle><![CDATA[The palest ink is better than the best memory.]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://kubicode.me/"/>
  <updated>2019-11-01T10:02:41.669Z</updated>
  <id>http://kubicode.me/</id>
  
  <author>
    <name><![CDATA[Kubi Code]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[可解释性推荐系统]]></title>
    <link href="http://kubicode.me/2019/10/15/Deep%20Learning/Explainable-Recommendation/"/>
    <id>http://kubicode.me/2019/10/15/Deep Learning/Explainable-Recommendation/</id>
    <published>2019-10-15T03:15:05.000Z</published>
    <updated>2019-11-01T10:02:41.669Z</updated>
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>在出推荐结果的同时产出一个理由，告诉用户这个item为啥要推荐给你~</p>
<center><img src="/img/Explainable-Recommendation/why_rec.jpg" width="450px"></center><br><a id="more"></a><br>大致的概念总结起来是这么一个图：<br><center><img src="/img/Explainable-Recommendation/arch.png" width="650px"></center>

<p>下面列举了一些最近自己调研的方法和理解</p>
<h2 id="矩阵分解方法">矩阵分解方法</h2><h3 id="EFM">EFM</h3><p>经典的矩阵分解方法可以根据 <code>User-Item</code> 的行为矩阵进行分解，然后得到<code>User</code>向量和<code>Item</code>向量之后进行推荐，而<code>EFM</code>在矩阵分解的基础上加入了 <code>User/Item</code>的显式特征矩阵，使得在推荐结果上可以拿到对应的显式特征，从而进行推荐的可解释性，当然，这里的特征一般指的是<code>Aspect</code>的属性。</p>
<p>EFM在关键idea时推荐的同时给到用户比较关心的特征，在paper的场景中，给到用户评分行为，同时评分时会得到相应的评价文本，</p>
<center><img src="/img/Explainable-Recommendation/rating.png" width="450px"></center>

<p>这样就是这样的一个评分矩阵，其中左侧是用户的评分行为，左侧有对应的评价文本，作者对该评价文本进行情感分析，比如可以得到<code>(screen,1),(earphone,-1)</code>的情感，这里的<code>screen</code>和<code>earphone</code>这些属性就可以作为对应的”特征”，因为根据评论情况，用户对于”特征”会有偏好，同时<code>Item</code>方面也会对不同的”特征”差异。</p>
<p>因此借助用户的评论对其情感分析，可以构建<code>User-Feature</code>和<code>Item-Feature</code>的显示特征矩阵，<br>其中对于<code>User-Feature</code>的填充值为:</p>
<p>$$ X_{i,j}=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad u_i \quad not \quad mention \quad feature \quad F_j \\<br>1+(N-1)(\frac{2}{1+e^{-t_{i,j}}}-1) &amp; \quad else \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>其中N表示$t_{i,j} \in [1,N]$ 为实际评分分数，为$N$为最大评分分数</p>
</blockquote>
<p>同时对于<code>Item-Feature</code>的填充值为:</p>
<p>$$ Y_{i,j}=\left\{<br>\begin{aligned}<br>0 &amp; \quad if \quad p_i \quad not \quad reviewed \quad feature \quad F_j \\<br>1+\frac{N-1}{1+e^{-k \cdot s_{i,j}}} &amp; \quad else \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>其中$k$为该$F_j$在$p_i$上出现的次数，同时$s_{i,j}$就是对应的平均评分数</p>
</blockquote>
<p>因此可以用<code>X</code>来表示用户的显式特征矩阵，<code>Y</code>来表示<code>Item</code>的显式特征矩阵,利用矩阵分解，可以有</p>
<p>$X = U_1 V ^T \quad Y = U_2 V^T$</p>
<p>这样$U_1,U_2$分别为用户和item对应的显式向量矩阵，而$V$为特征的显示向量矩阵，如果根据这两个矩阵直接进行推荐，其优化函数为:</p>
<p>$$ \underset{U_1,U_2,V}{minimize} \left \{ \lambda_x \parallel U_1V^T - X \parallel _F^2 + \lambda_y \parallel  U_2V -Y \parallel _F^2  \right \} , st. U_1 \in R^{m \times r},U_2 \in R^{n \times r},V \in R^{p \times r}$$</p>
<p>这边的$\lambda_x$和$\lambda_y$是正则项因子，同时$r$就是为显示特征的向量大小.</p>
<p>而上面的式子仅为用户行为在显式特征部分的表示，这些显式特征并无法全部表示用户的行为（至少丢掉了用户对应<code>item</code>的偏好），因此还需要再加入用户的隐式偏好。<br>这边使用${r}’$来表示隐式特征向量的大小，,其中使用$H_1$和$H_2$分别来表示用户和<code>Item</code>的隐式偏好矩阵，其中<code>A</code>为用户对于<code>Item</code>的评分矩阵，这里另$P=[U1,H1]$和$Q = [U2,H2]$,他们以拼接的方式来表示用户和<code>Item</code>的全部信息，则希望$$PQ^T \approx A$$。</p>
<center><img src="/img/Explainable-Recommendation/efm_integr.png" width="450px"></center>


<p>因此最终的优化函数为<br>$$ \underset{U_1,U_2,V,H_1,H_2}{minimize} \left \{ \parallel PQ^T - A \parallel _F^2 + \lambda_x \parallel U_1V^T - X \parallel _F^2 + \lambda_y \parallel  U_2V -Y \parallel _F^2 + \\ \lambda_u (\parallel U_1 \parallel^2 + \parallel U_2 \parallel^2  ) + \lambda_h (\parallel H_1 \parallel^2 + \parallel H_2 \parallel^2 ) + \lambda_v \parallel V \parallel^2  \right \} $$</p>
<blockquote>
<p>由于该式子无法直接优化，作者是通过每个矩阵依次迭代进行优化的，具体可以参考paper</p>
</blockquote>
<p>这边当$r=0$的时候，其实就是回归到了普通的用户行为矩阵推荐。</p>
<p>考虑到用户的显式特征信息，在实际推荐时，会选取用户最关心的$k$个显式特征$C = { c_1,..,c_k }$然后进行item的得分计算:<br>$$R_{i,j} = \alpha \cdot \frac{\sum_{c \in C} \tilde{X}_{ic} \cdot \tilde{Y}_jc }{kN} + (1-\alpha) \tilde{A}_{i,j}$$</p>
<blockquote>
<p>这边的$\alpha$就是取显式特征还是考虑综合行为的一个平衡因子</p>
</blockquote>
<p>再记得得到top的<code>Item</code>列表之后，再选取最关心的显式特征，套用预定好的模块即可展现推荐理由：</p>
<center><img src="/img/Explainable-Recommendation/efm_explain.png" width="450px"></center>

<h3 id="LRPPM">LRPPM</h3><p>LRPPM模型其实是EFM的一个泛化或者增强版本，主要做了下面两个方面的改进：</p>
<ol>
<li>从<code>User-Feature</code>和<code>Item-Feature</code>的显示特征矩阵直接衍化到了<code>User-Item-Feature</code>的立体</li>
<li>使用learning-to-rank的方式从<code>Pointwise</code>到<code>PairWise</code>的变更</li>
</ol>
<p>另外为了解决单个<code>item</code>上用户评论的稀疏性，LRPPM还提供到了类目测的模型</p>
<center><img src="/img/Explainable-Recommendation/lrppm_example.png" width="450px"></center>

<p>该三元立体的式子表示为:<br>$$\hat{T}_{uif} = \sum_{k=0}^{K-1} R_{uk}^U \cdot R_{fk}^{UF} + \sum_{k=0}^{K-1} R_{ik}^I \cdot R_{fk}^{iF} + \sum_{k=0}^{K-1} R_{uk}^U \cdot R_{ik}^I$$</p>
<p>该式子的含义就是用户$u$对于物品$i$在某个特征上$f$的感兴趣得分，值得注意的时候，对于特征$f$的向量，作者将$U$和$I$上面的特征给分来表示了。在进行优化的时候，作者参考了$BPR$的损失函数，他认为这个可以理解是一个pairwise的排序场景，也就是用户对于$ui$上的感兴趣特征分数比不感兴趣的高即可，所以可以有得到<br>$$\hat{T}_{uif_Af_B} = \hat{T}_{uif_A} - \hat{T}_{uif_B}$$</p>
<blockquote>
<p>其中$f_A$表示用户感兴趣的特征,而$f_B$则一般可以用 用户 没观察到的特征</p>
</blockquote>
<p>这样则其优化函数为<br>$$\hat{\theta} = \underset{\theta}{argmax} \sum_{u \in U} \sum_{i \in I} \sum_{f_A \in F^+} \sum_{f_B \in F^-} \text{log} \sigma (\hat{T}_{uif_Af_B}) -\lambda_{\theta} \parallel \theta \parallel_F^2$$</p>
<p>其实就是一个表示的    <code>BPR</code>的损失函数</p>
<p>与EFM一样，LRPPM模型也会集成CF进行排序，这样其最小化目标就为:<br>$$ \underset{\theta}{min} \sum_{u \in U} \sum_{ i \in I} (A_{ui}- R_u \cdot R_i)^2 -\lambda \sum_{u \in U} \sum_{i \in I} \sum_{f_A \in F^+} \sum_{f_B \in F^-} \text{log} \sigma (\hat{T}_{uif_Af_B}) + \lambda_{\theta} \parallel \theta \parallel_F^2$$</p>
<p>同时刚刚有提到，其实单个用户对于某个物品的评论是很稀疏的，这样导致整个特征立方体非常稀疏，为了解决这个问题，上述的公式可以很方便的转为基于”类目”的理论，因为往往在同一个类目下的不同物品都会有项目的特征，所以转为”类目”级别之后这个立方体为”User-Categroy-Feature”,式子更改为这样：<br>$$\hat{T}_{ucf}^* = \sum_{k=0}^{K-1} R_{uk}^U \cdot R_{fk}^{UF} + \sum_{k=0}^{K-1} R_{ck}^C \cdot R_{fk}^{cF} + \sum_{k=0}^{K-1} R_{uk}^U \cdot R_{ck}^C$$</p>
<p>在最小化目标函数上做相应的替换和变更即可.</p>
<h3 id="MTER">MTER</h3><p>MTER这篇paper最大的idea就是在之前三元立体的基础上新增了一位 关键词(Opinionated word),类似于 <code>价格-高</code>,<code>颜色-鲜艳</code></p>
<center><img src="/img/Explainable-Recommendation/mter_arch.png" width="450px"></center>

<p>因此整个场景就可以模型化为一个四维的矩阵(<code>U</code>:用户，<code>I</code>:物品，<code>F</code>:特征,<code>O</code>:Opinion)<br>这里考虑到四维矩阵的相乘复杂度太高，所以作者将其分成了三个三维的矩阵:</p>
<ol>
<li>$\hat{X}$:<code>U-I-F</code></li>
<li>$\hat{Y}^U$:<code>U-F-O</code></li>
<li>$\hat{Y}^I$:<code>I-F-O</code></li>
</ol>
<p>最终的优化公式为:<br>$$\underset{\hat{X},\hat{Y}^U,\hat{Y}^I}{min} \parallel \hat{X} - \tilde{X} \parallel_F + \parallel \hat{Y}^U - \tilde{Y}^U \parallel_F + \parallel \hat{Y}^I - \tilde{Y}^I \parallel_F$$</p>
<h2 id="深度学习方法">深度学习方法</h2><h3 id="NARRE">NARRE</h3><p>这边的思想其实很简单，将用户和Item的评论文本特征灌入的算分模型，同时借助<code>Attention</code>机制来获取权重最高的评论来作为推荐</p>
<center><img src="/img/Explainable-Recommendation/narre_arch.png" width="450px"></center>

<p>这边单个评论经过<code>CNN</code>进行embedding之后，与发表评论的user或者承载评论的item进行<code>Attention</code>是该paper的核心:<br>$$\hat{a}_{il} = h^T \text{ReLu}(W_oO_{il} + W_u u_{il} + b_1) + b_2$$<br>这样每条评论的权重可以经过softmax<br>$$ a_{il} = \frac{\hat{a}_{il}}{\sum exp(\hat{a}_{il})} $$</p>
<p>其中$O_{il}$表示评论的文本向量,$u_{il}$表示发表该评论用户，根据他们进行<code>Attention</code>之后按权重聚合得到$Y_i$作为整个<code>Item</code>的整体评论Embedding<br>同时用户产生的评论用类似的方式产生$X_u$,<br>最终使用$(q_u+X_u) \odot (p_i+Y_i)$点积的方式进行计算用户评分，其中$q_u$和$p_i$分别代表使用评论矩阵MF分解得到的用户和<code>Item</code>的向量</p>
<p>根据模型中$a_{il}$的权重即可来代表该<code>Item</code>最重要的评论进行推荐时展现</p>
<center><img src="/img/Explainable-Recommendation/narre_example.png" width="450px"></center>

<p>不过我觉得这部的<code>Attention</code>中并没有加入当前待排序用户的特征，所以$a_il$在不同的用户下应该都是同一个，因此评论并没有做到用户级别的个性化 -_-</p>
<h3 id="NRT">NRT</h3><p><code>NRT</code>的作者在使用普通矩阵分解评分的时候，利用隐向量的来进行tips文本序列的生成</p>
<center><img src="/img/Explainable-Recommendation/nrt_arch.png" width="450px"></center>

<p>而在序列生成时使用了比较经典的GRU架构，而生成最关键的就是初始化的输入，<code>NRT</code>他是这么构造的</p>
<ol>
<li>$u$:用户的隐向量</li>
<li>$v$:<code>Item</code>的隐向量</li>
<li>$\hat{r}$: 计算得分的onehot向量，比如总分5分，当前计算4.3分，则为$\{0,0,0,1,0\}$</li>
<li>$h_L^c$: 可以使用非常简易的生成方法：通过多层感知机之后得到最后一层$h_L^c$，该层映射之后的softmax的值$\hat{c}$来拟合真实评论文本的词分布$\sum c^k \text{log} \hat{c}^k$，该数据在训练时有groundtruth，在预测时只需要inference即可</li>
</ol>
<p>因此最终的初始化向向量输入为：$$h_0^s = tanh( W_uu + W_vv + W_r \hat{r} + W_c h_L^c + b)$$</p>
<p>该初始化向量其实含有信息量还是太少了，应该实际生成的效果相对来说还是比较差的</p>
<h3 id="CAML">CAML</h3><p><code>CAML</code>在解释生成时的关键是要对用户和item之间进行深层次的交互并进行显式的建模，因此他是在序列生成的初始输入上针对<code>NRT</code>做了很大的改进，<code>CAML</code>的核心是根据用户和<code>Item</code>的评论进行多层的<code>Co-Attention</code>，包含评论级别和评论的属性级别，因此最终的生成还能进行属性进行控制</p>
<center><img src="/img/Explainable-Recommendation/caml_arch.png" width="650px"></center>

<p>多层的<code>Co-Attention</code>是这样的：</p>
<ol>
<li>根据用户和<code>Item</code>的评论文本向量进行Co-Attention:$$\phi_{i,j} = F(d_{u,i})^T W_d F(d_{v,j})$$</li>
<li>同时取得用户和<code>Item</code>测各条评论最重要的得分$$a_i = \underset{j=1…l_d}{max} \phi_{i,j} , b_j = \underset{i=1…i_d}{max} \phi_{i,j}$$</li>
<li>这边然后使用<code>Gumbel-Softmax</code>函数得到最终的评论$$q_i = \frac{exp(\frac{a_i+g_i}{\tau})}{\sum exp(\frac{a_i+g_i}{\tau})}$$</li>
<li>然后可以得到用户和<code>Item</code>的重要评论${d}’_u$和${d}’_v$</li>
<li>这些评论自身都有他们对应的属性(Concept) $c$，这些$c$按照类似<code>1-4</code>的步骤记得最终这两条评论各自最重要的属性${c}’_u$和${c}’_v$</li>
<li>此时将他们向量进行拼接起来即可代表用户和<code>Item</code>的评论偏好$e_u = [{d}’_u,{c}’_u]$和$e_v = [{d}’_v,{c}’_v]$</li>
<li>由于用户或者<code>Item</code>可能不止对意向评论进行偏好，所以可以将<code>Gumbel-Softmax</code>变换随机值进行多次<code>Co-Attention</code>就可以得到他们的综合偏好</li>
<li>最终和自身的id特征进行拼接就是最终的<code>User</code>和<code>Item</code>向量了$$X_u = [h_u,e^0_u,e^1_u,..,e^n_u],X_v = [h_v,e^0_v,e^1_v,..,e^n_v]$$</li>
<li>这些向量将会作为评分矩阵FM的输入以及文本序列生成GRU的初始化向量（可能会做一些MLP变换）</li>
<li>在最终的loss上有一个比较有意思的，除了传统词的NLL损失函数，还有一个属性的损失函数:$$L_c = \frac{1}{\Omega} \sum \sum (max (-\tau_k \text{log}o_{t,k}))$$  这里$\tau$是用户和item偏好的评论属性向量，他们生成该文本总包含不评论属性，则做惩罚</li>
</ol>
<p>总体上来说这边的初始化向量构造对比<code>NRT</code>合理了很多：</p>
<ol>
<li>加入了用户信息的影响</li>
<li>同时引入了评论属性，这样生成文本时不容易偏移方向</li>
</ol>
<h3 id="还未细看">还未细看</h3><ol>
<li>进行在线的解释生成：Dynamic Explainable Recommendation based on Neural Attentive Models</li>
<li>对抗学习进行解释生成：Why I like it: multi-task learning for recommendation and explanation.</li>
<li>根据多视角来进行解释生成:Explainable Recommendation Through Attentive Multi-View Learning</li>
<li>利用图像进行解释推荐:Visually-aware fashion recommendation and design with generative image models</li>
<li>使用bandit方法进行解释模板选择：Explore, Exploit, and Explain- Personalizing Explainable Recommendations with Bandits</li>
</ol>
<h2 id="总结">总结</h2><p>总体来说可解释方面的方向在学术上还是比较火热的，也有不少看上去比较可行的方案，但是实际迁移到工业界其实还是有不少的难度：</p>
<ol>
<li>没有相应的训练数据</li>
<li>paper:单个模型，实际业务:多个模型的融合/结合</li>
<li>透出的文本就算做到99%的相关性/准确性，剩下的1%都是要命的</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>Zhang, Yongfeng, et al. “Explicit factor models for explainable recommendation based on phrase-level sentiment analysis.” Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval. ACM, 2014.</li>
<li>Chen, Xu, et al. “Learning to rank features for recommendation over multiple categories.” Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2016.</li>
<li>Wang, Nan, et al. “Explainable recommendation via multi-task learning in opinionated text data.” The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. ACM, 2018.</li>
<li>Chen, Chong, et al. “Neural attentional rating regression with review-level explanations.” Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conferences Steering Committee, 2018.</li>
<li>Li, Piji, et al. “Neural rating regression with abstractive tips generation for recommendation.” Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017.</li>
<li>Chen, Zhongxia, et al. “Co-attentive multi-task learning for explainable recommendation.” Proceedings of the 28th International Joint Conference on Artificial Intelligence. Vol. 10. AAAI Press, 2019.</li>
<li>ExplainAble Recommendation and Search</li>
<li><a href="https://blog.csdn.net/Y2c8YpZC15p/article/details/84801200" target="_blank" rel="external">https://blog.csdn.net/Y2c8YpZC15p/article/details/84801200</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="背景">背景</h2><p>在出推荐结果的同时产出一个理由，告诉用户这个item为啥要推荐给你~</p>
<center><img src="/img/Explainable-Recommendation/why_rec.jpg" width="450px" /></center><br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Recommendation" scheme="http://kubicode.me/tags/Recommendation/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[当协同过滤(Collaborative Filtering)遇上深度学习]]></title>
    <link href="http://kubicode.me/2019/01/16/Deep%20Learning/Collaborative-Filtering-Meet-to-Deep-Learning/"/>
    <id>http://kubicode.me/2019/01/16/Deep Learning/Collaborative-Filtering-Meet-to-Deep-Learning/</id>
    <published>2019-01-16T10:13:46.000Z</published>
    <updated>2019-01-24T11:05:14.124Z</updated>
    <content type="html"><![CDATA[<h2 id="介绍">介绍</h2><p>协同过滤(Collaborative Filtering,简称<code>CF</code>)是Amazon在2001年提出的应用于推荐领域的一个算法，至今各大家的推荐系统中都能见到协同过滤的影子，是推荐领域最经典的算法之一<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/cf.png" width="600px"></p>
<p>在实际场景中可以将用户对于<code>Item</code>的评分/购买/点击等行为 形成一张user-item的矩阵，单个的<code>User</code>或者<code>Item</code>可以通过对于有交互的<code>Item</code>和<code>User</code>来表示(最简单的就是<code>One-Hot</code>向量)，通过各种相似度算法可以计算到<code>User2User</code>、<code>Item2Item</code>以及<code>User2Item</code>的最近邻，先就假设按<code>User2Item</code>来说:<br><a id="more"></a></p>
<ol>
<li>和你购买相似宝贝的用户,其实和你相近的，也同时认为你们的习惯是相似的，</li>
<li>因此他们买的其他的宝贝你也是可能会去够买的，这批宝贝就可以认为和你相似的</li>
</ol>
<p>这种场景就非常使用与推荐系统非常匹配了，并且可解释性<code>极强</code>。<br>但是传统的<code>CF</code>会存在这两个问题:</p>
<ol>
<li>往往这个矩阵会非常<code>稀疏</code>，大部分稀疏程度在95%以上，甚至会超时99%，这样在计算相似度时就非常不准确了（置信度很低）</li>
<li>整个求最近邻过程中会引入很多<code>Trick</code>，比如平滑、各种阈值等,最终将<code>CF</code>拿到效果还是比较难的。</li>
<li>另外还有一个就是<code>冷启动</code>的问题，新用户或者新的item没法直接使用这种方式来计算</li>
</ol>
<p>因此后来针对<code>CF</code>提出了不少的优化，主要是对于<code>User/Item</code>的表示从<code>one-Hot</code>的方式想办法转为稠密的方式，假设原生的矩阵我们称之为$R$，如果存在<br>$$\tilde{R} = UV^T$$</p>
<blockquote>
<p>$R=[M,N],U=[M,K],V=[N,K]$,其中$M$为用户量，$N$为Item量</p>
</blockquote>
<p>并且使得$\tilde{R} \approx  R$,那么我们可以使用$U$来代表用户矩阵，$V$来代表item矩阵，此时每个用户或者item都可以使用一个$K$维来表示，也就是隐向量，他是一个稠密向量，对于one-hot有不少的优势，同时在整个模型中还可以加入其它特征信息，这就是景点的矩阵分解方式(<a href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems" target="_blank" rel="external">Matrix Factorization</a>，简称<code>MF</code>)，同时对于<code>MF</code>也有不少优化,比如<a href="https://arxiv.org/pdf/1205.2618.pdf" target="_blank" rel="external">BPR</a>以及最新的MF算法<a href="https://arxiv.org/pdf/1708.05024.pdf" target="_blank" rel="external">ELAS</a></p>
<p>一般来说，<code>MF</code>模型得到<code>User</code>和<code>Item</code>的向量之后就可以对这两个向量计算相似度来得到最终的结果，比如我们使用内积的方式:<br>$$y = f(u,i|U_u,V_i) = U_uV_i^T = \sum_{k=1}^K U_{u,k}V_{i,k}$$<br>但是其实由于参数空间和隐向量长度$K$限制的问题，对于<code>MF</code>隐向量之间相似度的结果和原生<code>User-Item</code>具体的相似度可能会出现不一致的情况，因此现在的DL盛行的时代，都想在这两个向量上再做一波<code>猛如虎</code>的操作再计算最终的结果，就是本文接下来要说的那些个模型，权当对于<code>CF</code>的最新进展进行一个同步学习:<br>他们的Task都是可以简化为，给定一个<code>User-Item</code>交互矩阵:<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/user_item.png" width="200px"></p>
<p>当特定的<code>User</code>和<code>Item</code>输入下计算他们的得分.<br>$$s = f(u,i|R,\theta) $$</p>
<h2 id="NeuCF">NeuCF</h2><p>针对MF算法最后通过内积聚合来得到算分的方式，这篇文章的作者认为<code>User</code>和<code>Item</code>的隐向量是相互独立的并且最后是等权重求和，因此他可以使用线性模型来表示，这样支持继续使用神经网络模型来进行加工，所以作者提出了基于神经网络的协同过滤（Neural Collaborative Filtering），说白了就是在隐向量上架MLP层和其他的聚合算子，其中隐向量是通过DL模型自己训练出来的：<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/neucf_arch.png" width="600px"><br>模型主要分两个子模块：GMF（左侧）和 NCF（右侧）:</p>
<ol>
<li><code>GMF</code>：<code>User</code>和<code>Item</code>的隐向量直接通过element-wise的相乘来进行聚合：$$h_{GMF} = \phi(p_u,q_i) = p_u \odot q_i$$</li>
<li><code>NCF</code>:<code>User</code>和<code>Item</code>的隐向量先进行concat操作，然后过多层的MLP，得到聚合的向量：$$h_{NCF} = \text{mlp}([p_u,q_i],\theta)$$</li>
<li>最后使用concat的方式将两个子模块进行融合$$\hat{y} = \sigma(W^T[h_{GMF},h_{NCF}])$$</li>
</ol>
<p>由于模型是有两部分组成，因此作者在先使用<code>GMF</code>和<code>NCF</code>分别训练模型，作为pre-train，然后再合并起来将<code>NeuCF</code>模型一起训练，来提升模型的性能<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/neucf_exp.png"></p>
<blockquote>
<p><code>Factor</code>表示模型预测的数量</p>
</blockquote>
<p>这里<code>GMF</code>和<code>MLP</code>(NCF)是他的两个子模型，实验结果也可以看到合并起来之后的模型效果要好于子模型，通过也要好于最新的<code>eALS</code>算法。同时作者还，对比了pre-train的效果，确实有不少的提升，具体细节尅看paper。</p>
<p>评一下：整个模型架构简单易懂，使用DL将隐向量做深度的交叉操作，可以继续压榨模型的性能，同时对于该模型用于线上也有很大的可行性。另外关于pre-train部分是否可以使用MF矩阵分解来作为初始化向量会不会更加来的直观一点。</p>
<h2 id="DMF">DMF</h2><p><code>DMF</code>(Deep Matrix Factorization)的作者受到了<a href="http://kubicode.me/2017/04/21/Deep%20Learning/Study-With-Deep-Structured-Semantic-Model/" target="_blank" rel="external">DSSM</a>模型的启发:<br><code>DSSM</code>中是通过Query对多个Item经过NN网络之间他们的Embedding来计算相似度，作为他们的语义相似，那么这推荐场景下可以迁移为User对于多个Item来计算行为相似度?<br>因此可以看图:<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/deepmf_arch.png" width="600px"></p>
<p>其实这个模型已经很清楚了:</p>
<ol>
<li>需要训练的数据就是这个用户评分矩阵，这里的训练目标是训练用户的评分</li>
<li>用$Y_{i*}$来表示用户的向量，用$Y_{j*}$来表示item的向量</li>
<li>他们分别过两个不同的<code>MLP</code>层:$$p_i = f_{\theta_N^U}(…f_{\theta_3^U}(W_{U2}f_{\theta_2^U}(Y_{i*W_{U1}}))…) \\ q_i = f_{\theta_N^I}(…f_{\theta_3^I}(W_{I2}f_{\theta_2^I}(Y_{i*W_{I1}}))…)$$</li>
<li>然后对于$p_i$和$p_j$就是用户和item的向量表示，对这两个向量通过cosine求相似度:$$\hat{Y}_{i,j} = F^{DMF}(u_i,v_j|\Theta) = cosine(p_i,q_j) = \frac{p_i^Tq_j}{||p_i|| ||q_j||}$$</li>
<li>最终是使用了一个带权重偏置的交叉熵来优化目标:$$L=-\sum \frac{Y_{i,j}}{\max{R}} \log{\hat{Y}_{_i,j}} + (1-\frac{Y_{i,j}}{\max{R}}) \log(1-{\hat{Y}_{_i,j}}) $$</li>
</ol>
<p>先来说说这个<code>Loss</code>，里面的$R$为评分的最大值（如果标准的1~5分中$R=5$），因为刚刚说了他其实是要预测分数，分数会有1~5，但同时会有0分，所以这个Loss下当$Y={1~5}$时，他其实是一个将回归问题归一化到0~1的分类问题，当$Y=0$时，他就是一个不折不扣的二分类问题，所以说这个任务下选择这个Loss其实是是挺合适的。</p>
<p>整个模型其实还是很好理解的，看下他的实验结果:<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/deepmf_exp.png"><br>主要对于<code>NeuMF</code>算法，还是有一些些提升的，但是从模型的架构来看，<code>DMF</code>出来除了使用两个单独的MLP，其他与<code>NeuMF</code>的差异并没有很大，模型还是<code>NeuMF</code>更加复杂嘞，个人感觉如果<code>NeuMF</code>使用了pre-train，<code>DMF</code>说不定还无法超过…，同时看了loss改进的提升并不是很多（不过比较符合正常情况-_-）</p>
<p>这里再对比一下DSSM：</p>
<ol>
<li>一个比较大的区别是DSSM的query和title都是word，都是他的网络是共享的，但是DMF里面其实并不是共享的（我之前的经验，不共享的情况下效果大大折扣。。。)</li>
<li>我觉得DSSM里面最重要的一个点是<code>Pair-Wise</code>的loss学习，但是<code>DMF</code>里面作者也说了，本文用的是<code>PointWise</code>的Loss，对于<code>Pair-Wise</code>的Loss在feature work中使用-_-!!</li>
</ol>
<!-- Personalized Neural Embeddings for Collaborative Filtering with Unstructured Text  这篇paper好像根本没发表  暂时不写了  晦涩
## CoMem
上文有也提到，这边`CF`最终希望解决的是在给定`User`和`Item`的情况下来计算一个score，当然除了之前`User-Item`矩阵，其实我们还可以引入其他信息。
因此这篇的作者将`User`和`Item`互动的非结构化文本引入到了模型里面，比如评价评分场景,既有评价的分数，也有评价的文本，所以作者在`CF`模型里面结合近两年比较热门的`Memory Network`。

对于`Memory Network`最经典的QA应用中，这里的推荐系统也可以进行类似的映射：
1. `Question`是用户会采用哪一个推荐的Item
2. 而非结构化的文本就是对应的`Story`
3. 其`query`就是User和Item的交互情况
-->
<h2 id="CMN">CMN</h2><p>传统的矩阵分解和基于DL-embedding的CF方法都是从全局的<code>User-Item</code>矩阵出发，都是只考虑的全局的矩阵。<br>而CMN（<code>Collaborative Memory Network</code>）的作者针对给定<code>User</code>和<code>Item</code>在算法时，根据<code>Item</code>得到<code>User</code>的最近邻出发，使用最近邻的Embedding来作为局部信息用于<code>CF</code>中，而这里求最近邻的Embedding使用了<code>Memory Network</code>来解。<br>模型结构还是挺漂亮的：<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/cmn_arch.png"><br>模型主要是分为<code>Glolab</code>信息和<code>Local</code>信息，<code>Glolab</code>和上面两篇文章说的大同小异，上面的结构图主要是通过<code>Memory Network</code>结构来说明<code>Local</code>信息的使用：<br>整个网络中有三个矩阵:</p>
<ol>
<li>用户矩阵$M \in R^{P \times d}$，其中$P$为用户量，$m_u$表示单个用户的向量</li>
<li>Item矩阵:$E \in R^{Q \times d}$，其中$Q$表示Item数量,$e_i$表示Item的向量</li>
<li>最近邻的Embedding矩阵$C$,大小与$M$一样，用于<code>Memory Network</code>外部矩阵,使用$c_v$来表示单个邻居的向量的</li>
</ol>
<p>在给定用户$u$和item  $i$的情况下，计算$u$和$i$发生交互的用户$v$的距离为：$$q_{uiv} = m_u^T m_v + e_i^T m_v \quad \quad \quad \forall v \in N(i)$$</p>
<blockquote>
<p>$N(i)$表示和$i$发生过交互的用户</p>
</blockquote>
<p>$q_{uiv}$是内积之后的结果，也就是一个值了，然后使用softmax可以求得各个近邻用户的权重<br>$$p_{uiv} = \frac{exp(q_{uiv})}{\sum_{k \in N(i)} exp(q_{uik})} \quad \quad \quad \forall v \in N(i)$$</p>
<p>该权重乘以对应的外部矩阵的向量就可以得到当前用户与item最近邻用户的向量了，作为$User$和$Item$的局部信息:<br>$$o_{ui} = \sum_{v \in N(i)} p_{uiv} c_v$$</p>
<p>最终在输出模型的时候与<code>Glolab</code>信息一起结合进去:<br>$$\hat{r}_{ui} = v^T \phi (U(m_u \cdot e_i) + W o_{ui} + b)$$</p>
<blockquote>
<p>这里CF的距离使用点积的方式，也就是$NumMF$的其中一个子模型版本</p>
</blockquote>
<p>刚刚描述的过程就是上图的<code>(a)</code>部分，<code>Memory Network</code>(<code>MN</code>)最大的优势就是可以使用叠加的方式来进行<code>Attention</code>，这样可以使用在后面的<code>MN</code>时会重新调整前面基层的<code>MN</code>，也就是<code>(b)</code>图所示，<br>这里第一层时$m_u$和$e_i$整合到了一起:$$z^0_{ui} = m_u + e_i$$</p>
<blockquote>
<p>邻居用户的算分就可以表示为:$$q_{uiv}^h = (z_{ui}^h)^Tm_v \forall v \in N(i)$$</p>
</blockquote>
<p>而其他层的$z$计算为:$$z_{ui}^h = \phi(Wz_{ui}^{h-1} + o_{ui}^h)$$</p>
<p>这种迭代机制正好可以将<code>MN</code>层正好可以堆叠起来，而实验中也是证明了多层的堆叠效果要优于单层的</p>
<p><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/cmn_exp.png"><br>实验结果中主要来对比一下<code>NeuMF</code>，有明显提升同时觉得他的提升比<code>DMF</code>更加合理哈哈，如果在<code>Gbobal</code>这块再做一些细节的处理应该能提升更多。</p>
<p>整个模型的复杂度为:$O(n(d|N(i)| + d^2)+d)$   而$n$就是<code>MN</code>的层数，因此就模型的工业化而言可行性其实是非常高的，不过需要对$|N(i)|$进行一些剪枝之类的trick处理</p>
<h2 id="DeepCF">DeepCF</h2><p>这篇paper的作者从<code>CF</code>的<code>Representation</code>和<code>Match</code>两个角度出发：<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/deepcf_arch.png" width="400px"><br>我细看了每天和<code>NeuMF</code>架构没啥差别，除了在<code>GMF</code>那里多了几层<code>MLP</code> -_-，因此细节就不说了。。。</p>
<h2 id="参考">参考</h2><ol>
<li><a href="http://www.ra.ethz.ch/cdstore/www10/papers/pdf/p519.pdf" target="_blank" rel="external">Item-Based Collaborative Filtering Recommendation Algorithms</a></li>
<li><a href="https://arxiv.org/pdf/1205.2618.pdf" target="_blank" rel="external">BPR: Bayesian Personalized Ranking from Implicit Feedback</a></li>
<li><a href="https://pdfs.semanticscholar.org/49be/f668aff3cc3d470339479dd3cee0b4c9cf4f.pdf" target="_blank" rel="external">Deep Matrix Factorization Models for Recommender Systems∗</a></li>
<li><a href="https://arxiv.org/pdf/1708.05031.pdf" target="_blank" rel="external">Neural Collaborative Filtering∗</a></li>
<li><a href="https://arxiv.org/pdf/1804.10862.pdf" target="_blank" rel="external">Collaborative Memory Network for Recommendation Systems</a></li>
<li>DeepCF -A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="介绍">介绍</h2><p>协同过滤(Collaborative Filtering,简称<code>CF</code>)是Amazon在2001年提出的应用于推荐领域的一个算法，至今各大家的推荐系统中都能见到协同过滤的影子，是推荐领域最经典的算法之一<br><img src="/img/Collaborative-Filtering-Meet-to-Deep-Learning/cf.png" width="600px" /></p>
<p>在实际场景中可以将用户对于<code>Item</code>的评分/购买/点击等行为 形成一张user-item的矩阵，单个的<code>User</code>或者<code>Item</code>可以通过对于有交互的<code>Item</code>和<code>User</code>来表示(最简单的就是<code>One-Hot</code>向量)，通过各种相似度算法可以计算到<code>User2User</code>、<code>Item2Item</code>以及<code>User2Item</code>的最近邻，先就假设按<code>User2Item</code>来说:<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[记一记梯度下降极其优化算法]]></title>
    <link href="http://kubicode.me/2018/12/27/Machine%20Learning/Study-Gradient-Descent-Optimization/"/>
    <id>http://kubicode.me/2018/12/27/Machine Learning/Study-Gradient-Descent-Optimization/</id>
    <published>2018-12-27T11:38:58.000Z</published>
    <updated>2019-11-03T13:20:53.573Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>本文主要是对于<a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="external">An overview of gradient descent optimization algorithms</a>的学习和理解，方便记忆</p>
</blockquote>
<h2 id="引言">引言</h2><p>梯度下降法是非常著名的优化算法之一，思想简单高效，被各种深度框架(Tensorflow、Pytorch)用做默认优化器。<br>梯度下降法是最小化目标函数的一种方法，利用目标函数梯度的反方向更新参数，沿着目标函数的斜面下降的方向，直到到达谷底。</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/Gradient_descent.png" width="200px"></center>

<p>由于被广泛使用，因此在梯度下降法出了很多变种以及许多优化算法，并且他们同时都是朝着加速收敛的方向进行优化。</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/rel_graph.png" width="650px"></center>

<a id="more"></a>
<h2 id="梯度下降极其变种">梯度下降极其变种</h2><h3 id="Batch_gradient_descent">Batch gradient descent</h3><p>批量梯度下降法是原始的方法，他需要对整个数据集进行计算之后才更新梯度:<br>$$\theta = \theta - \eta \cdot \nabla_{\eta} J(\theta)$$</p>
<p>用代码来表示就是这样的:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">  params_grad = evaluate_gradient(loss_function, data, params)</span><br><span class="line">  params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p>
<p>批量梯度下降法可以保证模型达到全局最优，但是他的缺点多了又多:</p>
<ol>
<li>梯度需要遍历整个数据集才能计算，并且只有一次参数更新</li>
<li>整个梯度更新很慢，同时数据量大到放不下内存时就不再适用该方法了</li>
<li>批量梯度下降法不使用online在更新</li>
</ol>
<h3 id="Stochastic_gradient_descent">Stochastic gradient descent</h3><p>随机梯度下降法的式子长这样子：<br>$$\theta = \theta - \eta \cdot \nabla_{\eta} J(\theta;x^i;y^i)$$<br>该方法每次计算一次样本就会更新一次梯度，用代码来表示是这样的（各个epoch之间需要对样本进行打散）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">  np.random.shuffle(data)</span><br><span class="line">  <span class="keyword">for</span> example <span class="keyword">in</span> data:</span><br><span class="line">    params_grad = evaluate_gradient(loss_function, example, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p>
<p><code>SGD</code>的特性(优势和劣势结合一起了-_-)是:</p>
<ol>
<li>运行速度要比批量梯度下降法快很多</li>
<li>可以适用于在线学习</li>
<li>每次都是以高方差的方式在更新梯度，会导致损失函数的波动很大,因为波动很大，因此这个波动性使得<code>SGD</code>能进入局部最优，但同时想达到最终收敛相对批量梯度下降法会更得更加复杂</li>
<li>当然有研究证明如果以一个足够小的学习率进行更新时最终也都能到达局部最优和全局最最优。</li>
</ol>
<h3 id="Mini-batch_gradient_descent">Mini-batch gradient descent</h3><p>而<code>批量梯度下降法</code>是<code>梯度下降法</code>和<code>随机梯度下降法</code>，他每次都是对一批样本进行梯度计算之后再更新参数，</p>
<p>$$\theta = \theta - \eta \cdot \nabla_{\eta} J(\theta;x^{i:i+n};y^{i:i+n})$$</p>
<p>用代码来表示则是:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">  np.random.shuffle(data)</span><br><span class="line">  <span class="keyword">for</span> batch <span class="keyword">in</span> get_batches(data, batch_size=<span class="number">50</span>):</span><br><span class="line">    params_grad = evaluate_gradient(loss_function, batch, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>代码是以<code>batch_size=50</code>为例，每次都是50个样本一次更新,其他和<code>SGD</code>都是一样的</p>
</blockquote>
<p>这种方式的好处有：</p>
<ol>
<li>在更新参数时可以减少异常点的参数更新，使得收敛会更加稳定（对于<code>SGD</code>而言）</li>
<li>他可以充分的利用矩阵计算的优化加速（<code>梯度下降法</code>样本量太多，<code>随机梯度下降法</code>单个样本没法使用矩阵计算），因此现在的<code>DeepLearning</code>算法中大部分都采用这种方式来学习</li>
</ol>
<p>然后<code>批量梯度下降法</code>仍旧会存在以下问题：</p>
<ol>
<li>学习率大小的问题：太小收敛会很慢，太大会很难到达最优</li>
<li>并不是所有特征的学习都是一样的，特别在稀疏数据下，每个特征的学习能力和到达最优的时间都是不一致的</li>
</ol>
<p>因此才有了下面的各种优化算法</p>
<h2 id="梯度下降优化算法">梯度下降优化算法</h2><h3 id="Momentum">Momentum</h3><p>动量优化算法可以理解为在<code>SGD</code>的基础上加了一个相关方向，使得<code>SGD</code>可以更快的到达最优点，如下图所示：</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/moment.png" width="600px"></center>

<p>动量法主要是将历史步长的更新向量增加到当前的更新向量中:<br>$$v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta) \\ \theta = \theta - v_t $$</p>
<blockquote>
<p>这里$v_t$就是历史梯度方向的累积，也称为方向动量，而$\gamma$称为动量项，一般都是设置为<code>0.9</code></p>
</blockquote>
<p>通俗得来将，比如一个小球从小山坡上滚下来的时候，越滚会越积累动能，速度也更快的到坡低。同样在进行参数更新时：</p>
<ol>
<li>与目标梯度方向相同的维度增加动量，参数更新更快，加快收敛</li>
<li>与目标梯度方向不一致的维度减少动量，降低参数更新速度，减少振荡；<blockquote>
<p>而$\gamma$就像小山坡上的风阻系数，非常形象</p>
</blockquote>
</li>
</ol>
<h3 id="NAG">NAG</h3><p><code>Momentum</code>方法虽然在参数更新时考虑了历史梯度方向，但是他在自身的梯度计算时仍为原来的方法（有波动的方向），因此<code>Nesterov加速法</code>(Nesterov accelerated gradient NAG)提出了在计算梯度时也加上历史的动量方向，这样每次更新的梯度也会考虑历史方向，也就是到终点就更加快了。<br>这里参考<code>Momentum</code>方法，<code>Nesterov</code>加速法的公式是这样的：<br>$$v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta-\gamma v_{t-1}) \\ \theta = \theta - v_t $$</p>
<blockquote>
<p>这里和<code>Momentum</code>的区别就在梯度那里的参数变成了$\theta-\gamma v_{t-1}$,而这一项正好可以让梯度朝着目标的方向计算</p>
</blockquote>
<p>用图来说明应该就是这样纸了：</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/nesterov_update_vector.png" width="400px"></center>


<ol>
<li>蓝色代表<code>Momentum</code>法，他可以快速更新并且方向沿着历史梯度方向</li>
<li>而棕色和红色是代表<code>Nesterov</code>方法，在后续的更新中，他的梯度会朝着最优的方向去更新（也就是红色），所以他会更快的达到最优点</li>
</ol>
<h3 id="AdaGrad">AdaGrad</h3><p><code>AdaGrad</code>是一个可以自适应学习率的优化算法：</p>
<ol>
<li>对于出现次数<code>较多</code>的特征，使用<code>小</code>的学习率去学习</li>
<li>对于出现次数<code>较少</code>的特征，使用<code>大</code>的学习率去学习</li>
</ol>
<p>因此它在每一次迭代更新参数时不同的特征的参数学习率都是不一样的，在<code>t</code>时刻，基于对$\theta_i$计算过的历史梯度，Adagrad 修正了对每个参数对于$\theta_i$的学习率：</p>
<p>$$ \theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} +\epsilon }}  g_{t,i} $$</p>
<blockquote>
<p>这边$G_{t,ii}$是一个对角矩阵，对角线上每个位置就是截止到$t$时刻的所有梯度的平方累加,$\epsilon$是为了防止除0，一般取<code>1e-8</code></p>
</blockquote>
<p>用向量相乘方式可以写为<br>$$\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{G_t+\epsilon}} \odot g_t $$</p>
<p><code>Adagrad</code>最大的好处就是无需手动调参，一般设置一个0.01的学习率让他自己run就行了额<br>不过由于$G$矩阵是平方和计算得到，所以随着训练次数的增加，$G$中的值会越来越大，导致实际的学习率会越来越小，这样当学习率逼近无限小的时候，模型的学习能力会明显不足</p>
<h3 id="Adadelta">Adadelta</h3><p><code>Adadelta</code>是<code>Adagrad</code>的一个改进版本，他可以处理<code>Adagrad</code>的学习率单调递减的问题，<br>它将梯度的平方递归地表示替换为所有历史梯度平方的均值<br>$$E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma) g^2_t$$</p>
<blockquote>
<p>这边的$\gamma$类似Momentum的动量参数，一般默认为0.9</p>
</blockquote>
<p>则替换了<code>Adagrad</code>的对角矩阵$G$之后为,梯度的表示为<br>$$\nabla \theta_t = - \frac{\eta}{ \sqrt{E[g^2]_t + \epsilon}} g_t$$</p>
<p>同时为了保持参数的一致性（黑人问号点），这边定义了另一个指数衰减均值，该值不是梯度平方，而是参数的平方的更新<br>$$E[\nabla \theta^2]_t = \gamma E[\nabla \theta^2]_{t-1} + (1-\gamma) \nabla \theta^2_t$$</p>
<p>他的更新式子为:<br>$$\nabla \theta_{t+1} = \theta_t - \frac{RMS[\nabla \theta]_{t-1}}{RMS[g]_t} g_t \\ \theta_t = \theta_{t-1} + \nabla \theta_{t+1}$$</p>
<blockquote>
<p>这边的$RMS$是平方根的简写形式,$RMS(x) = \sqrt{(x+\epsilon)}$</p>
</blockquote>
<p>因此最终<code>Adadelta</code>不仅解决了<code>Adagrad</code>的学习率消失问题，而且还不需要设置初始化的学习率</p>
<h3 id="RMSProp">RMSProp</h3><p><code>RMSProp</code>是<code>Hinton</code>提出但是未发表的一个优化算法，他与<code>Adadelta</code>几乎同时发现，可以理解为它是一个<code>Adadelta</code>的缩减版的特例:<br>$$E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g^2_t \\ \theta_t = \theta_{t-1} - \frac{\eta}{ \sqrt{E[g^2]_t + \epsilon}} g_t$$</p>
<blockquote>
<p>其实就是恢复了<code>Adadelta</code>的初始化学习率的问题</p>
</blockquote>
<h3 id="Adam">Adam</h3><p><code>Adam</code>(Adaptive Moment Estimation) 是另一个比较重要学习率自适应的算法，他同时结合了<code>Momentum</code>的动量来快速找到梯度更新方向，同时采用<code>RMSProp</code>的方式来找到每个特征不同的学习率。<code>Adam</code>中类似动量的指数衰减均值为$m_t$，另外历史平方梯度的平均为$v_t$：<br>$$ m_t = \beta m_{t-1} + (1- \beta_1^t) g_t \\ v_t = \beta_2 v_{t-1} + (1- \beta_2^t) g^2_t$$</p>
<p>$m_t$和$v_t$分别是对梯度的一阶矩（均值）和二阶矩（非确定的方差）的估计，由于他们的初始化为0向量，作者发现$\beta_1$和$\beta_2$的参数值接近于1的时候，$m_t$和$v_t$始终偏向于0 ，因此针对此问题做了矫正:</p>
<p>$$\hat{m}_t = \frac{m_t}{1-\beta_1} \\ \hat{v}_t = \frac{v_t}{1-\beta_2}$$</p>
<p>最终<code>Adam</code>的实际参数更新为:</p>
<p>$$\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{v}_t}+\epsilon} \hat{m}_t $$</p>
<blockquote>
<p>作者建议的参数为:$\beta_1 = 0.9$,$\beta_2 = 0.999$ , $\epsilon = 10e-8$ ,这个优化算法也是目前比较Work的一个，在DL里面非常的适用</p>
</blockquote>
<h3 id="AdaMax">AdaMax</h3><p>针对<code>Adam</code>中的二阶矩的泛化形式可以表述为:$$v_t = \beta_2^p v_{t-1} + (1-\beta_2^p) |g_t|^p $$</p>
<p>由于$p in \{1,2\}$一般是我们认为的一范数和二范数，通过实践证明都是比较稳定的，但是当$p$变大的时这个的规范化会出现不稳定的情况。不过如果将$p$趋向于无穷大的时候，该矩的表现也是很稳定的，也就是用$u_t$来表示<br>$$u_t = \beta_2^\infty  u_{t-1} + (1-\beta_2^\infty ) |g_t|^\infty  = max(\beta_2 \cdot u_{t-1},|g_t|) $$<br>最后的参数更新为:<br>$$\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{u_t}+\epsilon} \hat{m}_t $$</p>
<blockquote>
<p>这边的$u$矩不再会出现趋近于0 的情况，所以不需要再做矫正，同时建议的参数可以设置为$\beta_1 = 0.9$,$\beta_2 = 0.999$ , $\epsilon = 0.002$</p>
</blockquote>
<h3 id="Nadam">Nadam</h3><p>如果将<code>Adam</code>看做<code>Momentum</code>和<code>RMSProp</code>的组合，那其实<code>Nadam</code>就是<code>NAG</code>和<code>RMSProp</code>的组合的，最终眼熟的更新式子为:<br>$$\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{v_t}+\epsilon} ( \beta_1 \hat{m}_t + \frac{(1-\beta_1)g_t}{1-\beta_1^t}) $$</p>
<h3 id="AMSGrad">AMSGrad</h3><p><code>Adam</code>由于是通过累加平均二阶矩来进行参数学习率的自适应，当某些minbatch提供的信息量很大并且梯度很大时，他们会被平均掉，影响整体的训练，最终会陷入局部最优。<br>为了避免这种局部最优的情况，AMSGrad这个优化算法将二阶矩的矫正阶段替换为求$max$，用于增强高信息量的minbatch信息：</p>
<p>$$ m_t = \beta m_{t-1} + (1- \beta_1^t) g_t<br>\\ v_t = \beta_2 v_{t-1} + (1- \beta_2^t) g^2_t<br>\\ \hat{v}_t = max(\hat{v}_{t-1} , v_t)<br>\\ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} m_t $$</p>
<p>虽然作者有实验证明在一些小数据集上<code>AMSGrad</code>的优化效果要好于<code>Adam</code>，但是也有好多人也实验了<code>AMSGrad</code>的性能比<code>Adam</code>更加差 -_-</p>
<h2 id="总结">总结</h2><p>比较有创新性的应该还是<code>Momentum</code>和<code>RMSProp</code>，但是他们的结合<code>Adam</code>将更加普适应，他目前是各位普通炼金术士的首选</p>
<h2 id="参考">参考</h2><ol>
<li><a href="https://ruder.io/optimizing-gradient-descent/" target="_blank" rel="external">https://ruder.io/optimizing-gradient-descent/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>本文主要是对于<a href="http://ruder.io/optimizing-gradient-descent/">An overview of gradient descent optimization algorithms</a>的学习和理解，方便记忆</p>
</blockquote>
<h2 id="引言">引言</h2><p>梯度下降法是非常著名的优化算法之一，思想简单高效，被各种深度框架(Tensorflow、Pytorch)用做默认优化器。<br>梯度下降法是最小化目标函数的一种方法，利用目标函数梯度的反方向更新参数，沿着目标函数的斜面下降的方向，直到到达谷底。</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/Gradient_descent.png" width="200px" /></center>

<p>由于被广泛使用，因此在梯度下降法出了很多变种以及许多优化算法，并且他们同时都是朝着加速收敛的方向进行优化。</p>
<center><img src="/img/Study-Gradient-Descent-Optimization/rel_graph.png" width="650px" /></center>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深度学习在序列化推荐中的应用(2)]]></title>
    <link href="http://kubicode.me/2018/10/25/Deep%20Learning/More-Session-Based-Recommendation/"/>
    <id>http://kubicode.me/2018/10/25/Deep Learning/More-Session-Based-Recommendation/</id>
    <published>2018-10-25T09:39:51.000Z</published>
    <updated>2019-03-25T14:43:49.139Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>基于上一篇<code>GRU4REC</code>的继续聊聊深度学习在推荐系统中的应用</p>
<h2 id="NARM">NARM</h2><p>作者提出了一种混合Encoder的方式：全局(<code>Global</code>)所有的序列信息的Encoder和当前(<code>Local</code>)Session序列的Encoder</p>
<p>所以他的模型是：<br><img src="/img/More-Session-Based-Recommendation/narm_arch.png"></p>
<a id="more"></a>
<ol>
<li>在Global序列信息的Encoder中，取了用户之前的所有行为（应该会卡一段阈值）来过了GRU之后取到的Final State作为Encoder的Embedding $c_t^g = h_t $</li>
<li>在Local中Session序列中的Encoder中，向全局信息的Encoder一样，只是最后输出之后取了一层Attention操作，希望突出当前序列中的一些重要行为。$$c_t^l = \sum_{j=1}^t \alpha_{i,j} h_j , \alpha_{i,j} = q(h_t,h_j)$$</li>
<li>然后最终Local和Global给Concat起来作为Encoder的输出$$c_t = [c_t^g;c_t^l]$$</li>
<li>接下来所有候选的Item按Embedding的方式来输入，称为$emb_i$</li>
<li>将Encoder的Embedding和候选集的Embedding进行<code>Bilinear</code>操作：$$S_i=emb_i^T B c_t$$</li>
<li>这一步过后其实就会得到了各个候选项的一个score，进行softmax归一化之后可以作为各个候选项的概率$q_i$</li>
<li>最终的loss是$L(p,q) = -\sum_{i=1}^m p_i log(q_i)$</li>
</ol>
<p><img src="/img/More-Session-Based-Recommendation/narm_exp.png"><br>他的实验对比中，较于其他Baseline算法还是有不少的提升的，不过对于<code>Improved GRU-Rec</code>并没有太大优势</p>
<p>其实也可以理解,最大的贡献应该是在流推荐中同时考虑了<code>Global</code>和<code>Local</code>的结合，整个模型的思路还是很清晰简洁的，<code>Encoder-&gt;Attention-&gt;Bilinear-&gt;Cross Entropy</code>，但是也没有特别大的改进<br>特别是在<code>Local</code>中的<code>Attention</code>那一层，说的不明不白，他的$h_t$变量没有描述清楚，感觉就是一个非常普通的<code>Self-Attention</code>,也许在这一层的Attenion可以和<code>Global</code>中的信息结合起来。</p>
<h2 id="RepeatNet">RepeatNet</h2><p>在购物场景中，因为有一些商品属性的原因，经常会去重复购买一些商品，比如纸巾-_-!!,因此用户其实存在着一些复购需求，类似这种场景的还有<code>音乐</code>、<code>视频</code>。<br>而实际的推荐系统中，我们经常在进行实时推荐时会根据用户历史记录直接去重，就算是缩短去重窗口也很少会刻意去推荐已经推荐过的item。<code>RepeatNet</code>非常机制的结合了类似copynet的idea，在模型的设计上给人一种眼前一亮的赶脚,他在进行推荐(<code>Explore</code>)中同时会有一定概率来推荐出历史行为(<code>Repeat</code>)。<br>该模型是在序列推荐的技术上加入了重推的概率进行<code>Joint-Learning</code>，以一种非常巧妙的方式来进行重推（类似point-generator的copy机制）:<br>整个模型的优化目标是这样的:<br>$$P(i|I_s) = P(r|I_s) P(i|r,I_s) + P(e|I_s) P(i|e,I_s)$$</p>
<ul>
<li>其中$I_s$表示用户的session行为记录</li>
<li>而$P(r|I_s)$表示需要进行重推的概率，这样$P(e|I_s)=1-P(r|I_s)$表示正常推荐的概率，</li>
<li>$P(i|r,I_s)$则表示历史session中各个item被重推的概率，$P(i|e,I_s)$为候选item被推荐的概率了</li>
</ul>
<p>因此整个<code>RepeatNet</code>其实是在做是否重推情况下各个候选item的联合概率最大化.<br>整个模型的结构是这样:<br><img src="/img/More-Session-Based-Recommendation/repeatnet_arch.png"></p>
<ol>
<li>模型的输入一个一串序列:$I_s=i_1,i_2,i_3,…,i_t$</li>
<li>输入的序列$I_s$经过单向GRU之后得到每一步的状态$ST=[h_1,h_2,h_3,…,h_t]$</li>
<li><code>Repeat-Explore Mechanism</code>：这里将$ST$过一个<code>Self-Attention</code>之后进行一个二分类，来计算<code>Repeat</code>和<code>Explore</code>的概率</li>
<li><p><code>Repeat Model</code>:这里需要走到重推的计算逻辑，重推是表示从$I_s$里面推荐出一个概率最高的，这里对于$I_s$序列的item对于每个$ST$都进行一次Attention的前置公式，直接使用<code>Sofatmax</code>的结果，可以理解为$\alpha$因子，具体的公式是这样的:<br>$$e^r_{\tau}=v^T_r tanh (W_rh_t+U_rh_{\tau}) \\<br>P(i|r,I_s)=\left\{<br>\begin{aligned}<br>\frac{exp(e^r_i)}{\sum_{\tau=1}^t exp(e^r_\tau)}  &amp; \quad i \in i_s \\<br>0 &amp; \quad i \in I-I_s\\<br>\end{aligned}<br>\right.$$</p>
</li>
<li><p><code>Explore Mode</code>:在正常推荐时，会过一个<code>Self Attention</code>，然后时$h_t$进行concat,之后就是过一个正常的MLP层以及求softmax了</p>
</li>
</ol>
<p>因此该模型在这里的损失函数有两个:</p>
<ol>
<li>是否执行<code>Repeat</code>还是<code>Explore</code>的损失函数:<br> $$L_{model} = -(\mathbb{I}(i \in I_s)\text{log}P(r|I_s) + (1-\mathbb{I}(i \in I_s))\text{log}P(e|I_s))$$</li>
<li>候选item概率分布的损失函数:<br> $$L_{rec} = \text{log}P(i_\tau|I_s)$$</li>
</ol>
<p>最终该作者用了求和的方式来进行最终的优化:<br>$$L(\theta) = L_{model}+L_{rec}  $$</p>
<p>在实验结果里面显示，该目前也取得了不少的提升:<br><img src="/img/More-Session-Based-Recommendation/repeatnet_exp.png"></p>
<p>其实我到是可以理解为$RepeatNet$是一个更加贴合推荐实际的模型，结合了重推，但是其实在实际使用中可能还存在不少问题：</p>
<ol>
<li>比如在最近topK个已经展现过的再重推是否合适，是否应该有一个阈值来控制。</li>
<li>另外还有一个其实短<code>Session</code>内重复的量不会很高，那意味这个这个Train的Session会比较长，而在实际的场景中很少会用长session来做Inference，因为<code>RNN-based</code>的模型的预测速度和session长度成正比，并且<code>Session</code>太长也意味了效果会变差。</li>
</ol>
<h2 id="User-Based_GRU">User-Based GRU</h2><p>这个paper是在序列推荐模型的GRU模块里面加入用户信息，作者认为在序列建模时加入了用户特征之后能够更好的刻画整个行为序列，具体做法主要是针对<code>GRU</code>模块中加入<code>User</code>向量$v$进行倒腾，主要有三种集成的方式:</p>
<ol>
<li>Linear User Integration:线性方式的集成</li>
<li>Rectified Linear User Integration:比线性更加柔和的一种方式</li>
<li>Attentional User Integration: 以Attention的方式集成</li>
</ol>
<h3 id="Linear_User_Integration">Linear User Integration</h3><p>针对给定<code>GRU</code>的Cell和用户向量下，这种集成是将用户向量加入到更<code>gate</code>的计算以及更新的state中，看下Cell图（其实这个图画的并不是很清晰-_-）:<br><img src="/img/More-Session-Based-Recommendation/linear_gru.png" width="250px"><br>不过再配合一下公式就很清晰了:<br>$$\begin{bmatrix}<br>u \\<br>r<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>\sigma \\<br>\sigma<br>\end{bmatrix}<br>T<br>\begin{bmatrix}<br>h^{t-1} \\<br>E_i^t \\<br>E_v^t<br>\end{bmatrix}$$<br>这是<code>GRU</code>两个门的输出，在计算门的时候加入了用户向量$E_v^t$,其余操作就是和正常的<code>GRU</code>一样了</p>
<h3 id="Rectified_Linear_User_Integration">Rectified Linear User Integration</h3><p>但是针对线性的集成，可以发现用户向量在每一个step都是一样，并且是重复的，这样会增加整个训练的计算量，因此作者又想了一种更加柔和的方式来接入:<br><img src="/img/More-Session-Based-Recommendation/rect_gru.png" width="250px"></p>
<blockquote>
<p>其实改图还是看不大清楚要表达的-_-</p>
</blockquote>
<p>主要思想是 在每一个step时：</p>
<ol>
<li>将输入向量和用户向量concat之后之后过两个MLP得到两个对比向量$\kappa_1 , \kappa_2$</li>
<li>当用户向量$E_v^t$的每个元素都小于$\kappa_1$时，将当前的step的用户向量直接置0（丢弃的意思）</li>
<li>当用户向量有部分小于$\kappa_2$时，对于用户向量的每个元素都乘以一个因子$\omega$</li>
<li>否则，正常使用当前step的用户向量</li>
</ol>
<p>用公式来代替就是:<br>$$ E_v^t=\left\{<br>\begin{aligned}<br>0  &amp; \quad \quad  E_v^t&lt; \kappa_1 \\<br>\omega \cdot E_v^t &amp;\quad \quad  \kappa_1 &lt; E_v^t&lt; \kappa_2 \\<br>E_v^t &amp;\quad \quad  \text{else} \\<br>\end{aligned}<br>\right.$$</p>
<p>然后其余步骤就是和线性的集成一样了</p>
<h3 id="Attentional_User_Integration">Attentional User Integration</h3><p>先对普通线性集成的问题，作者又提了一个新的方式，他认为同一个用户向量在不同step下应该权重是不一样的，比如在t=0的时候，用户向量影响的作用应该是比较低（因为没有多少用户行为）</p>
<blockquote>
<p>哈哈，其实我觉得要看用户向量怎么选了，如果该用户向量可以较为精准的表示用户向量了，这个时候t=0的时候用户的向量应该也是还蛮重要的。</p>
</blockquote>
<p>因此不同的step下用户向量的权重应该是不同的，也就是类似<code>Attention</code>的方式了,但是其实感觉他paper里面和attention的思想还是有一些差异的，先看图<br><img src="/img/More-Session-Based-Recommendation/att_gru.png" width="250px"></p>
<p>该集成方式会根据三个输入来计算一个门(<code>gate</code>:$\xi$)<br>$$ \xi = \sigma(T h^{t-1} + TE_i^t + TE_v^t)$$<br>这个$\xi$用来做每个step的输入向量和用户向量的一个平衡，因此<code>GRU</code>的门计算就是这样了:<br>$$\begin{bmatrix}<br>u \\<br>r<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>\sigma \\<br>\sigma<br>\end{bmatrix}<br>T<br>\begin{bmatrix}<br>h^{t-1} \\<br>(1-\xi) E_i^t \\<br>\xi E_v^t<br>\end{bmatrix}$$<br>那再接下来的就是和线性集成一样了</p>
<p>所以后面两种集成的方式主要是针对线性集成每一步用同一个用户向量再改进的，他的实验效果是这样的:<br><img src="/img/More-Session-Based-Recommendation/userbase_exp.png"></p>
<p>可以看到针对改进过的gru的效果还是有不少提升的.<br>其实在实际工业界里面有不少很成熟的算法框架中也会尝试将一些用户的全局信息/兴趣点通过<code>gate</code>机制来融入到gru中进行训练，能得到一些微弱提升，但是性价比而言相对比较低，当然有富余人员配置时还是值得尝试的。</p>
<h2 id="SR-GNN">SR-GNN</h2><p>作者觉得用户的行为序列可以用图来表示，因此在传统的序列建模时改为使用$GNN^5$对来图进行建模，也就有了这个<code>SR-GNN</code>:<br>直接看架构图吧：<br><img src="/img/More-Session-Based-Recommendation/sr_rnn_arch.png"></p>
<blockquote>
<p>虽然图的头部画的session之间的item是有关联的，其实在model里面各个session其实是独立的-_-!!</p>
</blockquote>
<p>最重要的是他的GNN那块，以$[v_1,v_2,v_3,v_2,v_4]$这个用户的session为例，可以将session用图表示为:<br><img src="/img/More-Session-Based-Recommendation/sr_adj.png" width="250px"></p>
<ul>
<li>他使用邻接矩阵来表示</li>
<li>边之间的权重分为出度权重和入度权重</li>
<li>最终一个图可以用 一个带出度权重的矩阵和 带入度权重的矩阵来表示，他们的shape都是$[N,N]$</li>
</ul>
<p>对于整个序列使用GNN来进行表达：<br>$$a_{s,i}^t = A_{s,i}^T [v_1^{t-1},…,v_n^{t-1}]^T H + b \\<br>z_{s,i}^t = \sigma(W_z a_{s,i}^t + U_z v_i^{t-1}) \\<br>r_{s,i}^t = \sigma(W_r a_{s,i}^t + U_r v_i^{t-1}） \\<br>\tilde{v_i^t} = \text{tanh}(Wa_{s,i}^t + U(r_{s,i}^t \odot v_i^{t-1} )) \\<br>v_i^t = (1-z_{s,i}^t) \odot v_i^{t-1} + z_{s,i}^t \odot \tilde{v_i^t}$$</p>
<p>其中</p>
<ol>
<li>$z$和$r$分布表示重置门和更新门,$\odot$ 表示<code>element-wise</code>的相乘</li>
<li>$A$矩阵其实就是session图的邻接矩阵，$a$向量用户表示相当step下图相关的向量，用于接下来模块的初始化 </li>
<li>眼熟的一眼就看出来了，其实就是<code>GRU</code>单元的公式，最大的差别就是初始化使用的是$a$，状态的维持使用的是$v$向量</li>
</ol>
<blockquote>
<p>额 其实就是<code>GATED GRAPH SEQUENCE NEURAL NETWORKS</code>这篇中的式子</p>
</blockquote>
<p>经过GNN之后可以得到每个节点的embdding，接下来将整个session用<code>local</code>和<code>global</code>两个节点别表示，其中：</p>
<ol>
<li><code>local</code>级别的embedding可以直接使用最后一个item的向量来表示，也就是$s_l = v_n$</li>
<li><code>global</code>级别的embedding使用$soft-attention$来表示$$a_i = q^T \sigma(W_1v_n + W_2v_i+c) \\ s_g = \sum_i^n \alpha_iv_i$$</li>
</ol>
<p>最终的embedding是两个级别向量的合并转换:$$s_h = W_3[s_l;s_g]$$</p>
<blockquote>
<p>其实可以看到最终的embedding里面其实是极大的加强的最后一个item的权重，之前做过相关实验，确实是最后一个item的embedding的最重要的</p>
</blockquote>
<p>其训练时loss采用了经典的交叉熵。<br>实验效果再过一下：<br><img src="/img/More-Session-Based-Recommendation/sr_rnn_exp.png" width="600px"><br>对比本文里面提到了<code>NARM</code>算法效果有提升，但是效果不是提升的很明显。</p>
<p>其实整个<code>SR-GNN</code>模型就是将序列模型是将GRU改成了GNN建模，感觉实用性并不是很高，因为单用户的常规单session中并没有太多可以形成图。-_-</p>
<h2 id="参考">参考</h2><ol>
<li><a href="https://arxiv.org/pdf/1711.04725.pdf" target="_blank" rel="external">Neural Attentive Session-based Recommendation - arXiv</a></li>
<li><a href="https://arxiv.org/pdf/1812.02646.pdf" target="_blank" rel="external">RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</a></li>
<li><a href="https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/p152-donkers.pdf" target="_blank" rel="external">Sequential User-based Recurrent Neural Network Recommendations</a></li>
<li><a href="https://arxiv.org/pdf/1811.00855.pdf" target="_blank" rel="external">Session-based Recommendation with Graph Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1511.05493.pdf" target="_blank" rel="external">GATED GRAPH SEQUENCE NEURAL NETWORKS</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2><p>基于上一篇<code>GRU4REC</code>的继续聊聊深度学习在推荐系统中的应用</p>
<h2 id="NARM">NARM</h2><p>作者提出了一种混合Encoder的方式：全局(<code>Global</code>)所有的序列信息的Encoder和当前(<code>Local</code>)Session序列的Encoder</p>
<p>所以他的模型是：<br><img src="/img/More-Session-Based-Recommendation/narm_arch.png" /></p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深度学习在序列化推荐中的应用(1)-GRU4REC以及扩展]]></title>
    <link href="http://kubicode.me/2018/09/19/Deep%20Learning/GRU4REC-Session-Based-Recommendation/"/>
    <id>http://kubicode.me/2018/09/19/Deep Learning/GRU4REC-Session-Based-Recommendation/</id>
    <published>2018-09-19T09:39:51.000Z</published>
    <updated>2019-01-24T11:05:16.328Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>用户在互联网应用上的绝大部分的行为都是可以用一个序列来表示，比如购物、听音乐、看feed流等，用式子来表示就是$${x_1,x_2,x_3,..,x_N} -&gt; x_{N+1}$$<br>因此对于这个序列如何建模来获取整个用户的意图行为至关重要，而之前传统的ML只能基于统计或者经验的方式来尽量抽取这些序列信息，并无法hold整个序列，16年提出的<code>GRU4REC</code>利用<code>RNN-Based</code>对用户序列进行建模并且取得了不错的效果，同时也会有一些研究对于<code>GRU4REC</code>做了不少改进和扩展，本文主要对<code>GRU4REC</code>以及扩展做一些简答的自我了解和记录。</p>
<a id="more"></a>
<h2 id="GRU4REC">GRU4REC</h2><p><code>GRU4REC</code>是Session信息和GRU结合起来完成了推荐，他给定的场景是：</p>
<blockquote>
<p>用户在我们的应用上有一段行为<code>Session</code>（比如说点击item的需求），然后在于该Session信息来预测接下来可能会发生点击的item，而这笔的Session信息主要使用<code>GRU</code>模型来进行刻画：</p>
</blockquote>
<p><img src="/img/Session-Based-Recommendation/gru4rec_arch.png" width="400px"></p>
<ol>
<li>这边第一步的输入是用户的行为序列: $[x_1,x_2,x_3,..,x_N]$</li>
<li>这些行为序列可以接下来使用两种Embedidng表示，一种是<code>One-Hot</code>方式,另一种是在<code>One-Hot</code>接下来过一个Embedding层</li>
<li>将所有的输入进行向量化表示之后，会过若干层的GRU(就是比较核心的序列化建模了)</li>
<li>完成序列化建模之后再进行一个<code>Feedforward</code>的网络转换</li>
<li><p>最终对下一个目标进行预测,这边的目标其实就是$x_{N+1}$</p>
<blockquote>
<p>(作者说这种方式性能好，但是我到觉得这种场景下<code>One-Hot</code>不是很合适，<code>One-Hot</code>在这边他的DIM会巨大，并且会特别的稀疏,可能还是查表的来的好)</p>
</blockquote>
</li>
</ol>
<p>其实<code>GRU4REC</code>的整个思路还是很清晰，模型也很简单，但是该算法中比较重要的应该是他的加速优化和LOSS的选择可能会有比较大的参考价值意义:</p>
<p>为了能提高训练的效率，采用两种策略来进行训练的优化:</p>
<ol>
<li><p>使用<code>Mini-Batch</code>来进行训练:<br> <img src="/img/Session-Based-Recommendation/gru4rec_minibatch.png" width="400px"><br> 因为用户行为的Session有长有短，并且他的差异性很大，传统的滑窗方式来构建训练数据并不适用，他这里用的策略是将不同的<code>Session</code>给拼接了起来，在同一个序列中如果遇到下一次Session时，会将GRU中的向量参数给重新初始化掉，因为这边GRU是对Step进行预测，所以在序列中间直接初始化掉问题也不大，这样还可以提升数据的利用率，会比简单<code>PADDING</code>的方式更加的合适。</p>
</li>
<li><p>取巧的训练数据采样:<br> 原始的模型中是需要过softmax对于每个item都计算才能对目标的item进行训练，因为item的维度非常高，所以这里的计算量是超级大的。作者在这里比较机智的在目标的样本中根据<code>热门</code>程度进行了采样，采样完成之后将同一个<code>mini-batch</code>中但是是其他<code>Session</code>的next-item作为负样本。用这些正负样本来训练整个神经网络。下面这个图对于采样非常形象了：</p>
</li>
</ol>
<p><img src="/img/Session-Based-Recommendation/gru4rec_sampling.png" width="600px"></p>
<p>因此这个模型现在已经转为对正负样本的一个<code>0-1</code>分类的问题,而且推荐里面，并不存在绝对的正负样本，用户也可能会对多个item存在偏好，所以这边比较合适<code>Loss Function</code>就是用<code>Pair-Wise</code>的模式了(只需要   正样本的score大于负样本即可):</p>
<ol>
<li><code>BPR(Bayesian Personalized Ranking)</code>:这是一种基于矩阵分解的损失函数，他的式子是:$$L_s = - \frac{1}{N_s} \cdot \sum_{j=1}^{N_s} \text{log}(\sigma(\hat{r}_{s,i} - \hat{r}_{s,j}))$$ $N_s$是样本量的大小，$\hat{r}_{s,i}$表示正样本的分数，$\hat{r}_{s,j}$表示负样本的分数</li>
<li><code>TOP1</code>:这是种基于正则化方式的损失函数$$L_s = \frac{1}{N_s} \cdot \sum_{j=1}^{N_s} (\sigma(\hat{r}_{s,j} - \hat{r}_{s,i})) +\sigma(\hat{r^2_j})$$ 这种方式可以将$\hat{r}_{s,i}$的分数计算的更高，但是他同是也会是负样本，所以这边加了二范数来压制$\hat{r}$作为负样本时的分数</li>
</ol>
<p><code>GRU4REC</code>的实验结果也是蛮简单的,Baseline的实验不在这个表中，数据后面跟着的涨幅就是和Baseline的对比:<br><img src="/img/Session-Based-Recommendation/gru4rec_exp.png"><br>这边显示的也是<code>BPR</code>和<code>TOP1</code>这两种LOSS的效果会明显好于传统的交叉熵.</p>
<p><code>GRU4REC</code>是较早的将序列行为和GRU进行结合，其中<code>LOSS</code>这块的构建还是非常值得借鉴的。</p>
<blockquote>
<p>该作者还开放了源码<a href="https://github.com/hidasib/GRU4Rec" target="_blank" rel="external">https://github.com/hidasib/GRU4Rec</a></p>
</blockquote>
<h2 id="GRU4REC-Sampling">GRU4REC-Sampling</h2><blockquote>
<p>其中<code>GRU4REC-Sampling</code>和<code>GRU4REC</code>是同一个作者 ^_^</p>
</blockquote>
<p><code>GRU4REC-Sampling</code>也是在基于<code>GRU4REC</code>上的缺陷提出了额外的<code>Sampling</code>和新的<code>Loss Function</code><br>作者认为<code>GRU4REC</code>存在下面三种局限:</p>
<ol>
<li><code>BatchSize</code>一般都是比较小的，在总样本较多时，如果采样少的话，分数比较高的负样本被采样进来的概率就偏少了（这里高分数要用于下面的Loss） </li>
<li><code>BatchSize</code>会影响运行速度，但是由于设计的是<code>Mini-Batch</code>并行的方式，所以增加<code>BatchSize</code>也不会对速度有多大的影响</li>
<li>虽然<code>GRU4REC</code>用的是根据热度采样，但是实际中全根据热度也不一定适应所有数据集</li>
</ol>
<p>所以在<code>GRU4REC-Sampling</code>中又进行了额外的采样:同样是在<code>Mini-Batch</code>中进行采样，采样时根据这个公式$supp_i^\alpha$,而这边的$\alpha$是一个<code>0~1</code>的值，如果$\alpha=0$表示均匀采样，如果$\alpha=1$为完全的热门采样。</p>
<p>另外<code>GRU4REC</code>中的<code>BPR</code>和<code>TOP1</code>会存在梯度的消失问题，因此作者设计了一种新的损失函数希望来最大化正样本的分数:$$L_{pairwise-max}(r_i,{r_j}_{j=1}^{N_s}) = L_{pairwise}(r_i,max_jr^j)$$<br>从这儿可以看出，新的损失函数是对<code>Max-Score</code>的负样本做pair，但是这种是不可求导了，所以作者用了一种近似的方式来实现,刚刚对<code>Max-Score</code>做负样本的方式可以转为<code>Score</code>越大，则<code>Loss</code>中的权重也越大，而这个权重可以用归一化的<code>softmax</code>来表示:$$s_i = \frac{e^{r_i}}{\sum_{j=1}^N e^{r_j}}$$<br>有了每个样本的权重表示之后，原先的<code>Loss Function</code>可以更改为:</p>
<ol>
<li><code>TOP1-MAX</code>:$$L_{top1-max} = \sum_{j=1}^{N_S}s_j(\sigma(r_j-r_i) + sigma(r_j^2))$$</li>
<li><code>BPR-max</code>:$$L_{bpr-max} = -\text{log} \sum_{j=1}^{N_s} s_j \sigma(r_i,r_j)$$</li>
</ol>
<blockquote>
<p>对比一下<code>GRU4REC</code>中的<code>Loss Function</code>，其实就是额外增加了一个$s_j$的权重值。</p>
</blockquote>
<p><img src="/img/Session-Based-Recommendation/gru4rec_sampling_exp.png"><br>看下实验对比，额外的<code>Sampling</code>和新的<code>Loss Function</code>都还是有极大的提升的,惊呆。</p>
<blockquote>
<p>我个人感觉<code>Sampling</code>起这么大的作用应该是采样之后样本不足了，这是一个训练时间和模型性能上的权衡，那么我如果不采样是不是效果就更好了-_-!!</p>
</blockquote>
<h2 id="GRU4REC-DWell">GRU4REC-DWell</h2><p><code>GRU4REC-DWell</code>也是基于<code>GRU4REC</code>的一个简单的改进，其中<code>GRU4REC</code>已经证明在时序的推荐中序列化的建模非常有用。<br>另外作者认为在用户行为序列中，每个item的停留时间是非常重要的一个特征，而之前的<code>GRU4REC</code>算法只是用于简单的交互行为来构建样本，所以<code>GRU4REC-DWell</code>主要是很巧妙将用户在序列item上的停留时间和GRU4REC<code>结合了起来:</code></p>
<p><img src="/img/Session-Based-Recommendation/gru4rec_dwell.png" width="400px"><br>这里主要的Idea就是在原始的用户行为中，作者根据item上面的停留时间根据阈值进行切片，如果停留时间长的可能会有很多个切片，每个切片都作为一个新的行为项:<br>给定一个行为序列的集合$X=\{x_1,x_2,…,x_n\}$,每一个$x_i$对应的停留时间为$dt_i$,其中$t$为切片的阈值，则$x_i$可以分割的切片为$d_t/t + 1$。 也就是如上图所示，$i_{2,1}$就由于停留时间较久，所以分割成了三个切片。<br>然后其他的就如原始的<code>GRU4REC</code>一样了，但是作者在做对比实验室加入了<code>GRU4REC-SAMPLING</code>进行了一起对比：<br><img src="/img/Session-Based-Recommendation/gru4rec_dwell_exp.png" width="400px"><br>实验中显示，停留时间信息的加入对于模型的作用是非常巨大的。</p>
<h2 id="HRNN">HRNN</h2><p>用户往往会存在多段不连续的Session（比如逛淘宝时，早上公交逛一次，中午午睡时逛一次，晚上睡前逛一次，这样就有三段Session序列，每一段内部是连续的），而之前的模型都是将这些Session行为都是独立训练的，文本中作者认为同一用户的不同Session间是有关联的，建模每一段Session可以发现用户的衍化。<br>所以作者提出了一种层次化的RNN序列建模，在每一段的<code>Session-Level</code>内部使用RNN建模的同时，会有一个<code>User-Level</code>的RNN来建模当前用户跨Session的行为，而<code>User-Level</code>的RNN的输入就是每一段<code>Session-Level</code>的final state。</p>
<p>用户的所用行为表示为$$C^u = \{ S_1^u,S_2^u,…S_{M_u}^u \}$$ $S_m^u$代表一次完整的Session，其中$s_m^u$代表对应<code>Session</code>的<code>Representations</code>(也就是最终一个final state),则<code>User</code>级别的<code>Representations</code>为$$c_m = GRU_{usr}(s_m,c_{m-1}),m = 1,…,M_u$$</p>
<p>所以这边<code>HRNN</code>的整个层次结构如图所示:<br><img src="/img/Session-Based-Recommendation/hrnn_arch.png"></p>
<ul>
<li>上面一层代表<code>Session-Level</code>的RNN，输入的是item，会对<code>next basket</code>进行预测，同时输出<code>final state</code></li>
<li>下面一层代表<code>User-Level</code>的RNN，输入的是<code>Session-Level</code>的<code>final state</code>，用户维护当前用户在整个应用的行为建模，并且会将当前Session的state输出作为下一次Session的<code>init state</code></li>
</ul>
<p><img src="/img/Session-Based-Recommendation/hrnn_exp.png" width="600px"><br>主要对比的是原生的<code>GRU4REC</code>，性能大约有10%左右的提升，但是用的数据和<code>GRU4REC-Sampling</code>以及<code>GRU4REC-DWell</code>的不一样，感觉没有他们的提升多，并且在现实过程中，对于<code>Session</code>的划分也是需要很多的<code>trick</code>啊。</p>
<h2 id="总结">总结</h2><p>其实<code>GRU4REC</code>在DL中是一个非常<code>straight-forward</code>的框架，但是他的厉害之处就是设计了<code>Mini-Batch</code>和<code>Sampling</code>将整个模型跑了起来并且起到了一定的效果,另外后面的几个改进中停留时间的改进以及层次的<code>Session</code>还是比较不错，并且可实用性高一些。</p>
<h2 id="参考">参考</h2><ol>
<li>Hidasi, Balázs, et al. “Session-based recommendations with recurrent neural networks.” arXiv preprint arXiv:1511.06939 (2015).</li>
<li>Hidasi, Balázs, and Alexandros Karatzoglou. “Recurrent neural networks with top-k gains for session-based recommendations.” arXiv preprint arXiv:1706.03847 (2017).</li>
<li>Bogina, Veronika, and Tsvi Kuflik. “Incorporating dwell time in session-based recommendations with recurrent Neural networks.” CEUR Workshop Proceedings. Vol. 1922. 2017.</li>
<li>Quadrana, Massimo, et al. “Personalizing session-based recommendations with hierarchical recurrent neural networks.” Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 2017.</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2><p>用户在互联网应用上的绝大部分的行为都是可以用一个序列来表示，比如购物、听音乐、看feed流等，用式子来表示就是$${x_1,x_2,x_3,..,x_N} -&gt; x_{N+1}$$<br>因此对于这个序列如何建模来获取整个用户的意图行为至关重要，而之前传统的ML只能基于统计或者经验的方式来尽量抽取这些序列信息，并无法hold整个序列，16年提出的<code>GRU4REC</code>利用<code>RNN-Based</code>对用户序列进行建模并且取得了不错的效果，同时也会有一些研究对于<code>GRU4REC</code>做了不少改进和扩展，本文主要对<code>GRU4REC</code>以及扩展做一些简答的自我了解和记录。</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[据说有RNN和CNN结合的xDeepFM]]></title>
    <link href="http://kubicode.me/2018/09/17/Deep%20Learning/eXtreme-Deep-Factorization-Machine/"/>
    <id>http://kubicode.me/2018/09/17/Deep Learning/eXtreme-Deep-Factorization-Machine/</id>
    <published>2018-09-17T12:29:14.000Z</published>
    <updated>2018-09-18T02:41:25.767Z</updated>
    <content type="html"><![CDATA[<h2 id="介绍">介绍</h2><p>也是一篇在CTR预估中堆Deep层数的轮子文，先来了解一下：</p>
<ol>
<li><a href="Deep-in-out-Factorization-Machines-Series">DeepFM</a>：使用<code>FM</code>的特征组合能力灌给DNN进行joint-train</li>
<li><a href="Talk-About-CTR-With-Deep-Learning">Deep&amp;Cross</a>：根据首层和次层的依赖可以解决多阶特征组合的问题</li>
</ol>
<p>不过xDeepFM所提出的点是结合RNN和CNN的特性完成多阶特征的抽取，并且最终和和DNN以及Linear整合到一起完成显性特征的使用。<br><a id="more"></a></p>
<h2 id="CIN">CIN</h2><p>据说有RNN和CNN结合的xDeepFM中最重要的核心元素是<code>CIN</code>（Compressed Interaction Network）<br>一个图来解释<code>CIN</code>:<br><img src="/img/eXtreme-Deep-Factorization-Machine/CIN-Network.png" alt=""><br>这里：</p>
<ol>
<li>我们输入的是一个m个特征的D维Embedding数据，简称$X^0 \in R^{m \times D}$,这个作为第一层</li>
<li>然后CIN有设计一种计算下一层的式子：$$X_{h,*}^k = \sum_{i=1}^{H_{k-1}} \sum_{j=1}^m W_{i,j}^{k,h}(X_{i,*}^{k-1} \circ X_{j,*}^0)$$<ol>
<li>这里的$\circ$符号表示点击，$(a_1,a_2,a_3) \circ (b_1,b_2,b_3) = (a_1b_1,a_2b_2,a_3b_3)$</li>
<li>整个式子可以分解为两份，类RNN和CNN</li>
<li>在计算$X^k$时是依赖$X^{k-1}$的，所以类似RNN那种是依赖上一个状态，同时里面还引入了$X^0$，其实是参考了<code>Deep&amp;Cross</code>的做法，这一步形象的画出来就是上图(a)</li>
<li>他们一步完成之后会产生一个中间状态$z^{k+1}$，是一个三维的张量，其实基于$W$矩阵的投射可以重新转为一个二维的$X^{k+1}$，其实是类似一个CNN的卷积过程，就是图中$b$</li>
<li>这些深层级的$X$计算完毕之后，使用一个<code>sum pooling</code>将各个feature map进行聚合$$p_i^k = \sum_{j=1}^D X_{i,j}^k$$</li>
<li>将所有的聚合层concat之后得到$p^+ = [p^1,p^2…p^T]$</li>
<li>再通过激活函数得到最终的结果$$y=\frac{1}{1+exp(p^+W)}$$</li>
</ol>
</li>
</ol>
<p>这儿<code>CIN</code>各种复杂度：</p>
<ol>
<li>他的参数复杂度是:$\sum_{k=1}^T H_k \times (1+H_{k-1} \times m)$<ul>
<li>$T$表示<code>CIN</code>的总层数</li>
<li>每一层的W参数是$H_k \times H_{k−1} \times m$</li>
<li>顶部线性成的参数量是$H_k$</li>
</ul>
</li>
<li>他的计算复杂度是:$O(mH^2DT)$<ul>
<li>他单层的$Z^{k+1}$的计算复杂度是$O(mHD)$</li>
<li>并且额外的我们还需要将feature maps汇聚到$H$个隐藏节点</li>
</ul>
</li>
</ol>
<h2 id="xDeepFM">xDeepFM</h2><p>最终的<code>xDeepFM</code>的大结构是参考了<code>Wide&amp;Deep</code>的方式:<br><img src="/img/eXtreme-Deep-Factorization-Machine/eDeepFM-arch.png" align="center" width="600px"></p>
<ol>
<li>最左侧是一个线性模型（其实这儿是一个稀疏层）</li>
<li>中间是上面刚刚描述的<code>CIN</code>模型</li>
<li>最右侧其实就是一个传统的<code>DNN</code>模型了</li>
<li>最终将所有的隐藏层的值合并进行了计算：$$y=\sigma(W_{\text{linear}}^T a + W_{\text{dnn}}^T  x_{\text{dnn}} + W_{\text{cin}}^Tp^+ + b)$$</li>
</ol>
<p>他和<code>DeepFM</code>的关系：如果将<code>CIN</code>这一层里面的层数改为1，他其实就是一个FM</p>
<h2 id="实验结果">实验结果</h2><p>里面描述的实验结果中，<br><img src="/img/eXtreme-Deep-Factorization-Machine/exp.png" width="600px"><br>看起来<code>xDeepFM</code>还是有一些提升的，不过主要提升是在<code>DianPing</code>数据集上，另外两个数据集提升的还是很微弱，在这种复杂度下，计算性能和带来的效果回报的受益就比较低了。</p>
<h2 id="总结">总结</h2><ol>
<li>感觉<code>xDeepFM</code>主要引入了<code>Deep&amp;Cross</code>里面的<code>Cross</code>机制，就是在做堆叠</li>
<li>另外其实看到堆叠和交叉还是能带来一定效果的，但是受益越来越不明显了，如果运行性能和算法性能的性价比，<code>FM</code>无疑是最高，但是Deep模型可以说故事（chui）啊</li>
<li>作者开放了<a href="https://github.com/Leavingseason/xDeepFM" target="_blank" rel="external">源码</a>，赞一个</li>
</ol>
<h2 id="文献">文献</h2><ol>
<li>Lian, Jianxun, et al. “xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems.” arXiv preprint arXiv:1803.05170 (2018).</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="介绍">介绍</h2><p>也是一篇在CTR预估中堆Deep层数的轮子文，先来了解一下：</p>
<ol>
<li><a href="Deep-in-out-Factorization-Machines-Series">DeepFM</a>：使用<code>FM</code>的特征组合能力灌给DNN进行joint-train</li>
<li><a href="Talk-About-CTR-With-Deep-Learning">Deep&amp;Cross</a>：根据首层和次层的依赖可以解决多阶特征组合的问题</li>
</ol>
<p>不过xDeepFM所提出的点是结合RNN和CNN的特性完成多阶特征的抽取，并且最终和和DNN以及Linear整合到一起完成显性特征的使用。<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聊聊CTR预估的中的深度学习]]></title>
    <link href="http://kubicode.me/2018/03/19/Deep%20Learning/Talk-About-CTR-With-Deep-Learning/"/>
    <id>http://kubicode.me/2018/03/19/Deep Learning/Talk-About-CTR-With-Deep-Learning/</id>
    <published>2018-03-19T02:59:05.000Z</published>
    <updated>2018-03-20T16:42:36.000Z</updated>
    <content type="html"><![CDATA[<h2 id="CTR预估">CTR预估</h2><p>CTR预估一直以来都是工业界搜索、广告和推荐中的核心，而传统的LR模型（逻辑回归）几乎可以被称为CTR界的神算法，虽然他结构非常简单，但是他计算速度特别快，并且在加以特征工程师的修饰，一样可以拿到很好的效果。<br>但是这样的操作毕竟特征的选择会起比较重要的作用，如果遇到不同任务需要重新提取不同类型的特征。在2014年Facebook通过GBDT的生成LR特征的方式，取得了不错的效果。众所周知，GBDT中的策略树将会有一定的特征选择功能，因此该方式先原先（未经过太多特征工程的特征过一把GBDT），将GBDT的叶子节点作为特征继续输入到LR模型中，最终对目标的CTR值进行预测。<br>除特征工程外，LR的另一个缺陷就是对于高阶的表达能力不足，从这两个出发点，结合公司中手头的一些工作，整了下最近比较经典的Paper来说说深度学习在CTR预估中的一些方法，主要有:<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>、<code>Deep&amp;Cross</code>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM" target="_blank" rel="external">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM" target="_blank" rel="external">NFM</a>.</p>
<a id="more"></a>
<h2 id="FNN">FNN</h2><p>上海交大张伟楠老师利用<code>FM</code>做特征Embedding，然后在上面叠加nn，提出了<code>FNN</code>模型。</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/fnn_arch.png" width="400px"></center>

<p>其实模型架构图还是蛮清晰的，看懂了<code>FM</code>那一层之后就很明了了:</p>
<ol>
<li>输入的是各种稀疏特征（可以是最简单的各种id）</li>
<li>接下来将会经过一个<code>已训练</code>的<code>FM</code>层，直接取到<code>FM</code>模型中对于特征的隐向量</li>
<li>通过隐向量可以构造出<code>NN</code>的输入层<code>z</code>:$z = (w_0,z_1,z_2,…,z_n)$,而$z_i=(w_i,v_i^1,v_i^2,…v_i^K)$,其中$w_i$为<code>FM</code>中的一阶权重,$v_i$为对应特征的隐向量</li>
<li>再接下来就是堆一个<code>NN</code>层来计算最终的目标值了。</li>
</ol>
<p><code>FNN</code>的最大优势就是不需要再去做特征工程了，其特征由<code>FM</code>的隐向量构建得到。同时其缺点就是需要<code>pre-train</code>才能让这个<code>FNN</code>给跑起来.</p>
<h2 id="PNN">PNN</h2><p>2016年，张伟楠老师他们又提出了一种名为<code>PNN</code>的模型，对<code>Embedding</code>向量做<code>innner/outer product</code>（其实就是对原来的<code>FNN</code>模型进行改吧改吧）。</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/pnn_arch.png" width="400px"></center>

<p>其中（<code>bottom-top</code>方向）:</p>
<ol>
<li>其中第一层是输入的离散特征<code>Field N</code></li>
<li>第二层是对离散特征的<code>Embedding</code>（这儿<code>Embedding</code>的方式有很多种，最经典的就是<code>TF</code>的<code>lookup_table</code>）</li>
<li>重点在第三层，就是模型的创新点<code>Product Layer</code>，这里分两部分，一部分是$z$，他是保持了原有<code>Embedding</code>向量的数据，另一部分是$p$,主要对上一层的向量数据进行<code>pairwise feature interaction</code>,也就是做<code>product</code>的工作</li>
<li>接下来又是继续走一波<code>NN</code>网络</li>
<li>最后对点击率进行预估计算</li>
</ol>
<p>上面的是整个<code>PNN</code>的模型架构，而根据$p$中可选<code>Inner Product</code>和<code>Outer Product</code>的两种方式提出<code>IPNN</code>和<code>OPNN</code>这两个模型，这两模型中$z$是一样的，先来看一下$z$:<br>$$l_z =(l_z^1,l_z^2,…,l_z^n,…,l_z^{D1})$$<br>而<br>$$l_z^n = W_z^n \odot z_n =  \sum_j^M (W_z^n)_{j} f_{n,j}$$</p>
<blockquote>
<p>这里的$f_i$为第$i$个特征的<code>Embedding</code></p>
</blockquote>
<p>因此可以看出$l_z$其实只是对原有的<code>Embedding</code>做了一层转换</p>
<p>在$p$部分:<br>$$l_p =(l_p^1,l_p^2,…,l_p^n,…,l_p^{D1})$$<br>并且$$p={p_{i,j}} ,i=1…N,j=1..N$$</p>
<blockquote>
<p>其中$p_{i,j} = g(f_i,f_j)$<br> $g$就是可以做<code>Inner Product</code>和<code>Outer Product</code></p>
</blockquote>
<p>这里再细节的东西就不贴了，感觉Paper里的符号的上下标有点乱(当然也有可能是我没完全看明白-_-)，其实<code>PNN</code>里面的主要贡献就是在<code>Embedding</code>的基础上再多做一些<code>Pairwise Product</code>的操作增强高阶/非线性效果。</p>
<h2 id="Wide&amp;Deep">Wide&amp;Deep</h2><p>相比对<code>FNN</code>和<code>PNN</code>，Google在2016年提出来的<code>Wide&amp;Deep</code>模型更加有名气和通用化一些，顾名思义，整个模型将分为<code>Wide</code>和<code>Deep</code>两个部分:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/wdl_arch.png" width="600px"></center>


<p>左边的<code>Wide</code>是传统的大规模特征+线性模型（也就是经典的LR模型），右边的<code>Deep</code>是一个<code>DNN</code>模型，而中间的<code>Wide&amp;Deep</code>把两个模型在最后一层做了组合。原文中其实是将两个模型的输出求和:<br>$$P(Y=1|x) = \sigma(W_{wide}^T[x,\phi(x)] + W_{deep}^T \alpha^{(lf)}+b)$$</p>
<p>很明显是一个分治的思想，<code>Wide</code>负责处理大规模离散特征，<code>Deep</code>负责处理连续特征，各自发挥自己的优势。再按文章的意思就是:</p>
<ol>
<li><code>Wide</code>可以达到<code>Memorization</code>功能，从训练数据中学习已经出现过的共现和相关性。</li>
<li><code>Deep</code>可以有Generalization：对于没有出现过的数据，需要从数据中学习到抽象的概念,也就是泛化性。</li>
</ol>
<p><code>Wide&amp;Deep</code>模型简单，扩展性更加强，而且运行效率上也比较可控，因此在实际业务中使用非常广泛，并且原生的TF也还提供了<code>Wide&amp;Deep</code>的接口:<a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="external">https://www.tensorflow.org/tutorials/wide_and_deep</a></p>
<p>另外在<code>DeepFM</code>中有一个图对比<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>的区别，非常的清晰:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/fnn_pnn_wdl.png" width="600px"></center>

<h2 id="Deep&amp;Cross">Deep&amp;Cross</h2><p><code>Wide&amp;Deep</code>虽然经典，但是仍旧么有解决特征组合问题，特征组合算法在<code>FM</code>系列的深度学习中也已经有不少研究:<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM" target="_blank" rel="external">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM" target="_blank" rel="external">NFM</a>.,<code>Google</code>在2017年又提出了一种名为<code>Deep&amp;Cross</code>的CTR预估算法(也简称<code>DCN</code>)，可以用级联的方式来深度的提取高阶的特征，同样先来看下模型的架构:</p>
<center><img src="/img/Take-about-CTR-With-Deep-Learning/dcn_arch.png" width="400px"></center>

<p>如上图:</p>
<ol>
<li><code>DCN</code>模型的输入基本为连续特征(<code>Dense Feature</code>)和id类的离散特征(<code>Sparse Feature</code>),同时将会离线特征处理成embedding特征，这样就可以通过理解为模型的输入是一个连续的向量$x_0$</li>
<li>接下来模型分为两部分:<ol>
<li>右侧部分是传统的DNN模型，其中每个全连接层都使用<code>RELU</code>激活函数, 把输入特征通过多个全连接层之后特征变得更加高阶:$$h_i=\text{ReLu}(w_{h,i}x_{i-1}+b_{h,i})$$</li>
<li>左侧部分则是DCN的核心<code>Cross</code>层,每一层的特征都由其上一层的特征进行交叉组合，并且会吧上一层的原始特征重新加回来。这样既能做特征组合，又能保留低阶原始特征，而且还随着<code>Cross</code>层的增加，是可以生成任意高阶的交叉组合特征$$x_{l+1} = x_0x_l^Tw_l+b_l+x_l = f(x_l,w_l,b_l)+x_l$$</li>
</ol>
</li>
<li>最终会将<code>DNN</code>模型和<code>Cross</code>模型输出的向量进行<code>concat</code>起来之后过一把<code>LR</code>进行点击率预测。</li>
</ol>
<p>其中<code>Cross</code>的特征组合层与<code>FM</code>相比，可以理解为<code>FM</code>只能做到两阶的特征组合（因为<code>FM</code>是嵌套方式的，如果是多阶的特征是指数上升的），而<code>Cross</code>里面的可以完成任意多阶的组合，阶数与<code>Cross</code>的深度一致，并且其参数复杂度与阶数是线性关系$$d \times L_c \times 2$$</p>
<blockquote>
<p>$d$为输入向量的大小，$L_c$为<code>Cross</code>的深度</p>
</blockquote>
<h2 id="总结">总结</h2><p>上面几种深度学习模型基本是在一个固有的<code>DNN</code>结构上，在输入层加东西或者在隔壁加额外层来结合。<br><code>FNN</code>和<code>PNN</code>算法在特征组合与深度学习的结合上都给出了不少启发，但是毕竟<code>Google</code>出品，必属精品，<code>Wide&amp;Deep</code>无疑是使用更加广泛,当然在目前机器资源越来越好的情况下，也将会有更多更加复杂的深度模型将会取尝试。<br>同时也有经验表明，在不断上各种复杂模型的前提下，<code>CTR</code>预估的效果还是会不断的提升。</p>
<h2 id="参考">参考</h2><p>[1]. He, Xinran, et al. “Practical lessons from predicting clicks on ads at facebook.” Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, 2014.<br>[2]. Zhang, Weinan, Tianming Du, and Jun Wang. “Deep learning over multi-field categorical data.” European conference on information retrieval. Springer, Cham, 2016.<br>[3]. Qu, Yanru, et al. “Product-based neural networks for user response prediction.” Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016.<br>[4]. Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, 2016.<br>[5]. Wang, Ruoxi, et al. “Deep &amp; Cross Network for Ad Click Predictions.” arXiv preprint arXiv:1708.05123 (2017).</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="CTR预估">CTR预估</h2><p>CTR预估一直以来都是工业界搜索、广告和推荐中的核心，而传统的LR模型（逻辑回归）几乎可以被称为CTR界的神算法，虽然他结构非常简单，但是他计算速度特别快，并且在加以特征工程师的修饰，一样可以拿到很好的效果。<br>但是这样的操作毕竟特征的选择会起比较重要的作用，如果遇到不同任务需要重新提取不同类型的特征。在2014年Facebook通过GBDT的生成LR特征的方式，取得了不错的效果。众所周知，GBDT中的策略树将会有一定的特征选择功能，因此该方式先原先（未经过太多特征工程的特征过一把GBDT），将GBDT的叶子节点作为特征继续输入到LR模型中，最终对目标的CTR值进行预测。<br>除特征工程外，LR的另一个缺陷就是对于高阶的表达能力不足，从这两个出发点，结合公司中手头的一些工作，整了下最近比较经典的Paper来说说深度学习在CTR预估中的一些方法，主要有:<code>FNN</code>、<code>PNN</code>、<code>Wide&amp;Deep</code>、<code>Deep&amp;Cross</code>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#DeepFM">DeepFm</a>、<a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM">NFM</a>.</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深入浅出Factorization Machines系列]]></title>
    <link href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/"/>
    <id>http://kubicode.me/2018/02/23/Deep Learning/Deep-in-out-Factorization-Machines-Series/</id>
    <published>2018-02-23T12:33:22.000Z</published>
    <updated>2019-10-17T11:26:37.476Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>近期使用<code>FM</code>系列完成了一个<code>CTR</code>预估的任务，本文是阅读了一些paper之后对于<code>FM</code>、<code>FFM</code>、<code>DeepFM</code>、<code>NFM</code>,<code>AFM</code>的一个理解和记录</p>
</blockquote>
<h2 id="FM">FM</h2><p><code>Factorization Machine(FM)</code>由Steffen Rendle在2010年提出，旨在解决系数数据下的特征组合的问题，目前该系列模型在搜索推荐领域被广泛使用。</p>
<h3 id="一个栗子">一个栗子</h3><p>先来看一个经典的电影评分问题</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/fm_case.png" width="400px"></center>

<a id="more"></a>
<p>问题就是需要对电影进行评分($y$项)，而$x$都是特征,其中:</p>
<ol>
<li>第一部分蓝色的为当前评分的用户</li>
<li>第二部分红色的为被评分的电影</li>
<li>第三部分黄色的为该用户曾经对其他电影的评分情况</li>
<li>第四部分绿色的为该用户当前评分的月数</li>
<li>第五部分棕色为该用户最新一次评分的电影</li>
</ol>
<p>这是一个经典的回归问题，最简单粗暴的方法就先上一个线性回归，其中对于绿色特征处理成binary，这样计算公式就是为<br>$$y_{lr} = w_0 + \sum_i^n w_i \cdot x_i$$</p>
<p>这样可能会过于简单粗暴，按照算法（特征）工程师的套路会对某些特征进行组合，这样为了方便，咱们就给他来一个全组合:<br>$$y_{lr-cross} = w_0 + \sum_i^n w_i \cdot x_i + \sum_i^n \sum_{j=i+1}^n w_{i,j}  x_i x_j$$</p>
<p>看似问题解决了，但是这样会存在这么几个问题:</p>
<ol>
<li>参数空间过大,这里为$O(n^2)$，在处理互联网数据时，特征两级别可能是亿级别的</li>
<li>需要人工经验，这里一般会选择某些特征来组合，此时人工/专家经验就会很重要</li>
<li>样本量过滤稀疏，实际上那这种方式拿到的特征会是很稀疏的，对于在训练样本中未出现过的组合该模型无能为力</li>
</ol>
<h3 id="FM解法">FM解法</h3><blockquote>
<p>定理:对于一个正定举证$W$，始终存在一个矩阵$V$使得$W=V \cdot V^t$成立（需要$V$的维数$k$足够大）</p>
</blockquote>
<p>但是在巨大稀疏矩阵的情况下，当$k$并不是很大时$V \cdot V^t$也可以很接近$W$，因此可以用<br>$$w_{i,j} = \left \langle v_i,v_j \right \rangle = \sum_f^k v_{i,f} \cdot v_{j,f}$$<br>其中这里$v$为长度$k$的一个向量,$\left \langle v_i,v_j \right \rangle$表示两个向量的点积，在<code>FM</code>中也称为隐向量,这样就有了<code>FM</code>的式子:<br>$$y := w_0 + \sum_i^n w_i \cdot x_i + \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j$$<br>到了这里<code>FM</code>的式子:</p>
<ol>
<li>可以解决稀疏向量问题，因为每个特征都有一个隐向量，就算是稀疏向量在训练样本没有出现过的组合在预测时也可以进行计算</li>
<li>同时参数空间也降低到了$O(n\cdot k)$</li>
</ol>
<p>但是他实际的运算复杂度并没有降低，反而还到了$O(kn^2)$,但是<code>FM</code>这里的二阶项并没有依赖其他模型参数除了$v_i$，这里就可以鬼斧神工的写为:<br>$$\begin{equation}\begin{split} \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j &amp;= \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \left \langle v_i,v_j \right \rangle x_i x_j - \frac{1}{2} \sum_{i=1}^n \left \langle v_i,v_i \right \rangle x_i x_i  \\<br>&amp;= \frac{1}{2} \left ( \sum_{i=1}^n \sum_{j=1}^n \sum_{f=1}^k v_{i,f} v_{j,f} x_i x_j - \sum_{i=1}^n \sum_{f=1}^k v_{i,f} v_{i,f} x_i x_i  \right ) \\<br>&amp;= \frac{1}{2} \sum_{f=1}^k \left[ \left ( \sum_{i=1}^n v_{i,f}x_i \right ) \left( \sum_{j=1}^n v_{j,f}x_j \right ) -\sum_{i=1}^n v_{i,f}^2 x_i^2 \right ] \\<br>&amp;= \frac{1}{2} \sum_{f=1}^k \left[ \left ( \sum_{i=1}^n v_{i,f}x_i \right )^2 -\sum_{i=1}^n v_{i,f}^2 x_i^2 \right ]<br>\end{split}\end{equation}$$</p>
<p>经过这样的转换之后，最终的模型计算复杂度将会降低到$O(kn)$，同时由于是巨大的稀疏场景，样本实际的特征量的平均值为$\bar{m}$并且$\bar{m}&lt;&lt;n$,最终的模型复杂度将会降低到$O(k \bar{m})$</p>
<h3 id="FM学习">FM学习</h3><p>在<code>FM</code>中模型的参数有$w_0$,$W$以及$V$，这些参数可以通过梯度下降法进行高效的计算，其中梯度为:<br>$$ \frac{\partial}{\partial  \theta}y(x)=\left\{<br>\begin{aligned}<br>1 &amp; \quad if \quad \theta = w_0 \\<br>x_i &amp; \quad if \quad \theta = w_i \\<br>x_i \sum_{j=1}^n v_{j,f}x_j-v_{i,f}x_i^2 &amp; \quad if \quad \theta = v_{i,f} \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>其中$\sum_{j=1}^n v_{j,f}x_j$部分与$i$相互独立，可以预先计算出来,另外<code>FM</code>在过拟合方面一般推荐使用<code>L2正则项</code></p>
</blockquote>
<p>所以在梯度计算方面可以在$O(1)$下进行计算<br>作者也提供了一个很强大的开源工具来训练<code>FM</code>:<a href="http://www.libfm.org" target="_blank" rel="external">http://www.libfm.org</a></p>
<h3 id="扩展">扩展</h3><p>其实对于经典的特征组合问题，也非常容易能想到使用万能的<code>SVM</code>来求解，比如一个二阶的多项式<code>SVM</code>可以写成这样:<br>$$y_{svm} = w_0 + \sqrt{2} \sum_{i=1}^n w_ix_i + \sum_{i=1}^n w_i^{(2)}x_i^2 + \sqrt{2} \sum_{i=1}^n \sum_{j=i+1}^n w_{i,j}^{(2)}x_ix_j$$</p>
<p>这样可以发现二阶多项式的<code>svm</code>和<code>FM</code>十分相似，只多了一项$\sum_{i=1}^n w_i^{(2)}x_i^2$，但是<code>SVM</code>对于未出现在训练样本的组合特征也是无法计算，同时他需要使用对偶才能进行求解,并且他在预测的时候还需要训练样本的支持向量。</p>
<p>另外<code>FM</code>还可以用于<code>tag</code>的推荐排序，问题描述是给定用户信息$U$，宝贝信息$I$，对于相应的标签<code>T</code>进行排序，在binary特征下面模型可以表述为:<br>$$n:= |U \cup I \cup T|, \quad x_i=\delta (j=i \vee j=u \vee j=t)$$<br>使用<code>FM</code>的计算为<br>$$y(x) = w_0 +w_u+w_i+w_t+\left \langle v_u,v_i \right \rangle + \left \langle v_u,v_t \right \rangle + \left \langle v_i,v_t \right \rangle $$<br>但是在排序问题上，当对于<code>tagA</code>,<code>tagB</code>进行排序时，他们的$w_0 +w_u+w_i+\left \langle v_u,v_i \right \rangle$分项计算其实是一样的，所以<code>FM</code>模型最终在<code>tag</code>排序的问题上可以简化为:<br>$$y(x):=w_t+ \left \langle v_u,v_t \right \rangle + \left \langle v_i,v_t \right \rangle$$<br>这样就是<a href="https://www.ismll.uni-hildesheim.de/pub/pdfs/Rendle2010-PITF.pdf" target="_blank" rel="external">PITF</a>模型极为相似了.</p>
<p>当然上面说的都是二阶<code>FM</code>，其实<code>FM</code>还是支持多阶的，只是由于性能/效率问题一般二阶就够了，感兴趣的同学可以去看原始paper</p>
<h2 id="FFM">FFM</h2><p><code>FFM</code>其实是在<code>FM</code>的基础上做了一些更加细致化的工作:作者Yuchin认为相同性质的特征归于同一field，而当前特征在不同field上的表现应该是不同的.<br>比如在广告领域中性别对于广告商(Advertiser)和投放地(Publisher)的作用就是不一样的，比如:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/ffm_case.png" width="400px"></center>

<p>这里的特征被分为了三类，有投放地(Publisher)，广告商(Advertiser)和性别(Gender),如果使用<code>FM</code>来预估这个点击率则是:<br>$$\left \langle v_{ESPN},v_{Nike} \right \rangle + \left \langle v_{ESPN},v_{Male} \right \rangle + \left \langle v_{Nike},v_{Male} \right \rangle$$</p>
<p>这里可以看出<code>FM</code>中隐向量对于不同类别的特征进行组合时都是使用同一个向量，而基于<code>Field-aware</code>的<code>FFM</code>就是对这点进行修改，认为当前向量对于每一个类别都有一个不同的隐向量，比如性别和投放地进行组合的时候使用的隐向量为$v_{Male,G}$,这样推广开来之后这个问题中<code>FFM</code>的二阶项就可以表述为:<br>$$ \left \langle v_{ESPN,A},v_{Nike,P} \right \rangle + \left \langle v_{ESPN,G},v_{Male,P} \right \rangle + \left \langle v_{Nike,G},v_{Male,A} \right \rangle$$</p>
<p>这样,<code>FFM</code>使用通用化的学习公式表达了之后为:<br>$$y_{FFM}(x) = w_0 + \sum_i^n w_i \cdot x_i + \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_{i,f_j},v_{j,f_i} \right \rangle x_ix_j$$</p>
<p>因为<code>FFM</code>的参数空间为$nfk$,其计算复杂度为$O(\bar{n}k)$,但是<code>FFM</code>都是在特定的field的中来学习训练隐向量的，所以一般来说:<br>$$k_{FFM} &lt;&lt; k_{FM}$$</p>
<blockquote>
<p>其实我实际试用下来这里的$&lt;&lt;$不是很严谨，<code>FM</code>的$k$也并没有比<code>FFM</code>多太多，也许只可能是一个8和4的差别。-_-!!</p>
</blockquote>
<p><code>FFM</code>的改进看上去还是有挺有道理的，但是其实最终实验做出来和<code>FM</code>的效果不相上下:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/ffm_v_fm.png" width="600px"></center>

<p>实验结果上<code>FFM</code>也只是在某几个数据集上略好于<code>FM</code>，但是由于<code>FFM</code>中的隐向量与field有关，无法直接转为<code>FM</code>中的$O(k\bar{n})$的运算式子，所以在工业界追求运行效率的时候<code>FM</code>还是首选，不过是比赛中<code>FFM</code>也是一个不错的选择.</p>
<blockquote>
<p>这里符一下<code>FFM</code>的开源工具代码:<a href="https://www.csie.ntu.edu.tw/~cjlin/libffm/" target="_blank" rel="external">https://www.csie.ntu.edu.tw/~cjlin/libffm/</a>,注意里面有有提供只含二阶项的版本和同时含线性计算的版本.</p>
</blockquote>
<h2 id="DeepFM">DeepFM</h2><p>受到<code>Wide&amp;Deep</code>的启发，Huifeng等人将FM和Deep深度学习结合了起来，简单的说就是将<code>Wide</code>部分使用<code>FM</code>来代替，同时FM的隐向量可以充当Feature的Embedding，非常巧妙:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/deepfm_arch.png" width="600px"></center>

<p><code>DeepFM</code>的架构其实特别清晰:</p>
<ol>
<li>输入的是稀疏特征的id</li>
<li>进行一层lookup 之后得到id的稠密embedding</li>
<li>这个embedding一方面作为隐向量输入到FM层进行计算</li>
<li>同时该embedding进行聚合之后输入到一个DNN模型(deep)</li>
<li>然后将FM层和DNN层的输入求和之后进行co-train</li>
</ol>
<p>因为最终计算的式子也是非常清晰的明了:<br>Fm部分:<br>$$y_{\text{FM}} = \left \langle W,X \right \rangle + \sum_i^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_i x_j$$<br>Deep部分:<br>$$a(0) =[e ,e ,…,e ] \\<br>a(l+1) = \sigma (W^{(l)}a^{(l)} + b^{(l)}) \\<br>y_{\text{DNN}} = \sigma (W^{(H+1)}a^{H} + b^{(H+1)})$$</p>
<blockquote>
<p>其中$e$表示初始的embedding,$H$表示网络的深度</p>
</blockquote>
<p>最终DeepFM可以表示为:<br>$$y_{\text{DeepFm}} = sigmoid(y_{FM} + y_{DNN})$$</p>
<p>这个结合非常有意思，充分将<code>FM</code>中隐向量含<code>element-wise product</code>的功能结合到了<code>DNN</code>中，公司有实测<code>DeepFM</code>的效果略好于的<code>Wide&amp;Deep</code>,因此该算法还是非常有实操性的，特别是在公司里面要出成（zhuang）果（bi）的时候。</p>
<blockquote>
<p><code>DeepFm</code>的非作者源码分享<a href="https://github.com/ChenglongChen/tensorflow-DeepFM" target="_blank" rel="external">https://github.com/ChenglongChen/tensorflow-DeepFM</a></p>
</blockquote>
<h2 id="NFM">NFM</h2><p><code>NFM(Neural Factorization Machines)</code>又是在<code>FM</code>上的一个改进工作，出发点是<code>FM</code>通过隐向量可以对完成一个很好的特征组合工作，并且还解决了稀疏的问题，但是<code>FM</code>对于它对于<code>non-linear</code>和<code>higher-order</code> 特征交叉能力不足，而<code>NFM</code>则是结合了<code>FM</code>和<code>NN</code>来弥补这个不足。模型框架如下(图里没画一阶的回归)：</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/nfm_arch.png" width="600px"></center><br>其中:<br>1. <code>Input Feature Vector</code>层是输入的稀疏向量，可以带权<br>2. <code>Embedding Layer</code>对输入的稀疏向量look up 成稠密的embedding 向量<br>3. <code>Bi-Interaction Layer</code>将每个特征embedding进行两两做element-wise product，<code>Bi-Interaction</code>的输出是一个 k维向量（就是隐向量的大小）,这层负责了特征之间second-order组合。$$f_{\text{Bi}}(V_x) = \sum_i^n \sum_{j=i+1}^n x_iv_i \odot  x_jv_j$$ 类似FM的式子转换，这里同样可以做如下转换将复杂度降低:$$f_{\text{Bi}}(V_x) = \frac{1}{2} \left [ (\sum_i^n x_iv_i)^2 - \sum_i^n(x_iv_i)^2 \right ]$$<br>4. <code>Hidden Layers</code>这里是多层学习高阶组合特征学习,其实就是一个DNN模块:$$z_1=\sigma_1(W_1 f_{\text{Bi}}(V_x) + b_1) \\ z_2 = \sigma_2(W_2z_1+b_2) \\ … \\ z_L=\sigma_L(W_L z_{L-1}+b_L)$$<br>5. <code>Prediction Score</code>层就是输出最终的结果:$$y_{\text{NFM}}(x) = w_0 + \sum_i^n w_ix_i + h^T \sigma_L(W_l(…\sigma_1(W_1 f_{\text{Bi}}(V_x) + b_1))+b_L)$$<br><br>FM可以看做是NFM模型 Hidden Layer层数为0一种特殊形式。<br>最终的实验效果看来<code>NFM</code>也还是可以带来一个不错的效果:<br><center><img src="/img/Deep-in-out-Wide-n-Deep-Series/nfm_result.png" width="600px"></center>

<blockquote>
<p><code>NFM</code>作者分享的源码<a href="https://github.com/hexiangnan/neural_factorization_machine" target="_blank" rel="external">https://github.com/hexiangnan/neural_factorization_machine</a></p>
</blockquote>
<h2 id="AFM">AFM</h2><p>而<code>AFM(Attentional Factorization Machines)</code>同样，是在<code>FM</code>上做了一些小<code>trick</code>,在传统的<code>FM</code>中进行特征组合时两两特征之间的组合都是等价的(只能通过隐向量的点积来区别)，这里趁着<code>Attention</code>的热度走一波,因为<code>AFM</code>的最大的贡献就是通过<code>Attention</code>建立权重矩阵来学习两两向量组合时不同的权重。下面就是<code>AFM</code>的框架图:</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/afm_arch.png" width="600px"></center><br>从图中可以很清晰的看出,<code>AFM</code>比<code>FM</code>就是多了一层<code>Attention-based Pooling</code>，该层的作用是通过<code>Attention</code>机制生成一个$a_{i,j}$权重矩阵，该权重矩阵将会作用到最后的二阶项中，因此这里$a_{i,j}$的生成步骤是先通过原始的二阶点积求得各自的组合的一个score:<br>$${a}’_{i,j} = h^T \text{ReLu}(W(v_i \odot v_j)x_ix_j+b)$$<br><br>&gt; 其中$W \in \mathbb{R}^{t \times k},b \in \mathbb{R}^t , h \in \mathbb{R}^t$,这里$t$表示<code>Attention</code>网络的大小<br><br>然后对其score进行<code>softmax</code>的归一化:<br>$$a_{i,j} = \frac{exp({a}’_{i,j})}{\sum_{i,j} exp({a}’_{i,j})}$$<br>最后该权重矩阵再次用于二阶项的计算（也就是最终的<code>AFM</code>式子）:<br>$$y_{\text{AFM}}(x) = w_0+\sum_i^n w_i x_i + P^T \sum_{i=1}^n \sum_{j=i+1}^n a_{i,j} (v_i \odot v_j) x_ix_j$$<br><br>其实整个算法思路也是很简单，但是在实验上却有一个不错的效果:<br><center><img src="/img/Deep-in-out-Wide-n-Deep-Series/afm_result.png" width="400px"></center>

<blockquote>
<p>其实从实验效果来看<code>AFM</code>应该是优于<code>NFM</code><br><code>AFM</code>的作者源码分享<a href="https://github.com/hexiangnan/attentional_factorization_machine" target="_blank" rel="external">https://github.com/hexiangnan/attentional_factorization_machine</a></p>
</blockquote>
<h2 id="总结">总结</h2><ol>
<li><code>FMs</code>系列算法被广泛应用于ctr预估类的问题中，并且可以取得不错的效果，他最大特征是可以帮助解决特征组合问题</li>
<li>原始<code>FM</code>算法的运行性能最快，可以达到$O(k \bar{n})$,在工业中被适用最广最简单，其他带上神经网络的<code>FM</code>算法如果想在在线系统中使用得做很多离线计算和分解，比如<code>FFM</code>的现在复杂度是$O(k \bar{n}^2)$,将$O(\bar{n}^2)$中二阶计算的项尽可能的进行离线计算，在 在线的时候进行组合</li>
<li><code>FM</code>的二阶项部分很容易使用<code>TensorFlow</code>进行实现，这也意味了在实验上也很容易很其他复杂算法进行组合:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get the summed up embeddings of features.</span></span><br><span class="line">self.nonzero_embeddings = tf.nn.embedding_lookup(self.weights[<span class="string">'feature_embeddings'</span>], self.train_features, name=<span class="string">'nonzero_embeddings'</span>)</span><br><span class="line">self.summed_features_emb = tf.reduce_sum(self.nonzero_embeddings, <span class="number">1</span>, keep_dims=<span class="keyword">True</span>) <span class="comment"># None * 1 * K</span></span><br><span class="line"><span class="comment"># get the element-multiplication</span></span><br><span class="line">self.summed_features_emb_square = tf.square(self.summed_features_emb)  <span class="comment"># None * 1 * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># _________ square_sum part _____________</span></span><br><span class="line">self.squared_features_emb = tf.square(self.nonzero_embeddings)</span><br><span class="line">self.squared_sum_features_emb = tf.reduce_sum(self.squared_features_emb, <span class="number">1</span>, keep_dims=<span class="keyword">True</span>)  <span class="comment"># None * 1 * K</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ________ FM __________</span></span><br><span class="line">self.FM = <span class="number">0.5</span> * tf.subtract(self.summed_features_emb_square, self.squared_sum_features_emb, name=<span class="string">"fm"</span>)  <span class="comment"># None * 1 * K</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>摘自<code>AFM</code>源码</p>
</blockquote>
<h2 id="参考">参考</h2><p>[1]. Rendle, Steffen. “Factorization machines with libfm.” ACM Transactions on Intelligent Systems and Technology (TIST) 3.3 (2012): 57.<br>[2]. Juan, Yuchin, et al. “Field-aware factorization machines for CTR prediction.” Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 2016.<br>[3]. Guo, Huifeng, et al. “Deepfm: A factorization-machine based neural network for CTR prediction.” arXiv preprint arXiv:1703.04247 (2017).<br>[4]. He, Xiangnan, and Tat-Seng Chua. “Neural factorization machines for sparse predictive analytics.” Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017.<br>[5]. Xiao, Jun, et al. “Attentional factorization machines: Learning the weight of feature interactions via attention networks.” arXiv preprint arXiv:1708.04617 (2017).</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>近期使用<code>FM</code>系列完成了一个<code>CTR</code>预估的任务，本文是阅读了一些paper之后对于<code>FM</code>、<code>FFM</code>、<code>DeepFM</code>、<code>NFM</code>,<code>AFM</code>的一个理解和记录</p>
</blockquote>
<h2 id="FM">FM</h2><p><code>Factorization Machine(FM)</code>由Steffen Rendle在2010年提出，旨在解决系数数据下的特征组合的问题，目前该系列模型在搜索推荐领域被广泛使用。</p>
<h3 id="一个栗子">一个栗子</h3><p>先来看一个经典的电影评分问题</p>
<center><img src="/img/Deep-in-out-Wide-n-Deep-Series/fm_case.png" width="400px"/></center>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深度神经网络中防止过拟合的利器-Dropout]]></title>
    <link href="http://kubicode.me/2017/06/05/Deep%20Learning/Dropout-in-Deep-Neural-Network/"/>
    <id>http://kubicode.me/2017/06/05/Deep Learning/Dropout-in-Deep-Neural-Network/</id>
    <published>2017-06-05T13:14:36.000Z</published>
    <updated>2018-09-19T02:41:22.035Z</updated>
    <content type="html"><![CDATA[<h2 id="Dropout_in_Deep_Network">Dropout in Deep Network</h2><p>在机器学习任务中一提到过拟合，<code>L1</code>和<code>L2</code>正则项绝对是两大利器，但是在深度神经网络中，<code>Hiton</code>老爷子在2014年提出了一种称为<code>Dropout</code>的方法来避免过拟合，方式对比<code>L1</code>和<code>L2</code>更为灵活也是非常高效。</p>
<p>深度神经网络中，在不限制计算的条件下，最佳的正则化方式就是将所有可能组合成的模型进行平均输出，就类似<code>stack</code>的模型融合一样，但是这种方式存在两大问题:</p>
<ol>
<li>在计算时需要将训练文件进行相应的分离，因为神经网络的训练本身就是需要极多的数据，这么一分离可能会导致数据不够的情况</li>
<li>深度神经网络中的计算量本身就很大，计算多个之后其耗时将会更多</li>
</ol>
<p>而<code>Dropout</code>却可以完美的解决上述两个缺陷，他的思想很简单:<br><a id="more"></a></p>
<p>在训练时对于神经网络的某些神经点击直接进行移除，包括他的入边和出边，而这个移除可以简单的根据一个概率p，这个p一般就是Dropout需要设置的参数</p>
<blockquote>
<p>这个参数$p$一般设置为0.5比较好，因为他这样就可能产生$2^n$中网络情况了，极大的增加的参数空间</p>
</blockquote>
<p>因此经过Dropout之后两个神经网络的对比如下:</p>
<center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-or-not.png" width="550px"></center><br>可以看到经过<code>Dropout</code>之后<code>(b)</code>中很多单元节点直接被进行了移除（注意这里是一次<code>min-batch</code>走一次<code>Dropout</code>），使用了<code>Dropout</code>在预测时也是极其的简单:<br>在预测时这些曾经过移除过的节点仍然正常计划，唯一的差别就是在下一次的权重中乘以概率$p$<br><br><center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-layer.png" width="550px"></center>

<p>因此针对一个标准深度神经网络,当前层使用$l$来表示，$w$为需要训练的权重,$y$就是各个层的输出，$b$为各个层的偏置，则每一层的标准计算为:<br>$$z_i^{l+1} = w_i^{l+1}y^l + b_i^{l+1} \\<br>y_i^{l+1} = f(z_i^{l+1})$$</p>
<blockquote>
<p>其中$f$为激活函数</p>
</blockquote>
<p>而经过了<code>Dropout</code>之后整个计算过程就会变为这样:<br>$$r_j^l \sim \text{Bernoulli}(p) \\<br>\tilde{y}^l = r_j^l y^l \\<br>z_i^{l+1} = w_i^{l+1}\tilde{y}^l + b_i^{l+1} \\<br>y_i^{l+1} = f(z_i^{l+1})$$</p>
<p>也就是下图的样纸:</p>
<p><center><img src="/img/Dropout-in-Deep-Neural-Network/dropout-calc.png" width="550px"></center><br>而在预测的时候，只需要在<code>Dropout</code>层输出的权重上乘$p$即可:$w_{test}^l = pw^l$</p>
<p>关于使用了<code>Dropout</code>之后，如果使用<code>SGD</code>进行优化的话其梯度仍旧可以按照来的方式计算，不过他是在一次<code>min-batch</code>来计算一次<code>Dropout</code></p>
<blockquote>
<p>也就在同一次<code>min-batch</code>中，<code>Dropout</code>层中的点击移除与否的分布是一样的，不同的<code>Dropout</code>中是可能不一样的</p>
</blockquote>
<p>文献的实验正常传统的深度神经网络中加入了<code>Dropout</code>之后在训练集上面的误差可能会增大，但是在测试集上其误差会变小，也就是降低的过拟合的程度</p>
<h2 id="Dropout_in_Recurrent_Network">Dropout in Recurrent Network</h2><p>虽然<code>Dropout</code>中在传统的深度网络中很好使，但是直接用于<code>RNN</code>这类递归型的神经网络却不是很好使，原因是如果直接将<code>Dropout</code>层防止在<code>Memory Cell</code>中,循环会放大噪声，扰乱它自己的学习。<br><i>Wojciech Zaremba</i>针对此问题提出的核心解决方法就是在输入和输出层加<code>Dropout</code>:<br>$$\begin{pmatrix}<br>i\\<br>f\\<br>o\\<br>g<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>sigm\\<br>sigm\\<br>sigm\\<br>tanh<br>\end{pmatrix}<br>T_{2n,4n}<br>\begin{pmatrix}<br>D(x_t)\\<br>h_{t-1}^l<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>上面是一个<code>LSTM</code>的式子，计算三个门单元以及当前信息单元，$D$就是<code>Dropout</code>层,这里是加在了输入层</p>
</blockquote>
<h2 id="文献">文献</h2><ol>
<li>Srivastava, Nitish, et al. “Dropout: A simple way to prevent neural networks from overfitting.” The Journal of Machine Learning Research 15.1 (2014): 1929-1958.</li>
<li>Zaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. “Recurrent neural network regularization.” arXiv preprint arXiv:1409.2329 (2014).</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Dropout_in_Deep_Network">Dropout in Deep Network</h2><p>在机器学习任务中一提到过拟合，<code>L1</code>和<code>L2</code>正则项绝对是两大利器，但是在深度神经网络中，<code>Hiton</code>老爷子在2014年提出了一种称为<code>Dropout</code>的方法来避免过拟合，方式对比<code>L1</code>和<code>L2</code>更为灵活也是非常高效。</p>
<p>深度神经网络中，在不限制计算的条件下，最佳的正则化方式就是将所有可能组合成的模型进行平均输出，就类似<code>stack</code>的模型融合一样，但是这种方式存在两大问题:</p>
<ol>
<li>在计算时需要将训练文件进行相应的分离，因为神经网络的训练本身就是需要极多的数据，这么一分离可能会导致数据不够的情况</li>
<li>深度神经网络中的计算量本身就很大，计算多个之后其耗时将会更多</li>
</ol>
<p>而<code>Dropout</code>却可以完美的解决上述两个缺陷，他的思想很简单:<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[长短期记忆模型-LSTM]]></title>
    <link href="http://kubicode.me/2017/05/22/Deep%20Learning/Long-Short-Term-Memory-Model-LSTM/"/>
    <id>http://kubicode.me/2017/05/22/Deep Learning/Long-Short-Term-Memory-Model-LSTM/</id>
    <published>2017-05-22T01:50:40.000Z</published>
    <updated>2019-10-15T02:14:53.950Z</updated>
    <content type="html"><![CDATA[<h2 id="RNN的缺点">RNN的缺点</h2><p><code>RNN</code>的特点毋庸置疑就是在训练/预测当前层节点时可以拿到先前层的数据来进行辅助计算，因此对于序列的学习非常有效。但事实上这个利用前面全部的信息并不是非常有效。比如看下面两个<code>language mdoel</code>:</p>
<pre><code><span class="operator">the</span> clouds are <span class="operator">in</span> <span class="operator">the</span> sky
</code></pre><p>这里要预测的<code>sky</code>只需要依赖前前面几个<code>term</code>即可</p>
<p>再看看另一个句子:    </p>
<pre><code><span class="keyword">I</span> grew up in France… <span class="keyword">I</span> speak fluent French.
</code></pre><p>这里在预测<code>French</code>的时候需要前面较长的信息，甚至已经跨到前面一句话了。<br>因此是可以看出就算在<code>Language Model</code>中不同样本下可能是需要不同的长度的历史信息的，而对于<code>RNN</code>而言他并不能控制历史信息的长度.</p>
<a id="more"></a>
<h2 id="LSTM的计算">LSTM的计算</h2><p>而<code>LSTM</code>的设计之初就是为了解决<code>RNN</code>这种长期依赖的问题，一个最标准的<code>RNN</code>中每一个单元/层他是经过过一个<code>tanh</code>，结构是长这样的:</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-SimpleRNN.png" width="450px"></center>

<p>而<code>LSTM</code>的复杂很多，展开之后他是长这样的:</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-chain.png" width="450px"></center><br>&gt;<code>LSTM</code>中最核心的就是门(<code>gate</code>)结构了，每一个<code>gate</code>经过一个<code>sigmoid</code>($\sigma$)结果输出一个<code>0~1</code>的输，可以精确的控制每一股的数据流量大小.<br><br>接下来一步一步解析<code>LSTM</code>单元内的每个小组件:<br><code>第一步</code>是决定哪些历史信息需要流入到当前的单元中，<br>这里会经过<code>遗忘门</code>(<code>forget gate layer</code>)，作用对于历史信息的遗忘程度:<br><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-f.png" width="450px"></center>

<p>这个门的输入为上一层的隐含层信息($h_{t-1}$)和当前层的输入数据($x_t$),输出一个<code>0~1</code>的数字用于$C_{t-1}$，如果通过<code>遗忘门</code>之后输出1，则表示所有$C_{t-1}$的数据都保留，如果输出的0，则相当于$C_{t-1}$的数据经会被重置为0.</p>
<p><code>第二步</code>是当前哪些信息数据需要流入到当前的组件中，首先会经过<code>输入门</code>(<code>input gate layer</code>)会决定哪些输入值需要更新，其次再经过一个$tanh$函数来生成一个新的$\tilde{C}_t$来与原先的$C_{t-1}$进行求和合并.</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-i.png" width="450px"></center>

<p><code>第三步</code>是生成一个新的$C_t$值，它是综合$C_{t-1}$的遗忘信息以及当前新保留的$\tilde{C}_t$信息</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-C.png" width="450px"></center>

<p><code>最后</code>就是控制输出的数据了（就是输出隐含层单元的信息）</p>
<center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-focus-o.png" width="450px"></center><br>最终的输出是依赖当前的单元信息$C_t$，它经过一个$tanh$函数之后将数据scale到<code>-1~1</code>，然后再通过一个输出门来控制需要数据的信息.<br>上述4步是每个单元内的计算步骤，实际对于train目前应该还有一步$y_t=f(h_t)$,如果是<code>Language Model</code>的话$f$就是<code>softmax</code><br><br><br><br>综合上面的图解，一个完整的<code>LSTM</code>的单元里面的计算流程是这样:<br>1. 遗忘门的计算:<br>    $$f_t=\sigma(W_f \cdot [h_{t-1},x_t],b_f)$$<br>2. 输入门的计算:<br>    $$f_i=\sigma(W_i \cdot [h_{t-1},x_t],b_i)$$<br>3. 当前单元信息的计算:<br>    $$\tilde{C}_t=tanh(W_c \cdot[h_{t-1},x_t]+b_C)$$<br>4. 根据先前的单元信息$C_{t-1}$和当前的单元信息$\tilde{C}_t$，以遗忘门$f_t$和输入门$f_i$作为因子得到新的单元信息:<br>    $$C_t = f_t \cdot C_{t-1} + f_i \cdot \tilde{C}_t$$<br>5. 输出门的计算:<br>    $$f_o=\sigma(W_o \cdot [h_{t-1},x_t],b_o)$$<br>6. 根据新的单元信息$C_t$以及输出门$f_o$计算要输出的隐含单元信息:<br>    $$h_t = o_t \cdot tanh(C_t)$$<br>7. 根据隐含单元信息计算训练/预测的目标:<br>    $$y_t = f(h_t)$$<br>8. 一个单元计算完毕，回到<code>1</code>进入下一个单元的计算<br><br><br>## LSTM变种<br><br>上面描述的<code>LSTM</code>结果其实还复杂的，比标准的<code>RNN</code>至少多了三个门单元($f_t,f_i,f_o$)以及单元信息$C$，多了这么多信息之后随之而言的就是计算量会增加许多，同时事实上很多任务中比不需要这么多信息，因此就会有较多的$LSTM$变种出现:<br>下面这个<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="external">变种</a>是将<code>遗忘门</code>去掉，其值改为$1-f_t$<br><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-var-tied.png" width="450px"></center>

<p>另外一个非常著名的变种就是<a href="https://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="external">GRU</a>了</p>
<p><center><img src="/img/Long-Short-Term-Memory-Model-LSTM/LSTM3-var-GRU.png" width="450px"></center><br>他将:</p>
<ol>
<li><code>遗忘门</code>和<code>输入门</code>合并为了<code>更新门</code></li>
<li>同时将<code>单元信息</code>(<code>cell state</code>)和<code>隐含信息</code>(<code>hidden state</code>)进行了合并</li>
</ol>
<p>从计算式子就可以看出整个单元的计算对比$LSTM$进行了极大的简化，但是其效果却几乎不降低。<br>当然还有很多其他的变种不再一一描述，可以参见<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">参考</a></p>
<h2 id="参考">参考</h2><ol>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="RNN的缺点">RNN的缺点</h2><p><code>RNN</code>的特点毋庸置疑就是在训练/预测当前层节点时可以拿到先前层的数据来进行辅助计算，因此对于序列的学习非常有效。但事实上这个利用前面全部的信息并不是非常有效。比如看下面两个<code>language mdoel</code>:</p>
<pre><code><span class="operator">the</span> clouds are <span class="operator">in</span> <span class="operator">the</span> sky
</code></pre><p>这里要预测的<code>sky</code>只需要依赖前前面几个<code>term</code>即可</p>
<p>再看看另一个句子:    </p>
<pre><code><span class="keyword">I</span> grew up in France… <span class="keyword">I</span> speak fluent French.
</code></pre><p>这里在预测<code>French</code>的时候需要前面较长的信息，甚至已经跨到前面一句话了。<br>因此是可以看出就算在<code>Language Model</code>中不同样本下可能是需要不同的长度的历史信息的，而对于<code>RNN</code>而言他并不能控制历史信息的长度.</p>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[初识递归神经网络-RNN]]></title>
    <link href="http://kubicode.me/2017/05/15/Deep%20Learning/Understanding-about-RNN/"/>
    <id>http://kubicode.me/2017/05/15/Deep Learning/Understanding-about-RNN/</id>
    <published>2017-05-15T01:17:48.000Z</published>
    <updated>2017-06-05T01:12:31.000Z</updated>
    <content type="html"><![CDATA[<h2 id="RNN是啥?">RNN是啥?</h2><p>当需要处理一些输入或者输出有相互依赖的任务时，传统的神经网络已经不再适用，比如在<code>Language Model</code>中在给定几个单词的情况下来预测下面将会出什么单词的时候。<br>这时候RNN就有用武之地了，RNN在预测/训练当前节点的时候可以获取前面节点的记忆（memory）信息，这样就可以很自然的完成序列任务的学习了。<br>一图胜千言，经典的RNN结构是长这样纸的:<br><a id="more"></a></p>
<center><img src="/img/Understanding-about-RNN/rnn.jpg"></center>

<p>上图的左侧是一个未展开的RNN结构图，可以看出通过<code>W</code>来完成一个自循环，将其展开之后就很好理解了，展开后可以看做是一个横向的神经网络，每一层都有一个自己的输入，RNN的整个训练或者主要是为了计算<code>U</code>、<code>W</code>、<code>V</code>这三个矩阵，其训练时前向传播的步骤如下:</p>
<ol>
<li>$x_t$表示第$t$层/步的输入，输入的数据可以是一个<code>one-hot</code>的向量或者一个其他的<code>pre-train</code>的向量</li>
<li>$s_t$表示当前$t$的隐含状态,也就是整个网络中拥有<code>记忆</code>的那一块，他是根据上一层的隐含状态$s_{t-1}$以及当前层的输入$x_t$计算得到的，$s_t=f(Ux_t+Ws_{t-1})$， 其中$f(\cdot)$为激活函数，一般可以为<code>tanh</code>或者<code>ReLu</code>，另外$s_{-1}$为初始化的隐含状态，一般来说可以都初始化为<code>0</code></li>
<li>$o_t$就是每一步的输出了，计算公式为$o_t = f(Vs_t)$，比如在<code>Language Model</code>中每一步的输出就是预测到下一个词的概率，这输出的就是在<code>vocabulary</code>维度的一个概率向量$o_t=\text{softmax}(Vs_t)$</li>
</ol>
<p>另外还有几点要说的:</p>
<ol>
<li>$s_t$为整个网络的记忆，但是在实际中,$s_t$的记忆功能是有限的，并不能捕捉$s_t$步之前的全部信息</li>
<li>在传统的深度神经网络中，每一层都有自己的参数，但是RNN与之不同，所有层之间都是共享<code>U</code>、<code>W</code>、<code>V</code>这三个参数的</li>
<li>另外关于输出，上面说到的是每一层是一个输出，但是并不是非得这样，有一些其他的变种可以仅在最后一层有一个输出。</li>
</ol>
<h2 id="RNN的训练">RNN的训练</h2><p>将<code>RNN</code>进行展开之后可以看做一个横向的神经网络，因为<code>RNN</code>也可以按神经网络的方式进行训练和预测，这里以一个实际的语言模型来回顾一下<code>RNN</code>的前向预测:</p>
<ol>
<li>$s_t= \text{tanh}(Ux_t+Ws_{t-1})$</li>
<li>$o_t = \text{softmax}(Vs_t)$</li>
</ol>
<p>对于<code>RNN</code>的参数我们就是需要求<code>U</code>、<code>W</code>和<code>V</code>这三个矩阵，这里可以使用<code>SGD</code>来进行模型参数的优化，同时其梯度可以用一种叫做<code>BPTT</code>的当时来求得<br>我们使用交叉熵来定义<code>RNN</code>模型每一层的损失:<br>$$E_t(o_t,\hat{o}_t) = -o_t\log \hat{o}_t$$<br>则整个模型的损失通过累加可以求得:<br>$$E=\sum_t E_t(o_t,\hat{o}_t) = -\sum_t o_t\log \hat{o}_t$$</p>
<blockquote>
<p>这里的$t$表示当前的步数(层数),$\hat{o}_t$为第$t$的预测值.</p>
</blockquote>
<p>这里的梯度使用<code>BP</code>来计算，为了计算方便，以$t=3$为例<br>$$\begin{equation}\begin{split} \frac{\partial E_3}{\partial V}&amp;= \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial V} \\<br>&amp;= \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial z_3} \frac{\partial z_3}{\partial V}  \\<br>&amp;= \frac{\partial E_3}{\partial z_3} \frac{\partial z_3}{\partial V}  \\<br>&amp;= (\hat{o}_3-o_3)s_3 \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>辅助推导:<br>$$\begin{equation}\begin{split} \frac{\partial E}{\partial z^j}&amp;= \frac{\partial -o\text{log}\hat{o}}{\partial z^j} \\<br>&amp;= \frac{\partial -\sum_k o^k\text{log}\hat{o}^k}{\partial V^js}  \\<br>&amp;=  -\frac{1}{s} \sum_k o^k \cdot \frac{1}{\hat{o}^k} \frac{\partial \hat{o}^k}{V_j} \\<br>&amp;= \text{使用softmax推导} \\<br>&amp;=   -\frac{1}{s} \left( o^j  \frac{1}{\hat{o}^j} s \hat{o}^j(1-\hat{o}^j) + \sum_{k:k \neq j} o^k  \frac{1}{\hat{o}^k} \cdot(-s\hat{o}^j\hat{o}^k )   \right) \\<br>&amp;= -\left( o^j-o^j\hat{o}^j - \sum_{k:k \neq j} o^k \hat{o}^j \right) \\<br>&amp;= -\left( o^j - \hat{o}^j \sum_ko^k \right) \\<br>&amp;= \hat{o}^j-o^j \\<br>\end{split}\end{equation}$$<br>其中$z_3=Vs_3$,$z^j=V^js$,$V^j$为第$j$个类别的向量权重</p>
</blockquote>
<p>可以看到损失函数对$V$求梯度时最后式子是极其简单，只需要计算当前预测的$o$以及当前隐含层的$s$即可,<br>现在来看下对于$W$的求导，这里会有稍微的不同:<br>$$\frac{\partial E_3}{\partial W}=\frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial s_3} \frac{\partial s_3}{\partial W}$$<br>而这里$s_3$时依赖$s_2$的<br>$$s_3=tanh(W s_2 + Ux_3)$$<br>而同时$s_2$还是依赖$s_1$的,因此在对于$E_3$求$W$的导数的时候并不能将$s_2$作为一个常量进行简单的求导,这样我们再次根据链式法则将会有如下:<br>$$\frac{\partial E_3}{\partial W} = \sum_{k=0}^3 \frac{\partial E_3}{\partial \hat{o}_3} \frac{\partial \hat{o}_3}{\partial s_3} \frac{\partial s_3}{\partial s_k} \frac{\partial s_k}{\partial W}$$<br>因为这里的$W$是共享的，每一步输出都有用到，因此对于$W$的求导只需要将每一步($t=0..3$)的梯度加起来即可</p>
<center><img src="/img/Understanding-about-RNN/rnn-bptt-with-gradients.png" width="450px"></center>

<p>由于$U$的参与前向计算的式子也$W$的类似，因此关于$\frac{\partial E}{\partial U}$也可以用上述方式来求导。<br>这三个参数的梯度计算与普通的BP计算类似，最大的区别是这三个参数在每一层都是共享的。</p>
<p>由于在求导时需要向后计算，如果层数很多就会遇到经典的梯度消失问题，所以实际的<code>RNN</code>中每一个链可能都会做一个一定长度限制的截断。另外关于梯度消失的问题可以参考<code>RNN</code>的其他变种<code>LSTM</code>和<code>GRU</code>等.</p>
<h2 id="总结">总结</h2><p><code>RNN</code>与传统的神经网络最大的特别就是在每一层计算的时候可以拿到前面几层的信息，这样特别可以有效适用于序列相关的学习，当然在实际操作中效果可能没有这么好~-_-!!</p>
<h2 id="参考:">参考:</h2><ol>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</a></li>
<li><a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" target="_blank" rel="external">http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="RNN是啥?">RNN是啥?</h2><p>当需要处理一些输入或者输出有相互依赖的任务时，传统的神经网络已经不再适用，比如在<code>Language Model</code>中在给定几个单词的情况下来预测下面将会出什么单词的时候。<br>这时候RNN就有用武之地了，RNN在预测/训练当前节点的时候可以获取前面节点的记忆（memory）信息，这样就可以很自然的完成序列任务的学习了。<br>一图胜千言，经典的RNN结构是长这样纸的:<br>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[学习记录一下深度语义匹配模型-DSSM]]></title>
    <link href="http://kubicode.me/2017/04/21/Deep%20Learning/Study-With-Deep-Structured-Semantic-Model/"/>
    <id>http://kubicode.me/2017/04/21/Deep Learning/Study-With-Deep-Structured-Semantic-Model/</id>
    <published>2017-04-21T14:53:03.000Z</published>
    <updated>2018-01-22T02:41:35.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>DSSM这篇paper发表在cikm2013，短小但是精炼，值得记录一下<br>ps:后来跟了几篇dssm的paper，一并记录在这里</p>
</blockquote>
<h2 id="DSSM">DSSM</h2><h3 id="DSSM的结构">DSSM的结构</h3><p><code>DSSM</code>最大的卖点在检索场景下  使用点击数据来训练语义层次的匹配，简单的来说，传统检索场景下的匹配主要有:</p>
<ol>
<li>字面匹配:<code>TFIDF</code>、<code>BM25</code>等</li>
<li>使用<code>LSA</code>类模型进行语义匹配，但是效果不好</li>
</ol>
<p>而DSSM训练出来之后，检索场景下用户输入query之后，可以根据该query计算各个doc的语义相似度。</p>
<p>这里上图最直接:</p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_arch.png"></center>

<a id="more"></a>
<p>上面是<code>DSSM</code>训练的架构图:</p>
<ol>
<li>输入的是一个<code>query</code>和这个query相关的<code>doc</code>，这里的输入特征可以是最简单的<code>one-hot</code>,而需要<code>train</code>的是这个query下各个doc的相关性(<code>DSSM</code>里面使用点击率来代替相关性)</li>
<li><p>由于这种<code>one-hot</code>的输入可能会有两个问题:</p>
<ol>
<li>导致<code>vocabulary</code>太大</li>
<li><p>会出现<code>oov</code>的问题</p>
<p>因此输入特征之后的第一层是做一个叫做<code>Word Hashinging</code>的操作</p>
</li>
</ol>
</li>
<li>接下来就是传统的神经网络了<br> $$l_i=f(W_il_{i-1}+b_i),i = 2,…,N-1 \\<br> y=f(W_Nl_{N-1}+b_N) $$<blockquote>
<p>这里的<code>f</code>是激活函数，文中使用$tanh$来计算:$f(x)=\frac{1-e^{-2x}}{1+e^{-2x}}$</p>
</blockquote>
</li>
<li>得到的$y$就是语义特征了,query和doc之间的相关性就可以直接使用特想之间的相似性来度量，这里使用cosine来计算<br> $$R(Q,D)=cosine(y_Q,y_D) = \frac{y_Q^Ty_D}{||y_Q||||y_D||}$$</li>
<li>最终得到的相似度就可以去训练query和doc的相关性了</li>
</ol>
<p>因此整个结构就可以看做做了一层<code>Word Hashing</code>之后去训练<code>DNN</code>网络</p>
<h3 id="Word_Hashing">Word Hashing</h3><p><code>Word Hashing</code>是paper非常重要的一个<code>trick</code>，以英文单词来说，比如<code>good</code>，他可以写成<code>#good#</code>，然后按tri-grams来进行分解为<code>#go goo ood od#</code>，再将这个tri-grams灌入到<code>bag-of-word</code>中，这种方式可以非常有效的解决<code>vocabulary</code>太大的问题(因为在真实的web search中vocabulary就是异常的大)，另外也不会出现<code>oov</code>问题，因此英文单词才26个，3个字母的组合都是有限的，很容易枚举光。<br>那么问题就来了，这样两个不同的单词会不会产出相同的tri-grams，paper里面做了统计，说了这个冲突的概率非常的低，500K个word可以降到30k维，冲突的概率为0.0044%</p>
<blockquote>
<p>但是在中文场景下，这个<code>Word Hashing</code>估计没有这么有效了<br>因为直接使用了word hashing，因为无法记录上下文信息</p>
</blockquote>
<h3 id="训练DSSM">训练DSSM</h3><p>上面是前向计算过程，在进行训练的时候需要计算给定<code>Query</code>下与<code>Doc</code>的相关性:<br>    $$P(D|Q) = \frac{exp(\gamma R(Q,D))}{\sum_{d_i \in D} exp(\gamma R(Q,D))}$$</p>
<p>最终他需要优化的损失函数为:<br>    $$L(\Lambda) = - \text{log} \prod_{(Q,D^+)} P(D^+|Q)$$</p>
<blockquote>
<p>$D^+$表示被点击的文档，这里就是最大化点击文档的相关性的最大似然</p>
</blockquote>
<h2 id="CDSSM">CDSSM</h2><p><code>CDSSM</code>(又称<code>CLSM</code>:Convolutional latent semantic model)在一定程度上他可以弥补<code>DSSM</code>会丢失上下文的问题,他的结构也很简单，主要是将<code>DNN</code>替换成了<code>CNN</code></p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/cdssm_arch.png" width="400px"></center><br>他的前向步骤主要计算如下:<br>1. 使用指定滑窗大小对输入序列取窗口数据（称为<code>word-n-gram</code>）<br>2. 对于这些<code>word-n-gram</code>按<code>letter-trigram</code>进行转换构成representation vector(其实就是<code>Word Hashing</code>)<br>3. 对窗口数据进行一次卷积层的处理(窗口里面含有部分上下文)<br>4. 使用<code>max-pooling</code>层来取那些比较重要的<code>word-n-gram</code><br>5. 再过一次FC层计算语义向量<br>6. 他最终输出的还是128维<br><br>&gt; 因为使用<code>CDSSM</code>来做语义匹配的工作也是比较合适的<br><br>## DSSM-LSTM<br>既然是为了记录输入句子的上下文，这个无疑是<code>Lstm</code>这个模型更为擅长，因此又有了一种<code>Lstm</code>来构造的<code>DSSM</code>模型<br><center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_lstm_arch.png" width="400px"></center>

<p>这篇相对于<code>CDSMM</code>来说改的更为简单，其实就是将原始<code>DSSM</code>的模型替换为了<code>LSTM</code>模型…</p>
<h2 id="MV-DSSM">MV-DSSM</h2><p><code>MV-DSSM</code>里面的<code>MV</code>为<code>Multi-View</code>，一般可以理解为多视角的<code>DSSM</code>，在原始的DSSM中需要训练的有<code>Query</code>和<code>Doc</code>这两类的embedding,同时里面<code>DNN</code>的所有权重都是共享的，而<code>MV-DSSM</code>他可以训练不止两类的训练数据，同时里面的深度模型的参数是相互独立:</p>
<p><center><img src="/img/Study-With-Deep-Structured-Semantic-Model/mv_dssm_arch.png" width="400px"></center><br>基于<code>Multi-View</code>的<code>DSSM</code>是的参数变多了，由于多视角的训练，输入的语料也可以变得不同，自由度也更大了，但是随之带来的问题就是训练会变得越来越困难^_^</p>
<h2 id="总结">总结</h2><p><code>DSSM</code>类的模型其实在计算相似度的时候最后一步除了使用Cosine，可能再接入一个MLP会更加好，因为Cosine是完全无参的。</p>
<p><code>DSSM</code>的优势:</p>
<ol>
<li><code>DSSM</code>看起来在真实检索场景下可行性很高，一方面是直接使用了用户天然的点击数据，出来的结果可行度很高，另一方面文中的doc可以使用title来表示，同时这个部分都是可以离线进行语义向量计算的，然后最终query和doc的语义相似性也是相当诱人</li>
<li><code>DSSM</code>出的结果不仅可以直接排序，还可以拿中间见过做文章:<code>semantic feature</code>可以天然的作为<code>word embedding</code>嘛</li>
</ol>
<p><code>DSSM</code>的劣势:</p>
<ol>
<li>用户信息较难加入(不过可以基于<code>MVDSSM</code>改造)</li>
<li>貌似训练时间很长啊</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>Huang P S, He X, Gao J, et al. Learning deep structured semantic models for web search using clickthrough data[C]// ACM International Conference on Conference on Information &amp; Knowledge Management. ACM, 2013:2333-2338.</li>
<li>Shen, Yelong, et al. “A latent semantic model with convolutional-pooling structure for information retrieval.” Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. ACM, 2014.</li>
<li>Palangi, Hamid, et al. “Semantic modelling with long-short-term memory for information retrieval.” arXiv preprint arXiv:1412.6629 (2014).</li>
<li>Elkahky, Ali Mamdouh, Yang Song, and Xiaodong He. “A multi-view deep learning approach for cross domain user modeling in recommendation systems.” Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2015.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>DSSM这篇paper发表在cikm2013，短小但是精炼，值得记录一下<br>ps:后来跟了几篇dssm的paper，一并记录在这里</p>
</blockquote>
<h2 id="DSSM">DSSM</h2><h3 id="DSSM的结构">DSSM的结构</h3><p><code>DSSM</code>最大的卖点在检索场景下  使用点击数据来训练语义层次的匹配，简单的来说，传统检索场景下的匹配主要有:</p>
<ol>
<li>字面匹配:<code>TFIDF</code>、<code>BM25</code>等</li>
<li>使用<code>LSA</code>类模型进行语义匹配，但是效果不好</li>
</ol>
<p>而DSSM训练出来之后，检索场景下用户输入query之后，可以根据该query计算各个doc的语义相似度。</p>
<p>这里上图最直接:</p>
<center><img src="/img/Study-With-Deep-Structured-Semantic-Model/dssm_arch.png" /></center>]]>
    
    </summary>
    
      <category term="Deep Learning" scheme="http://kubicode.me/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://kubicode.me/categories/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Federated Search Papers学习笔记]]></title>
    <link href="http://kubicode.me/2017/01/09/Search%20Engine/The-Recorder-for-some-Federated-Search-Papers/"/>
    <id>http://kubicode.me/2017/01/09/Search Engine/The-Recorder-for-some-Federated-Search-Papers/</id>
    <published>2017-01-09T01:58:31.000Z</published>
    <updated>2017-01-13T04:03:17.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px"></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br><a id="more"></a><br>下面就是<code>Federated Search</code>的链路架构<br><center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/architecture.png" width="500px" height="500px"></center>

<p>其<code>Federated Search</code>可以分解为两个任务:</p>
<ol>
<li><code>Resource Selection</code>:也叫<code>Vertical Selection</code>，就是选择不同的<code>Vertical Resource</code>去进行排序</li>
<li><code>Merge Result</code>:也有叫<code>Aggegate Content</code>，在拿到不同<code>Vertical</code>之后进行合并排序</li>
</ol>
<p>其中<code>Resource Selection</code>的难点有:</p>
<ol>
<li>待选择的<code>Vertical</code>可能是黑盒（比如第三方的引擎），没有里面细致的数据（这个点已经就很难了）</li>
<li>待选择的<code>Vertical</code>一般都是异构的</li>
</ol>
<p>另外<code>Merge Result</code>的难点有:</p>
<ol>
<li>各种<code>Vertical</code>出来都是异构的，也就是里面的特征会不一致</li>
<li>就算特征一直，同特征的分布范围还不一致，所以无法用单一的模型去解决这个事情</li>
</ol>
<h2 id="[RS&amp;MR]CORI2">[RS&amp;MR]CORI<sup>2</sup></h2><blockquote>
<p><code>CORI</code>该算法包含了<code>Resource Selection</code>和<code>Merge Result</code></p>
</blockquote>
<p>在给定$Q$、观察到资源类别$C_i$,每个资源根据$P(Q|C_i)$来进行排序</p>
<p>$$T=\frac{df}{df+50+150*cw/avg\_{cw}} \\<br>I=\frac{log(|DB|+0.5)/cf}{log(|DB|+1.0)} \\<br>p(r_k|C_i)=b+(1-b)*T*I<br>$$</p>
<p>其中:</p>
<ul>
<li>$r_k$为$Q$中的第$k$个term</li>
<li>$df$为资源$C_i$中包含$r_k$的文档数量</li>
<li>$cf$为包含$r_k$的资源数量</li>
<li>$|DB|$为需要排序的资源数量</li>
<li>$cw$为在资源$C_i$中出现$r_k$的频次</li>
<li>$avg\_cw$某个$C_i$的平均$cw$</li>
<li>$b$默认值 一般为0.4</li>
</ul>
<p>在合并的时候可以使用类似这种方式进行<code>resultmerge</code>:<br>$$C_i^{*} = \frac{(C_i-C_{min})}{(C_{max}-C_{min})} \\<br>D_i^{*} = \frac{(D_i-D_{min})}{(D_{max}-D_{min})}$$<br>最终归一化的score为(其实这儿就是做了一个映射):<br>$$D^{**} = \frac{D^{*} + 0.4*D^{*}*C_i^{*}}{1.4}$$</p>
<h2 id="[MR]Semisupervised_Learning(SSL)3">[MR]Semisupervised Learning(SSL)<sup>3</sup></h2><blockquote>
<p>这个算法主要用于<code>Merge Result</code>阶段</p>
</blockquote>
<p>用户在输入query时，希望会将该query分发到各个需要排序的引擎(database-specific)上面,此时同时会将query分发到一个中心的涵盖所有的资源的单独引擎上面(database-independent)</p>
<p>这个时候会出两个score:</p>
<ol>
<li><code>database-specific-scorer</code>:不同资源引擎排序的score，不同资源之间的维度不一样</li>
<li><code>database-independent -scroer</code>：中心独立引擎上面，不同资源建所计算的score在同一个维度(估计这里只能用一个common的特征的排序)</li>
</ol>
<p>同时会有讲个假设:</p>
<ol>
<li>同一个query出现在<code>database-specific</code>上面的大部分也会出现在<code>database-independent</code>中</li>
<li><code>database-specific</code>与<code>database-independent</code>两者的overlap的doc拿到的score对使用机器学习方式可计算出一个映射</li>
</ol>
<p>此时假设对于overlap的doc有如下score的pair对$s_{ind},s_{spe}$<br>需要做的就是使用线性回归的方式对两个score简建立一个映射<br>$$s_{ind} = w*s_{spe}+b$$<br>其需要优化的是:</p>
<p>$$argmin_w \sum_i (f(w,s_{spe})-s_{ind})^2$$</p>
<p>这样在各个混排引擎出来的时候就使用归一到同一纬度的score了，并且线性函数的运算很快<br>当然在训练数据不足的时候可以退化为<code>CORI</code></p>
<p>但是他也有其他的缺点：</p>
<ol>
<li>需要额外维护一个中心引擎</li>
<li>中心引擎出的score是同一纬度的算分，也是各个混排引擎的训练目标，但是如果他算分计算不准确，这个训练的结果将会很尴尬</li>
</ol>
<h2 id="[RS]REDDE4">[RS]REDDE<sup>4</sup></h2><blockquote>
<p>主要是做<code>Resource Selection</code>，但是预先先做了<code>Resource Sampling</code></p>
</blockquote>
<h3 id="Sample-Resample">Sample-Resample</h3><p>首先需要使用<code>sample-resample</code>对未知的垂直资源进行一个数据量大小的估计:</p>
<ol>
<li>先从已采样的垂直资源中随机选几个query-term</li>
<li>然后使用<code>query-term</code>再去请求垂直资源拿到返回的请求数以及<code>top rank</code>的部分doc</li>
</ol>
<p>其中</p>
<ul>
<li>$C_j$表示某个垂直资源/数据库</li>
<li>$\tilde{C}_j$表示该垂直资源的采样数据集</li>
<li>$N_{C_j}$表示垂直资源里面的数据大小(条数)[未知]</li>
<li>$N_{\tilde{C}_j}$表示采样垂直资源里面的数据大小条数</li>
<li>$q_i$表示垂直资源中被选择出来的某个<code>query term</code></li>
<li>$df_{q_iC_j}$表示垂直资源$C_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>$df_{q_i\tilde{C}_j}$表示采样垂直资源$\tilde{C}_j$中包含$q_i$的文档数量（就是逆文档频次）</li>
<li>事件$A$表示从垂直资源中采样的某个文档包含$q_i$</li>
<li>事件$B$表示垂直资源中某个文档包含$q_i$</li>
</ul>
<p>则有:<br>$$P(A) = \frac{df_{q_i\tilde{C}_j}}{N_{\tilde{C}_j}} \\<br>P(B) = \frac{df_{q_iC_j}}{N_{C_j}}$$<br>假设采样可以很好的表示整个数据库/垂直资源，因此有$P(A) \approx  P(B)$,则近似的有：<br>$$\hat{N}_{C_j} =  \frac{N_{\tilde{C}_j} *df_{q_iC_j} }{df_{q_i\tilde{C}_j}}$$</p>
<p>最终是使用全部估计的均值来表示的</p>
<h3 id="Resource_Selection">Resource Selection</h3><p>在给定查询词$q$下对于$C_j$的相关性估计为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in C_j}P(rel|d_i) * P(d_i|C_j) * N_{C_j}$$</p>
<p>其中:</p>
<ul>
<li>$N_{C_j}$为资源$C_j$的总文档量，我们使用$\hat{N}_{C_j}$来近似</li>
<li>$P(d_i|C_j)$这个概率将会是$\frac{1}{N_{C_j}}$</li>
</ul>
<p>相应的，相关性的估计将可以被写为:<br>$$\hat{Rel}_q(j) = \sum_{d_i \in \tilde{C}_j} P(rel|d_i) \frac{1}{\tilde{N}_{C_j}}  * \hat{N}_{C_j}$$</p>
<p>这样唯一剩下未知就是文档$d_i$与$q$的相关性了$P(rel|d_i)$<br>该paper并没有直接对其相关性做深入的研究，假如目前有一个中心数据库包含了所有的垂直资源，对其中心数据库来检索，则其相关性可以为:<br>$$P(rel|d_i)=\left\{<br>\begin{aligned}<br>C_q &amp; \quad if Rank\_central(d_i) &lt; ratio * \hat{N}_{all} \\<br>0 &amp; \quad \text{otherwise} \\<br>\end{aligned}<br>\right.$$</p>
<p>其中:</p>
<ul>
<li>$Rank\_central(d_i) $为中心数据库中对于$d_i$的排序</li>
<li>$ratio$为一个阈值，指示关注top多少的一个阈值(0.002~0.005表示合适)</li>
<li>$\hat{N}_{all}$为中心数据中所有文档量的一个估计值</li>
<li>$C_q$是一个独立于$q$的常量</li>
</ul>
<p>这种完备的中心数据库其实建立起来不大可行，但是我们可以使用采样的中心数据库.<br>现在向采样的中心进行query检索，可以根据其返回结果来推断出实际中心数据库中各个文档的排序的位置:<br>$$Rank\_central(d_i) = \sum_{d_j | Rank\_S(d_j) &lt; Rank\_S(d_i)} \frac{\hat{N}_{c(d_j)}}{\tilde{N}_{c(d_j)}}$$</p>
<p>这样最终$\hat{Rel}_q(j) $就可以计算出来了，最终在资源选择分布时可以按比例来:<br>$$\hat{Rank\_Rel}_q(j) = \frac{\hat{Rel}_q(j)}{\sum_i \hat{Rel}_q(i)}$$</p>
<h2 id="[RS]Adaptation_of_Offline_Vertical_Selection5">[RS]Adaptation of Offline Vertical Selection<sup>5</sup></h2><p>原本最常用的垂直资源选择是使用<code>one_vs_all</code>的分类分类方法，其中$k$个垂直资源，这样就需要分$k+1$个类别，训练完预测的时候选择类别概率高的来进行展现</p>
<p>而这篇paper主要是在输入类别概率之后还将用户反馈加入了进来再计算:</p>
<h3 id="Multiple_Beta_Prior">Multiple Beta Prior</h3><p>$p_q^v$可以用来表示某个Query下对于某个垂直资源类别v的相关概率，并且它是呈现<code>beta</code>分布的:<br>$$p_q^v \text{~} Beta(a_q^v,b_q^v)$$</p>
<p>其中$\pi_q^v$为离线模型概率，$\mu$为控制因子<br>$$a_q^v=\mu \pi_q^v \quad \quad b_q^v=\mu (1-\pi_q^v)$$</p>
<p>最后我们可以将相关性的后验写为<br>$$\tilde{p}_q^v = \frac{R_q^v + \mu \pi_q^v}{V_q^v + \mu}$$</p>
<blockquote>
<p>$R_q^v$为$q$下展现$v$同时被点击的数量,$\bar{R}_q^v$表示展现了  但是未被点击的数量,$V_q^v$则表示一共展现的数量</p>
</blockquote>
<h3 id="Logistic_Normal_Prior">Logistic Normal Prior</h3><p>其先验为<br>$$p_q^v = \frac{exp(W_{tv})}{exp(W_{tv}) + exp(\bar{W}_{tv})}$$</p>
<blockquote>
<p>$W$和$\bar{W}$是$t \times k$的随机矩阵，并且服从$W,\bar{W} ~ N_{2tk}(\eta,\sum)$,$\sum$为一个协方差矩阵</p>
</blockquote>
<p>则其后验可以转为:<br>$$\tilde{p}_q^v = \frac{\pi_q^v exp(a_q^v)}{\pi_q^v exp(a_q^v) + (1-\pi_q^v) exp(b_q^v)}$$</p>
<p>最终关于$a_q^v,b_q^v$都是可以被计算出来的:<br>$$a_q^v = R_q^v+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} \bar{R}_q^{v’}$$<br>$$b_q^v =  \bar{R}_q^{v’}+ \sum_{v’ \neq v} \frac{\sigma}{V_{q’}^{v’}} R_q^v $$<br>其中:</p>
<ol>
<li>$R_q^v$表示$q$与$v$相关的对数</li>
<li>$V_q^v$表示$q$与$v$共现的总次数</li>
</ol>
<h3 id="Similar_Queries">Similar Queries</h3><p>假设某个query1下知道他对于不同垂直资源的偏好，此时有一个query2与query1很相似，那么他关于垂直类目的偏好也会很相似<br>这个也是利用beta分布来估计的，算的是这个Bhattacharyya相似性，感兴趣自己去看paper</p>
<h3 id="Randomizing_Decisions">Randomizing Decisions</h3><p>对于偏好概率很低的垂直资源也会有某个概率$\varepsilon $进行选择它，加了这个概率波动的之后，最后在选择垂直资源是这么计算的，其相关性为：$$P(v)=\frac{1}{Z} exp(\frac{\tilde{p}_q^v}{\tau})$$<br>它是符合<code>Boltzmann</code>分布,其中:</p>
<ol>
<li>$\tilde{p}_q^v$为后验概率</li>
<li>$Z=\sum_vexp(\frac{\tilde{p}_q^v}{\tau})$</li>
<li>$\tau$是一个大于0的值，如果$\tau$趋向于正无穷，那么$P(v)$将会更加随机化，如果$\tau$接近于0，$P(v)$的选择将会更加贪婪（也就是哪个大选哪个）</li>
</ol>
<h2 id="[RS]Vertical_Selection_Evidence6">[RS]Vertical Selection Evidence<sup>6</sup></h2><p>使用分类的方法来进行资源类别选择，里面讲的主要是各种特征</p>
<p>评估指标为:<br>$$P=\frac{1}{|Q|} \left( \sum_{q \in Q | V_q \neq \varnothing } I(\tilde{v}_q \in V_q) + \sum_{q \in Q | V_q = \varnothing } I(\tilde{v}_q = \varnothing)   \right)$$</p>
<p>其中:</p>
<ol>
<li>$V$表示所有垂直资源的集合</li>
<li>$Q$表示所有Query的集合</li>
<li>$V_q$为与某个$q$相关的垂直资源集合</li>
<li>$\tilde{v}_q$表示对于$q$预测的与其相关的一个垂直资源</li>
<li>$I(\cdot)$表示示性函数，应该就是${0,1}$的二值函数吧</li>
</ol>
<p>下面是三大类特征<code>Query String</code>、<code>Query Logs</code>、<code>vertical corpora</code>:</p>
<h3 id="1-Query_String">1.Query String</h3><blockquote>
<p>该特征是为了利用Query中的一些关键短语与垂直资源的内容进行一些匹配</p>
</blockquote>
<h4 id="Rule-based_vertical_triggers(基于规则的触发)">Rule-based vertical triggers(基于规则的触发)</h4><p>文章中一共建立了45类别的属性来刻画query的垂直意图（其实就像类目，比如,local<br>phone, product, person, weather, movies, driving direction,<br>music artist）<br>同时这45类触发将会有三种规则：</p>
<ol>
<li><code>一对一触发</code>:<code>movies → movies, autos→ autos</code></li>
<li><code>一对多触发</code>:<code>{sports players,sports} → sports, {product review, product} → shopping</code></li>
<li><code>不显示对应</code>：但是会提供一些<code>positive或者negative</code>的标志用于分类器,比如, <code>patent, events, weather</code></li>
</ol>
<p>里面的触发类别都是用过正则表达来提出取来，另外一个query可能关联到多个类别，一个触发器至少会匹配到一个query</p>
<h4 id="Geographic_features(地理特征)">Geographic features(地理特征)</h4><p>在输入query下提取地理特征，并且会形成一个指定维护的概率向量:<code>airport,colloquial,continent,town,</code>等，将会与垂直资源中常常提到的这些地理词进行匹配</p>
<h3 id="2-_Query-Log_Features">2. Query-Log Features</h3><p>使用<code>Query-log</code>建立一个一元的语言模型<br>$$QL_q(V_i) = \frac{1}{Z}P(q|\theta_{v_i}^{qlog})$$<br>其中$\theta_{v_i}^{qlog}$为垂直资源$V_i$的语言模型，另外<br>$$Z=\sum_{v_j \in V}P(q|\theta_{v_j}^{qlog})$$</p>
<h3 id="3-Corpus_Features">3.Corpus Features</h3><blockquote>
<p>垂直资源的语料特征</p>
</blockquote>
<h4 id="垂直资源采样">垂直资源采样</h4><blockquote>
<p>应该是这儿的垂直资源可能是分布到各种不同的引擎里面的（第三方），作者并无法取到全部的离线数据，所以在进行语料相关特征计算的时候需要拿到具有代表性的资源文档数据</p>
</blockquote>
<p>在采样的时候使用垂直资源的top-query取访问垂直引擎，拿到文档再去统计，另一次关于垂直资源的语料去Wikipedia获取也是一种相当好的方式，因为里面都做好了结构化</p>
<h4 id="基于语料的特征">基于语料的特征</h4><p>1). <strong>Retrieval Effectiveness Features</strong></p>
<p>$$Clarity_q(C) = \sum_{w \in V} P(w|\theta_q) \text{log} \frac{P(w|\theta_q)}{P(w|\theta_C)}$$</p>
<p>其中:</p>
<ul>
<li>$V$是垂直资源$C$的语料/word</li>
<li>$P(w|\theta_q)$和$P(w|\theta_C)$分别是query和垂直资源的语言模型<br>  $$P(w|\theta_q) = \frac{1}{Z} \sum_{d \in R_{100}} P(w|\theta_d) P(w|\theta_d)$$<br>  $P(q|\theta_d)$为文本$d$的query似然分数，另外$Z=\sum_{d \in R_{100}}P(q|\theta_d)$</li>
</ul>
<blockquote>
<p><code>Clarity</code>分数越小表示检索效果越差</p>
</blockquote>
<p>最终各个资源也是按比例分数来计算的<br>$$Clarity_q^*(V_i) = \frac{1}{Z^*} Clarity_q(S_i^*)$$</p>
<p>2). ReDDE Features.<br>该Feature其实就是Luo.si  2003paper里面的计算方式<br>$$ReDDE_q^*(V_i) = |V_i| \sum_{d \in R_{100}} I(d \in S_i^*) P(q|\theta_d) P(d|S_i^*)$$<br>其中<br>$$P(d|S_i^*) = \frac{1}{S_i^*}$$</p>
<p>3). Soft.ReDDE Features<br>使用Bhattacharyya correlation<br>$$B(d,V_i) = \sum_{w \in top query}\sqrt{P(w|\theta_d) P(w|\theta_{V_i})} $$<br>其中<br>$$\phi(d,V_i) = \frac{B(d,V_i)}{\sum_{V_j \in V}B(d,V_j)}$$<br>最终soft针对文档的$B$进行求和，同时使用$P(q|\theta_d)$来加权:<br>$$Soft.ReDDE_q(V_i) = \sum_{d \in R_{100}} \phi(d,V_i) \times P(q|\theta_d)$$</p>
<p><code>Soft.ReDDE</code>有两大好处：</p>
<ol>
<li>每个文档在他的资源类别排序中多多少少都有贡献</li>
<li>不需要手动做文档到资源类别的映射(这个不懂….)</li>
</ol>
<p>4). Categorical Features<br>最大熵求取多级类目特征</p>
<h2 id="[MR]_Aggregate_Vertical_Results7">[MR] Aggregate Vertical Results<sup>7</sup></h2><p><code>Aggregate Vertical Results</code>(就是最终多源搜索结果的合并)有两大难处：</p>
<ol>
<li>不同来源的特征不一致</li>
<li>就是特征一直，同一个特征的值的分布也是不一致的</li>
</ol>
<p>因此无法直接使用一个ML算法去学习他们的排序,需要一种算法去学习这种不一致的特征排序任务（好像是用了某些特征关系映射）<br>整个<code>Aggregate Result</code>有如下的假设:</p>
<ol>
<li>相同的垂直资源应该是被排到一起的</li>
<li>垂直资源只能被嵌入到指定的坑位</li>
<li>网页结果往往都是主排序</li>
<li>不同的垂直资源是需要有关联的（这个有点难吧）</li>
<li>我们假设用户不会去看那些不相关的垂直资源</li>
</ol>
<p>这儿做的叫做<code>block-rank</code>坑位排序，比如有坑位<code>1~3(w1)</code>、<code>4~6(w2)</code>、<code>7~10(w3)</code>等，其中任务是预测排序顺序$\sigma(q)$与$\sigma^*(q)$尽量相似，其相似度可以使用$\text{Kendall’s} \tau$ 来衡量。<br>另外为了防止某些不相关性的<code>block</code>也被展现，所以有一个叫做<code>end of search result</code>(eos)的模块，如果被预测到这个模块，将会被放置到最下面并且不会展现</p>
<p>先说一下ML所使用到的特征<code>Pre-retrieval Features</code>和<code>Post-retrieval Features</code></p>
<p>1) <strong>Pre-retrieval Features</strong></p>
<blockquote>
<p>在检索到垂直引擎之前的提取的特征</p>
</blockquote>
<ul>
<li><code>Named-Entity Type Features</code></li>
<li><code>Category Features.</code></li>
<li><code>Click-through Features</code></li>
<li><code>Vertical-Intent Features.</code>(这个意图识别还是较难较重)</li>
</ul>
<p>2) <strong>Post-retrieval Features</strong></p>
<blockquote>
<p>这个为在检索到垂直引擎之后提取的特征</p>
</blockquote>
<ul>
<li><code>Hit Count Features</code>:垂直引擎的召回量</li>
<li><code>Temporal Features</code>:时间性相关的特征（时效性）</li>
<li><code>Text-Similarity Features.</code></li>
</ul>
<h3 id="BLOCK-RANKING_APPROACHES">BLOCK-RANKING APPROACHES</h3><blockquote>
<p>下面是实际的排序方法了</p>
</blockquote>
<p>1) <strong>Classification Approach</strong><br>每个垂直资源都有一个自己的分类器(这是使用的LR这个二分类器)<br>这里每个坑位都有一个阈值(除上面<code>w1~3</code>之外，还有一个eos的<code>w4</code>)<br>预测的是这个概率:<br>$$P(\sigma_q(v) &lt; \sigma_q(eos))$$<br>也就是是否要被展现的概率，最终按这种方式进行填坑<br>$$P(\sigma_q(v) &lt; \sigma_q(eos)) &gt; \tau_y \forall x&lt;y $$<br>这样就可以填入<code>x</code>坑位了（$\tau_y$是<code>1~4</code>坑位的阈值）</p>
<p>2) <strong>Voting Approach</strong><br>这里也是使用独立的分类模型,但是他的分类对象是<br>$$P(\sigma_q(i)) &lt; P(\sigma_q(j))$$<br>也就是pair，预测垂直资源$i$是否排在$j$前面，同时由于不同资源特征的限制,不同的$i,j$比较都是需要单独训练一个模型，最终使用投票的方式来确定哪个排在前面</p>
<blockquote>
<p>这种方式将会训练大量模型，虽然paper中将某些<code>block</code>因素归一了，但是训练的模型量还是巨大的</p>
</blockquote>
<p>3) <strong>Learning to Rank Approaches</strong><br>使用<code>RankSvm</code>进行排序,但是会遇到不同类别的特征体系不一致的问题，通过下面三种方式解决</p>
<ol>
<li><code>Equally Correlated Features</code>:针对部分common特征可以合并起来</li>
<li><code>Uniquely Correlated Features.</code>:对类别相关的特征进行copy和平铺出来，比如不同类别下同一个相关性特征可能会写两遍，但是都是时间特征在某些类别下只需要写一遍</li>
<li><code>Equally and Uniquely Correlated Features.</code>:结合上面两种特征</li>
</ol>
<p>但是上面的操作可能会导致过拟合，所以需要比较多的训练样本</p>
<h2 id="[MR]Merging_Multiple_Result_Lists8">[MR]Merging Multiple Result Lists<sup>8</sup></h2><p>用<code>LambdaMerge</code>的方法，其中好多使用了DNN，其框架为:</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/lambdamerge.png" width="500px" height="500px"></center>


<p>其中</p>
<ul>
<li>$f(x_{i,j}^d;\theta)$为文档相关的算法，前面那层的DNN,$x_{i,j}^d$为文档特征</li>
<li>$g(z_i;\eta)$为不同搜索引擎相关的特征（比如google、bing等）,$g(z_i;\eta)$也搜索引擎相关的特征,也是用DNN过了一层</li>
<li>$h(y_j;\phi)$为不同资源相关的特征,$y_j$为特征，也用dnn过了一层</li>
</ul>
<p>最终使用<code>lambdarank</code>来解，感觉这种方法写paper可以，但是实际使用起来代价有点高的</p>
<h2 id="[MR]Federated_Search_at_LinkedIn9">[MR]Federated Search at LinkedIn<sup>9</sup></h2><blockquote>
<p>这篇文章讲了混排在LinkedIn的实践，虽然没有高深的算法，但是讲的实在</p>
</blockquote>
<p>在Linked中的，混排的对象有Job、People、Companies、post等，但是没有一个主要的排序对象（web search中一般网页都是主要排序对象）<br>下面是他们的混排框架</p>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/linkedin1.png" width="500px" height="500px"></center>


<ol>
<li>用户输入一个query</li>
<li>希望向各个垂直引擎进行请求</li>
<li>请求完了之后各自引擎算完相关性得到top result（用LR进行计算的）</li>
<li>根据top result中各个得分选出主要的资源P,其他的资源都称为C</li>
<li>里面会对P和C的混排分进行一个归一化(没有细讲)</li>
<li>然后以$P_i$为主，将其$C_i$与$P_i$比大小进行插入完成混排</li>
</ol>
<p>其中排序选取的特征有:</p>
<ol>
<li><code>Searcher Intent</code>:用户自身的意图（稳定的，一天跑一把）</li>
<li><code>Keyword Intent</code>:query的意图 实时概率预测</li>
<li><code>Base Ranking Features</code>：基础特征了</li>
</ol>
<p>整个算法简单粗暴，效果还可以，主要实现起来快，而且各个大引擎主要跑一次</p>
<h2 id="[RS]2013-TREC10">[RS]2013-TREC<sup>10</sup></h2><blockquote>
<p>2013年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="resource_selection-Krisztian_Balog">resource selection-Krisztian Balog</h3><p>使用语言模型进行估计:<br>两种方式，将一种资源统一看成一种文档:<br>$$P(q|c) = \prod_{t \in q}\left\{ (1-\lambda)\left(\sum_{d \in c}P(t|d)P(d|c)\right) + \lambda P(t)\right\}^{n(t,q)}$$</p>
<ul>
<li>$t$为$q$中出现的term</li>
<li>$n(t,q)$表示$q$中出现$t$次数</li>
<li>$P(t|d)$和$P(t)$为给定文档下面的最大似然估计</li>
<li>$\lambda$为平滑因子</li>
<li>$P(d|c) = \frac{1}{|c|}$看成均匀分布式</li>
</ul>
<p>另一种方式是看一种资源看成多个文档<br>$$P(q|c) = \sum_{d \in c} P(d|c) \prod_{t \in q} \left( (1-\lambda)P(t|d)+\lambda P(t) \right)^{n(t,q)}$$</p>
<p>最终将两个分数进行一个合并<br>$$P(q|c) = \beta P_{cc}(q|c) + (1-\beta)P_{dc}(q|c)$$</p>
<h3 id="resource_selection-Emanuele_Di_Buccio">resource selection-Emanuele Di Buccio</h3><p>使用两个因子:</p>
<ol>
<li>Inverse Resource Frequency (IRF)   类似逆文档频率<br>$$IRF_t^{(z)} = \text{log} \frac{N^{(z)}}{n_t^{(z)}}$$</li>
</ol>
<ul>
<li>$t$表示term</li>
<li>$N^{(z)}$表示在$z$级别包含$t$的量</li>
<li>$n_t^{(z)}$表示具体某个资源包含$t$的量</li>
</ul>
<blockquote>
<p>关于$z$有是有三个级别:: (1) document, (2) search engines and (3) the set of search engine</p>
</blockquote>
<ol>
<li>Term Weighted Frequency (TWF)<br>$$w_{i,t}^{(z)} = TWF_{i,t}^{(z)} \cdot IRF_t^{(z-1)} $$<br>同时<br>$$TWF_{i,t}^{(z)} = \sum_{r \in R_i^z} TWF_{i,t}^{(z-1)} \cdot IRF_t^{(z-1)}$$</li>
</ol>
<p>这儿是一个递归的方式</p>
<h2 id="[RS]2014-TREC-Federated_Search11">[RS]2014-TREC-Federated Search<sup>11</sup></h2><blockquote>
<p>2014年TREC比赛上关于<code>Resource Selection</code>的一些做法</p>
</blockquote>
<h3 id="1-resource_selection_-_Qiuyue_Wang">1.resource selection - Qiuyue Wang</h3><p>使用LDA来进行Resource和query的分布<br>由于query很短，作者的处理是用query查询google api取得top 50的文档的摘要，用组成的摘要来训练LDA，最终使用KL距离来衡量相似性</p>
<h2 id="总结">总结</h2><p>看了一些<code>Federated Search</code>相关的<code>Paper</code>（当然还有两个综述也讲的很好[12],[13]），其中</p>
<ul>
<li><code>Resource Selection</code>主要从<code>统计学</code>、<code>相似度计算</code>、<code>概率生成模型</code>以及<code>分类模型来完成</code></li>
<li><code>Merge Result</code>有使用<code>多源归一化</code>，<code>回归模型</code>、<code>LTR模型</code>来完成，同时在算分最后大多使用<code>Slot Filling</code>的方法来做</li>
</ul>
<p><code>Resource Selection</code>目前的方法中好的<code>Resource</code>将会被更多的选择则，该阶段尝试加入<code>Bandit</code>相关策略也许会有比较好的效果,<br>另外<code>Resource Selection</code>和<code>Merge Result</code>目前在优化中其实并没有太大的联系，有没有可能有一种方法能将两个阶段联合起来进行全局优化?</p>
<h2 id="参考文献">参考文献</h2><ol>
<li>Arguello, Jaime, Fernando Diaz, and Milad Shokouhi. “Integrating and ranking aggregated content on the web.” Proc. WWW 2012 (2012).</li>
<li>Callan, James P., Zhihong Lu, and W. Bruce Croft. “Searching distributed collections with inference networks.” Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1995.</li>
<li>Sushmita, Shanu, et al. “Factors affecting click-through behavior in aggregated search interfaces.” Proceedings of the 19th ACM international conference on Information and knowledge management. ACM, 2010.</li>
<li>Si, Luo, and Jamie Callan. “Relevant document distribution estimation method for resource selection.” Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 2003.</li>
<li>Diaz, Fernando, and Jaime Arguello. “Adaptation of offline vertical selection predictions in the presence of user feedback.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, et al. “Sources of evidence for vertical selection.” Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009.</li>
<li>Arguello, Jaime, Fernando Diaz, and Jamie Callan. “Learning to aggregate vertical results into web search results.” Proceedings of the 20th ACM international conference on Information and knowledge management. ACM, 2011.</li>
<li>Lee, Chia-Jung, et al. “An Optimization Framework for Merging Multiple Result Lists.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015</li>
<li>Arya, Dhruv, Viet Ha-Thuc, and Shakti Sinha. “Personalized Federated Search at LinkedIn.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.</li>
<li><a href="http://trec.nist.gov/pubs/trec22/trec2013.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec22/trec2013.html</a></li>
<li><a href="http://trec.nist.gov/pubs/trec23/trec2014.html" target="_blank" rel="external">http://trec.nist.gov/pubs/trec23/trec2014.html</a></li>
<li>Shokouhi, Milad, and Luo Si. “Federated search.” Foundations and Trends in Information Retrieval 5.1 (2011): 1-102.</li>
<li>Kopliku, Arlind, Karen Pinel-Sauvagnat, and Mohand Boughanem. “Aggregated search: A new information retrieval paradigm.” ACM Computing Surveys (CSUR) 46.3 (2014): 41.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Federated_Search_介绍1">Federated Search 介绍<sup>1</sup></h2><blockquote>
<p><strong>Federated search</strong> is an information retrieval technology that allows the simultaneous search of multiple searchable resources. —from WikiPedia</p>
</blockquote>
<center><img src="/img/The-Recorder-for-some-Federated-Search-Papers/example.png" width="400px" height="400px" /></center><br>上图就是一个<code>Federated Search</code>的栗子，在搜索了<code>lyon</code>关键词之后有<code>地图</code>、<code>图片</code>、<code>视频</code>以及<code>网页</code>，其各种资源一般来说是不在同一个引擎的，其中召回排序算法也是不一致的，而<code>Federated Search</code>要做的就是接收到关键词之后给用户展现一个统一的界面。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[最大熵模型]]></title>
    <link href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/"/>
    <id>http://kubicode.me/2016/12/12/Machine Learning/Maximum-Entropy-Model/</id>
    <published>2016-12-12T01:39:30.000Z</published>
    <updated>2017-01-03T13:16:38.000Z</updated>
    <content type="html"><![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br><a id="more"></a></p>
<center><img src="/img/Maximum-Entropy-Model/binary_ent.png" width="400px"></center>

<blockquote>
<p>上图是两个类别的示例，可以看到这两个类别的<code>概率一样</code>时其熵值最大</p>
</blockquote>
<p>在机器学习领域，我们通常以最小化风险为目标，其实就是将熵进行最大化.<br>最大熵模型亦是如此，直观的说，<code>最大熵模型就是在满足现有的约束条件之下，将那部分不确定的都设为等可能（熵最大）</code>，<br>下面看一个简单的例子:<br>假设现在有一个随机变量$X$可能取值为$\{A,B,C\}$,现在需要来估计各个值的概率:$P(A)$,$P(B)$,$P(C)$</p>
<p>其实这些概率值肯定会满足如下条件:<br>$$P(A)+P(B)+P(C)=1$$<br>但是满足这个约束条件的概率分布有无限多个，如果没有其他信息的条件下，则取值风险最小的方法是:<br>$$P(A)=P(B)=P(C)=\frac{1}{3}$$<br>现告诉你取$P(A)$的概率为$\frac{1}{2}$,则根据熵最大的原理其他两个概率取值将会为<br>$$P(B) = P(C) = \frac{1}{4}$$<br>也就是$B$和$C$是等概率的，假如接下来还有其他可知的约束条件的话，在满足其他约束条件的情况下继续进行等概率分布.上面的整个划分的过程也就是遵循了<code>最大熵原理</code></p>
<p>现假如用欧式空间的单纯形来表示随机变量$X$的话，定义单纯形中的任意一点到$x$到达相应顶点对应边的距离为取值概率，并且三边距离之和为1，这两种取值情况:<br>$$P(A)=1,P(B)=P(C)=0 \\<br>P(A)=P(B)=P(C)=\frac{1}{3}$$<br>可以依次使用下面两个图来表示</p>
<center><img src="/img/Maximum-Entropy-Model/complex1.png" width="400px"></center>

<p>知道了上面单纯形的表示方法之后，根据下图其最大熵原理可以得到如下的刻画:</p>
<ol>
<li>不加任何约束的时候，可以用图(a)表示，整个取值空间为单纯形上的任何一点，只需要找到熵最大的情况即可</li>
<li>当添加约束<code>C1</code>的时候，将需要在满足<code>C1</code>的情况下再寻找熵最大的取值(也就是图(b))</li>
<li>图(c)表示在图(b)的<code>C1</code>基础上继续增加了<code>C2</code>的约束，此时对两个约束进行了满足之后取值空间将会被固定在<code>C1</code>和$C2$的交点上，只有一个唯一解</li>
<li>假设图(d)里面在<code>C1</code>的基础了增加了<code>C2</code>，但是此时<code>C1</code>和<code>C2</code>并无交点，在这两者约束下将会无解<center><img src="/img/Maximum-Entropy-Model/complex2.png"></center>

</li>
</ol>
<h2 id="最大熵模型介绍">最大熵模型介绍</h2><blockquote>
<p>最大熵模型其实就是在<code>满足已有约束的条件下求得熵最大的过程</code>,最终会转为一个<code>解约束最优化</code>的问题</p>
</blockquote>
<p>现将最大熵原理应用到分类的最大熵模型:<br>假设现有训练数据集<br>$$T=\{(x_1,y_1),(x_2,y_2),….(x_n,y_n)\}$$<br>最大熵模型就是分别根据已有的输入$X$和输出$Y$集合去学习训练数据的条件概率分布$P(y|x)$，应用最大熵原理去学习分类能力最好的模型.<br>根据最大熵原理，是需要在满足约束的情况对已有数据求得熵最大，那在最大熵分类模型里面的<code>约束条件</code>又是啥呢？</p>
<p>对于给定的训练数据集，我们可以确定联合分布$P(X,Y)$的<code>经验分布</code>$\tilde{P}(X,Y)$以及边缘分布$P(X)$的<code>经验分布</code>$\tilde{P}(X)$，即:<br>$$\tilde{P}(X=x,Y=y)=\frac{count(X=x,Y=y)}{N} \\ \tilde{P}(X=x) = \frac{count(X=x)}{N}$$</p>
<blockquote>
<p>其中$count(\cdot)$表示满足条件在样本中的计数，$N$表示总的训练样本容量</p>
</blockquote>
<p>现在引入<code>特征函数</code>$f(x,y)$，它是描述输入$x$与输出$y$之间满足的某一事实，为了方便起见，我们将$f(x,y)$定义为二值函数:<br>$$ f(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{x,y满足某一事实} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$</p>
<blockquote>
<p>上面的特征函数比较抽象，下面借用别人的栗子来说明一下:<br>假设我们需要来判断<code>打</code>字是量词还是动词，目前有下面的训练数据集:<br>$$<br>(x_1,y_1) = (\text{一打火柴},\text{量词}) \\<br>(x_2,y_2) = (\text{三打啤酒},\text{量词}) \\<br>(x_3,y_3) = (\text{五打袋子},\text{量词}) \\<br>(x_4,y_4) = (\text{打电话},\text{动词}) \\<br>(x_5,y_5) = (\text{打篮球},\text{动词})<br>$$<br>通过观察我们可以发现<code>打</code>前面位<code>数字</code>时，<code>打</code>为<code>量词</code>，如果<code>打</code>后面跟着的是<code>名词</code>,则打为<code>动词</code>，为基于刚刚观察的两个实时我们用特征函数来表示则为:<br>$$ f_1(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的前面为数字} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>$$ f_2(x,y)=\left\{<br>\begin{aligned}<br>1 &amp; \quad \text{“打”的后面为名词} \\<br>0 &amp; \quad \text{否则} \\<br>\end{aligned}<br>\right.$$<br>有了特征函数之后，我们将现有的数据代入这两个特征函数即有:<br>$$f_1(x_1,y_1) = f_1(x_2,y_2) = f_1(x_3,y_3) = 1,f_1(x_4,y_4) = f_1(x_5,y_5) = 0 \\<br>f_2(x_1,y_1) = f_2(x_2,y_2) = f_2(x_3,y_3) = 0,f_2(x_4,y_4) = f_2(x_5,y_5) = 1<br>$$</p>
</blockquote>
<p>对于任意的特征函数$f(x,y)$,<br>现记$E_{\tilde{P}}(f)$表示特征函数$f$在训练数据集$T$上关于$\tilde{P}(x,y)$的数学期望，有:<br>$$E_{\tilde{P}}(f) = \sum_{x,y} \tilde{P}(x,y) f(x,y)$$<br>另记$E_{P}(f)$表示特征函数$f$在训练数据集$T$上关于$P(x,y)$的数学期望，有:<br>$$E_{P}(f) = \sum_{x,y} P(x,y) f(x,y)$$<br>但是$P(x,y)$是未知的，而我们的目标是为了计算$P(y|x)$，根据<code>Bayes</code>我们可以做如下转换<br>$$P(x,y) = P(y|x) \cdot p(x)$$<br>虽说$p(x)$仍为未知，但是我们此时可以使用$\tilde{P}(x)$进行近似,也就是最终有:<br>$$E_{P}(f) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>我们希望上述两个期望值是一值的（应该也是符合既定事实的吧?），这样就会有:<br>$$E_{\tilde{P}}(f) = E_{P}(f)$$<br>或者<br>$$ \sum_{x,y} \tilde{P}(x,y) f(x,y) = \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)$$</p>
<p>上述式子就可以作为模型的<code>约束条件</code>，假如有$n$个特征函数，则就会有$n$个约束条件(实际中一般特征的维度就是约束条件的个数)<br>用$C$来表示满足约束的模型集合:<br>$$C=\{P|E_{\tilde{P}}(f) = E_{P}(f),I=1,2,3..n\}$$<br>满足约束条件同时使用$P(y|x)$的熵最大的模型即为最大熵模型~</p>
<p>到了这里我们还差一个熵的定义，我们的目标是为了获取条件概率的分布，因为也使用了相应的<code>条件熵</code><br>$$H(P)= - \sum_{x,y}  \tilde{P}(x) P(y|x) log P(y|x)$$</p>
<blockquote>
<p>向上面一样,$P(x)$用$\tilde{P}(x)$进行了近似</p>
</blockquote>
<p>这样我们就可以给出最大熵模型的完成公式描述了:<br>$$<br>\begin{align}<br>\underset{P \in C}{max} &amp;\quad H(P) = - \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad E_{P}(f) = E_{\tilde{P}}(f),I=1,2,3..n \\<br>&amp;\quad \sum_y P(y|x)=1<br>\end{align}<br>$$</p>
<h2 id="最大熵模型学习">最大熵模型学习</h2><p>最大熵模型的学习就是求解最大熵的过程，按照优化的习惯，我们一般会将<code>最大化</code>问题转为<code>最小化</code>再进行优化:<br>$$<br>\begin{align}<br>\underset{P \in C}{min} &amp;\quad -H(P) =  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) \\<br>st. &amp;\quad  E_{\tilde{P}}(f)- E_{P}(f) = 0,I=1,2,3..n \\<br>&amp;\quad 1-\sum_y P(y|x)=0<br>\end{align}<br>$$</p>
<p>接下来我们求解的思路是:</p>
<ol>
<li>接下来的求解方式是利用拉格朗日乘子将带约束的最优化问题转为等价无约束优化，它是一个<code>极小极大问题</code></li>
<li>然后利用对偶的等价性，将上述<code>极小极大问题</code>转为对偶的<code>极大极小问题</code></li>
</ol>
<h3 id="原始问题与对偶问题">原始问题与对偶问题</h3><p>首先我们引入拉格朗日乘子$w_0,w_1,w_2….w_n$,定义拉格朗日函数为$L(P,W)$<br>$$<br>\begin{align}<br>L(P,W) &amp;= -H(P) + w_0\left(1-\sum_y P(y|x) \right) + \sum_{i=1}^n w_i\left( E_{\tilde{P}}(f)- E_{P}(f) \right) \\<br> &amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right)<br>\end{align}<br>$$</p>
<p>则最优化的原始问题为:<br>$$\underset{P \in C}{\text{min}}  \underset{W}{\text{max}} L(P,W)$$<br>则转为等价的对偶问题为:<br>$$ \underset{W}{\text{max}} \underset{P \in C}{\text{min}} L(P,W)$$</p>
<p>其中$L(P,W)$是关于$P$的凸函数,那我们首先求对偶的极小化部分$ \underset{P \in C}{\text{min}} L(P,W)$,它是关于$W$的函数，将其记为:<br>$$\varphi(w) =  \underset{P \in C}{\text{min}} L(P,W) = L(P_w,W)$$<br>其中<br>$$P_w = \underset{P \in C}{\text{argmin}} L(P,W) = P_w(y|x)$$</p>
<blockquote>
<p>关于这里，我认为我们需要求解的是$P(y|x)$，同时可以将$L(P,W)$看为关于$P(y|x)$的函数,所以为了上面的解，需要下面的偏导~</p>
</blockquote>
<h3 id="指数形式求解">指数形式求解</h3><p>先对$L(P,W)$求$P(y|x)$的偏导,<br>$$<br>\begin{align}<br>\frac{\delta L(P,W)}{\delta P(y|x)} &amp;=  \left( \sum_{x,y}  \tilde{P}(x)  \text{log} P(y|x) + \sum_{x,y}  \tilde{P}(x)  \right) - \sum_yw_0 -\sum_{i=1}^n w_i \tilde{P}(x) f_i(x,y) \\<br> &amp;=  \sum_{x,y} \tilde{P}(x) \left( \text{log} P(y|x) + 1-w_0- \sum_{i=1}^n w_i  f_i(x,y) \right)<br> \end{align}<br>$$</p>
<p>这里对于$\tilde{P}(x)&gt;0$，在求最小值是其偏导数为0，因此会有:<br>$$P(y|x) = e^{\sum_{i=1}^n w_i  f_i(x,y)+w_0-1} = \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{e^{1-w_0}}$$</p>
<p>因为有$\sum_yP(y|x)=1$,则可以有:<br>$$e^{1-w_0} = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>最终我们可以将$P_w(y|x)$表示为:<br>$$P_w(y|x) = \frac{1}{Z_w(x)} e^{\sum_{i=1}^n w_i  f_i(x,y)} $$<br>其中<br>$$Z_w(x) = \sum_y e^{\sum_{i=1}^n w_i  f_i(x,y)}$$</p>
<blockquote>
<p>$Z_w(x)$被称为规范化因子，上面样式的算分与逻辑回归非常相似，所以又称为<code>对数线性模型</code>，同时又经过了规范化因子之后可以发现其最后的算分与<code>Softmax</code>极其相似</p>
</blockquote>
<p>这里上面两个式子就是表示$P_w = P_w(y|x)$的最大熵模型，其中向量$W$即为模型的参数<br>现在求解了内部的极小化之后，还需要求解外部的极大化<br>$$\underset{w}{\text{max}} \varphi(W) $$<br>其解标记为$W^{*}$<br>$$W^{*} = \underset{w}{\text{max}} \varphi(W) $$<br>模型参数$W^{*}$就是对对偶的极大化，得到的$W^{*}$可以表示为$W^{*} \in C$，最终$P_{w^{*}} = P_{w^{*}}(y|x)$即为模型的最终解。也就是最大熵模型需要解对偶函数 $\varphi(W)$的极大化~</p>
<h3 id="最大似然估计">最大似然估计</h3><p>在求解上面极大化之前，我们先来看下最大熵模型的极大似然法:<br>已知其经验概率分布$\tilde{P}(X,Y)$和其条件概率分布$P(Y|X)$，可以得到其对数似然函数为:<br>$$<br>\begin{align}<br>LL_{\tilde{P}}(P_w) &amp;=  \text{log} \prod_{x,y} P(y|x)^{\tilde{P}(x,y)} \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} P(y|x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} \frac{e^{\sum_{i=1}^n w_i  f_i(x,y)}}{Z_w(x)}  \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \text{log} e^{\sum_{i=1}^n w_i  f_i(x,y)} - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x,y) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_{x,y} \tilde{P}(x) \tilde{P}(y|x) \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y \tilde{P}(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i  f_i(x,y) - \sum_x \tilde{P}(x) \text{log} Z_w(x) \quad    \text{利用} {\color{Blue} {\sum_y \tilde{P}(y|x)=1}}<br> \end{align}<br>$$</p>
<p>回头再将$P(y|x)$的解代入到对偶函数$\varphi(W)$中:<br>$$<br>\begin{align}<br>\varphi(w) &amp;=  \sum_{x,y}  \tilde{P}(x) P(y|x) \text{log} P(y|x) + w_0\left(1-\sum_y P(y|x) \right)    \\<br>&amp;\quad + \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= \sum_{x,y}  \tilde{P}(x) P(y|x) \left(\sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x) \right) \\<br>&amp;\quad +  \sum_{i=1}^n w_i\left( \sum_{x,y} \tilde{P}(x,y) f(x,y)- \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y) \right) \\<br>&amp;= {\color{Red}{\sum_{x,y}  \tilde{P}(x) P(y|x) \sum_{i=1}^n w_i f_i(x,y)}}  - \sum_{x,y}  \tilde{P}(x) P(y|x)\text{log}Z_w(x) \\<br>&amp;\quad +  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y)- {\color{Red}{\sum_{i=1}^n w_i \sum_{x,y} P(y|x) \tilde{P}(x) f(x,y)}}  \\<br>&amp;=  \sum_{i=1}^n w_i \sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_x \tilde{P}(x) {\color{Blue}{\sum_y P(y|x)}} \text{log} Z_w(x) \\<br>&amp;= \sum_{x,y} \tilde{P}(x,y)\sum_{i=1}^n w_i f(x,y) - \sum_x \tilde{P}(x)\text{log} Z_w(x)<br> \end{align}<br>$$</p>
<blockquote>
<p>上面第一步的换算是借助了$\text{log} P(y|x) = \sum_{i=1}^n w_i f_i(x,y) - \text{log}Z_w(x)$，同时还有$\sum_y P(y|x)=1$</p>
</blockquote>
<p>现在再来对比$\varphi(w)$与$LL_{\tilde{P}}(P_w)$最终的表达式，可以惊奇的发现:<br>$$\varphi(w) = LL_{\tilde{P}}(P_w)$$<br>于是就证明了对偶函数的极大化等于模型极大似然估计这一事实，这样模型学习就可以在给定训练数据条件下进行极大化似然估计~</p>
<h2 id="总结">总结</h2><blockquote>
<p>关于具体的解就不再详说了，既然是可以用最大似然法解，则其常用的解法有<code>梯度下降法</code>、<code>牛顿法</code>或者还有专门的<code>GIS</code>法等，参考[2]</p>
</blockquote>
<p>关于最大熵模型:</p>
<ol>
<li>利用最大熵原理<code>熵越大事物越混乱，其分类风险越小</code></li>
<li>为了防止其解空间太大，利用<code>特征函数</code>建立起约束</li>
<li>在求解模型时使用对偶的方式进行求解，先解最小化的负熵，再求极大化的对偶函数</li>
<li>解最小化负熵时可以得到最大熵模型最后的形式是指数形式，类似逻辑回归</li>
<li>又在求极大化对偶函数时，可以发现其对偶函数与模型的极大似然法形式一致</li>
<li>因此最终可以按极大似然法的方式去解决模型</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://www.cnblogs.com/ooon/p/5677098.html" target="_blank" rel="external">最大熵模型 Maximum Entropy Model</a></li>
<li>《统计学习方法》.李航 第6章</li>
<li><a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="external">最大熵学习笔记</a></li>
<li>1996-A Maximum Entropy Approach</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="最大熵原理">最大熵原理</h2><p><code>熵</code>：其物理意义是体系混乱程度的衡量，在热力学中<code>熵</code>越大表示物质越混乱，但同时也为越稳定~<br>现假设离线随机变量$X$的概率分布为$P(X)$,则其熵为定义为:<br>$$H(P)= -\sum_x P(x) \text{log} P(x)$$</p>
<p>当$X$为均匀分布时，熵值最大:<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Softmax的二三事]]></title>
    <link href="http://kubicode.me/2016/11/27/Machine%20Learning/Something-for-Softmax/"/>
    <id>http://kubicode.me/2016/11/27/Machine Learning/Something-for-Softmax/</id>
    <published>2016-11-27T08:24:28.000Z</published>
    <updated>2018-03-21T01:39:10.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All" target="_blank" rel="external">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One" target="_blank" rel="external">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯" target="_blank" rel="external">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li><a href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/" target="_blank" rel="external">最大熵模型</a></li>
<li>。。。</li>
</ol>
<a id="more"></a>
<p>同时本文要说到的<code>Softmax</code>是一个是<code>Logistic</code>模型上的一个扩展，可以轻松的完成多分类任务，它是一个有监督的学习，不过可以和相当热门的神经网络可以轻松结合起来.</p>
<h2 id="Logistic回顾">Logistic回顾</h2><p><code>Logistic</code>模型是一个非常基础而又高效的<code>二分类</code>模型，并且由于其最终值会归一化到0~1，因此也很多场景下也会作为<code>回归</code>模型使用，比如<code>ctr预估</code>。<br><code>Logistic</code>的输入数据是<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>其中$x^i$为输入的特征向量，$y^i$即为要训练的目标，在<code>二分类</code>中，一般$y^i \in \{0,1\}$，则<code>Logistic</code>的算分函数为<br>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^Tx}}$$</p>
<p>使用最大似然法进行参数估计,其似然函数为<br>$$\prod h_{\theta}(x^i)^{y^i} \times (1-h_{\theta}(x^i))^{(1-y^i)}$$</p>
<p>对其进行负的对数转换之后则最终的损失函数为<br>$$ J(\theta) = -\frac{1}{m} \sum_{i=1}^m \left [ y^i \text{log}h_{\theta}(x^i) + (1-y^i)\text{log}(1-h_{\theta}(x^i)) \right ]    $$</p>
<p>在<code>Logistic</code>模型中我们可以发现我们最终需要求的是$\theta$向量.</p>
<h2 id="Softmax_模型">Softmax 模型</h2><p>在<code>Softmax</code>模型中，其输入也是类似向量的设计<br>    $$\{(x^1,y^1),(x^2,y^2)…(x^m,y^m)\}$$</p>
<p>只是这个的$y^i \in \{1,2,…k\}$有$k$个类别，而最终要求的应该是这个值<br>$$P(y=k_j | x)$$<br>也就是类别$k_j$可能的概率，也就是会形成一个$k$维的输出<br>$$<br>h_{\theta}(x^i)=\begin{bmatrix} P(y^i=1|\theta_1,x_i)<br>\\ P(y^i=2|\theta_2,x_i)<br>\\ …<br>\\ P(y^i=k|\theta_k,x_i)<br>\end{bmatrix}<br>=<br>\frac{1}{\sum_{s=1}^k e^{\theta_s^Tx_i}}<br>\begin{bmatrix} e^{\theta_1^Tx_i}<br>\\ e^{\theta_2^Tx_i}<br>\\ …<br>\\ e^{\theta_k^Tx_i}<br>\end{bmatrix}<br>$$</p>
<p>则我们整个模型最终要求的是一个$\theta$<code>矩阵</code>(注意,在<code>Logistic</code>中求是一个向量),矩阵的每一行$\theta_i$其实就是与输入参数$x$相乘的向量~</p>
<blockquote>
<p>注意:分子$\frac{1}{\sum_{s=1}^k e^{\theta_s^Tx_i}}$是为了让最终所有类别的概率之和为<code>1</code></p>
</blockquote>
<p>每个类别j的概率为:<br>$$p_j=\frac{e^{\theta_j^Tx}}{\sum_{s=1}^k e^{\theta_s^Tx}}$$</p>
<h2 id="Softmax的损失函数">Softmax的损失函数</h2><p>同样,<code>Softmax</code>使用最大似然法进行参数的估计,则似然函数为<br>$$\prod_i^m \prod_{j=1}^k p_j^{I\{y^i = k_j\}}$$</p>
<blockquote>
<p>其中$I\{y^i = k_j\}$为二值函数，当且仅当$y^i == k_j$时为1，否则为0</p>
</blockquote>
<p>对其<code>取负的对数</code>可以得到其损失函数:<br>$$J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \text{log} p_j \right]$$</p>
<p>假设我们使用梯度下降法对损失函数进行优化，因此对$\theta$进行求导,在求导之前先算下面这个:<br>$$ \frac{\delta p_j}{\delta \theta_i}=\left\{<br>\begin{aligned}<br>\frac{\frac{e^{\theta_j^Tx}}{\delta \theta_{\color{Red} j}}\sum_{s=1}^k e^{\theta_s^Tx}-\frac{\sum_{s=1}^k e^{\theta_s^Tx}}{\delta \theta_{\color{Red} j}}e^{\theta_j^Tx}}{(\sum_{s=1}^k e^{\theta_s^Tx})^2} &amp;= x p_j(1-p_j)  &amp; \quad if i=j \\<br>\frac{\frac{e^{\theta_j^Tx}}{\delta \theta_{\color{Red} i}}\sum_{s=1}^k e^{\theta_s^Tx}-\frac{\sum_{s=1}^k e^{\theta_s^Tx}}{\delta \theta_{\color{Red} i}}e^{\theta_j^Tx}}{(\sum_{s=1}^k e^{\theta_s^Tx})^2} &amp;= x p_ip_j &amp; \quad if i \neq j\\<br>\end{aligned}<br>\right.$$</p>
<p>有了上面的基础之后，我们对于$J(\theta)$进行求导，就可以得到如下的梯度:</p>
<p>$$\begin{equation}\begin{split} \triangledown_{\theta_j}J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k I\{y^i = k_j\} \frac{1}{p_j} \frac{\delta p_j}{\delta \theta_j  }  \right]\\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \left ( I\{y^i = k_i\} \frac{1}{p_i} x^i p_i(1-p_i) -  \sum_{j=1,j \neq i}^k I\{y^i = k_j\} \frac{1}{p_j} x^i p_i p_j \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_i\} (1-p_i) -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} i}\} - I\{y^i = k_i\}p_i -   \sum_{j=1,j \neq i}^k I\{y^i = k_j\}  p_i \right )  \right ] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_{\color{Red} j}\} -  \sum_{j=1}^k I\{y^i = k_j\} p_i \right )  \right ]  \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m x^i \left ( I\{y^i = k_j\} - p_i \right )  \right ]<br>\end{split}\end{equation}$$</p>
<p>注意有:</p>
<ul>
<li>$\sum_{j=1}^k I\{y^i = k_j\} = 1 $ ,因为样本必定会落到一个类别上</li>
<li>同时上面式子里面红色的${\color{Red} j}$是因为左侧分离出来,其中分离的条件是$i=j$</li>
</ul>
<p>上面的梯度最终将会是一个向量的形式,$\frac{\delta J(\theta)}{\delta \theta_{j,l}}$表示第$j$的类别的第$l$个特征的梯度方式，有了该梯度了之后，最终可以得到如下的参数更新:<br>$$\theta_j = \theta_j - \alpha \triangledown_{\theta_j}J(\theta) \quad j \in \{1,…k\}$$</p>
<p>到了这一步，整体看到就和二分类的<code>Logistic</code>很像了，上面是使用梯度下降法的求解，当然还可以使用类似<code>L-BFGS</code>算法进行优化~<br>另外关于其<code>L1</code>和<code>L2</code>的正则项也是可以参考<code>Logistic</code></p>
<h2 id="Softmax与Logistic的联系">Softmax与Logistic的联系</h2><p>在<code>Softmax</code>的$k=2$时(其实就是二分类了)，再来观察<code>Softmax</code>的一些式子</p>
<h3 id="算分函数">算分函数</h3><p>$$\begin{equation}\begin{split} h_\theta(x^i) &amp;= \frac{1}{e^{\theta_1^Tx_i}+e^{\theta_2^Tx_i}}<br>\begin{bmatrix} e^{\theta_1^Tx_i}<br>\\ e^{\theta_2^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \frac{1}{e^{(\theta_1-\theta_1)^Tx_i}+e^{(\theta_2-\theta_1)^Tx_i}}<br>\begin{bmatrix} e^{(\theta_1-\theta_1)^Tx_i}<br>\\ e^{(\theta_2-\theta_1)^Tx_i}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\\ \frac{e^{(\theta_2-\theta_1)^Tx_i}}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>&amp;= \begin{bmatrix}  \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\\ 1- \frac{1}{1+e^{(\theta_2-\theta_1)^Tx_i}}<br>\end{bmatrix} \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>在上面第一到第二步减去$\theta_1$任成立的原因是，<code>Softmax</code>的参数过多，是一个大矩阵，里面存在着冗余的参数:<br>$$\begin{equation}\begin{split} h_{\theta_j}(x^i) &amp;= \frac{e^{\theta_jx^i}}{\sum_{s=1}^k e^{\theta_sx^i}} \\<br>&amp;= \frac{e^{(\theta_j-\phi)x^i}}{\sum_{s=1}^k e^{(\theta_s-\phi)x^i}} \\<br>&amp;= \frac{e^{\theta_jx^i}e^{-\phi x^i}}{\sum_{s=1}^k e^{\theta_sx^i}e^{-\phi x^i}} \\<br>&amp;= \frac{e^{\theta_jx^i}}{\sum_{s=1}^k e^{\theta_sx^i}}<br>\end{split}\end{equation}$$<br>因此，参数矩阵中减去同一个<code>向量</code>并不会影响最终的优化结果~关于参数过度化问题可以参考<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">这里</a></p>
</blockquote>
<p>所以当$k=2$时<code>Softmax</code>的算分函数其实就是<code>Logistic</code>的变形~</p>
<h3 id="损失函数">损失函数</h3><p><code>Softmax</code>的损失函数为<br>$$\begin{equation}\begin{split} J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^2 I\{y^i = k_j\} \text{log} p_j \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + I\{y^i = k_2\} \text{log} p_2  \right] \\<br>&amp;= -\frac{1}{m} \left[ \sum_{i=1}^m  I\{y^i = k_1\} \text{log} p_1 + (1-I\{y^i = k_1\}) \text{log} (1-p_1)  \right]  \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>因为:$I\{y^i = k_1\} + I\{y^i = k_2\}  =1$ 以及 $p_1+p_2=1$</p>
</blockquote>
<p>最终也就变成了<code>Logistic</code>的损失函数形式了</p>
<h2 id="总结">总结</h2><ol>
<li><code>Softmax</code>模型其实是<code>Logistic</code>对于多分类上面的扩展</li>
<li><code>Softmax</code>最终产出的每一类的概率之和为1</li>
<li><code>Softmax</code>其实并不是一个损失函数（因为看到很多文章中都会很自然的写道<code>Softmax损失函数</code>）,它自己求优化时还是使用者交叉熵的这一套</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92#Softmax.E5.9B.9E.E5.BD.92.E6.A8.A1.E5.9E.8B.E5.8F.82.E6.95.B0.E5.8C.96.E7.9A.84.E7.89.B9.E7.82.B9" target="_blank" rel="external">Softmax回归 ufldl</a><blockquote>
<p>文本大致组织按这个参考来的，因为它写的实在太好了，自己在造一遍轮子，以便记忆^_^</p>
</blockquote>
</li>
<li><a href="http://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function" target="_blank" rel="external">Derivative of Softmax loss function</a></li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Softmax_介绍">Softmax 介绍</h2><p>多分类是机器学习中一类非常常见的任务，比如将0~9某个字写到图片上，使用多分类的方法来识别这个图片上写的到底是几(<code>MNIST手写体识别</code>)，对于多分类任务常用的机器学习方法有:</p>
<ol>
<li>借助<code>二分类</code>，使用<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-All">One vs All</a>或者<a href="http://kubicode.me/2015/08/30/Machine%20Learning/Multiclass-Classification/#One-Vs-One">One vs One</a>来完成多分类</li>
<li>使用<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/#朴素贝叶斯">朴素贝叶斯</a>来完成多分类</li>
<li>决策树类模型~</li>
<li><a href="http://kubicode.me/2016/12/12/Machine%20Learning/Maximum-Entropy-Model/">最大熵模型</a></li>
<li>。。。</li>
</ol>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用点击图来计算Query-Doc的文本相关性]]></title>
    <link href="http://kubicode.me/2016/11/03/Search%20Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/"/>
    <id>http://kubicode.me/2016/11/03/Search Engine/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/</id>
    <published>2016-11-03T12:07:18.000Z</published>
    <updated>2016-11-07T01:59:53.000Z</updated>
    <content type="html"><![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br><a id="more"></a></p>
</blockquote>
<h2 id="已有点击行为的向量计算">已有点击行为的向量计算</h2><p>在搜索场景下用户输入query，对搜索的结果进行点击反馈，将所有用户的搜索行为收集起来之后可以形成一张大的<code>Click-Graph</code>，为了简单，我们使用二部分来表示，其中左侧为$Query$，右侧为$Doc$，如果$q_i$到$d_j$存在点击行为，则左右侧将会有一条边连接，连上的权重及<code>点击的次数</code></p>
<center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/co-click-graph.png" width="400px"></center>

<p>现在假设语料的长度为$V$,则$Query$构成的矩阵为$|Query| \times V$，以及$Doc$构成的矩阵为$|Doc| \times V$，那么现在的任务就是如何计算这两个矩阵!</p>
<blockquote>
<p>其实这个语料就是上面所说道的$Query$和$Doc$同处的向量空间,一般值$Query$里面抠出来的<code>Term</code>或者$Doc$里面的<code>title</code>/<code>content</code>抠出来的<code>term</code>.</p>
</blockquote>
<p>这里使用的是<code>向量传播</code>来对$Query$和$Doc$进行计算，计算之前有这么这个假设:</p>
<ol>
<li><code>点击二部图</code>上的边连接的$q_i$和$d_i$是有相关性的(或者说有较高的相关性)</li>
<li>$q_i$上的<code>term</code>与$d_i$上的<code>title</code>/<code>content</code>的<code>term</code>应该是存在联系的</li>
</ol>
<p>目前暂不考虑缺少行为的$Query$和$Doc$，向量传播模型的步骤为:</p>
<ol>
<li>随意选择一侧进行向量初始化（$Query$和$Doc$端均可），我们使用$Query$向量来进行初始化$Q_i^0$,其中$Q_i^0$使用<code>one-hot</code>来表示，同时用$L2$进行归一化<blockquote>
<p>$i$表示第$Query$中的第$i$个,$0$表示第1次迭代（也就是初始化~）</p>
</blockquote>
</li>
<li>则第$D_j^n$个值($n&gt;=1$)的更新根据被点击$Query$的向量进行加权求和即可:<br> $$D_j^n=\frac{1}{||\sum_{i=1}^{|Query|}C_{i,j} \cdot Q_i^{n-1}||_2} \sum_{i=1}^{Query}C_{i,j} \cdot Q_i^{n-1}$$<blockquote>
<p>其中$Q_i^n$就是上一次迭代的$Query$向量，同样$D_j^n$也会进行一个$L2$正则化。</p>
</blockquote>
</li>
<li>$Doc$的向量表示进行了一次迭代更新之后继续更新$Query$的向量，这里是根据$Query$下公共点击的文档信息进行更新，其方式与$Doc$的更新是一样的:<br> $$Q_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}C_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}C_{i,j} \cdot D_i^{n-1}$$</li>
<li>按<code>2</code>、<code>3</code>的步骤不断进行迭代，直至收敛，其产出的$Query$的$Doc$的向量就都在一个空间内，同时还可以计算相似度/相关性</li>
</ol>
<p>这里以上的图为例再说一下计算过程:</p>
<ol>
<li>初始化$Query$的向量:<ul>
<li>$Q_1:\{yahoo:\frac{1}{\sqrt{2}},finance:\frac{1}{\sqrt{2}},mail:0\}$</li>
<li>$Q_2:\{yahoo:1,finance:0,mail:0\}$</li>
<li>$Q_3:\{yahoo:\frac{1}{\sqrt{2}},finance:0,mail:\frac{1}{\sqrt{2}}\}$<blockquote>
<p>因为图中$Query$的语料三个<code>term</code>，所以这里初始化为3维.</p>
</blockquote>
</li>
</ul>
</li>
<li>根据上一次$Query$的迭代信息以及与$Doc$的点击信息来更新$Doc$的向量:<ul>
<li>$D_1=\frac{(\frac{3}{8}Q_1 + \frac{5}{8}Q_2)}{||\frac{3}{8}Q_1 + \frac{5}{8}Q_2||_2}$</li>
<li>$D_2=\frac{(\frac{1}{5}Q_2 + \frac{4}{5}Q_3)}{||\frac{1}{5}Q_2 + \frac{4}{5}Q_3||_2}$</li>
</ul>
</li>
<li>然后就是不断的迭代就行了，这样已经很清晰了</li>
</ol>
<p>了解过一些信息检索或者链接分析的朋友可能会马上想到，咦~这好像<code>Hits</code>这个算法。的确是的，在计算过程中极为相似，不过<code>Hits</code>权重主要是计算<code>Hubs</code>与<code>Authority</code>两端的权重，而[1]中迭代完得到的是各个向量，有异曲同工之妙~<br>另外在实际的query量级一般都是百万以上，这样$Query$的语料的量就很大了,而搜索引擎中需要计算的性能要求极高，，所以一般进行稀疏存储，并且只取一些重要的<code>term</code>来对$Query$进行表示</p>
<h2 id="缺少点击行为的向量计算">缺少点击行为的向量计算</h2><p>但是实际应用中用户搜索之后带来了点击行为的只是一小部分就，如果仅按照上述点击传播的方式来计算的话无query点击的文档将会将会无法得到正常的向量，同时一些新的$\hat{Query}$（从未有用户搜索过的query）也就无法得到正常的向量数据，所以需要一种对于这种缺失行为的$\hat{Query}$和$\hat{Doc}$进行向量表示估计.</p>
<p>由于在线计算相关性时对于已有行为的$Query-Doc$和缺失行为的是一视同仁的，因此为了在线计算时不应该因为训练数据产生偏差，所以需要与已有行为的$Qeury-Doc$向量在同一个空间内，同时考虑已有行为的$Query$和$Doc$的向量均已计算得到，我们还借助这些数据来预估缺失行为的向量.</p>
<h3 id="提取Unit向量">提取Unit向量</h3><p>既然未行为的$\hat{Query}$与$\hat{Doc}$之间没有任何边向量，那我们可以通过有行为的$Query$进行造边，先将$\hat{Query}$分解为各种<code>Unit</code>，这样就有$u_i \in unit(q_i)$,如果存在$Query$含有$u_i$，则将$u_i$对对应的$Query$之间形成一条虚拟的边,同时称含有$u_i$的所有$Query$的集合为$O_{u_i}$</p>
<blockquote>
<p>这里分解时可以按<code>n-gram</code>进行分解，但是某个$Query$进行分解之后不能有<code>overlap</code></p>
</blockquote>
<p><center><img src="/img/Learning-Query-And-Document-Relevanec-from-a-Web-scale-Click-Graph/absent_graph.png" width="700px"></center><br>这种边的构建方式如上图，$q_1$、$q_2$和$q_3$均都包含了<code>yahoo</code>这个词，则在他们之间形成这条虚线的边。<br>接下来我们可以理解$Query-Doc$之间的向量传播方法，我们当然也可以完成$Unit-Doc$的传播.<br>$u_i$会有$q_i$有边相连，而$q_i$与$d_i$又有变相连，因此我们可以间接认为$u_i$与$d_i$也是有边相连。<br>现假设$q_k$包含了$u_i$，同时$q_k$与$d_j$存在点击行为，$P_{i,k,j}$表示为这个二折线的权重，则该权重其实为$q_k$与$d_j$的点击次数，那么我们就会有<br>$$P_{i,j} = \sum_{k=1}^{|O_{u_i}|} P_{i,k,j}$$<br>其演示就是上图的右侧部分，<code>yahoo</code>与$d_1$之间的权重为8，与$d_2$之间的权重为5，既然到了这一步，我们就可以按照上一小节的传播方式来计算,这样就可以巧妙的得到$U_i$的向量:<br>$$U_i^n=\frac{1}{||\sum_{i=1}^{|Doc|}P_{i,j} \cdot D_i^{n-1}||_2} \sum_{i=1}^{Doc}P_{i,j} \cdot D_i^{n-1}$$</p>
<p>上面得到的是关于$\hat{Query}$上<code>unit</code>的向量，同样的我们也可以从$\hat{Doc}$这一侧出发，来计算$\hat{Doc}$<br>相关的<code>unit</code></p>
<h3 id="计算Unit向量权重">计算Unit向量权重</h3><p>有了<code>unit</code>的向量之后，接下来要解决的问题就是如何得到$\hat{Query}$或者$\hat{Doc}$的向量了，其实最简单的方法就是将他们各自的<code>unit</code>进行平均即可,不过[1]使用线性回来来解决该权重问题，在进行权重训练时使用最小平方差:<br>$$\underset{w}{min} \sum_{i=1}^{|T|} || T_i-\sum_{u_j \in U_{T_i}^{all}} W_j \cdot U_j||_2^2$$</p>
<blockquote>
<p>$T_i$是使用有点击行为的$Query$计算得到的向量，也就是我们所认为的<code>gold-set</code><br>这样求出来的$W$就是各个$unit_i$不同的权重</p>
</blockquote>
<h3 id="预估向量">预估向量</h3><p>根据上面两个步骤得到的<code>unit</code>的向量和权重之后，得到整体的$\hat{Query}$或者$\hat{Doc}$就很方便了，由于<code>unit</code>本身就是$\hat{Query}$或者$\hat{Doc}$分解出来的，这里基础数据也都已经计算完成了，所以直接进行加权求和即可:<br>$$q_v=\sum_{u_i \in u_q} W_iU_i$$<br>和<br>$$d_v=\sum_{u_i \in u_d} W_iU_i$$</p>
<p>这样一来缺失形式的向量数据也都可以计算出来了</p>
<h2 id="总结">总结</h2><p>该方法成功的借助了点击日志对于相关性进行估计（其实我觉得这种方式得到的文本相关性与ctr的预估会有部分重叠了），并且在实现上:</p>
<ol>
<li>已有点击数据的$Query$和$Doc$的向量直接离线就按完成</li>
<li>缺失点击的$\hat{Query}$和$\hat{Doc}$可以利用离线计算的<code>unit</code>向量在线直接进行加权求和即可</li>
<li>对于在线存储均使用稀疏方式并只存<code>top-k</code>，因此存储并不是问题</li>
<li>在线计算相关性可以直接按相似度计算，复杂度为$k log k$所以并不是很高~</li>
</ol>
<p>可实现性还是比较强的，但是对于一些未登录词就无能为力了….</p>
<blockquote>
<p>关于改算法的最终实现结果去看paper吧，效果自然是还可以的</p>
</blockquote>
<p>看了这篇paper，其实还是有点其他启发:</p>
<ol>
<li>如果搜索了query之后对于未点击的文档是不是可以进行降权（因为点击的文档是进行加权的）</li>
<li>再想想，~其实直接使用来计算文本相关性风险还是挺大</li>
</ol>
<h2 id="参考">参考</h2><ol>
<li>2016-Learning Query and Document Relevance from a Web-scale Click Graph</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="文本相关性">文本相关性</h2><p>在信息检索中文本相关性是排序因子中非常重要的一个特征，大部分的文本相关性特征是直接根据<code>query</code>和<code>doc</code>上的<code>term</code>进行各种匹配、各种计算得到的， 比如<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>,今天看到参考[1]这篇paper，提到了可以将点击日志构成二部图,根据二部分进行向量传播，最终收敛之后进行文本相关性的计算，也算是比较新颖了，下文就主要是对该paper的一个学习以及自己理解的记录。<br>该paper提出的三个贡献:</p>
<ol>
<li>可以使<code>query</code>和<code>doc</code>在同一空间上生成词向量考虑</li>
<li>对于未曾有点击行为的<code>query</code>和<code>doc</code>也可以进行该空间词向量的估计</li>
<li>最终计算的效率较高，可以用于商业的搜索引擎</li>
</ol>
<blockquote>
<p>如果已知了<code>query</code>和<code>doc</code>在同一空间上的向量表示，这样文本相关性就可以直接使用相似度的计算方式来得到了~<br>]]>
    
    </summary>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/categories/Search-Engine/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[语言模型在信息检索中的平滑方法]]></title>
    <link href="http://kubicode.me/2016/10/24/Machine%20Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/"/>
    <id>http://kubicode.me/2016/10/24/Machine Learning/A-Study-of-Smoothing-Methods-for-Language-Models-Applied-to-Information-Retrieval/</id>
    <published>2016-10-24T11:58:01.000Z</published>
    <updated>2016-11-05T16:33:15.000Z</updated>
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br><a id="more"></a><br>由于在给定$q$下，不同文档的$p(q)$是一样的，这里关注的是排序，所以可以直接将$p(q)$进行移除，另外式子右侧的$p(d)$为文档$d$对于任何$q$的相关性先验，在$p(q|d)$就是在给定$d$下生成$q$的概率，也就是文档$d$到$q$的匹配程度.<br>为了简单起见，我们假设$p(d)$是均匀分布的，这样的话$p(d)$就不会影响排序，那么信息检索的问题就会转为一个一元语言模型:<br>$$p(q|d) = \prod_i p(q_i|d)$$<br>大多数平滑的方法都会使用两类分布:</p>
<ol>
<li>一类是对于在文档中出现的词的模型$p_s(w|d)$</li>
<li>另一个是没有出现在文档中的词的模型$p_u(w|d)$</li>
</ol>
<p>这样的话在一个$q$中根据词在文档中的出现与否可以写为:<br>$$\begin{equation}\begin{split}log p(q|d)&amp;= \sum_i log p(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i;d)&gt;0} log p_s(q_i|d) - \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i;d)&gt;0} log p_u(q_i|d) + \sum_{i:c(q_i|d)=0} log p_u(q_i|d) \\<br>&amp;= \sum_{i:c(q_i|d)&gt;0} log \frac{p_s(q_i|d)}{p_u(q_i|d)} + \sum_i log p_u(q_i|d) \\<br>\end{split}\end{equation}$$</p>
<p>其中未在文档中出现的词的概率典型的表示方法就是该词在所有集合中出现的频率:<br>$$p_u(q_i|d) = \alpha_d p(q_i|C)$$</p>
<blockquote>
<p>其中$\alpha_d$为独立于文档的一个常量，$p(q_i|C)$为集合中的语言模型，这样我们就会有</p>
</blockquote>
<p>$$log p(q|d) = \sum_{i:c(q_i:d)&gt;0} log \frac{p_s(q_i|d)}{\alpha_d p(q_i|C)} + n log \alpha_d + \sum_i log p(q_i|C)$$</p>
<blockquote>
<p>其中$n$为$q$的长度，上面式子的右侧与$d$并没有关系，所以直接去掉也不会影响排序</p>
</blockquote>
<p>这样的话检索函数就变成了两部分，第一部分为$q$与$d$相匹配<code>term</code>的权重，第二部分为与$q$无关的一个常量，一般是用于对非匹配<code>term</code>的平滑。</p>
<p>这时候再看下第一部分，其实可以上面$p(q_i|C)$大致可以看为<code>IDF</code>,而$p_s(q_i|d)$又非常向tf,因为上面的Language Model与<code>tf*idf</code>路线还是挺像的。</p>
<h2 id="Smoothing_Methods">Smoothing Methods</h2><p>看了上面的描述，接下来主要讲一下对于$p(w|d)$的估计，最简单的使用数数的方式，最大似然法进行估计为:<br>$$p_{ml}(w|d) = \frac{w;d}{\sum_w c(w;d)}$$</p>
<blockquote>
<p>其实就是词在文档中出现的频率</p>
</blockquote>
<p>这种方式对于没出现在文档中的词将会低估（其实就是没值了），因为对于没有在文档中出现的词会给予一个非0概率的平滑。<br>通常我们会对出现在文档中的词的概率进行一个折损，同时对于未出现在文档中的词的概率给予一个额外的值:<br>$$ p(w|d)=\left\{<br>\begin{aligned}<br>p_s(w|d) &amp; \quad if \quad word \quad w \quad is \quad seen \\<br>\alpha_d p(w|C) &amp; \quad otherwise\\<br>\end{aligned}<br>\right.$$</p>
<p>同时$\alpha_d$将会依赖$d$，如果$p(w|d)$给定的情况下，我们将会有:<br>$$\alpha_d = \frac{1-\sum_{w:c(w:d)&gt;0} p_s(w|d)}{1-\sum_{w:c(w:d)&gt;0}p(w|C)}$$</p>
<p>因此这里最大的问题是需要计算$p_s(w|d)$,因为在信息检索中对于性能的要求将其高，因此为考虑性能和效果，下面主要简单的介绍三种平滑方式</p>
<h3 id="Jelinek-Mercer">Jelinek-Mercer</h3><p>这种方式是融合了最大似然发以及一个置信因子来控制各个模型<br>$$p_{\lambda} = (1-\lambda)p_{ml}(w|d) + \lambda p(w|C)$$</p>
<blockquote>
<p>这种方式非常的高效</p>
</blockquote>
<h3 id="Dirichlet">Dirichlet</h3><p>他其实是贝叶斯平滑，然后使用了<code>Dirichlet</code>先验，使用这种可以得到<br>$$p_{\mu}(w|d) = \frac{c(w;d) + \mu p(w|C)}{\sum_w c(w;d)+ \mu}$$</p>
<h3 id="Absolute_discount">Absolute discount</h3><p>这种方式主要是通过降低可见词的概率来完成的,类似<code>Jelinek-Mercer</code>方法,与$1-\lambda$不同的是  使用减去一个常量来完成:<br>$$p_{\delta } = \frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \sigma p(w|C)$$</p>
<blockquote>
<p>其中$\delta \in [0,1]$,为一个折损常量，$\sigma = \delta|d|_u/|d|$,所以所有的概率之和为1，$|d|_u$为文档中不同<code>term</code>的数量,$|d|$为文档中<code>term</code>的总数量</p>
</blockquote>
<p>另外注意$max(c(w:d)-\delta,0)$中的$c(w:d)$应该是归一化0~1了，这样才可以和$\delta$相减</p>
<p>对于这三种平滑方式的一个表格表示（非常清晰）:</p>
<table>
<thead>
<tr>
<th style="text-align:center">平滑方法</th>
<th style="text-align:center">$p_s(w &#124; d)$</th>
<th style="text-align:center">$\alpha_d$</th>
<th style="text-align:center">参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Jelinek-Mercer</code></td>
<td style="text-align:center">$(1-\lambda)p_{ml}(w &#124; d) + \lambda p(w &#124; C)$</td>
<td style="text-align:center">$\lambda$</td>
<td style="text-align:center">$\lambda$</td>
</tr>
<tr>
<td style="text-align:center"><code>Dirichlet</code></td>
<td style="text-align:center">$\frac{c(w;d) + \mu p(w &#124; C)}{\sum_w c(w;d)+ \mu}$</td>
<td style="text-align:center">$\frac{\mu}{\sum_w c(w;d)+\mu}$</td>
<td style="text-align:center">$\mu$</td>
</tr>
<tr>
<td style="text-align:center"><code>Absolute discount</code></td>
<td style="text-align:center">$\frac{max(c(w:d)-\delta,0)}{\sum_w c(w:d)} + \frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} p(w &#124; C)$</td>
<td style="text-align:center">$\frac{\delta &#124; d &#124; _{u}}{ &#124; d &#124;} $</td>
<td style="text-align:center">$\delta$</td>
</tr>
</tbody>
</table>
<p>看上面三种平滑的计算方式都是非常的简单，并且$\alpha$都是可以离线计算，其最终的复杂度为$O(k|q|)$,$k为文档的平均长度$</p>
<blockquote>
<p>其实复杂度不用这么多，如果在线查找term时使用二分的话  复杂度仅为$O(log(k)|q|)$</p>
</blockquote>
<h2 id="总结">总结</h2><p>这三种方法比较经典，并且可实现性强，$p_s(w|d)$和$\alpha_d$全部都可以离线计算完成，在线只需要进行简单的求和即可,值得一试~</p>
<h2 id="参考">参考</h2><ol>
<li>Zhai, Chengxiang, and John Lafferty. “A study of smoothing methods for language models applied to ad hoc information retrieval.” Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2001.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="引言">引言</h2><p>在信息检索中文本相关性计算是至关重要的一个特征，关于文本相关性计算时用的比较多的有:<code>词频/频率</code>、<code>tf/idf/tf*idf</code>、<code>bm25</code>、<code>布尔模型</code>、<code>空间向量模型</code>以及<code>语言模型</code>，本文主要是对于<code>[1]</code>的一些学习理解，虽然<code>[1]</code>历史久远，但是可行性高，同时目前也有不少搜索引擎在使用<code>[1]</code>的方法，主要介绍的是语言模型在信息检索中使用的平滑方法，主要侧重点就是性能。</p>
<h2 id="Language_Model">Language Model</h2><p>现假设<code>query</code>是基于文档<code>d</code>进行生成的,那么给定一个<code>query</code>$q=q_1q_2..q_n$以及一个文档$d=d_1d_2…d_n$,我们比较关心的是$p(d|q)$这个条件概率，即在观察到$q$的情况下生成$d$的一个概率，假设文档中的词是相关独立的，根据贝叶斯公式，则有:<br>$$p(d|q) \propto p(q|d)p(d)$$<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Python画ROC曲线以及AUC值]]></title>
    <link href="http://kubicode.me/2016/09/19/Machine%20Learning/AUC-Calculation-by-Python/"/>
    <id>http://kubicode.me/2016/09/19/Machine Learning/AUC-Calculation-by-Python/</id>
    <published>2016-09-18T16:02:43.000Z</published>
    <updated>2016-09-18T16:39:41.000Z</updated>
    <content type="html"><![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/" target="_blank" rel="external">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br><a id="more"></a></p>
<h2 id="AUC计算">AUC计算</h2><p><code>AUC</code>的计算分为下面三个步骤：</p>
<ol>
<li>计算数据的准备，如果模型训练时只有训练集的话一般使用交叉验证的方式来计算，如果有评估集(<code>evaluate</code>)一般就可以直接计算了，数据的格式一般就是需要预测得分以及其目标类别（注意是目标类别，不是预测得到的类别）</li>
<li>根据阈值划分得到横（X:<code>False Positive Rate</code>）以及纵（Y:<code>True Positive Rate</code>）点</li>
<li>将坐标点连成曲线之后计算其曲线下面积,就是<code>AUC</code>的值</li>
</ol>
<p>直接上python代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! -*- coding=utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log,exp,sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluate_result=<span class="string">"you file path"</span></span><br><span class="line">db = []  <span class="comment">#[score,nonclk,clk]</span></span><br><span class="line">pos, neg = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">with</span> open(evaluate_result,<span class="string">'r'</span>) <span class="keyword">as</span> fs:</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">		nonclk,clk,score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		nonclk = int(nonclk)</span><br><span class="line">		clk = int(clk)</span><br><span class="line">		score = float(score)</span><br><span class="line">		db.append([score,nonclk,clk])</span><br><span class="line">		pos += clk</span><br><span class="line">		neg += nonclk</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">db = sorted(db, key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算ROC坐标点</span></span><br><span class="line">xy_arr = []</span><br><span class="line">tp, fp = <span class="number">0.</span>, <span class="number">0.</span>			</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(db)):</span><br><span class="line">	tp += db[i][<span class="number">2</span>]</span><br><span class="line">	fp += db[i][<span class="number">1</span>]</span><br><span class="line">	xy_arr.append([fp/neg,tp/pos])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算曲线下面积</span></span><br><span class="line">auc = <span class="number">0.</span>			</span><br><span class="line">prev_x = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> xy_arr:</span><br><span class="line">	<span class="keyword">if</span> x != prev_x:</span><br><span class="line">		auc += (x - prev_x) * y</span><br><span class="line">		prev_x = x</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"the auc is %s."</span>%auc</span><br><span class="line"></span><br><span class="line">x = [_v[<span class="number">0</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">y = [_v[<span class="number">1</span>] <span class="keyword">for</span> _v <span class="keyword">in</span> xy_arr]</span><br><span class="line">pl.title(<span class="string">"ROC curve of %s (AUC = %.4f)"</span> % (<span class="string">'svm'</span>,auc))</span><br><span class="line">pl.xlabel(<span class="string">"False Positive Rate"</span>)</span><br><span class="line">pl.ylabel(<span class="string">"True Positive Rate"</span>)</span><br><span class="line">pl.plot(x, y)<span class="comment"># use pylab to plot x and y</span></span><br><span class="line">pl.show()<span class="comment"># show the plot on the screen</span></span><br></pre></td></tr></table></figure></p>
<p>输入的数据集可以参考<a href="/img/AUC-Calculation-by-Python/evaluate_result.txt">svm预测结果</a><br>其格式为:</p>
<pre><code>nonclk <span class="string">\t</span> clk <span class="string">\t</span> score
</code></pre><p>其中：</p>
<ol>
<li><code>nonclick</code>:未点击的数据，可以看做负样本的数量</li>
<li><code>clk</code>:点击的数量，可以看做正样本的数量</li>
<li><code>score</code>:预测的分数，以该分数为group进行正负样本的预统计可以减少<code>AUC</code>的计算量</li>
</ol>
<p>运行的结果为:</p>
<center><img src="/img/AUC-Calculation-by-Python/auc.png" width="500px"></center>


<blockquote>
<p>如果本机没安装<code>pylab</code>可以直接注释依赖以及画图部分</p>
</blockquote>
<h2 id="注意">注意</h2><p>上面贴的代码:</p>
<ol>
<li>只能计算二分类的结果（至于二分类的标签随便处理）</li>
<li>上面代码中每个<code>score</code>都做了一次阈值，其实这样效率是相当低的，可以对样本进行采样或者在计算横轴坐标时进行等分计算</li>
</ol>
<h2 id="参考">参考</h2><ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm" target="_blank" rel="external">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#roc_curve_for_binary_svm</a></li>
</ul>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="AUC介绍">AUC介绍</h2><p><code>AUC</code>(Area Under Curve)是机器学习二分类模型中非常常用的评估指标，相比于<code>F1-Score</code>对项目的不平衡有更大的容忍性，目前常见的机器学习库中(比如<a href="http://scikit-learn.org/stable/">scikit-learn</a>)一般也都是集成该指标的计算，其计算原理可以参考这个<a href="https://www.douban.com/note/284051363/?type=like">ROC和AUC介绍以及如何计算AUC
</a>，但是有时候模型是单独的或者自己编写的，此时想要评估训练模型的好坏就得自己搞一个<code>AUC</code>计算模块，本文在查询资料时发现<code>libsvm-tools</code><sup>1</sup>有一个非常通俗易懂的<code>auc</code>计算，因此抠出来用作日后之用。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LambdaRank-支持非平滑损失函数的学习排序算法]]></title>
    <link href="http://kubicode.me/2016/08/28/Machine%20Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/"/>
    <id>http://kubicode.me/2016/08/28/Machine Learning/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/</id>
    <published>2016-08-28T14:44:59.000Z</published>
    <updated>2016-09-06T15:59:12.000Z</updated>
    <content type="html"><![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br><a id="more"></a></p>
<p><center><img src="/img/LambdaRank-Learning-to-Rank-with-Nonsmooth-Cost-Functions/rank.png" alt=""><br>图1</center><br>如图1，每个线条表示一个文档，位置越上面表示排序越靠前，其中蓝色线条表示相关的文档，灰色则是不相关的文档，计算左侧得到的<code>Pairwise Error</code>为13，此时将最上面的蓝色线条下移3个位置，将下面的蓝色线条上移5个位置，则其<code>Pairwise Error</code>下降到了11。然而传统的排序评估指标<code>NDCG</code>或者<code>ERR</code>都是比较关心靠前的位置，类似刚刚右侧的变化并不希望出现。<br>而<code>LambdaRank</code>可以支持对这种非平滑的评估指标(比如<code>NDCG</code>)进行直接的优化.</p>
<h2 id="LambdaRank原理">LambdaRank原理</h2><p>在图1右侧中，我们用$D_i$和$D_j$分别表示上下两个相关的文档，对于训练时下一次的移动中，我们更加愿意看到红色箭头的变化，因为此时$D_i$移动头部比$D_j$移动到头部明显代价更小，并且同样能减少损失函数.<br>对于$i &lt;&lt; j$这种情况($D_i$排在前面)，<code>LambdaRank</code>将会有:<br>$$|\frac{\partial C}{\partial o_i}| &gt;&gt; |\frac{\partial C}{\partial o_j}|$$</p>
<p>同时，<code>LambdaRank</code>并不是显示对的优化函数进行求导在求最优，而是<br>$$\frac{\partial C}{\partial o_i} = -\lambda_i(o_1,l_1…o_n,l_n)$$，</p>
<blockquote>
<p>$o_i$表示给定query下文档的打分值,$l_i$表示该文档对应的标签</p>
</blockquote>
<p>可以看到这个梯度是依赖<code>query</code>下全部文档的分数以及其标签,这也应该是算一个<code>ListWise</code>的学习方法了,其中式子中带了符号表示$\lambda_i$为正数时将会在排序列表中向上移动同时会降低损失函数的值.<br>那么问题来了，这个$\lambda$函数该如何选呢?</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的神经网络加速算法中，其<br>$$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} =  -\frac{1}{1+e^{o_i-o_j}} $$</p>
<blockquote>
<p>这里目标概率$\overline{P}_{i,j}=1$</p>
</blockquote>
<p><code>LambdaRank</code>的机智之处就是在计算$\lambda_{i,j}$的时候引入了优化指标的梯度,变成了<br>$$\lambda_{i,j} =  -\frac{1}{1+e^{o_i-o_j}} |\Delta Z|$$<br>其中$\Delta Z$表示将文档$D_i$和$D_j$的位置相关调换之后重新计算得到的评估指标的差值（此时其他的文档顺序是不变的）<br>即可从新计算得到$\lambda_i$为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$<br>这个$\lambda$可以理解为上面图中的箭头<code>方向和强度</code></p>
<ol>
<li>符号表示方向，正好为向上移动</li>
<li>大小表示强度，绝对值越大，表示移动的距离越大</li>
</ol>
<p>接下来<code>LambdaRank</code>具体的训练和使用方式就即可和<code>RankNet</code>一致了.</p>
<p>这个的$\Delta Z$可以替换成任何评估指标(比如<code>NDCG</code>、<code>ERR</code>)了，这样的话其实$LambdaRank$就可以变相的直接对学习排序的评估指标进行优化了，解决了之前评估指标由于是非凸无法进行优化的问题</p>
<blockquote>
<p>这个具体的证明要看去原始paper了[1],是一个不是很容易理解的东西 -_-||</p>
</blockquote>
<h2 id="总结">总结</h2><p>$LambdaRank$其实是做了两个大贡献:</p>
<ol>
<li>一是对传统的<code>RankNet</code>提出了一个加速算法（我直接将其丢了<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速" target="_blank" rel="external">RankNet</a>的学习中）</li>
<li>二是在<code>RankNet</code>的优化目标的基础上添加了一个基于评估指标的梯度$\Delta Z$因子，可以变相的直接对学习排序的评估指标进行优化</li>
</ol>
<p>虽然貌似没有见一些其他工业上说明使用了该算法，但是该算法对于鼎鼎大名的<code>LambdaMart</code>的启发无疑是最大的。</p>
<h2 id="参考">参考</h2><ol>
<li>Schölkopf, B, Platt, J, Hofmann, T. Learning to Rank with Nonsmooth Cost Functions[C]// MIT Press, 2007:193 - 200.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="为啥要有LambdaRank">为啥要有LambdaRank</h2><p>首先来看这么一个问题，机器学习一般都会有两个指标，一个叫做优化指标(Optimization Cost)，另一个叫做评测指标(Target Cost)，其中优化指标是训练时一直优化的目标，他一般都是需要连续可导（否则优化难度很大），另一个评测指标就是模型训练完了之后来评估这个模型的好坏。比如<code>SVM</code>模型的优化指标就是样本点距离分类面的距离最大化($\underset{w,b}{max} \quad \gamma$),而其评测指标一般都是准确率、F1值或者AUC等。<br>在信息检索领域其实也是这样，其排序的评测指标一般是NDCG、MAP、ERR等，但是这类指标都是非凸或者不连续，并无法直接进行优化，所以很多排序学习算法的优化一般都是都是<code>Corss Entropy</code>或者<code>MSE</code>。</p>
<p>在<a href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/#神经网络加速">RankNet</a>中优化的目标是<code>Corss Entropy</code>，他们是近似于<code>Pairwise Error</code>,但是这个评估指标并没有考虑排在靠前的文档。<br>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RankNet:基于梯度下降的学习排序]]></title>
    <link href="http://kubicode.me/2016/05/30/Machine%20Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/"/>
    <id>http://kubicode.me/2016/05/30/Machine Learning/RankNet-Learning-to-Rank-using-Gradient-Descent/</id>
    <published>2016-05-30T11:51:21.000Z</published>
    <updated>2016-09-22T17:33:19.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>
<a id="more"></a>
<p>我们现在将$P(D_i \triangleright D_j)$前后顺序的预测概率表示为$P_{i,j}$,同时定义$o_i \equiv f(x_i)$ 以及 $o_{i,j}=f(x_i)-f(x_j)$，则我们可以<code>logistic</code>函数来表示$P_{i,j}$:<br>$$P_{i,j} \equiv \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} \equiv \frac{1}{1+e^{-o_{i,j}}}$$</p>
<p>为了衡量预测概率$P_{i,j}$与期望/目标概率$\bar{P}_{i,j}$的接近程度，这里使用<code>Cross Entropy</code>作为损失函数:<br>$$C_{i,j} = -\bar{P}_{i,j} log P_{i,j} - (1-\bar{P}_{i,j}) log (1-P_{i,j})$$</p>
<p>将$P_{i,j}$代入损失函数$C_{i,j}$之后即可得到:<br>$$\begin{equation}\begin{split}C_{i,j}&amp;=-\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (1-\frac{e^{o_{i,j}}}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - (1-\bar{P}_{i,j}) log (\frac{1}{1+e^{o_{i,j}}}) \\<br>&amp;= -\bar{P}_{i,j} \left( log \frac{e^{o_{i,j}}}{1+e^{o_{i,j}}} - log (\frac{1}{1+e^{o_{i,j}}}) \right) - log (\frac{1}{1+e^{o_{i,j}}})  \\<br>&amp;= -\bar{P}_{i,j}  o_{i,j} + log(1+e^{o_{i,j}})<br>\end{split}\end{equation}$$</p>
<p>下面的图是当$\bar{P}_{i,j} \in \{0,0.5,1\}$时的损失函数情况:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/lossfunction.png" style="align:center;margin:0 auto" width="400px"></p>
<p>当$\bar{P}_{i,j} = 1$的时候，<code>Cross Entropy</code>的损失函数将会变为:$$C_{i,j}=log(1+e^{-o_{i,j}})$$<br>直接会变为一个<code>log</code>型的损失函数，其中$o_i-o_j$越大，损失函数的值也就会越小，这也是我们所期望训练的结果(表示我们的样本全部成立)</p>
<p>现我们损失函数$C_{i,j}$求$o$的偏导:<br>$$\frac{ \partial{C}}{ \partial{o_i}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) =\left( -\bar{P}_{i,j}+P_{i,j} \right) = -\frac{ \partial{C}}{ \partial{o_j}}$$</p>
<blockquote>
<p>其实可以发现就是在$-\bar{P}_{i,j}+P_{i,j}=0 $时就是我们的目标<br>另外请注意这里的$P_{i,j}$其实就是<code>文献2</code>中的$S_{i,j}$，但是由于他们的取值范围不一致 $P_{i,j} \in \{0,0.5,1\}$,$S_{i,j} \in \{-1,0,1\}$，因此导致了<code>文献2</code>中对于<code>C</code>的偏导与本文的有微小的偏差</p>
</blockquote>
<p>现我们认为$w$为$o=f(x:w)$的一个权重,也就是我们最终希望求解的值，而这个参数我们就可以使用<code>随机梯度下降法来求解</code>:<br>$$w_k \rightarrow  w_k - \eta \frac{\partial{C}}{\partial{w_k}} = w_k - \eta \left( \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}} \right)$$</p>
<p>其中$\eta$表示学习率，一般取一个比较小的数（比如:$1e-3$,$1e-5$）<br>另外我们可以求得$C$的增量变化:<br>$$\Delta C = \sum_k \frac{\partial{C}}{\partial{w_k}} \Delta w_k = \sum_k \frac{\partial{C}}{\partial{w_k}} \left( - \eta \frac{\partial{C}}{\partial{w_k}} \right) = - \eta \sum_k \left( \frac{\partial{C}}{\partial{w_k}} \right)^2  &lt; 0 $$</p>
<ol>
<li>$\Delta C &lt; 0 $表示随着权重参数$w$的沿着负梯度的变化，损失函数$C$会越来越小</li>
<li>另外当梯度$\frac{\partial{C}}{\partial{w_k}} = 0$时，才会让损失函数达到最小值</li>
</ol>
<p>上面的式子告诉我们通过梯度下降法求解<code>RankNet</code>时，就算<code>算分</code>函数没有好的梯度或者不可求导时任可以进行权重的更新（直接对$o$进行梯度下降，但是其梯度方向需要自己指定，并且要求权重$w$与最终的算法$o$是相关的）。</p>
<h2 id="合并概率">合并概率</h2><p>理想的情况下，$\bar{o}$的输出得到的模型应该是这样纸的:$$\bar{P}_{i,j}=\frac{e^{\bar{o}_{i,j}}}{1+e^{\bar{o}_{i,j}}}$$</p>
<blockquote>
<p>其中$\bar{o}_{i,j}=\bar{o}_i-\bar{o}_j$</p>
</blockquote>
<p>上面的模型需要$\bar{P}_{i,j}$保持一致性，也就是如果$D_i$的相关性要高于$D_j$,$D_j$的相关性同时也是要高于$D_k$，则$D_i$的相关性也是一定要高于$D_j$，如果没有保持一致性，其实上面的理论就不好使了。。。<br>现给定$\bar{P}_{i,j}$和$\bar{P}_{j,k}$时会有:</p>
<p>$$\begin{equation}\begin{split} \bar{P}_{i,k}&amp;= \frac{e^{\bar{o}_{i,k}}}{1+e^{\bar{o}_{i,k}}}\\<br>&amp;= \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}} \\<br>&amp;= \frac{ \frac{e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})} }{ \frac{1+e^{\bar{o}_{i,j}e^\bar{o}_{j,k}}}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{\frac{(1+e^{\bar{o}_{i,j}}+e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})+(2e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{i,j}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})-(e^{\bar{o}_{j,k}}+e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}})}{(1+e^{\bar{o}_{i,j}})(1+e^{\bar{o}_{j,k}})}} \\<br>&amp;= \frac{\bar{P}_{i,j} \bar{P}_{j,k}}{1+2\bar{P}_{i,j}\bar{P}_{j,k}-\bar{P}_{i,j}-\bar{P}_{j,k}}<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>其中第一步是基于这个来的:$$\begin{equation}\begin{split}e^{\bar{o}_{i,k}}&amp;=e^{\bar{o}_i-\bar{o}_k} \\<br>&amp;= e^{\bar{o}_i-\bar{o}_j+\bar{o}_j-\bar{o}_k}\\<br>&amp;= e^{\bar{o}_{i,j}+\bar{o}_{j,k}}  \\<br>&amp;= e^{\bar{o}_{i,j}}e^{\bar{o}_{j,k}}<br>\end{split}\end{equation}$$</p>
</blockquote>
<p>当$\bar{P}_{i,j}=\bar{P}_{i,k}=P$时，其$\bar{P}_{i,k}$的取值情况为:<br><img src="/img/RankNet-Learning-to-Rank-using-Gradient-Descent/pik.png" width="400px"></p>
<ol>
<li>$P=0$时，有$\bar{P}_{i,k}=P=0$ 表示:$D_i$排$D_j$后面,$D_j$排$D_j$的后面，则$D_i$也一定排$D_j$的后面</li>
<li>$0 &lt; P &lt; 0.5$时，$\bar{P}_{i,k} &lt; P$</li>
<li>$P=0.5$时，有$\bar{P}_{i,k}=P=0.5$ 表示:$D_i$有一般概率排$D_j$前面,$D_j$也有一半的概率排$D_j$的前面，则$D_i$同样也是一半的概率排$D_j$的前面</li>
<li>$0.5 &lt; P &lt; 1$时，$\bar{P}_{i,k} &gt; P$</li>
<li>$P=1$时，有$\bar{P}_{i,k}=P=1$ 表示:$D_i$排$D_j$前面,$D_j$排$D_j$的前面，则$D_i$也一定排$D_j$的前面</li>
</ol>
<blockquote>
<p>从上面的图中可以看到，其实目标概率是都可以保持一致性的.</p>
</blockquote>
<h2 id="神经网络训练">神经网络训练</h2><p><code>RankNet</code>使用的是一个2层的神经网络作为算分模型$f(x:w,b)$,他在排序分数的公式是:<br>$$o = f(x:w,b) = f^{(2)}  \left( \sum_l w_l^{(2)} \cdot f^{(1)}  \left( \sum_k w_{lk}^{(1)}x_k +b^{(1)} \right) +b^{(2)} \right)$$</p>
<p>其中:</p>
<ol>
<li>$x_k$表示输入的$k$个特征元素</li>
<li>$w$表示每一层的权重,$b$表示每一层的偏置，上标$(\cdot)$表示当前所属的神经网络的层数</li>
<li>下标$l$表示第一层的单元数量</li>
<li>$f$使用<code>sigmoid</code>作为激活函数</li>
</ol>
<p>在对于上面的二层神经网络求解时:<br>$$\frac{\partial{C}}{\partial{b^{(2)}}} = \lambda_{i,j}({f’}_i^{(2)}-{f’}_i^{(2)}) = \Delta_i^{(2)} - \Delta_j^{(2)} \\<br>\frac{\partial{C}}{\partial{w^{(2)}}} = \Delta_i^{(2)}f_i^{(1)}  - \Delta_j^{(2)}f_j^{(1)} \\<br>\frac{\partial{C}}{\partial{b^{(1)}}} = \Delta_i^{(2)}f_i^{(1)}w^{(2)}   - \Delta_j^{(2)}f_j^{(1)}w^{(2)} \\<br>\frac{\partial{C}}{\partial{w_k^{(1)}}} = \Delta_i^{(2)} x_{i,k} - \Delta_j^{(2)} x_{j,k}<br>$$<br>这样神经网络就可以使用<code>前向预测</code>和<code>后向反馈</code>来进行训练了,只是其后向反馈阶段是需要通过<code>pair</code>进行计算的。</p>
<h2 id="神经网络加速">神经网络加速</h2><p>这里我们输入的样本是<code>pair</code>对$\{(x_i,x_j),\bar{P}_{i,j}\}$,其中$\bar{P}_{i,j}$就是我们的目标概率,根据第一小节(算法原理)中指到的，使用梯度下降法进行求解:<br>$$\begin{equation}\begin{split} \frac{\partial{C}}{\partial{w_k}} &amp;= \frac{\partial{C}}{\partial{o_i}} \frac{\partial{o_i}}{\partial{w_k}} + \frac{\partial{C}}{\partial{o_j}} \frac{\partial{o_j}}{\partial{w_k}}  \\<br>&amp;=  \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right)\\<br>&amp;=  \lambda_{i,j} \left( \frac{\partial{o_i}}{\partial{w_k}} - \frac{\partial{o_j}}{\partial{w_k}}\right) \\<br>\end{split}\end{equation}$$</p>
<blockquote>
<p>记$\lambda_{i,j} =  \frac{\partial{C}}{\partial{o_i}}  = -\frac{\partial{C}}{\partial{o_j}} = \left( -\bar{P}_{i,j}+\frac{e^{o_i-o_j}}{1+e^{o_i-o_j}} \right) $</p>
</blockquote>
<p>上面的是对于每一对<code>pair</code>都会进行一次权重的更新，其实是可以对同一个query下的所有文档<code>pair</code>全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数，其更新的公式为:</p>
<p>$$\Delta w_k = -\eta \sum_{\{i,j\}\in I}  \left(\lambda_{i,j} \frac{\partial{o_i}}{\partial{w_k}} - \lambda_{i,j} \frac{\partial{o_j}}{\partial{w_k}}\right) = -\eta \sum_i \lambda_i \frac{\partial{o_i}}{\partial{w_k}} $$</p>
<blockquote>
<p>$I$表示某个<code>query</code>下所有不同排序的<code>pair</code>出现一次的集合，$\{i,j\}$表示两个文档满足$D_i \triangleright D_j$,也就是$\bar{P}_{i,j}=1$</p>
</blockquote>
<p>这里要着重介绍一下$\lambda_i$:</p>
<p>$\lambda$可以理解为某个给定query（给定排序）下第$i$个文档$D_i$的一个<code>值</code>,为了计算$\lambda_i$，需要找到这个排序下所有排在$D_i$前面的文档$D_j$（此时有$\{i,j\} \in I$），以及所有排在$D_i$后面的文档$D_k$（有$\{k,i\} \in I$）,同时针对$\lambda_{i,j}$的文档进行累加，对于$\lambda_{k,i}$的文档进行累减.</p>
<blockquote>
<p>比如  当前排序下只有一个pair,有$I=\{\{1,2\}\}$，则有$\lambda_1 = \lambda_{1,2} = -\lambda_2$<br>又比如，当前排序下有三个pair，有$I=\{\{1,2\},\{1,3\},\{2,3\}\}$,则有$\lambda_1 = \lambda_{1,2}+\lambda_{1,3}$、$\lambda_2 = \lambda_{2,3}-\lambda_{1,2}$、$\lambda_3 = -\lambda_{1,3}-\lambda_{2,3}$</p>
</blockquote>
<p>对于表示成式子为:<br>$$\lambda_i = \sum_{j:\{i,j\} \in I} \lambda_{i,j} - \sum_{j:\{j,i\} \in I} \lambda_{i,j}$$</p>
<p>因此，我们可以认为$\lambda_i$为在某个给定<code>query</code>的$D_i$需要移动的方向以及移动的强度,另外这种方式可以看做是一种mini-batch的梯度下降算法，不要将全部的<code>pair</code>进行反向传播,其复杂度可以降到$O(n_q)$可以大大加快原始的神经网络训练.这也为<code>LambdaRank</code>奠定了基础（其实很多在<code>LambdaRank</code>的paper提出来的）</p>
<h2 id="总结">总结</h2><p><code>RankNet</code>训练希望文档<code>pair</code>对的前后排序概率与目标概率一致，用交叉熵作为损失函数，在实际排序中使用了神经网络作为算分排序函数，同时可以有<code>min-batch</code>的批量训练方法。据说微软的<code>Bing</code>之前使用着他.</p>
<h2 id="参考">参考</h2><ol>
<li>Burges, Chris, et al. “Learning to rank using gradient descent.” Proceedings of the 22nd international conference on Machine learning. ACM, 2005.</li>
<li>Burges, Christopher JC. “From ranknet to lambdarank to lambdamart: An overview.” Learning 11 (2010): 23-581.</li>
<li>Li, Hang. “Learning to rank for information retrieval and natural language processing.” Synthesis Lectures on Human Language Technologies 7.3 (2014): 1-121.</li>
</ol>
<hr>
<blockquote>
<p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/" target="_blank">[知识共享署名-非商业性使用-相同方式共享 2.5]</a>中国大陆许可协议进行许可，我的博客欢迎复制共享，但在同时，希望保留我的署名权<a href="http://kubicode.me/" target="_blank" rel="external">kubiCode</a>，并且，不得用于商业用途。如您有任何疑问或者授权方面的协商，请给<a href="http://kubicode.me/about/" target="_blank" rel="external">我留言</a>。</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p><code>RankNet</code>是一种基于<code>pairwise</code>的学习排序,假设文档<code>A</code>以<code>P</code>的概率排在文档<code>B</code>的前面，则<code>RankNet</code>就是使用神经网络算法来使得这个概率最大化.last update at:2016-08-28</p>
</blockquote>
<h2 id="算法原理">算法原理</h2><p>假设现在有一对文档$D_i$和$D_j$,给定一个目标概率$\bar{P}_{i,j}$,以表示文档$D_i$将会排在文档$D_j$的前面.</p>
<ol>
<li>如果$\bar{P}_{i,j}=1$,表示$D_i$一定会排在$D_j$前面</li>
<li>如果$\bar{P}_{i,j}=0.5$,表示$D_i$和$D_j$的前后关系将无法确定</li>
<li>如果$\bar{P}_{i,j}=0$,表示$D_i$一定不会排在$D_j$前面</li>
</ol>
<p>现在有一个实值的排序函数$f$,如果$f(x_i) &gt; f(x_j)$，则会有$D_i \triangleright D_j$(表示$D_i$会排在$D_j$前面)</p>
<blockquote>
<p>这里$x$是为文档$D$所表示的特征向量</p>
</blockquote>]]>
    
    </summary>
    
      <category term="Machine Learning" scheme="http://kubicode.me/tags/Machine-Learning/"/>
    
      <category term="Search Engine" scheme="http://kubicode.me/tags/Search-Engine/"/>
    
      <category term="Machine Learning" scheme="http://kubicode.me/categories/Machine-Learning/"/>
    
  </entry>
  
</feed>