
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>深度学习在序列化推荐中的应用(2) | Kubi Code&#39;Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Kubi Code">
    

    
    <meta name="description" content="前言基于上一篇GRU4REC的继续聊聊深度学习在推荐系统中的应用
NARM作者提出了一种混合Encoder的方式：全局(Global)所有的序列信息的Encoder和当前(Local)Session序列的Encoder
所以他的模型是：">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习在序列化推荐中的应用(2)">
<meta property="og:url" content="http://kubicode.me/2018/10/25/Deep Learning/More-Session-Based-Recommendation/index.html">
<meta property="og:site_name" content="Kubi Code'Blog">
<meta property="og:description" content="前言基于上一篇GRU4REC的继续聊聊深度学习在推荐系统中的应用
NARM作者提出了一种混合Encoder的方式：全局(Global)所有的序列信息的Encoder和当前(Local)Session序列的Encoder
所以他的模型是：">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/narm_arch.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/narm_exp.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/repeatnet_arch.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/repeatnet_exp.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/linear_gru.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/rect_gru.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/att_gru.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/userbase_exp.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/sr_rnn_arch.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/sr_adj.png">
<meta property="og:image" content="/img/More-Session-Based-Recommendation/sr_rnn_exp.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习在序列化推荐中的应用(2)">
<meta name="twitter:description" content="前言基于上一篇GRU4REC的继续聊聊深度学习在推荐系统中的应用
NARM作者提出了一种混合Encoder的方式：全局(Global)所有的序列信息的Encoder和当前(Local)Session序列的Encoder
所以他的模型是：">

    
    <link rel="alternative" href="/atom.xml" title="Kubi Code&#39;Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/simpson.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?439f8b724bc712e367d66b5e348997bd";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
      </script>

</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/bart-simpson-09.png" alt="Kubi Code&#39;Blog" title="Kubi Code&#39;Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Kubi Code&#39;Blog">Kubi Code&#39;Blog</a></h1>
				<h2 class="blog-motto">The palest ink is better than the best memory.</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/books">Books</a></li>
					
						<li><a href="/favorites">Favorites</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//bing.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:kubicode.me">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/10/25/Deep Learning/More-Session-Based-Recommendation/" title="深度学习在序列化推荐中的应用(2)" itemprop="url">深度学习在序列化推荐中的应用(2)</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Kubi Code" target="_blank" itemprop="author">Kubi Code</a>
		
  <p class="article-time">
    <time datetime="2018-10-25T09:39:51.000Z" itemprop="datePublished"> 发表于 2018-10-25</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NARM"><span class="toc-number">2.</span> <span class="toc-text">NARM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RepeatNet"><span class="toc-number">3.</span> <span class="toc-text">RepeatNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#User-Based_GRU"><span class="toc-number">4.</span> <span class="toc-text">User-Based GRU</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear_User_Integration"><span class="toc-number">4.1.</span> <span class="toc-text">Linear User Integration</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Rectified_Linear_User_Integration"><span class="toc-number">4.2.</span> <span class="toc-text">Rectified Linear User Integration</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attentional_User_Integration"><span class="toc-number">4.3.</span> <span class="toc-text">Attentional User Integration</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SR-GNN"><span class="toc-number">5.</span> <span class="toc-text">SR-GNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">6.</span> <span class="toc-text">参考</span></a></li></ol>
		
		</div>
		
		<h2 id="前言">前言</h2><p>基于上一篇<code>GRU4REC</code>的继续聊聊深度学习在推荐系统中的应用</p>
<h2 id="NARM">NARM</h2><p>作者提出了一种混合Encoder的方式：全局(<code>Global</code>)所有的序列信息的Encoder和当前(<code>Local</code>)Session序列的Encoder</p>
<p>所以他的模型是：<br><img src="/img/More-Session-Based-Recommendation/narm_arch.png"></p>
<a id="more"></a>
<ol>
<li>在Global序列信息的Encoder中，取了用户之前的所有行为（应该会卡一段阈值）来过了GRU之后取到的Final State作为Encoder的Embedding $c_t^g = h_t $</li>
<li>在Local中Session序列中的Encoder中，向全局信息的Encoder一样，只是最后输出之后取了一层Attention操作，希望突出当前序列中的一些重要行为。$$c_t^l = \sum_{j=1}^t \alpha_{i,j} h_j , \alpha_{i,j} = q(h_t,h_j)$$</li>
<li>然后最终Local和Global给Concat起来作为Encoder的输出$$c_t = [c_t^g;c_t^l]$$</li>
<li>接下来所有候选的Item按Embedding的方式来输入，称为$emb_i$</li>
<li>将Encoder的Embedding和候选集的Embedding进行<code>Bilinear</code>操作：$$S_i=emb_i^T B c_t$$</li>
<li>这一步过后其实就会得到了各个候选项的一个score，进行softmax归一化之后可以作为各个候选项的概率$q_i$</li>
<li>最终的loss是$L(p,q) = -\sum_{i=1}^m p_i log(q_i)$</li>
</ol>
<p><img src="/img/More-Session-Based-Recommendation/narm_exp.png"><br>他的实验对比中，较于其他Baseline算法还是有不少的提升的，不过对于<code>Improved GRU-Rec</code>并没有太大优势</p>
<p>其实也可以理解,最大的贡献应该是在流推荐中同时考虑了<code>Global</code>和<code>Local</code>的结合，整个模型的思路还是很清晰简洁的，<code>Encoder-&gt;Attention-&gt;Bilinear-&gt;Cross Entropy</code>，但是也没有特别大的改进<br>特别是在<code>Local</code>中的<code>Attention</code>那一层，说的不明不白，他的$h_t$变量没有描述清楚，感觉就是一个非常普通的<code>Self-Attention</code>,也许在这一层的Attenion可以和<code>Global</code>中的信息结合起来。</p>
<h2 id="RepeatNet">RepeatNet</h2><p>在购物场景中，因为有一些商品属性的原因，经常会去重复购买一些商品，比如纸巾-_-!!,因此用户其实存在着一些复购需求，类似这种场景的还有<code>音乐</code>、<code>视频</code>。<br>而实际的推荐系统中，我们经常在进行实时推荐时会根据用户历史记录直接去重，就算是缩短去重窗口也很少会刻意去推荐已经推荐过的item。<code>RepeatNet</code>非常机制的结合了类似copynet的idea，在模型的设计上给人一种眼前一亮的赶脚,他在进行推荐(<code>Explore</code>)中同时会有一定概率来推荐出历史行为(<code>Repeat</code>)。<br>该模型是在序列推荐的技术上加入了重推的概率进行<code>Joint-Learning</code>，以一种非常巧妙的方式来进行重推（类似point-generator的copy机制）:<br>整个模型的优化目标是这样的:<br>$$P(i|I_s) = P(r|I_s) P(i|r,I_s) + P(e|I_s) P(i|e,I_s)$$</p>
<ul>
<li>其中$I_s$表示用户的session行为记录</li>
<li>而$P(r|I_s)$表示需要进行重推的概率，这样$P(e|I_s)=1-P(r|I_s)$表示正常推荐的概率，</li>
<li>$P(i|r,I_s)$则表示历史session中各个item被重推的概率，$P(i|e,I_s)$为候选item被推荐的概率了</li>
</ul>
<p>因此整个<code>RepeatNet</code>其实是在做是否重推情况下各个候选item的联合概率最大化.<br>整个模型的结构是这样:<br><img src="/img/More-Session-Based-Recommendation/repeatnet_arch.png"></p>
<ol>
<li>模型的输入一个一串序列:$I_s=i_1,i_2,i_3,…,i_t$</li>
<li>输入的序列$I_s$经过单向GRU之后得到每一步的状态$ST=[h_1,h_2,h_3,…,h_t]$</li>
<li><code>Repeat-Explore Mechanism</code>：这里将$ST$过一个<code>Self-Attention</code>之后进行一个二分类，来计算<code>Repeat</code>和<code>Explore</code>的概率</li>
<li><p><code>Repeat Model</code>:这里需要走到重推的计算逻辑，重推是表示从$I_s$里面推荐出一个概率最高的，这里对于$I_s$序列的item对于每个$ST$都进行一次Attention的前置公式，直接使用<code>Sofatmax</code>的结果，可以理解为$\alpha$因子，具体的公式是这样的:<br>$$e^r_{\tau}=v^T_r tanh (W_rh_t+U_rh_{\tau}) \\<br>P(i|r,I_s)=\left\{<br>\begin{aligned}<br>\frac{exp(e^r_i)}{\sum_{\tau=1}^t exp(e^r_\tau)}  &amp; \quad i \in i_s \\<br>0 &amp; \quad i \in I-I_s\\<br>\end{aligned}<br>\right.$$</p>
</li>
<li><p><code>Explore Mode</code>:在正常推荐时，会过一个<code>Self Attention</code>，然后时$h_t$进行concat,之后就是过一个正常的MLP层以及求softmax了</p>
</li>
</ol>
<p>因此该模型在这里的损失函数有两个:</p>
<ol>
<li>是否执行<code>Repeat</code>还是<code>Explore</code>的损失函数:<br> $$L_{model} = -(\mathbb{I}(i \in I_s)\text{log}P(r|I_s) + (1-\mathbb{I}(i \in I_s))\text{log}P(e|I_s))$$</li>
<li>候选item概率分布的损失函数:<br> $$L_{rec} = \text{log}P(i_\tau|I_s)$$</li>
</ol>
<p>最终该作者用了求和的方式来进行最终的优化:<br>$$L(\theta) = L_{model}+L_{rec}  $$</p>
<p>在实验结果里面显示，该目前也取得了不少的提升:<br><img src="/img/More-Session-Based-Recommendation/repeatnet_exp.png"></p>
<p>其实我到是可以理解为$RepeatNet$是一个更加贴合推荐实际的模型，结合了重推，但是其实在实际使用中可能还存在不少问题：</p>
<ol>
<li>比如在最近topK个已经展现过的再重推是否合适，是否应该有一个阈值来控制。</li>
<li>另外还有一个其实短<code>Session</code>内重复的量不会很高，那意味这个这个Train的Session会比较长，而在实际的场景中很少会用长session来做Inference，因为<code>RNN-based</code>的模型的预测速度和session长度成正比，并且<code>Session</code>太长也意味了效果会变差。</li>
</ol>
<h2 id="User-Based_GRU">User-Based GRU</h2><p>这个paper是在序列推荐模型的GRU模块里面加入用户信息，作者认为在序列建模时加入了用户特征之后能够更好的刻画整个行为序列，具体做法主要是针对<code>GRU</code>模块中加入<code>User</code>向量$v$进行倒腾，主要有三种集成的方式:</p>
<ol>
<li>Linear User Integration:线性方式的集成</li>
<li>Rectified Linear User Integration:比线性更加柔和的一种方式</li>
<li>Attentional User Integration: 以Attention的方式集成</li>
</ol>
<h3 id="Linear_User_Integration">Linear User Integration</h3><p>针对给定<code>GRU</code>的Cell和用户向量下，这种集成是将用户向量加入到更<code>gate</code>的计算以及更新的state中，看下Cell图（其实这个图画的并不是很清晰-_-）:<br><img src="/img/More-Session-Based-Recommendation/linear_gru.png" width="250px"><br>不过再配合一下公式就很清晰了:<br>$$\begin{bmatrix}<br>u \\<br>r<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>\sigma \\<br>\sigma<br>\end{bmatrix}<br>T<br>\begin{bmatrix}<br>h^{t-1} \\<br>E_i^t \\<br>E_v^t<br>\end{bmatrix}$$<br>这是<code>GRU</code>两个门的输出，在计算门的时候加入了用户向量$E_v^t$,其余操作就是和正常的<code>GRU</code>一样了</p>
<h3 id="Rectified_Linear_User_Integration">Rectified Linear User Integration</h3><p>但是针对线性的集成，可以发现用户向量在每一个step都是一样，并且是重复的，这样会增加整个训练的计算量，因此作者又想了一种更加柔和的方式来接入:<br><img src="/img/More-Session-Based-Recommendation/rect_gru.png" width="250px"></p>
<blockquote>
<p>其实改图还是看不大清楚要表达的-_-</p>
</blockquote>
<p>主要思想是 在每一个step时：</p>
<ol>
<li>将输入向量和用户向量concat之后之后过两个MLP得到两个对比向量$\kappa_1 , \kappa_2$</li>
<li>当用户向量$E_v^t$的每个元素都小于$\kappa_1$时，将当前的step的用户向量直接置0（丢弃的意思）</li>
<li>当用户向量有部分小于$\kappa_2$时，对于用户向量的每个元素都乘以一个因子$\omega$</li>
<li>否则，正常使用当前step的用户向量</li>
</ol>
<p>用公式来代替就是:<br>$$ E_v^t=\left\{<br>\begin{aligned}<br>0  &amp; \quad \quad  E_v^t&lt; \kappa_1 \\<br>\omega \cdot E_v^t &amp;\quad \quad  \kappa_1 &lt; E_v^t&lt; \kappa_2 \\<br>E_v^t &amp;\quad \quad  \text{else} \\<br>\end{aligned}<br>\right.$$</p>
<p>然后其余步骤就是和线性的集成一样了</p>
<h3 id="Attentional_User_Integration">Attentional User Integration</h3><p>先对普通线性集成的问题，作者又提了一个新的方式，他认为同一个用户向量在不同step下应该权重是不一样的，比如在t=0的时候，用户向量影响的作用应该是比较低（因为没有多少用户行为）</p>
<blockquote>
<p>哈哈，其实我觉得要看用户向量怎么选了，如果该用户向量可以较为精准的表示用户向量了，这个时候t=0的时候用户的向量应该也是还蛮重要的。</p>
</blockquote>
<p>因此不同的step下用户向量的权重应该是不同的，也就是类似<code>Attention</code>的方式了,但是其实感觉他paper里面和attention的思想还是有一些差异的，先看图<br><img src="/img/More-Session-Based-Recommendation/att_gru.png" width="250px"></p>
<p>该集成方式会根据三个输入来计算一个门(<code>gate</code>:$\xi$)<br>$$ \xi = \sigma(T h^{t-1} + TE_i^t + TE_v^t)$$<br>这个$\xi$用来做每个step的输入向量和用户向量的一个平衡，因此<code>GRU</code>的门计算就是这样了:<br>$$\begin{bmatrix}<br>u \\<br>r<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>\sigma \\<br>\sigma<br>\end{bmatrix}<br>T<br>\begin{bmatrix}<br>h^{t-1} \\<br>(1-\xi) E_i^t \\<br>\xi E_v^t<br>\end{bmatrix}$$<br>那再接下来的就是和线性集成一样了</p>
<p>所以后面两种集成的方式主要是针对线性集成每一步用同一个用户向量再改进的，他的实验效果是这样的:<br><img src="/img/More-Session-Based-Recommendation/userbase_exp.png"></p>
<p>可以看到针对改进过的gru的效果还是有不少提升的.<br>其实在实际工业界里面有不少很成熟的算法框架中也会尝试将一些用户的全局信息/兴趣点通过<code>gate</code>机制来融入到gru中进行训练，能得到一些微弱提升，但是性价比而言相对比较低，当然有富余人员配置时还是值得尝试的。</p>
<h2 id="SR-GNN">SR-GNN</h2><p>作者觉得用户的行为序列可以用图来表示，因此在传统的序列建模时改为使用$GNN^5$对来图进行建模，也就有了这个<code>SR-GNN</code>:<br>直接看架构图吧：<br><img src="/img/More-Session-Based-Recommendation/sr_rnn_arch.png"></p>
<blockquote>
<p>虽然图的头部画的session之间的item是有关联的，其实在model里面各个session其实是独立的-_-!!</p>
</blockquote>
<p>最重要的是他的GNN那块，以$[v_1,v_2,v_3,v_2,v_4]$这个用户的session为例，可以将session用图表示为:<br><img src="/img/More-Session-Based-Recommendation/sr_adj.png" width="250px"></p>
<ul>
<li>他使用邻接矩阵来表示</li>
<li>边之间的权重分为出度权重和入度权重</li>
<li>最终一个图可以用 一个带出度权重的矩阵和 带入度权重的矩阵来表示，他们的shape都是$[N,N]$</li>
</ul>
<p>对于整个序列使用GNN来进行表达：<br>$$a_{s,i}^t = A_{s,i}^T [v_1^{t-1},…,v_n^{t-1}] + b \\<br>z_{s,i}^t = \sigma(W_z)a_{s,i}^t + U_z v_i^{t-1} \\<br>r_{s,i}^t = \sigma(W_r)a_{s,i}^t + U_r v_i^{t-1} \\<br>\tilde{v_i^t} = \text{tanh}(Wa_{s,i}^t + U(r_{s,i}^t \odot v_i^{t-1} )) \\<br>v_i^t = (1-z_{s,i}^t) \odot v_i^{t-1} + z_{s,i}^t \odot \tilde{v_i^t}$$</p>
<p>其中</p>
<ol>
<li>$z$和$r$分布表示重置门和更新门,$\odot$ 表示<code>element-wise</code>的相乘</li>
<li>$A$矩阵其实就是session图的邻接矩阵，$a$向量用户表示相当step下图相关的向量，用于接下来模块的初始化 </li>
<li>眼熟的一眼就看出来了，其实就是<code>GRU</code>单元的公式，最大的差别就是初始化使用的是$a$，状态的维持使用的是$v$向量</li>
</ol>
<blockquote>
<p>额 其实就是<code>GATED GRAPH SEQUENCE NEURAL NETWORKS</code>这篇中的式子</p>
</blockquote>
<p>经过GNN之后可以得到每个节点的embdding，接下来将整个session用<code>local</code>和<code>global</code>两个节点别表示，其中：</p>
<ol>
<li><code>local</code>级别的embedding可以直接使用最后一个item的向量来表示，也就是$s_l = v_n$</li>
<li><code>global</code>级别的embedding使用$soft-attention$来表示$$a_i = q^T \sigma(W_1v_n + W_2v_i+c) \\ s_g = \sum_i^n \alpha_iv_i$$</li>
</ol>
<p>最终的embedding是两个级别向量的合并转换:$$s_h = W_3[s_l;s_g]$$</p>
<blockquote>
<p>其实可以看到最终的embedding里面其实是极大的加强的最后一个item的权重，之前做过相关实验，确实是最后一个item的embedding的最重要的</p>
</blockquote>
<p>其训练时loss采用了经典的交叉熵。<br>实验效果再过一下：<br><img src="/img/More-Session-Based-Recommendation/sr_rnn_exp.png" width="600px"><br>对比本文里面提到了<code>NARM</code>算法效果有提升，但是效果不是提升的很明显。</p>
<p>其实整个<code>SR-GNN</code>模型就是将序列模型是将GRU改成了GNN建模，感觉实用性并不是很高，因为单用户的常规单session中并没有太多可以形成图。-_-</p>
<h2 id="参考">参考</h2><ol>
<li><a href="https://arxiv.org/pdf/1711.04725.pdf" target="_blank" rel="external">Neural Attentive Session-based Recommendation - arXiv</a></li>
<li><a href="https://arxiv.org/pdf/1812.02646.pdf" target="_blank" rel="external">RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</a></li>
<li><a href="https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/p152-donkers.pdf" target="_blank" rel="external">Sequential User-based Recurrent Neural Network Recommendations</a></li>
<li><a href="https://arxiv.org/pdf/1811.00855.pdf" target="_blank" rel="external">Session-based Recommendation with Graph Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1511.05493.pdf" target="_blank" rel="external">GATED GRAPH SEQUENCE NEURAL NETWORKS</a></li>
</ol>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/Machine-Learning/">Machine Learning</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://kubicode.me/2018/10/25/Deep Learning/More-Session-Based-Recommendation/" data-title="深度学习在序列化推荐中的应用(2) | Kubi Code&#39;Blog" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2019/01/16/Deep Learning/Collaborative-Filtering-Meet-to-Deep-Learning/" title="当协同过滤(Collaborative Filtering)遇上深度学习">
  <strong>上一篇：</strong><br/>
  <span>
  当协同过滤(Collaborative Filtering)遇上深度学习</span>
</a>
</div>


<div class="next">
<a href="/2018/09/19/Deep Learning/GRU4REC-Session-Based-Recommendation/"  title="深度学习在序列化推荐中的应用(1)-GRU4REC以及扩展">
 <strong>下一篇：</strong><br/> 
 <span>深度学习在序列化推荐中的应用(1)-GRU4REC以及扩展
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NARM"><span class="toc-number">2.</span> <span class="toc-text">NARM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RepeatNet"><span class="toc-number">3.</span> <span class="toc-text">RepeatNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#User-Based_GRU"><span class="toc-number">4.</span> <span class="toc-text">User-Based GRU</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear_User_Integration"><span class="toc-number">4.1.</span> <span class="toc-text">Linear User Integration</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Rectified_Linear_User_Integration"><span class="toc-number">4.2.</span> <span class="toc-text">Rectified Linear User Integration</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attentional_User_Integration"><span class="toc-number">4.3.</span> <span class="toc-text">Attentional User Integration</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SR-GNN"><span class="toc-number">5.</span> <span class="toc-text">SR-GNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">6.</span> <span class="toc-text">参考</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/Akka/" title="Akka">Akka<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Algorithm/" title="Algorithm">Algorithm<sup>34</sup></a></li>
		  
		
		  
			<li><a href="/categories/Data-Struct/" title="Data Struct">Data Struct<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Deep-Learning/" title="Deep Learning">Deep Learning<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/Dotnet/" title="Dotnet">Dotnet<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/Effective-Java/" title="Effective Java">Effective Java<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/Food/" title="Food">Food<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hadoop/" title="Hadoop">Hadoop<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hexo/" title="Hexo">Hexo<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Java-Base/" title="Java Base">Java Base<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/Java-Source/" title="Java Source">Java Source<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/Javascript/" title="Javascript">Javascript<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/LeetCode/" title="LeetCode">LeetCode<sup>25</sup></a></li>
		  
		
		  
			<li><a href="/categories/Linux/" title="Linux">Linux<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Mac/" title="Mac">Mac<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Machine-Learning/" title="Machine Learning">Machine Learning<sup>27</sup></a></li>
		  
		
		  
			<li><a href="/categories/OSGi/" title="OSGi">OSGi<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/PHP/" title="PHP">PHP<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Python/" title="Python">Python<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Scala/" title="Scala">Scala<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Search-Engine/" title="Search Engine">Search Engine<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/Spark/" title="Spark">Spark<sup>5</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Machine-Learning/" title="Machine Learning">Machine Learning<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/Algorithm/" title="Algorithm">Algorithm<sup>37</sup></a></li>
			
		
			
				<li><a href="/tags/LeetCode/" title="LeetCode">LeetCode<sup>25</sup></a></li>
			
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>21</sup></a></li>
			
		
			
				<li><a href="/tags/Search-Engine/" title="Search Engine">Search Engine<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/Deep-Learning/" title="Deep Learning">Deep Learning<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/CSharp/" title="CSharp">CSharp<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/Food/" title="Food">Food<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/Spark/" title="Spark">Spark<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Asp-Net/" title="Asp.Net">Asp.Net<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Scala/" title="Scala">Scala<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Vim/" title="Vim">Vim<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Data-Struct/" title="Data Struct">Data Struct<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/OSGi/" title="OSGi">OSGi<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/pager/" title="pager">pager<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Mac/" title="Mac">Mac<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://quanru.github.io/" target="_blank" title="quanru&#39;s Blog">quanru&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://qcl6355.github.io/" target="_blank" title="Sheng Li&#39;s Blog">Sheng Li&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://youngyoungkang.github.io/" target="_blank" title="Young Young Kang&#39;s Blog">Young Young Kang&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://nlpnoob.com/" target="_blank" title="DataKingdom&#39;s Blog">DataKingdom&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://jinfagang.gitlab.io" target="_blank" title="jinfagang&#39;s Blog">jinfagang&#39;s Blog</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.yifanguo.top/" target="_blank" title="yifanguo&#39;s Blog">yifanguo&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2019 
		
		<a href="/about" target="_blank" title="Kubi Code">Kubi Code</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'kubiCode';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX","output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['\$','\$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    displayAlign: "center"
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="/js/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>

